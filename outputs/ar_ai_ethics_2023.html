<!DOCTYPE html>
<html lang="arabic" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>أخلاقيات الذكاء الاصطناعي</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        
        /* RTL Support */
        [dir="rtl"] {
            text-align: right;
        }
        
        [dir="rtl"] body {
            font-family: 'Traditional Arabic', 'Simplified Arabic', Arial, sans-serif;
        }
        
        /* Header */
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        .metadata {
            font-size: 0.9rem;
            opacity: 0.9;
        }
        
        /* Container */
        .container {
            display: flex;
            max-width: 1400px;
            margin: 2rem auto;
            gap: 2rem;
            padding: 0 1rem;
        }
        
        /* Navigation */
        nav {
            flex: 0 0 280px;
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            position: sticky;
            top: 2rem;
            height: fit-content;
            max-height: calc(100vh - 4rem);
            overflow-y: auto;
        }
        
        nav h2 {
            font-size: 1.2rem;
            margin-bottom: 1rem;
            color: #667eea;
        }
        
        nav ul {
            list-style: none;
        }
        
        nav li {
            margin-bottom: 0.5rem;
        }
        
        nav a {
            color: #555;
            text-decoration: none;
            display: block;
            padding: 0.3rem 0.5rem;
            border-radius: 4px;
            transition: all 0.2s;
        }
        
        nav a:hover {
            background: #f0f0f0;
            color: #667eea;
        }
        
        nav .level-2 {
            padding-left: 1rem;
            font-size: 0.9rem;
        }
        
        nav .level-3 {
            padding-left: 2rem;
            font-size: 0.85rem;
        }
        
        /* Main Content */
        .content {
            flex: 1;
            background: white;
            padding: 3rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        /* Sections */
        section {
            margin-bottom: 3rem;
            padding-bottom: 2rem;
            border-bottom: 1px solid #e0e0e0;
        }
        
        section:last-child {
            border-bottom: none;
        }
        
        section h2 {
            color: #667eea;
            font-size: 2rem;
            margin-bottom: 0.5rem;
        }
        
        section h3 {
            color: #764ba2;
            font-size: 1.5rem;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
        }
        
        section h4 {
            color: #555;
            font-size: 1.2rem;
            margin-top: 1rem;
            margin-bottom: 0.5rem;
        }
        
        .page-range {
            font-size: 0.9rem;
            color: #888;
            font-style: italic;
            margin-bottom: 1rem;
        }
        
        /* Paragraphs */
        p {
            margin-bottom: 1rem;
            text-align: justify;
        }
        
        /* Footer */
        footer {
            text-align: center;
            padding: 2rem;
            color: #888;
            font-size: 0.9rem;
        }
        
        /* Print Styles */
        @media print {
            body {
                background: white;
            }
            
            nav {
                display: none;
            }
            
            .container {
                margin: 0;
            }
            
            section {
                page-break-inside: avoid;
            }
        }
        
        /* Mobile Responsive */
        @media (max-width: 768px) {
            .container {
                flex-direction: column;
            }
            
            nav {
                position: static;
                max-height: none;
            }
            
            .content {
                padding: 1.5rem;
            }
            
            header h1 {
                font-size: 1.8rem;
            }
        }
    </style>
</head>
<body>
    <header>
    <h1>أخلاقيات الذكاء الاصطناعي</h1>
    <div class="metadata">By مارك كوكلبيرج • Sept 10, 2024</div>
</header>
    <div class="container">
        <nav>
    <h2>Contents</h2>
    <ul>
        <li class="level-1"><a href="#section-1">شكر وتقدير</a></li>
<li class="level-1"><a href="#section-2">١ - أيتها المرآة على الحائط</a></li>
<li class="level-1"><a href="#section-3">الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي</a></li>
<li class="level-1"><a href="#section-4">كل ما له علاقة بالبشر</a></li>
<li class="level-1"><a href="#section-5">٤ - أهي حقًّا مجرد آلات؟</a></li>
<li class="level-1"><a href="#section-6">التكنولوجيا</a></li>
<li class="level-1"><a href="#section-7">٦ - لا تنسَ (علم) البيانات</a></li>
<li class="level-1"><a href="#section-8">الخصوصية وغيرها من القضايا</a></li>
<li class="level-1"><a href="#section-9">لامسئوليةُ الآلات والقرارات غير المبررة</a></li>
<li class="level-1"><a href="#section-10">التحيز ومعنى الحياة</a></li>
<li class="level-1"><a href="#section-11">السياسات المقترحة</a></li>
<li class="level-1"><a href="#section-12">١١ - التحديات التي تُواجه صانعي السياسات</a></li>
<li class="level-1"><a href="#section-13">١٢ - تحدِّي تغيّر المناخ: حول الأولويات وحقبة التأثير البشري</a></li>
<li class="level-1"><a href="#section-14">مسرد المصطلحات</a></li>
<li class="level-1"><a href="#section-15">ملاحظات</a></li>
<li class="level-1"><a href="#section-16">قراءات إضافية</a></li>
<li class="level-1"><a href="#section-17">المراجع</a></li>
    </ul>
</nav>
        <main class="content">
            <section id="section-1">
    <h2>شكر وتقدير</h2>
    <div class="page-range">Pages 11-12</div>
    <p>ﺷﻜﺮ وﺗﻘﺪﻳﺮ
ﻻﻳﻌﺘﻤﺪﻫﺬا اﻟﻜﺘﺎبﻋﲆﻋﻤﲇ اﻟﺨﺎصﰲﻣﻮﺿﻮع أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻓﺤﺴﺐ،
ﺑﻞﻳﻌﻜﺲ املﻌﺮﻓﺔ واﻟﺨﱪةﰲﻫﺬا املﺠﺎلﺑﺄﻛﻤﻠِﻪ. وﺳﻴﻜﻮنﻣﻦ املُﺴﺘﺤﻴﻞ إدراجﺟﻤﻴﻊ
اﻷﺷﺨﺎص اﻟﺬﻳﻦﻧﺎﻗﺸﺘُﻬﻢ وﺗﻌﻠﱠﻤﺖُﻣﻨﻬﻢﻋﲆﻣﺪار اﻟﺴﻨﻮات املﺎﺿﻴﺔ،ﻟﻜﻦ املﺠﺘﻤﻌﺎت
ذات اﻟﺼﻠﺔ واﻟﴪﻳﻌﺔ اﻟﻨﻤﻮ اﻟﺘﻲ أﻋﺮﻓﻬﺎﺗﻀﻢﺑﺎﺣﺜنيﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺜﻞ
ﺟﻮاﻧﺎﺑﺮﻳﺴﻮن وﻟﻮكﺳﺘﻴﻠﺰ، وزﻣﻼﺋﻲ اﻟﻔﻼﺳﻔﺔﰲﻣﺠﺎل اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻣﺜﻞﺷﺎﻧﻮنﻓﺎﻟﻮر
وﻟﻮﺗﺸﻴﺎﻧﻮﻓﻠﻮرﻳﺪي، وأﻛﺎدﻳﻤﻴنيﻳﺴﻌَﻮن إﱃ اﻻﺑﺘﻜﺎر املﺴﺌﻮلﰲﻫﻮﻟﻨﺪا واملﻤﻠﻜﺔ املﺘﺤﺪة،
ﻣﺜﻞﺑريﻧﺪﺳﺘﺎلﰲﺟﺎﻣﻌﺔ ديﻣﻮﻧﺘﻔﻮرت، وﺑﻌﺾ اﻷﺷﺨﺎص اﻟﺬﻳﻦ اﻟْﺘَﻘﻴﺖُﺑﻬﻢﰲﻓﻴﻴﻨﺎ،
ﻣﺜﻞ روﺑﺮتﺗﺮاﺑﻞ، وﺳﺎرةﺳﺒﻴﻜﺮﻣﺎن، ووﻟﻔﺠﺎﻧﺞ )ﺑﻴﻞ(ﺑﺮاﻳﺲ، وزﻣﻼﺋﻲ اﻷﻋﻀﺎءﰲ
اﻟﻬﻴﺌﺎت اﻻﺳﺘﺸﺎرﻳﺔ ذات اﻟﺘﻮﺟﱡﻬﺎت اﻟﺴﻴﺎﺳﻴﺔ،ﻓﺮﻳﻖ اﻟﺨﱪاء اﻟﺮﻓﻴﻊ املﺴﺘﻮى املَﻌﻨﻲﱢﺑﺎﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ )املﻔﻮﺿﻴﺔ اﻷوروﺑﻴﺔ( واملﺠﻠﺲ اﻟﻨﻤﺴﺎويﻟﻠﺮوﺑﻮﺗﺎت واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻣﻦ
ﺿِﻤﻨﻬﻢﻋﲆﺳﺒﻴﻞ املﺜﺎلﻻ اﻟﺤﴫ راﺟﺎﺷﺎﺗﻴﻼ، وﻓريﺟﻴﻨﻴﺎ دﻳﺞﻧﻮم، وﺟريوﻳﻦﻓﺎن دﻳﻦ
ﻫﻮﻓﻦ، وﺳﺎﺑنيﻛﻮﺳﻴﺠﻲ، وﻣﺎﺗﻴﺎسﺷﻮﺗﺰ. أودﱡ أﻳﻀًﺎ أن أﺷﻜﺮﺑﺤﺮارة زاﻛﺎريﺳﺘﻮرﻣﺰ
ﻟﻠﻤﺴﺎﻋﺪةﰲ اﻟﺘﺪﻗﻴﻖ اﻟﻠﻐﻮيﻟﻠﻜﺘﺎب وﺗﻨﺴﻴﻘﻪ، وﻟﻴﻨﺎﺳﺘﺎرﻛﻞ وإﻳﺰاﺑﻴﻞ واﻟﱰﻋﲆ دﻋﻤﻬﻤﺎ
ﰲ اﻟﺒﺤﺚﻋﻦ اﻷدﺑﻴﺎت.</p>
</section>
<section id="section-2">
    <h2>١ - أيتها المرآة على الحائط</h2>
    <div class="page-range">Pages 13-18</div>
    <p>اﻟﻔﺼﻞ اﻷول
أﻳﺘﻬﺎ اﳌﺮآةﻋﲆ اﳊﺎﺋﻂ
اﻟﻀﺠﺔ واملﺨﺎوف اﻟﺘﻲﻳُﺜريﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ: أﻳﺘﻬﺎ املﺮآةﻋﲆ اﻟﺤﺎﺋﻂ:
ﻣَﻦ اﻷذﻛﻰﰲ اﻟﻌﺎﻟَﻢ؟
ﻋﻨﺪﻣﺎ أُﻋﻠﻨﺖ اﻟﻨﺘﺎﺋﺞ، اﻏﺮورﻗﺖﻋﻴﻨﺎ اﻟﻼﻋﺐﱄﺳﻴﺪولﺑﺎﻟﺪﻣﻮع.ﺣﻘﱠﻖ »أﻟﻔﺎﺟﻮ«، وﻫﻮ
١ﰲ-ﺑﺮﻧﺎﻣﺞ ذﻛﺎء اﺻﻄﻨﺎﻋﻲﻃﻮﱠرَﺗْﻪﴍﻛﺔ »دﻳﺐﻣﺎﻳﻨﺪ« اﻟﺘﺎﺑﻌﺔ إﱃﺟﻮﺟﻞ،ﻓﻮزًا ٤
ﻟﻌﺒﺔ »ﺟﻮ« )ﻟﻌﺒﺔ »ﺟﻮ«ﻫﻲﻟﻌﺒﺔ اﺳﱰاﺗﻴﺠﻴﺔﻗﺪﻳﻤﺔﻇﻬﺮتﰲ اﻟﺼني وﻳُﺸﺎركﻓﻴﻬﺎ
ﻻﻋﺒﺎن اﺛﻨﺎن(.ﺗﺎرﻳﺦ اﻟﺤﺪث:ﻣﺎرس ٦١٠٢.ﻗﺒﻞﻋﻘﺪَﻳﻦﻣﻦ اﻟﺰﻣﺎن،ﺧﴪﻻﻋﺐ اﻟﺸﻄﺮﻧﺞ
ﺟﺎريﻛﺎﺳﺒﺎروف اﻟﺤﺎﺻﻞﻋﲆﻟﻘﺐ »ﺟﺮاﻧﺪﻣﺎﺳﱰ« )اﻷﺳﺘﺎذ اﻟﻜﺒري( أﻣﺎم اﻵﻟﺔ »دﻳﺐ
ﺑﻠﻮ«، واﻵنﻓﺎزﺑﺮﻧﺎﻣﺞﻛﻤﺒﻴﻮﺗﺮﻋﲆﺑﻄﻞ اﻟﻌﺎﻟﻢﻟﺜﻤﺎﻧﻲﻋﴩةﻣﺮة؛ﱄﺳﻴﺪول،ﰲﻟﻌﺒﺔ
ﻣُﻌﻘﱠﺪةﻛﺎنﻳُﻨﻈَﺮ إﻟﻴﻬﺎﻋﲆ أﻧﻬﺎﻟﻌﺒﺔﻻﻳﻤﻜﻦ أنﻳﻠﻌﺒﻬﺎ إﻻ اﻟﺒﴩ،ﺑﺎﺳﺘﺨﺪامﺣﺪﺳِﻬﻢ
وﺗﻔﻜريﻫﻢ اﻻﺳﱰاﺗﻴﺠﻲ. اﻷدﻫﻰﻣﻦ ذﻟﻚ أن اﻟﻜﻤﺒﻴﻮﺗﺮﻟﻢﻳﻔُﺰﺑﺎﺗﺒﺎع اﻟﻘﻮاﻋﺪ املُﻌﻄﺎةﻟﻪ
ﻣﻦﻗِﺒَﻞ املُﱪﻣﺠني، وإﻧﻤﺎﻋﻦﻃﺮﻳﻖﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﻘﺎﺋﻢﻋﲆ املﻼﻳنيﻣﻦﻣﺒﺎرﻳﺎت »ﺟﻮ«
اﻟﺴﺎﺑﻘﺔ وﻋﲆ اﻟﻠﻌﺐﺿﺪﱠﻧﻔﺴﻪ.ﰲﻣﺜﻞﻫﺬه اﻟﺤﺎﻟﺔ،ﻳُﻌِﺪ املﱪﻣﺠﻮنﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت
وﻳُﻨﺸِﺌﻮن اﻟﺨﻮارزﻣﻴﺎت، وﻟﻜﻦﻻﻳُﻤﻜﻨﻬﻢﻣﻌﺮﻓﺔ اﻟﺘﺤﺮﱡﻛﺎت اﻟﺘﻲﺳﻴﺄﺗﻲﺑﻬﺎ اﻟﱪﻧﺎﻣﺞ.
ﻓﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺘﻌﻠﱠﻢﻣﻦﺗﻠﻘﺎءﻧﻔﺴﻪ. وﺑﻌﺪﻋﺪدٍﻣﻦ اﻟﺘﺤﺮﱡﻛﺎتﻏري املﻌﺘﺎدة واملﻔﺎﺟﺌﺔ،
(.Borowiec 2016)اﺿﻄُﺮﱠﺑﻄﻞ اﻟﻌﺎﻟﻢﱄ إﱃ اﻻﻧﺴﺤﺎب
إﻧﻪ إﻧﺠﺎز راﺋﻊﺣﻘﱠﻘَﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻟﻜﻨﻪ،ﻣﻊ ذﻟﻚ،ﻳُﺜري املﺨﺎوفﰲﻗﻠﻮﺑﻨﺎ. إﻧﻨﺎ
ﻣُﻌﺠﺒﻮنﺑﺠﻤﺎل اﻟﺤﺮﻛﺎت، وﻟﻜﻨﻨﺎ أﻳﻀًﺎﺣﺰاﻧﻰ، ورﺑﻤﺎﺣﺘﻰﺧﺎﺋﻔﻮن.ﻧﺄﻣُﻞﰲ أنﺗﺴﺎﻋﺪﻧﺎ
أﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻷﻛﺜﺮ ذﻛﺎءًﰲ إﺣﺪاثﺛﻮرةﰲ اﻟﺮﻋﺎﻳﺔ اﻟﺼﺤﻴﺔ أوﰲ إﻳﺠﺎدﺣﻠﻮلٍ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻟﺠﻤﻴﻊ أﻧﻮاع املﺸﻜﻼت املﺠﺘﻤﻌﻴﺔ، وﻟﻜﻦﻳُﺮاودﻧﺎ اﻟﻘﻠﻖﻣﻦ أنﺗﺴﻴﻄﺮ اﻵﻻتﻋﲆ زﻣﺎم
أﻣﻮرﻧﺎ.ﻓﻬﻞﺗﺴﺘﻄﻴﻊ اﻵﻻت أنﺗﺘﻔﻮﱠقﻋﻠﻴﻨﺎ وﺗﺘﺤﻜﱠﻢﻓﻴﻨﺎ؟ﻫﻞﻻﻳﺰال اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻣﺠﺮد أداة، أم إﻧﻪﺳﻴُﺼﺒﺢ روﻳﺪًا روﻳﺪًاﺳﻴﺪﻧﺎﻻﻣﺤﺎﻟﺔ؟ﺗُﺬﻛﱢﺮﻧﺎﻫﺬه املﺨﺎوفﺑﻜﻠﻤﺎت
»ﻫﺎل«ﻛﻤﺒﻴﻮﺗﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﻓﻴﻠﻢ اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ اﻟﺬي أﺧﺮﺟﻪﺳﺘﺎﻧﲇﻛﻮﺑﺮﻳﻚ:
»١٠٠٢:ﻣﻠﺤﻤﺔ اﻟﻔﻀﺎء« )١٠٠٢:ﺳﺒﻴﺲ أودﻳﴘ(،ﺣنيﻗﺎل ردٍّاﻋﲆ اﻷﻣﺮ اﻟﺒﴩي »اﻓﺘﺢ
أﺑﻮاب املﺮﻛﺒﺔ اﻟﺼﻐرية«: »أﺧﴙ أﻧﻨﻲﻻ أﺳﺘﻄﻴﻊ أن أﻓﻌﻞ ذﻟﻚﻳﺎ دﻳﻒ.« وإذاﻟﻢﻳﻜُﻦﻫﻨﺎك
ﺧﻮف،ﻓﻘﺪﻳﻜﻮنﻫﻨﺎكﺷﻌﻮرﺑﺎﻟﺤﺰن أوﺧﻴﺒﺔ اﻷﻣﻞ.ﻟﻘﺪ أﻃﺎح داروﻳﻦ وﻓﺮوﻳﺪﺑﺈﻳﻤﺎﻧﻨﺎ
ﺑﺘﻤﻴﱡﺰﻧﺎ، وﺑﺈﺣﺴﺎﺳﻨﺎﺑﺎﻟﺘﻔﻮﱡق، وأﻃﺎﺣﺎﺑﺄوﻫﺎم اﻟﺴﻴﻄﺮة اﻟﺘﻲﻳﻌﻴﺶﻓﻴﻬﺎ اﻟﺒﴩ؛ واﻵنﺟﺎء
دور اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴُﻮﺟﱢﻪﴐﺑﺔً أﺧﺮى إﱃﺻﻮرة اﻟﺒﴩﻋﻦ ذواﺗﻬﻢ. إذاﻛﺎﻧﺖ اﻵﻟﺔ
ﺗﺴﺘﻄﻴﻊ اﻟﻘﻴﺎمﺑﺬﻟﻚ،ﻓﻤﺎذاﺗﺒﻘﱠﻰﻟﻨﺎ؟ﻣﺎذاﻧﺤﻦ؟ﻫﻞﻧﺤﻦﻣﺠﺮﱠد آﻻت؟ﻫﻞﻧﺤﻦ آﻻت
ردﻳﺌﺔ،ﺑﻬﺎ اﻟﻜﺜريﻣﻦ اﻟﻌﻴﻮب واﻷﺧﻄﺎء؟ وﻣﺎذاﺳﻴﺤﺪُثﻟﻨﺎ؟ﻫﻞﺳﻨُﺼﺒﺢﻋﺒﻴﺪًاﻟﻶﻻت؟ أو
ﻣﺎﻫﻮ أﺳﻮأ،ﻣﺠﺮدﻣﺼﺪرﻟﻠﻄﺎﻗﺔ،ﻛﻤﺎﰲﻓﻴﻠﻢ »املﺼﻔﻮﻓﺔ« )ذاﻣﺎﺗﺮﻳﻜﺲ(؟
اﻟﺘﺄﺛري اﻟﺤﻘﻴﻘﻲ واﻟﻮاﺳﻊ اﻟﻨﻄﺎقﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻟﻜﻦ إﻧﺠﺎزات اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻻﺗﻘﺘﴫﻋﲆ اﻷﻟﻌﺎب أوﻋﺎﻟَﻢ اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ.ﻓﺎﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻳﺤﺪث اﻵن وﻫﻮﻣُﺘﻮﻏﱢﻞﰲﻛﻞﻣﺎﺣﻮﻟﻨﺎ، وﻏﺎﻟﺒًﺎﻣﺎﻳﻜﻮنﻣُﻀﻤﱠﻨًﺎﻋﲆﻧﺤﻮ
Boddington)ﻏريﻣﺮﺋﻲﰲ أدواﺗﻨﺎ اﻟﻴﻮﻣﻴﺔ وﺑﻜﻮﻧﻪﺟﺰءًاﻣﻦ اﻷﻧﻈﻤﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ املﻌﻘﱠﺪة
(. وﻧﻈﺮًا إﱃ اﻟﻨﻤﻮ اﻟﻬﺎﺋﻞﻟﻘﺪرة اﻟﻜﻤﺒﻴﻮﺗﺮ، وإﺗﺎﺣﺔ اﻟﺒﻴﺎﻧﺎت )اﻟﻀﺨﻤﺔ(ﺑﺴﺒﺐ2017
وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ واﻻﺳﺘﺨﺪام اﻟﻬﺎﺋﻞ ملﻠﻴﺎرات اﻟﻬﻮاﺗﻒ اﻟﺬﻛﻴﺔ، وﺷﺒﻜﺎت املﺤﻤﻮل
اﻟﴪﻳﻌﺔ، أﺣﺮَزَ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﺧﺎﺻﺔﺗﻌﻠﱡﻢ اﻵﻟﺔ،ﺗﻘﺪﱡﻣًﺎﻛﺒريًا. وﻗﺪﻣﻜﱠﻦَﻫﺬا
اﻟﺨﻮارزﻣﻴﺎتﻣﻦﺗﻮﱄﱢ اﻟﻌﺪﻳﺪﻣﻦ أﻧﺸﻄﺘﻨﺎ،ﺑﻤﺎﰲ ذﻟﻚ اﻟﺘﺨﻄﻴﻂ واﻟﻜﻼم واﻟﺘﻌﺮﱡفﻋﲆ
اﻟﻮﺟﻮه واﺗﺨﺎذ اﻟﻘﺮار.ﻳﻤﺘﻠﻚ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﻄﺒﻴﻘﺎتٍﰲ اﻟﻌﺪﻳﺪﻣﻦ املﺠﺎﻻت،ﺑﻤﺎ
ﰲ ذﻟﻚ اﻟﻨﻘﻞ واﻟﺘﺴﻮﻳﻖ واﻟﺮﻋﺎﻳﺔ اﻟﺼﺤﻴﺔ واﻟﺘﻤﻮﻳﻞ واﻟﺘﺄﻣني واﻷﻣﻦ واﻟﺠﻴﺶ واﻟﻌﻠﻮم
واﻟﱰﻓﻴﻪ واﻟﻔﻨﻮن1واﻟﺘﻌﻠﻴﻢ واﻟﻌﻤﻞ املﻜﺘﺒﻲ واملﺴﺎﻋﺪة اﻟﺸﺨﺼﻴﺔ )ﻣﺜﻞﺟﻮﺟﻞ دوﺑﻠﻜﺲ
)ﻣﺜﻞ اﺳﱰﺟﺎع املﻮﺳﻴﻘﻰ وﺗﺄﻟﻴﻔﻬﺎ( واﻟﺰراﻋﺔ، وﺑﺎﻟﻄﺒﻊ اﻟﺘﺼﻨﻴﻊ.
ﺗﺘﻢﱡﻋﻤﻠﻴﺎت إﻧﺸﺎء اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﺳﺘﺨﺪاﻣﻪﻟﺪىﴍﻛﺎتﺗﻜﻨﻮﻟﻮﺟﻴﺎ املﻌﻠﻮﻣﺎت
واﻹﻧﱰﻧﺖ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻟﻄﺎملﺎ اﺳﺘﺨﺪﻣﺖﺟﻮﺟﻞ اﻟﺬﻛﺎءَ اﻻﺻﻄﻨﺎﻋﻲﰲﻣُﺤﺮﱢك اﻟﺒﺤﺚ
اﻟﺨﺎصﺑﻬﺎ.ﻛﻤﺎﻳﺴﺘﺨﺪمﻓﻴﺴﺒﻮك اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ اﻹﻋﻼﻧﺎت املﺴﺘﻬﺪﻓﺔ وإﺷﺎرات
14</p>
<p>أﻳﺘﻬﺎ املﺮآةﻋﲆ اﻟﺤﺎﺋﻂ
اﻟﺼﻮر.ﻛﺬﻟﻚﺗﺴﺘﺨﺪمﻣﺎﻳﻜﺮوﺳﻮﻓﺖ وأﺑِﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﺗﺸﻐﻴﻞﻣﺴﺎﻋﺪَﻳﻬﻤﺎ
اﻟﺮﻗﻤﻴني.ﻟﻜﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻻﻳﻘﺘﴫﻋﲆﻗﻄﺎعﺗﻜﻨﻮﻟﻮﺟﻴﺎ املﻌﻠﻮﻣﺎتﺑﻤﻌﻨﺎه اﻟﻀﻴﱢﻖ.
ﻓﻬﻨﺎك،ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻟﻜﺜريﻣﻦ اﻟﺨُﻄﻂ املﻠﻤﻮﺳﺔ، واﻟﺘﺠﺎربﰲﻣﺠﺎل اﻟﺴﻴﺎرات اﻟﺬاﺗﻴﺔ
اﻟﻘﻴﺎدة.ﻓﻬﺬه اﻟﺘﻘﻨﻴﺔﺗﻌﺘﻤﺪ أﻳﻀًﺎﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻛﻤﺎﺗﺴﺘﺨﺪِم اﻟﻄﺎﺋﺮات دون
ﻃﻴﺎر اﻟﺬﻛﺎءَ اﻻﺻﻄﻨﺎﻋﻲ،ﻣﺜﻠﻬﺎﻣﺜﻞ اﻷﺳﻠﺤﺔ اﻟﺬاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞ اﻟﺘﻲﻳﻤﻜﻦ أنﺗﻘﺘُﻞ دون
ﺗﺪﺧﱡﻞٍﺑﴩي.ﺑﻞ إن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺪ اﺳﺘُﺨﺪِمﺑﺎﻟﻔﻌﻞﰲ اﺗﺨﺎذ اﻟﻘﺮارﰲ املﺤﺎﻛﻢ.
ﻓﻔﻲ اﻟﻮﻻﻳﺎت املﺘﺤﺪة،ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﺳﺘُﺨﺪمﻧﻈﺎم »ﻛﻮﻣﺒﺎس«ﻟﻠﺘﻨﺒﱡﺆﺑﺎﻟﺬﻳﻦﻳُﺤﺘﻤَﻞ أن
ﻳُﻌﺎودوا ارﺗﻜﺎب اﻟﺠﺮاﺋﻢ.ﻳﺪﺧﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎﰲ املﺠﺎﻻت اﻟﺘﻲﻧﻌﺘﱪِﻫﺎﻋﻤﻮﻣًﺎ
أﻛﺜﺮﺷﺨﺼﻴﺔ أوﺣﻤﻴﻤﻴﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦﻟﻶﻻت اﻵنﻗﺮاءة وﺟﻮﻫﻨﺎ،ﻟﻴﺲﻓﻘﻂ
ﻟﻠﺘﻌﺮﱡفﻋﻠﻴﻨﺎ، وﻟﻜﻦ أﻳﻀًﺎﻟﻘﺮاءة اﻧﻔﻌﺎﻻﺗﻨﺎ واﺳﱰدادﺟﻤﻴﻊ املﻌﻠﻮﻣﺎت املﺮﺗﺒﻄﺔﺑﻨﺎ.
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺤﺪث اﻵن وﻫﻮﻣُﺘﻮﻏﱢﻞﰲﻛﻞﱢﻣﺎﺣﻮﻟﻨﺎ، وﻏﺎﻟﺒًﺎﻣﺎﻳﻜﻮنﻣُﻀﻤﱠﻨًﺎﻋﲆﻧﺤﻮٍﻏري
ﻣﺮﺋﻲﰲ أدواﺗﻨﺎ اﻟﻴﻮﻣﻴﺔ.
اﻟﺤﺎﺟﺔ إﱃﻣﻨﺎﻗﺸﺔ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ واملﺠﺘﻤﻌﻴﺔ
ﻳﻤﻜﻦ أنﻳﻜﻮنﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺪﻳﺪﻣﻦ اﻟﻔﻮاﺋﺪ. وﻳﻤﻜﻦ اﺳﺘﺨﺪاﻣﻪﻟﺘﺤﺴني اﻟﺨﺪﻣﺎت
اﻟﻌﺎﻣﺔ واﻟﺘﺠﺎرﻳﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳُﻌﺪ اﻟﺘﻌﺮﱡفﻋﲆ اﻟﺼﻮرﺷﻴﺌًﺎﻣﻔﻴﺪًاﰲ اﻟﻄﺐ؛ إذ رﺑﻤﺎ
ﻣﺜﻞ اﻟﴪﻃﺎن وﻣﺮض أﻟﺰﻫﺎﻳﻤﺮ. وﻟﻜﻦﻣﺜﻞﻫﺬه اﻟﺘﻄﺒﻴﻘﺎت
ﻳﺴﺎﻋﺪﰲﺗﺸﺨﻴﺺ أﻣﺮاضٍ
اﻟﻴﻮﻣﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗُﻈﻬِﺮ أﻳﻀًﺎﻛﻴﻒﺗُﺜري اﻟﺘﻘﻨﻴﺎت اﻟﺠﺪﻳﺪةﺗﺨﻮﱡﻓﺎت أﺧﻼﻗﻴﺔ.
واﺳﻤﺤﻮاﱄ أن أُﻗﺪﱢمﺑﻌﺾ اﻷﻣﺜﻠﺔﻋﲆ أﺳﺌﻠﺔٍﺣﻮل أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
ﻫﻞﻳﺠﺐ أنﺗﺤﺘﻮي اﻟﺴﻴﺎرات اﻟﺬاﺗﻴﺔ اﻟﻘﻴﺎدةﻋﲆﻗﻴﻮدٍ أﺧﻼﻗﻴﺔﻣﻀﻤﱠﻨﺔ؟ وإذاﻛﺎن
اﻷﻣﺮﻛﺬﻟﻚ،ﻓﻤﺎﻧﻮعﻫﺬه اﻟﻘﻴﻮد وﻛﻴﻒﻳﻨﺒﻐﻲﺗﺤﺪﻳﺪﻫﺎ؟ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إذا واﺟﻬﺖ
ﺳﻴﺎرة ذاﺗﻴﺔ اﻟﻘﻴﺎدةﻣﻮﻗﻔًﺎﻳﺘﻌنيﱠﻋﻠﻴﻬﺎﻓﻴﻪ اﻻﺧﺘﻴﺎرﺑني أنﺗﺼﻄﺪمﺑﻄﻔﻞٍ أوﺗﺼﻄﺪم
ﺑﺠﺪارٍﻹﻧﻘﺎذﺣﻴﺎة اﻟﻄﻔﻞ، وﻟﻜﻦﻣﻊ اﺣﺘﻤﺎلﻗﺘﻞ راﻛِﺒﻬﺎ،ﻓﻤﺎذاﺗﺨﺘﺎر؟ وﻫﻞﻳﻨﺒﻐﻲﺗﺮﺧﻴﺺ
اﻷﺳﻠﺤﺔ اﻟﻔﺘﱠﺎﻛﺔ اﻟﺬاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞﻣﻦ اﻷﺳﺎس؟ﻛﻢﻋﺪد اﻟﻘﺮارات اﻟﺘﻲﻧُﺮﻳﺪﺗﻔﻮﻳﻀﻬﺎ إﱃ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻣﺎ اﻟﻘَﺪْر اﻟﺬيﻧُﻔﻮﱢﺿﻪﻣﻨﻬﺎ؟ وﻣَﻦﺳﻴﻜﻮن املﺴﺌﻮلﻋﻨﺪﻣﺎﻳﺤﺪُثﺧﻄﺄ
ﻣﺎ؟ﰲ إﺣﺪى اﻟﻘﻀﺎﻳﺎ، وﺿَﻊَ اﻟﻘﻀﺎةﺛﻘﺘﻬﻢﰲﺧﻮارزﻣﻴﺔ »ﻛﻮﻣﺒﺎس« أﻛﺜﺮﻣﻦﺛِﻘﺘﻬﻢﰲ
15</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻓﻬﻞﺳﻨﻌﺘﻤﺪﻛﺜريًاﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟2.اﻻﺗﻔﺎﻗﺎت اﻟﺘﻲﺗﻮﺻﱠﻞ إﻟﻴﻬﺎ اﻟﺪﻓﺎع واﻻدﻋﺎء
ﺗُﻌﺪﺧﻮارزﻣﻴﺔ »ﻛﻮﻣﺒﺎس« أﻳﻀًﺎﻣُﺜريةﻟﻠﺠﺪل إﱃﺣﺪﱟﻛﺒري؛ﻧﻈﺮًا إﱃ أن اﻷﺑﺤﺎث أﻇﻬﺮت
أن اﻷﺷﺨﺎص اﻟﺬﻳﻦﺗﻨﺒﱠﺄَت اﻟﺨﻮارزﻣﻴﺔﺑﺄﻧﻬﻢﺳﻴُﻌﻴﺪون ارﺗﻜﺎب اﻟﺠﺮاﺋﻢ وﻟﻜﻨﻬﻢﻟﻢﻳﻔﻌﻠﻮا
(. وﺑﺎﻟﺘﺎﱄﻳﻤﻜﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنFry 2018)ﻛﺎﻧﺖ اﻟﻨﺴﺒﺔ اﻟﻜﱪىﻣﻨﻬﻢﻣِﻦ اﻟﺴﻮد
ﻳُﻌﺰﱢز اﻟﺘﺤﻴﱡﺰ واﻟﺘﻤﻴﻴﺰﻏري اﻟﻌﺎدل. وﻳﻤﻜﻦ أنﺗﻨﺸﺄﻣﺸﻜﻼتﻣُﻤﺎﺛﻠﺔﻣﻊ اﻟﺨﻮارزﻣﻴﺎت اﻟﺘﻲ
ﺗُﻮﴆﺑﻘﺮاراتٍﺑﺸﺄنﻃﻠﺒﺎت اﻟﺮﻫﻦ اﻟﻌﻘﺎري وﻃﻠﺒﺎت اﻟﺘﻘﺪﱡمﻟﻠﻮﻇﺎﺋﻒ. أوﻓﻠﻨُﻔﻜﺮﻓﻴﻤﺎ
ﻳُﺴﻤﻰﺑﺎﻟﴩﻃﺔ اﻟﺘﻨﺒﱡﺆﻳﺔ:ﺗُﺴﺘﺨﺪَم اﻟﺨﻮارزﻣﻴﺎتﻟﻠﺘﻨﺒﺆﺑﺎملﻜﺎن املُﺤﺘﻤَﻞﻻرﺗﻜﺎب اﻟﺠﺮاﺋﻢ
)ﻋﲆﺳﺒﻴﻞ املﺜﺎل، أيﻣﻨﻄﻘﺔﰲ املﺪﻳﻨﺔ( وﻣَﻦﻗﺪﻳﺮﺗﻜِﺒﻬﺎ، وﻟﻜﻦﻗﺪﺗﻜﻮن اﻟﻨﺘﻴﺠﺔ أن
ﺗُﺴﺘﻬﺪَفﻣﺠﻤﻮﻋﺎت اﺟﺘﻤﺎﻋﻴﺔ واﻗﺘﺼﺎدﻳﺔ أوﻋِﺮﻗﻴﺔﻣُﻌﻴﱠﻨﺔﻟﻠﻤﺮاﻗﺒﺔ اﻟﴩﻃﻴﺔﺑﺪرﺟﺔٍ أﻛﱪ
ﻣﻦﻏريﻫﻢﻣﻦ املﺠﻤﻮﻋﺎت. وﻗﺪﺟَﺮَت اﻻﺳﺘﻌﺎﻧﺔﺑﺎﻟﻔﻌﻞﺑﺎﻟﴩﻃﺔ اﻟﺘﻨﺒﱡﺆﻳﺔﰲ اﻟﻮﻻﻳﺎت
املﺘﺤﺪة، وﻛﻤﺎﻳُﻈﻬﺮﺗﻘﺮﻳﺮﺣﺪﻳﺚ ملﻨﻈﻤﺔ »أﻟﺠﻮرﻳﺬم ووﺗﺶ« )٩١٠٢(،ﻓﻘﺪ اﺳﺘُﻌني
وﻏﺎﻟﺒًﺎﻣﺎﺗُﺴﺘﺨﺪَمﺗﻘﻨﻴﺔ اﻟﺘﻌﺮﱡفﻋﲆ اﻟﻮﺟﻮه اﻟﻘﺎﺋﻤﺔﻋﲆ اﻟﺬﻛﺎء3.ﺑﻬﺎ أﻳﻀًﺎﰲ أوروﺑﺎ
اﻻﺻﻄﻨﺎﻋﻲﻷﻏﺮاض املُﺮاﻗﺒﺔ، وﻣِﻦﺛَﻢﻳﻤﻜﻦ أنﺗُﺸﻜﱢﻞ اﻧﺘﻬﺎﻛًﺎﻟﺨﺼﻮﺻﻴﺔ اﻷﻓﺮاد.ﻛﻤﺎ
ﻳُﻤﻜﻨﻬﺎﺑﺸﻜﻞٍ أوﺑﺂﺧَﺮ اﻟﺘﻨﺒﺆﺑﺎملﻴﻮل اﻟﺠﻨﺴﻴﺔﻟﺪى اﻷﻓﺮاد. اﻷﻣﺮﻻﻳﺘﻄﻠﱠﺐ أيﻣﻌﻠﻮﻣﺎت
ﻣﻦﻫﺎﺗﻔﻚ أو أيﺑﻴﺎﻧﺎتﺑﻴﻮﻣﱰﻳﺔ )ﺑﻴﺎﻧﺎت املﻘﺎﻳﻴﺲ اﻟﺤﻴﻮﻳﺔ(. وﺗﻘﻮم اﻵﻟﺔﺑﻌﻤﻠﻬﺎﻋﻦﺑُﻌﺪ.
وﻣِﻦﺛَﻢﻓﺈﻧﻨﺎﺑﺎﺳﺘﺨﺪام اﻟﻜﺎﻣريات املﻮﺟﻮدةﰲ اﻟﺸﻮارع واﻷﻣﺎﻛﻦ اﻟﻌﺎﻣﺔ اﻷﺧﺮى،ﻳﻤﻜﻦ
اﻟﺘﻌﺮﱡفﻋﻠﻴﻨﺎ و»ﻗﺮاءﺗﻨﺎ«،ﺑﻤﺎﰲ ذﻟﻚ اﻟﺘﻌﺮفﻋﲆﺣﺎﻟﺘﻨﺎ املﺰاﺟﻴﺔ. وﻋﻦﻃﺮﻳﻖﺗﺤﻠﻴﻞ
ﺑﻴﺎﻧﺎﺗﻨﺎ،ﻳﻤﻜﻦ اﻟﺘﻨﺒﺆﺑﺼﺤﱠﺘﻨﺎ اﻟﻌﻘﻠﻴﺔ واﻟﺠﺴﺪﻳﺔ؛ دونﻋِﻠﻤﻨﺎﺑﺬﻟﻚ. وﻳﻤﻜﻦﻷﺻﺤﺎب اﻟﻌﻤﻞ
اﺳﺘﺨﺪام اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ ملُﺮاﻗﺒﺔ أداﺋﻨﺎ. وﻳﻤﻜﻦﻟﻠﺨﻮارزﻣﻴﺎت اﻟﻨﺸﻄﺔﻋﲆ وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ
اﻻﺟﺘﻤﺎﻋﻲ أنﺗﻨﴩﺧﻄﺎب اﻟﻜﺮاﻫﻴﺔ أو املﻌﻠﻮﻣﺎت اﻟﺨﻄﺄ؛ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦ أنﺗﻈﻬﺮ
ﻣﺤﺘﻮًىﺳﻴﺎﺳﻴٍّﺎ. إﺣﺪى اﻟﺤﺎﻻت
ﺣﻘﻴﻘﻴﱢني وﺗﻨﴩُ
اﻟﺮوﺑﻮﺗﺎت اﻟﺴﻴﺎﺳﻴﺔﰲﻫﻴﺌﺔ أﺷﺨﺎصٍ
املﻌﺮوﻓﺔﻫﻲﺑﺮﻧﺎﻣﺞ اﻟﺪردﺷﺔ اﻵﱄﻣﻦﻣﺎﻳﻜﺮوﺳﻮﻓﺖﻟﻌﺎم ٦١٠٢ املُﺴﻤﻰ »ﺗﺎي« املُﺼﻤﱠﻢ
ﻹﺟﺮاءﻣﺤﺎدﺛﺎتﻣَﺮِﺣﺔﻋﲆﺗﻮﻳﱰ، وﻟﻜﻦﻋﻨﺪﻣﺎ أﺻﺒﺢ أﻛﺜﺮ ذﻛﺎءً،ﺑﺪأﰲﻧﴩﺗﻐﺮﻳﺪات
ﺗﺤﻤِﻞ دﻻﻻتٍﻋﻨﴫﻳﺔ.ﻳﻤﻜﻦﻟﺒﻌﺾﺧﻮارزﻣﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﻧﺸﺎءﺧﻄﺎﺑﺎتﻓﻴﺪﻳﻮ
4.ﻛﺎذﺑﺔ،ﻣﺜﻞ اﻟﻔﻴﺪﻳﻮ اﻟﺬيﺟﺮى إﻧﺸﺎؤهﻟﻴُﺸﺒﻪﺑﺸﻜﻞٍﻣُﻀﻠﱢﻞﺧﻄﺎﺑًﺎﻟﺒﺎراك أوﺑﺎﻣﺎ
ﻏﺎﻟﺒًﺎﻣﺎﺗﻜﻮن اﻟﻨﻮاﻳﺎﻃﻴﺒﺔ. وﻟﻜﻦﻫﺬه املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔﻋﺎدةًﻣﺎﺗﻜﻮنﻧﺘﺎﺋﺞﻏري
ﻣﻘﺼﻮدةﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎ:ﻓﻤﻌﻈﻢﻫﺬه اﻟﺘﺄﺛريات،ﻣﺜﻞ اﻟﺘﺤﻴﱡﺰ أوﺧﻄﺎب اﻟﻜﺮاﻫﻴﺔ،ﻟﻢﻳﻘﺼﺪﻫﺎ
ﻣﻄﻮرو اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ أوﻣُﺴﺘﺨﺪﻣﻮﻫﺎ.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻫﻨﺎكﺳﺆالﻣﻬﻢﻳﺠﺐﻃﺮﺣﻪ داﺋﻤًﺎ:
16</p>
<p>أﻳﺘﻬﺎ املﺮآةﻋﲆ اﻟﺤﺎﺋﻂ
ﻣﻦ أﺟﻞﻣَﻦﻳﺘﻢ اﻟﺘﺤﺴني؟ﻣﻦ أﺟﻞ اﻟﺤﻜﻮﻣﺔ أمﻣﻦ أﺟﻞ املﻮاﻃﻨني؟ﻣﻦ أﺟﻞ اﻟﴩﻃﺔ أمﻣﻦ
أﺟﻞﻣَﻦﺗﺴﺘﻬﺪﻓﻬﻢ اﻟﴩﻃﺔ؟ﻣﻦ أﺟﻞﺑﺎﺋﻊ اﻟﺘﺠﺰﺋﺔ أمﻣﻦ أﺟﻞ اﻟﺰﺑﻮن؟ﻣﻦ أﺟﻞ اﻟﻘﻀﺎة
أمﻣﻦ أﺟﻞ املُﺘﻬﻤني؟ﻛﻤﺎﺗﻈﻬﺮ اﻷﺳﺌﻠﺔ املﺘﻌﻠﻘﺔﺑﺎﻟﺴﻠﻄﺔ واﻟﻬﻴﻤﻨﺔ،ﻛﺎﻟﺤﺎلﻋﲆﺳﺒﻴﻞ
Nemitz)املﺜﺎلﻋﻨﺪﻣﺎﻳﻘﺘﴫﺗﺸﻜﻴﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻋﲆﻋﺪدٍﻗﻠﻴﻞﻣﻦ اﻟﴩﻛﺎت اﻟﻀﺨﻤﺔ
(.ﻓﻤَﻦ اﻟﺬيﻳُﺸﻜﻞﻣُﺴﺘﻘﺒﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟2018
ﻳُﻠﻘﻲﻫﺬا اﻟﺴﺆال اﻟﻀﻮءﻋﲆ اﻷﻫﻤﻴﺔ اﻻﺟﺘﻤﺎﻋﻴﺔ واﻟﺴﻴﺎﺳﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﺗﺘﻌﻠﱠﻖ
أﺧﻼﻗﻴﱠﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﺘﻐريﱡ اﻟﺘﻜﻨﻮﻟﻮﺟﻲ وﺗﺄﺛريهﻋﲆﺣﻴﺎة اﻷﻓﺮاد، وﻟﻜﻨﻬﺎﺗﺘﻌﻠﻖ
أﻳﻀًﺎﺑﺎﻟﺘﺤﻮﻻت اﻟﺘﻲﺗﺤﺪُثﰲ املﺠﺘﻤﻊ وﰲ اﻻﻗﺘﺼﺎد. وﺗﺪلﱡﻗﻀﺎﻳﺎ اﻟﺘﺤﻴﱡﺰ واﻟﺘﻤﻴﻴﺰﺑﺎﻟﻔﻌﻞ
ﻋﲆ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣُﺮﺗﺒِﻂﺑﺎملﺠﺘﻤﻊ. وﻟﻜﻨﻪﻳُﻐريﱢ أﻳﻀًﺎ اﻻﻗﺘﺼﺎد، وﺑﺎﻟﺘﺎﱄ رﺑﻤﺎﻳُﻐريﱢ
اﻟﻬﻴﻜﻞ اﻻﺟﺘﻤﺎﻋﻲ ملﺠﺘﻤﻌﺎﺗﻨﺎ. ووﻓﻘًﺎ ملﻜﺎﰲ وﺑﺮﻳﻨﺠﻮﻟﻔﺴﻮن )٤١٠٢(،ﻓﻘﺪ دﺧﻠﻨﺎﻋﴫ اﻵﻟﺔ
اﻟﺜﺎﻧﻲ، اﻟﺬيﻻﺗﻜﻮنﻓﻴﻪ اﻵﻻتﻣُﻜﻤﻠﺔﻟﻠﺒﴩﻓﺤﺴﺐ،ﻛﻤﺎﰲ اﻟﺜﻮرة اﻟﺼﻨﺎﻋﻴﺔ، وﻟﻜﻨﻬﺎ أﻳﻀًﺎ
ﺑﺪاﺋﻞﻟﻠﺒﴩ. وﻧﻈﺮًا إﱃ أن املِﻬﻦ واﻷﻋﻤﺎلﻣﻦﺟﻤﻴﻊ اﻷﻧﻮاعﺳﺘﺘﺄﺛﺮﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،
ﻓﻤﻦ املﺘﻮﻗﱠﻊ أنﻳﺘﻐريﱠﻣﺠﺘﻤﻌﻨﺎﺗﻐريﱡ ًاﺟﺬرﻳٍّﺎﻣﻊ دﺧﻮل اﻟﺘﻘﻨﻴﺎت اﻟﺘﻲ وَﺻﻔﺖﰲﻳﻮمٍ
McAfee and Brynjolfsson)ﻣﻦ اﻷﻳﺎمﰲ رواﻳﺎت اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲﺣﻴﱠﺰ اﻟﻌﺎﻟﻢ اﻟﺤﻘﻴﻘﻲ
(.ﻓﻤﺎﻫﻮﻣﺴﺘﻘﺒﻞ اﻟﻌﻤﻞ؟ وﻣﺎﻧﻮع اﻟﺤﻴﺎة اﻟﺘﻲﺳﻨﻌﻴﺸﻬﺎﻧﺤﻦﻋﻨﺪﻣﺎﻳﺘﻮﱃ اﻟﺬﻛﺎء2017
اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﻴﺎمﺑﺎﻟﻮﻇﺎﺋﻒ؟ وﻣَﻦ »ﻧﺤﻦ«؟ وﻣَﻦ اﻟﺬيﺳﻴﺴﺘﻔﻴﺪﻣﻦﻫﺬا اﻟﺘﺤﻮﱡل وﻣﻦ
ﺳﻴﺨﴪ؟
ﻫﺬا اﻟﻜﺘﺎب
اﺳﺘﻨﺎدًا إﱃ اﻹﻧﺠﺎزات املُﺬﻫﻠﺔ اﻟﺘﻲﺗﻢﺗﺤﻘﻴﻘﻬﺎ،ﻓﻬﻨﺎك اﻟﻜﺜريﻣﻦ اﻟﻀﺠﺔ املُﺜﺎرةﺣﻮل اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ. وﻳُﺴﺘﺨﺪَم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﻔﻌﻞﰲﻣﺠﻤﻮﻋﺔٍ واﺳﻌﺔﻣﻦﻣﺠﺎﻻت املﻌﺮﻓﺔ
واملﻤﺎرﺳﺎت اﻟﺒﴩﻳﺔ. وﻗﺪ أﺛﺎرت اﻷوﱃﺗﻜﻬﱡﻨﺎتٍﺟﺎﻣﺤﺔﺣﻮلﻣﺴﺘﻘﺒﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ،ﻛﻤﺎ
أﺛﺎرتﻣﻨﺎﻗﺸﺎتٍﻓﻠﺴﻔﻴﺔًﻣﻬﻤﱠﺔﺣﻮلﻣﻌﻨﻰ أنﺗﻜﻮن إﻧﺴﺎﻧًﺎ.ﺑﻴﻨﻤﺎﺧﻠﻘﺖ اﻟﺜﺎﻧﻴﺔ إﺣﺴﺎﺳًﺎ
ﺑﺎﻹﻟﺤﺎحﻣﻦﺟﺎﻧﺐ اﻷﺧﻼﻗﻴني وﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎتﻟﻀﻤﺎن أنﺗُﻔﻴﺪﻧﺎﻫﺬه اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺑﺪﻻً
ﻣﻦ أنﺗﺨﻠﻖ أﻣﺎم اﻷﻓﺮاد واملﺠﺘﻤﻌﺎتﺗﺤﺪﻳﺎتﻻﻳُﻤﻜﻨﻬﻢ اﻟﺘﻐﻠﱡﺐﻋﻠﻴﻬﺎ. وﺗُﻌﺪﻫﺬه املﺨﺎوف
اﻷﺧرية أﻛﺜﺮﻋﻤﻠﻴﺔً وإﻟﺤﺎﺣًﺎ.
17</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺗﺘﻌﻠﻖ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﺘﻐريﱡ اﻟﺘﻜﻨﻮﻟﻮﺟﻲ وﺗﺄﺛريِهﻋﲆﺣﻴﺎة اﻷﻓﺮاد، وﻟﻜﻨﻬﺎﺗﺘﻌﻠﻖ
أﻳﻀًﺎﺑﺎﻟﺘﺤﻮﱡﻻت اﻟﺘﻲﺗﺤﺪثﰲ املﺠﺘﻤﻊ وﰲ اﻻﻗﺘﺼﺎد.
ﻳﺘﻨﺎولﻫﺬا اﻟﻜﺘﺎب، اﻟﺬيﻛﺘﺒَﻪﻓﻴﻠﺴﻮف أﻛﺎدﻳﻤﻲﻟﺪَﻳﻪ أﻳﻀًﺎﺧﱪةﰲﺗﻘﺪﻳﻢ املﺸﻮرة
ﻣﻦ أﺟﻞ وﺿﻊ اﻟﺴﻴﺎﺳﺎت،ﻛِﻼ اﻟﺠﺎﻧﺒَني؛ﻓﻬﻮﻳﺘﻌﺎﻣﻞﻣﻊ اﻷﺧﻼﻗﻴﺎتﻋﲆﻫﺬه املﺴﺘﻮﻳﺎت
ﻛﺎﻓﺔ. وﻳﻬﺪف إﱃ إﻋﻄﺎء اﻟﻘﺎرئﻧﻈﺮةًﻋﺎﻣﺔﺟﻴﺪةﻋﲆ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲﻳُﺜريﻫﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ،ﺑﺪءًاﻣﻦ اﻟﴪدﻳﺎت املﺆﺛﺮةﺣﻮلﻣﺴﺘﻘﺒﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻷﺳﺌﻠﺔ اﻟﻔﻠﺴﻔﻴﺔ
ﺣﻮلﻃﺒﻴﻌﺔ اﻹﻧﺴﺎن وﻣُﺴﺘﻘﺒﻠﻪ، واﻧﻄﻼﻗًﺎ إﱃ اﻟﻘﻀﺎﻳﺎ اﻷﺧﻼﻗﻴﺔ املُﺘﻌﻠﻘﺔﺑﺎملﺴﺌﻮﻟﻴﺔ واﻟﺘﺤﻴﱡﺰ
وﻛﻴﻔﻴﺔ اﻟﺘﻌﺎﻣُﻞﻣﻊ املﺴﺎﺋﻞ اﻟﻌﻤﻠﻴﺔ اﻟﻮاﻗﻌﻴﺔ اﻟﺘﻲ أﺛﺎرﺗﻬﺎ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻋﻦﻃﺮﻳﻖ وﺿﻊ
اﻟﺴﻴﺎﺳﺎت؛ﻻﺳﻴﻤﺎ إذاﻛﺎن ذﻟﻚﻗﺒﻞﻓﻮات اﻷوان.
ﻟﻜﻦﻣﺎذاﺳﻴﺤﺪُث إذا »ﻓﺎت اﻷوان«؟ﺑﻌﺾ اﻟﺴﻴﻨﺎرﻳﻮﻫﺎتﻣﺘﺸﺎﺋﻤﺔ وﻣﺘﻔﺎﺋﻠﺔﰲ اﻟﻮﻗﺖ
ﻧﻔﺴﻪ. اﺳﻤﺤﻮاﱄ أن أﺑﺪأﺑﺒﻌﺾ اﻷﺣﻼم واﻟﻜﻮاﺑﻴﺲﺣﻮلﻣﺴﺘﻘﺒﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ، واﻟﴪدﻳﺎت
املﺆﺛﺮة اﻟﺘﻲﺗﺒﺪو، وﻟﻮﻟﻠﻮﻫﻠﺔ اﻷوﱃﻋﲆ اﻷﻗﻞ، ذاتﺻِﻠﺔٍﺑﺘﻘﻴﻴﻢ اﻟﻔﻮاﺋﺪ واملﺨﺎﻃﺮ املُﺤﺘﻤَﻠﺔ
ﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
18</p>
</section>
<section id="section-3">
    <h2>الذكاء الفائق والوحوش ونهاية العالم بالذكاء الاصطناعي</h2>
    <div class="page-range">Pages 19-30</div>
    <p>اﻟﻔﺼﻞ اﻟﺜﺎﻧﻲ
اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻟﻮﺣﻮش وﳖﺎﻳﺔ اﻟﻌﺎﱂ
ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ وﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ
أدﱠت اﻟﻀﺠﺔ املُﺤﻴﻄﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﻇﻬﻮرﺟﻤﻴﻊ أﻧﻮاع اﻟﺘﻜﻬﱡﻨﺎتﺣﻮلﻣﺴﺘﻘﺒﻞ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣﺴﺘﻘﺒﻞﻣﺎﺳﻴﻜﻮنﻋﻠﻴﻪ اﻹﻧﺴﺎن. إن إﺣﺪى اﻷﻓﻜﺎر اﻟﺸﺎﺋﻌﺔ، واﻟﺘﻲ
ﺗﺘﻜﺮﱠرﻛﺜريًاﰲ وﺳﺎﺋﻞ اﻹﻋﻼم وﰲ اﻟﻨﻘﺎﺷﺎت اﻟﻌﺎﻣﺔﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺑﻞﻳﻨﴩﻫﺎ
أﻳﻀًﺎﺧﱪاء اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ املﺆﺛﱢﺮون اﻟﺬﻳﻦﻳُﻄﻮﱢرونﺗﻘﻨﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺜﻞ إﻳﻠﻮن
ﻣﺎﺳﻚ ورايﻛﻮرزواﻳﻞ،ﻫﻲﻓﻜﺮة اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ، وﺑﺸﻜﻞٍ أﻛﺜﺮﻋﻤﻮﻣﻴﺔ،ﻓﻜﺮة أن اﻵﻻت
ﺳﺘُﺴﻴﻄﺮﻋﻠﻴﻨﺎ، وﺗﺴﺘﻌﺒِﺪﻧﺎ وﻟﻴﺲ اﻟﻌﻜﺲ.ﺑﺎﻟﻨﺴﺒﺔ إﱃ اﻟﺒﻌﺾ،ﻫﺬاﺣﻠﻢ؛ وﺑﺎﻟﻨﺴﺒﺔ إﱃ
اﻟﻜﺜريﻳﻦ،ﻫﺬاﻛﺎﺑﻮس. وﻫﻨﺎكﻣَﻦﻳﺮَون أﻧﻪﺣﻠﻢ وﻛﺎﺑﻮسﰲ اﻟﻮﻗﺖﻧﻔﺴﻪ.
ﻓﻜﺮة اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖﻫﻲ أن اﻵﻻتﺳﺘﺘﻔﻮﱠقﻋﲆ اﻟﺬﻛﺎء اﻟﺒﴩي. وﻫﻲﻏﺎﻟﺒًﺎﻣﺎﺗﺮﺗﺒﻂ
ﺑﻔﻜﺮة اﻧﻔﺠﺎر اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺘﻔﺮﱡد اﻟﺘﻜﻨﻮﻟﻮﺟﻲ. ووﻓﻘًﺎﻟﻨﻴﻚﺑﻮﺳﱰوم )٤١٠٢(،
ﺳﻨﻘﻊﰲﻣﺄزقٍﻳُﻤﺎﺛﻞ ذﻟﻚ اﻟﺬي وﻗﻌﺖﻓﻴﻪ اﻟﻐﻮرﻳﻼ، اﻟﺘﻲﻳﻌﺘﻤﺪﻣﺼريﻫﺎ اﻟﻴﻮمﻋﻠﻴﻨﺎ
ﺑﺸﻜﻞٍﻛﺎﻣﻞ. إﻧﻪﻳﺮىﻃﺮﻳﻘَنيﻋﲆ اﻷﻗﻞﻟﺒﻠﻮغ اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ وﻣﺎﻳُﺴﻤﱠﻰ أﺣﻴﺎﻧًﺎﺑﺎﻧﻔﺠﺎر
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. أﺣﺪﻫﻤﺎ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺳﻮفﻳُﻄﻮﱢرﺗﺤﺴﻴﻨًﺎ ذاﺗﻴٍّﺎﺗﻜﺮارﻳٍّﺎ؛
إذﻳﺴﺘﻄﻴﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺼﻤﻴﻢﻧﺴﺨﺔٍﻣُﺤﺴﱠﻨﺔﻣﻦﻧﻔﺴﻪ، واﻟﺘﻲﺑﺪورﻫﺎﺗُﺼﻤﱢﻢ
ﻧﺴﺨﺔً أﻛﺜﺮ ذﻛﺎءًﻣﻦﻧﻔﺴﻬﺎ، وﻫﻜﺬا دواﻟﻴﻚ. أﻣﺎ اﻟﻄﺮﻳﻖ اﻵﺧَﺮﻓﻬﻮﻣﺤﺎﻛﺎة اﻟﺪﻣﺎغﺑﺎﻟﻜﺎﻣﻞ
أوﺗﺤﻤﻴﻠﻪ: دﻣﺎغﺑﻴﻮﻟﻮﺟﻲﻳُﻤﻜِﻦﻣﺴﺤﻪﺿﻮﺋﻴٍّﺎ وﺻُﻨﻊﻧﻤﻮذجﻟﻪ،ﺛﻢ إﻋﺎدة إﻧﺘﺎﺟِﻪﰲ
ﻣﻜﻮﻧﺎتٍﺑﺮﻣﺠﻴﺔ ذﻛﻴﱠﺔ وﻣِﻦﺧﻼﻟﻬﺎ.ﻳﺘﻢﺑﻌﺪ ذﻟﻚﺗﻮﺻﻴﻞﻫﺬه املُﺤﺎﻛﺎةﻟﻠﺪﻣﺎغ اﻟﺒﻴﻮﻟﻮﺟﻲ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺑﺠﺴﻢ إﻧﺴﺎن آﱄ. وﺳﺘﺆديﻣﺜﻞﻫﺬه اﻟﺘﻄﻮﱡرات إﱃ اﻧﻔﺠﺎرٍﰲ اﻟﺬﻛﺎءﻏري اﻟﺒﴩي.ﺣﺘﻰ
إنﻣﺎﻛﺲﺗﺠﻤﺎرك )٧١٠٢(ﻳﺘﺨﻴﻞ أنﻓﺮﻳﻘًﺎﻣﺎﻳُﻤﻜِﻨﻪ إﻧﺸﺎء ذﻛﺎء اﺻﻄﻨﺎﻋﻲﻳُﺼﺒﺢ
ﰲﻣﻨﺘﻬﻰ اﻟﻘﻮةﺑﺤﻴﺚﻳﺴﺘﻄﻴﻊ إدارة اﻟﻜﻮﻛﺐ. وﻳﻜﺘﺐﻳﻮﻓﺎلﻫﺮاريﻋﻦﻋﺎﻟَﻢٍﻟﻢﻳﻌُﺪ
ﻓﻴﻪ اﻟﺒﴩﻳﺴﻴﻄﺮون، وﻟﻜﻨﻬﻢﻳﻌﺒﺪون اﻟﺒﻴﺎﻧﺎت وﻳﺜﻘﻮنﰲﻗﺪرة اﻟﺨﻮارزﻣﻴﺎتﻋﲆ اﺗﺨﺎذ
ﻗﺮاراﺗﻬﻢ. وﺑﻌﺪ اﻧﻬﻴﺎرﻛﻞﱢ أوﻫﺎم اﻹﻧﺴﺎﻧﻴني واملﺆﺳﺴﺎت اﻟﻠﻴﱪاﻟﻴﺔ،ﻟﻦﻳﺒﻘﻰﻟﻠﺒﴩ إﻻ أن
ﻳﺤﻠﻤﻮاﺑﺎﻻﻧﺪﻣﺎجﰲﺗﺪﻓﱡﻖ اﻟﺒﻴﺎﻧﺎت.ﻳﺴري اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﻣﺴﺎره اﻟﺨﺎص، »اﻟﺬﻫﺎب
Harari) «إﱃﺣﻴﺚﻟﻢﻳﺬﻫﺐ أي إﻧﺴﺎنٍﻣﻦﻗﺒﻞ؛ وإﱃﺣﻴﺚﻻﻳﻤﻜﻦﻷي إﻧﺴﺎنٍ أنﻳﺘﺒﻌﻪ
(.2015, 393
:«ﺗﺮﺗﺒﻂﻓﻜﺮة اﻧﻔﺠﺎر اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ ارﺗﺒﺎﻃًﺎ وﺛﻴﻘًﺎﺑﻔﻜﺮة »اﻟﺘﻔﺮﱡد اﻟﺘﻜﻨﻮﻟﻮﺟﻲ
ﻟﺤﻈﺔﰲﺗﺎرﻳﺦ اﻟﺒﴩﻳﺔﺳﻴُﺤﺪِثﻓﻴﻬﺎ اﻟﺘﻘﺪﱡم اﻟﺘﻜﻨﻮﻟﻮﺟﻲ اﻟﻬﺎﺋﻞﺗﻐﻴريًا دراﻣﺎﺗﻴﻜﻴٍّﺎﺑﺤﻴﺚ
Shanahan) «ﻻﻧﻌﻮدﻧﺴﺘﻮﻋِﺐﻣﺎﻳﺤﺪث و»ﺗﻨﺘﻬﻲ اﻟﺸﺌﻮن اﻹﻧﺴﺎﻧﻴﺔﻛﻤﺎﻧﻔﻬﻤﻬﺎ اﻟﻴﻮم
(.ﰲﻋﺎم ٥٦٩١،ﺗﻜﻬﱠﻦَﻋﺎﻟﻢ اﻟﺮﻳﺎﺿﻴﺎت اﻟﱪﻳﻄﺎﻧﻲ إﻳﺮﻓﻴﻨﺞﺟﻮنﺟﻮد2015, xv
ﺑﺂﻟﺔﻓﺎﺋﻘﺔ اﻟﺬﻛﺎءﺗُﺼﻤﱢﻢ آﻻتٍ أﻓﻀﻞ؛ وﰲ اﻟﺘﺴﻌﻴﻨﻴﺎت، رأىﻣﺆﻟﻒ اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ وﻋﺎﻟﻢ
اﻟﻜﻤﺒﻴﻮﺗﺮﻓريﻧﻮرﻓﻴﻨﺞ أنﻫﺬاﺳﻴﻌﻨﻲﻧﻬﺎﻳﺔﻋﴫ اﻹﻧﺴﺎن. وﻗﺪ اﻗﱰح راﺋﺪﻋﻠﻢ اﻟﻜﻤﺒﻴﻮﺗﺮ
ﺟﻮنﻓﻮنﻧﻴﻮﻣﺎنﺑﺎﻟﻔﻌﻞ اﻟﻔﻜﺮةﰲﺧﻤﺴﻴﻨﻴﺎت اﻟﻘﺮن اﻟﻌﴩﻳﻦ. وﺗﺒﻨﱠﻰ رايﻛﻮرزواﻳﻞ
)٥٠٠٢(ﻣﺼﻄﻠﺢ »اﻟﺘﻔﺮﱡد« وﺗﻮﻗﱠﻊ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺟﻨﺒًﺎ إﱃﺟﻨﺐٍﻣﻊ أﺟﻬﺰة
اﻟﻜﻤﺒﻴﻮﺗﺮ وﻋﻠﻢ اﻟﻮراﺛﺔ وﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﻨﺎﻧﻮ وﻋﻠﻢ اﻟﺮوﺑﻮﺗﺎت،ﺳﻴﺆدي إﱃﻧﻘﻄﺔٍﻳﻜﻮنﻓﻴﻬﺎ
ذﻛﺎءُ اﻵﻟﺔ أﻗﻮىﻣﻦﻛﻞﱢ اﻟﺬﻛﺎء اﻟﺒﴩيﻣُﺠﺘﻤﻌًﺎ، وﻳﻨﺪﻣﺞﻋﻨﺪﻫﺎ اﻟﺬﻛﺎء اﻟﺒﴩي وذﻛﺎء اﻵﻟﺔ
ﰲ اﻟﻨﻬﺎﻳﺔ. وﺳﻮفﻳﺘﺠﺎوز اﻟﺒﴩﺣﺪود أﺟﺴﺎﻣﻬﻢ اﻟﺒﻴﻮﻟﻮﺟﻴﺔ. وﻛﻤﺎﺟﺎءﰲﻋﻨﻮانﻛﺘﺎﺑﻪ:
»اﻟﺘﻔﺮﱡدﻗﺮﻳﺐ«. وﻫﻮﻳﻌﺘﻘﺪ أنﻫﺬاﺳﻴﺤﺪثﺣﻮاﱄﻋﺎم ٥٤٠٢.
ﻟﻴﺲﻟﻬﺬه اﻟﻘﺼﺔﺑﺎﻟﴬورةﻧﻬﺎﻳﺔﺳﻌﻴﺪة:ﻓﻔﻲ رأيﺑﻮﺳﱰوم وﺗﺠﻤﺎرك وآﺧﺮﻳﻦ،
ﺛﻤﱠﺔ »ﻣﺨﺎﻃﺮ وﺟﻮدﻳﺔ«ﻣُﺮﺗﺒﻄﺔﺑﺎﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ. وﻗﺪﺗﻜﻮنﻧﺘﻴﺠﺔﻫﺬه اﻟﺘﻄﻮﱡرات أن اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻟﻔﺎﺋﻖﺳﻮفﻳُﺴﻴﻄﺮ وﻳﺘﻮﱃﱠ زﻣﺎم اﻷﻣﻮر وﻳُﻬﺪﱢدﺣﻴﺎة اﻹﻧﺴﺎن اﻟﺬﻛﻴﺔ. وﺳﻮاء
أﻛﺎنﻫﺬا اﻟﻜﻴﺎن واﻋﻴًﺎ أمﻻ، وﺑﺼﻮرة أﻋﻢﻣﻬﻤﺎﻛﺎﻧﺖﺣﺎﻟﺘﻪ أوﻛﻴﻔﻴﺔﻧﺸﻮﺋﻪ،ﻓﺈن اﻟﻘﻠﻖ
ﻫﻨﺎﻳﺘﻌﻠﱠﻖﺑﻤﺎﺳﻴﻔﻌﻠﻪﻫﺬا اﻟﻜﻴﺎن )أوﻣﺎﻻﻳﻔﻌﻠﻪ(.ﻗﺪﻻﻳﻬﺘﻢﱡ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺄﻫﺪاﻓﻨﺎ
اﻟﺒﴩﻳﺔ. وﻧﻈﺮًاﻟﻌﺪم اﻣﺘﻼﻛِﻪﺟﺴﺪًاﺑﻴﻮﻟﻮﺟﻴٍّﺎ،ﻓﺈﻧﻪﻟﻦﻳﻔﻬﻢﺣﺘﻰ املﻌﺎﻧﺎة اﻟﺒﴩﻳﺔ. وﻳُﻘﺪم
ﺑﻮﺳﱰومﺗﺠﺮﺑﺔًﻓﻜﺮﻳﺔﻟﺬﻛﺎءٍ اﺻﻄﻨﺎﻋﻲﻳُﺤﺪﱠدﻟﻪﻫﺪفﻣُﻌنيﱠ وﻫﻮﺗﺼﻨﻴﻊﻣﺸﺎﺑﻚ اﻟﻮرق
ﺑﺄﻛﱪﻛﻢﱟﻣُﻤﻜِﻦ،ﻓﻤﺎﻛﺎنﻣﻨﻪ إﻻ أنﺣﻮﱠلﻛﻮﻛﺐ اﻷرض واﻟﺒﴩ اﻟﺬﻳﻦﻳﻌﻴﺸﻮنﻋﻠﻴﻪ إﱃ
20</p>
<p>اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻟﻮﺣﻮش وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻣﻮاردﻹﻧﺘﺎجﻣﺸﺎﺑﻚ اﻟﻮرق. إذَن اﻟﺘﺤﺪﱢي اﻟﺬيﻳُﻮاﺟﻬﻨﺎ اﻟﻴﻮمﻫﻮ اﻟﺘﺄﻛﱡﺪﻣﻦ أﻧﻨﺎﻧﺒﻨﻲ
ذﻛﺎءً اﺻﻄﻨﺎﻋﻴٍّﺎﻻﻳُﺜريﺑﻄﺮﻳﻘﺔٍﻣﺎﻣﺸﻜﻠﺔ اﻟﺴﻴﻄﺮةﻫﺬه؛ﺑﻤﻌﻨﻰ أﻧﻪﻳﻔﻌﻞﻣﺎﻧﺮﻳﺪ وﻳﺄﺧﺬ
ﺣﻘﻮﻗﻨﺎﰲ اﻻﻋﺘﺒﺎر.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻫﻞﻳﺠﺐ أنﻧﺤﺪﱠﺑﻄﺮﻳﻘﺔٍﻣﺎﻣﻦﻗﺪرات اﻟﺬﻛﺎء
1اﻻﺻﻄﻨﺎﻋﻲ؟ وﻛﻴﻒﻳُﻤﻜﻨﻨﺎ اﺣﺘﻮاء اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟
ﺛﻤﱠﺔ أﻓﻜﺎر أﺧﺮىﻣﱰاﺑﻄﺔ وذاتﺻﻠﺔ؛ أﻻ وﻫﻲ اﻷﻓﻜﺎر املﺘﻌﻠﱢﻘﺔﺑﺘﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ.
ﰲﺿﻮء اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻹﺣﺒﺎطﻣﻦ اﻟﻀﻌﻒ اﻟﺒﴩي و»اﻷﺧﻄﺎء«،ﻳﺠﺎدل أﻧﺼﺎرﺗﺠﺎوز
اﻹﻧﺴﺎﻧﻴﺔﻣﺜﻞﺑﻮﺳﱰومﺑﺄﻧﻨﺎﺑﺤﺎﺟﺔٍ إﱃﺗﻌﺰﻳﺰ اﻹﻧﺴﺎن:ﺟﻌﻠﻪ أﻛﺜﺮ ذﻛﺎءً، وأﻗﻞﻋُﺮﺿﺔً
ﻟﻠﻤﺮض، وأﻃﻮَلﻋﻤﺮًا، ورﺑﻤﺎﺣﺘﻰﺧﺎﻟﺪًا،ﻣﻤﺎﻳﺆدي إﱃﻣﺎﻳُﺴﻤﱢﻴﻪﻫﺎراري »اﻹﻧﺴﺎن اﻹﻟﻪ«:
ﺗﺮﻗﻴﺔ اﻟﺒﴩ إﱃ آﻟﻬﺔ. وﻛﻤﺎﻗﺎلﻓﺮاﻧﺴﻴﺲﺑﻴﻜﻮنﰲ »دﺣﺾ اﻟﻔﻠﺴﻔﺎت«: اﻟﺒﴩ »آﻟﻬﺔ
(. ملﺎذاﻻﻧُﺤﺎولﺗﺤﻘﻴﻖ اﻟﺨﻠﻮد؟ وﻟﻜﻦﺣﺘﻰﻟﻮﻟﻢﻧﺴﺘﻄﻊBacon 1964, 106) «ﻓﺎﻧﻴﺔ
ﺗﺤﻘﻴﻖ ذﻟﻚ،ﻓﺈن اﻵﻟﺔ اﻟﺒﴩﻳﺔ، وﻓﻘًﺎ ملُﻨﺎﴏيﺗﺠﺎوُز اﻹﻧﺴﺎﻧﻴﺔ،ﺑﺤﺎﺟﺔٍ إﱃﺗﺮﻗﻴﺔ.ﻓﻨﺤﻦ
إذاﻟﻢﻧﻔﻌﻞ ذﻟﻚ،ﻓﺴﻴُﺨﺎﻃﺮ اﻟﺒﴩﺑﺄنﻳﻈﻠﻮا »اﻟﺠﺰء املُﺘﺨﻠﻒﻏري اﻟﻜﻒءﺑﺸﻜﻞﻣﺘﺰاﻳﺪ«
(. إن اﻟﺒﻴﻮﻟﻮﺟﻴﺎ اﻟﺒﴩﻳﺔﺑﺤﺎﺟﺔٍ إﱃ إﻋﺎدةArmstrong 2014, 23)ﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺗﺼﻤﻴﻢ، وﻟﺬاﻳﺘﺴﺎءلﺑﻌﺾﻣﺆﻳﺪيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ، ملﺎذاﻻﻧﺘﺨﻠﱠﺺﺗﻤﺎﻣًﺎﻣﻦ اﻷﺟﺰاء
اﻟﺒﻴﻮﻟﻮﺟﻴﺔ وﻧُﺼﻤﱢﻢﻛﺎﺋﻨﺎتٍ ذﻛﻴﺔﻏريﻋﻀﻮﻳﺔ؟
ﻋﲆ اﻟﺮﻏﻢﻣﻦ أنﻣﻌﻈﻢ اﻟﻔﻼﺳﻔﺔ واﻟﻌﻠﻤﺎء اﻟﺬﻳﻦﻳُﺮوﱢﺟﻮنﻟﻬﺬه اﻷﻓﻜﺎرﻳﺤﺮﺻﻮن
ﻋﲆﺗﻤﻴﻴﺰ آراﺋﻬﻢﻋﻦ اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ واﻟﺪﻳﻦ،ﻓﺈن اﻟﻌﺪﻳﺪﻣﻦ اﻟﺒﺎﺣﺜنيﻳُﻔﴪﱢ ون أﻓﻜﺎرﻫﻢ
ﺑﻬﺬه املﺼﻄﻠﺤﺎتﺑﺎﻟﻀﺒﻂ.ﺑﺎدئ ذيﺑﺪء،ﻟﻴﺲﻣﻦ اﻟﻮاﺿﺢﻣﺪى ارﺗﺒﺎط أﻓﻜﺎرﻫﻢ
ﺑﺎﻟﺘﻄﻮﱡرات اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ اﻟﺤﺎﻟﻴﺔ وﻋﻠﻮم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻣﺎ إذاﻛﺎنﻫﻨﺎكﻓﺮﺻﺔ
ﺣﻘﻴﻘﻴﺔﻟﻠﻮﺻﻮل إﱃ اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖﰲ املُﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ،ﻫﺬا إن أﻣﻜﻦ اﻟﻮﺻﻮل إﻟﻴﻪﻣﻦ
اﻷﺳﺎس. إذﻳﺮﻓﺾ اﻟﺒﻌﺾﺗﻤﺎﻣًﺎ إﻣﻜﺎﻧﻴﺔ اﻟﻮﺻﻮل إﻟﻴﻪ )اﻧﻈﺮ اﻟﻔﺼﻞ اﻟﺘﺎﱄ(، وﺣﺘﻰﻫﺆﻻء
اﻟﺬﻳﻦﻋﲆ اﺳﺘﻌﺪادٍﻟﻘﺒﻮل إﻣﻜﺎﻧﻴﺔ اﻟﻮﺻﻮل إﻟﻴﻪﻣﻦﺣﻴﺚ املﺒﺪأ،ﻣﺜﻞ اﻟﻌﺎﻟِﻤﺔﻣﺎرﺟﺮﻳﺖ
ﺑﻮدن،ﻓﺈﻧﻬﻢﻻﻳﻌﺘﻘﺪون أﻧﻪﻣﻦ املُﺮﺟﱠﺢ اﻟﻮﺻﻮل إﻟﻴﻪﻋﻤﻠﻴٍّﺎ. إنﻓﻜﺮة اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ
ﺗﻔﱰِض أﻧﻨﺎﺳﻨُﻄﻮﱢر »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم«، أو اﻟﺬﻛﺎء اﻟﺬيﻳﻜﺎﻓﺊ اﻟﺬﻛﺎء اﻟﺒﴩي
أوﻳﺘﻔﻮﱠقﻋﻠﻴﻪ، وﻫﻨﺎك اﻟﻌﺪﻳﺪﻣﻦ اﻟﻌﻘﺒﺎت اﻟﺘﻲﻳﺠﺐ اﻟﺘﻐﻠﱡﺐﻋﻠﻴﻬﺎﻗﺒﻞﺗﺤﻘﻴﻖ ذﻟﻚ.
وﺗﺮىﺑﻮدن )٦١٠٢( أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺲ واﻋﺪًاﻛﻤﺎﻳﺘﻮﻗﱠﻊ اﻟﻜﺜريون. وﰲﺗﻘﺮﻳﺮٍ
ﺻﺎدرﻋﻦ اﻟﺒﻴﺖ اﻷﺑﻴﺾﻋﺎم ٦١٠٢،ﺗﻢ اﻟﺘﺄﻛﻴﺪﻋﲆ اﺗﻔﺎقﺧﱪاء اﻟﻘﻄﺎع اﻟﺨﺎصﻋﲆ
أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎمﻟﻦﻳﺘﺤﻘﱠﻖﻋﲆ اﻷﻗﻞﻗﺒﻞﻋﻘﻮد.ﻛﻤﺎﻳﺮﻓﺾ اﻟﻌﺪﻳﺪﻣﻦ
21</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺒﺎﺣﺜنيﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺮؤى املُﻈﻠﻤﺔ املﺘﺸﺎﺋﻤﺔ اﻟﺘﻲﻳُﺮوﱢجﻟﻬﺎﺑﻮﺳﱰوم
وآﺧﺮون، وﻳﺤﻀﱡﻮنﻋﲆ اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞٍ إﻳﺠﺎﺑﻲ،ﻛﻤﺴﺎﻋﺪٍ أو زﻣﻴﻞ.
وﻟﻜﻦ املﺴﺄﻟﺔﻻﺗﺘﻌﻠﻖﺑﻤﺎﺳﻴﺤﺪثﻓﻌﻠﻴٍّﺎﰲ املﺴﺘﻘﺒﻞ.ﺑﻞﻳﻮﺟَﺪﳾء آﺧَﺮﻳُﺜري اﻟﻘﻠﻖ وﻫﻮ
أنﻫﺬه املﻨﺎﻗﺸﺔﺣﻮلﺗﺄﺛريات اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ املﺴﺘﻘﺒﻞ )اﻟﺒﻌﻴﺪ(ﺗُﺸﺘﱢﺖ اﻻﻧﺘﺒﺎهﻋﻦ
Crawford and Calo)املﺨﺎﻃﺮ اﻟﺤﻘﻴﻘﻴﺔ واملﻮﺟﻮدةﺣﺎﻟﻴٍّﺎﻟﻸﻧﻈﻤﺔ اﻟﺘﻲﺗﻢﻧﴩﻫﺎﻓﻌﻠﻴٍّﺎ
(.ﻳﺒﺪو أنﻫﻨﺎكﺧﻄﺮًاﺣﻘﻴﻘﻴٍّﺎ أﻧﻪﰲ املﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ،ﻟﻦﺗﻜﻮن اﻷﻧﻈﻤﺔ ذﻛﻴﺔً2016
ﺑﻤﺎﻓﻴﻪ اﻟﻜﻔﺎﻳﺔ وأﻧﻨﺎﺳﻨﻔﻬﻢ آﺛﺎرﻫﺎ اﻷﺧﻼﻗﻴﺔ واﻻﺟﺘﻤﺎﻋﻴﺔﺑﺸﻜﻞٍﻏريﻛﺎفٍ ، وﻣﻊ ذﻟﻚ
ﺳﻨﺴﺘﺨﺪِﻣﻬﺎﻋﲆﻧﻄﺎقٍ واﺳﻊ.ﻛﻤﺎ أن اﻟﱰﻛﻴﺰ املُﻔﺮِطﻋﲆ اﻟﺬﻛﺎء،ﺑﻮﺻﻔﻪﺳِﻤﺔً رﺋﻴﺴﻴﺔ
(.Boddington 2017)ﻟﻺﻧﺴﺎﻧﻴﺔ، وﻫﺪﻓًﺎﻧﻬﺎﺋﻴٍّﺎ وﺣﻴﺪًا،ﻫﻮ أﻳﻀًﺎ أﻣﺮﻣﺸﻜﻮكﻓﻴﻪ
ﻣﻊ ذﻟﻚ،ﺗﺴﺘﻤﺮ اﻷﻓﻜﺎرﻣﺜﻞ اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖﰲ اﻟﺘﺄﺛريﻋﲆ املﻨﺎﻗﺸﺔ اﻟﻌﺎﻣﺔ. وﻣﻦ
املُﺤﺘﻤﻞ أنﺗﺆﺛﱢﺮ أﻳﻀًﺎﻋﲆﺗﻄﻮﱡر اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻻﻳُﻌﺘﱪ رايﻛﻮرزواﻳﻞ
ﻣﻦ دُﻋﺎة املﺴﺘﻘﺒﻠﻴﺔﻓﺤﺴﺐ.ﺑﻞ إﻧﻪﻳﺸﻐﻞﻣﻨﺼﺐﻣﺪﻳﺮ اﻟﻬﻨﺪﺳﺔﰲﴍﻛﺔﺟﻮﺟﻞﻣﻨﺬﻋﺎم
٢١٠٢.ﻛﻤﺎﻳﺒﺪو أن إﻳﻠﻮنﻣﺎﺳﻚ، اﻟﺮﺋﻴﺲ اﻟﺘﻨﻔﻴﺬيﻟﴩﻛﺔﺗﻴﺴﻼ وﴍﻛﺔﺳﺒﻴﺲ إﻛﺲ،
وﻫﻮﺷﺨﺼﻴﺔﻋﺎﻣﺔﻣﻌﺮوﻓﺔﺟﺪٍّا،ﻳﺆﻳﺪﺳﻴﻨﺎرﻳﻮﻫﺎت اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واملﺨﺎﻃﺮ اﻟﻮﺟﻮدﻳﺔ
)ﺳﻴﻨﺎرﻳﻮﻫﺎت اﻟﻬﻼك؟( اﻟﺘﻲ وﺿﻌﻬﺎﺑﻮﺳﱰوم وﻛﻮرزواﻳﻞ. وﻗﺪﺣﺬﱠرﻣﺮارًاﻣﻦﺧﻄﻮرة
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، واﻋﺘﱪَ َهﺗﻬﺪﻳﺪًا وﺟﻮدﻳٍّﺎ وزﻋﻢ أﻧﻨﺎﻻﻳُﻤﻜﻨﻨﺎ اﻟﺘﺤﻜﱡﻢﰲ اﻟﺸﻴﻄﺎن
(. وﻳﻌﺘﻘﺪﻣﺎﺳﻚ أن اﻟﺒﴩﺳﻴﻨﻘﺮﺿﻮنﻋﲆ اﻷرﺟﺢ،ﻣﺎﻟﻢﻳُﺪﻣَﺞ اﻟﺬﻛﺎءDowd 2017)
.اﻟﺒﴩي واﻟﺬﻛﺎء اﻵﱄ أوﻧﺘﻤﻜﱠﻦﻣﻦ اﻟﻬﺮوب إﱃ املﺮﻳﺦ
رﺑﻤﺎﺗﻜﻮنﻫﺬه اﻷﻓﻜﺎرﻣﺆﺛﺮةﻟﻠﻐﺎﻳﺔﻷﻧﻬﺎﺗﻤﺲﱡﻣﺨﺎوف وآﻣﺎﻻًﻋﻤﻴﻘﺔًﺗﺘﻌﻠﱠﻖﺑﺎﻟﺒﴩ
واﻵﻻت داﺧﻞ وﻋﻴِﻨﺎ اﻟﺠﻤﻌﻲ. وﺳﻮاءﻗَﺒِﻠﻨﺎﻫﺬه اﻷﻓﻜﺎر املُﺤﺪﱠدة أو رﻓَﻀْﻨﺎﻫﺎ،ﻓﺈنﻫﻨﺎك
ﺻِﻼتٍ واﺿﺤﺔﺑﺎﻟﴪدﻳﺎت اﻟﺨﻴﺎﻟﻴﺔﰲ اﻟﺜﻘﺎﻓﺔ اﻟﺒﴩﻳﺔ واﻟﺘﺎرﻳﺦ اﻟﺘﻲﺗُﺤﺎول أنﺗﻔﻬﻢ
اﻹﻧﺴﺎن وﻋﻼﻗﺘﻪﺑﺎﻵﻻت. وﻳﺠﺪُرﺑﻨﺎ أنﻧُﻮﺿﱢﺢﻫﺬه اﻟﴪدﻳﺎتﻟﻜﻲﻧﻔﻬﻢﺑﻌﺾﻫﺬه
اﻷﻓﻜﺎرﻋﲆﻧﺤﻮٍ أﻓﻀﻞ وﻧﻀﻌﻬﺎﰲﺳﻴﺎﻗﻬﺎ اﻟﺼﺤﻴﺢ. وﺑﺸﻜﻞٍﻋﺎم،ﻓﺈﻧﻪﻣﻦ املُﻬﻢ أن
ﻧﺪﻣﺞﺑﺤﺚ اﻟﴪدﻳﺎتﰲ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻟﻜﻲﻧﻔﻬﻢ
اﻷﺳﺒﺎب اﻟﺘﻲﺗﺠﻌﻞﺑﻌﺾ اﻟﴪدﻳﺎتﻣُﻨﺘﴩة، وﻣَﻦ أﻧﺸﺄﻫﺎ، وﻣَﻦ اﻟﺬيﻳﺴﺘﻔﻴﺪﻣﻨﻬﺎ
(.ﻛﻤﺎﻳﻤﻜﻦ أنﻳُﺴﺎﻋﺪﻧﺎﰲ إﻧﺸﺎءﴎدﻳﱠﺎتﺟﺪﻳﺪةﺣﻮلﻣﺴﺘﻘﺒﻞRoyal Society 2018)
.اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
22</p>
<p>اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻟﻮﺣﻮش وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﺣﺶﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ اﻟﺠﺪﻳﺪ
ﻣِﻦ اﻟﺴﺒﻞ اﻟﺘﻲﻳُﻤﻜﻨﻨﺎ اﺗﺨﺎذﻫﺎﻟﺘﺠﺎوُز اﻟﻀﺠﺔ املﺜﺎرة أنﻧﻔﻜﱢﺮﰲﺑﻌﺾ اﻟﴪدﻳﺎت
ذات اﻟﺼﻠﺔﻣﻦﺗﺎرﻳﺦ اﻟﺜﻘﺎﻓﺔ اﻟﺒﴩﻳﺔ اﻟﺘﻲﺗُﺸﻜﻞ املﻨﺎﻗﺸﺔ اﻟﻌﺎﻣﺔ اﻟﺤﺎﻟﻴﺔﺣﻮل اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ.ﻓﻠﻴﺴﺖﻫﺬهﻫﻲ املﺮة اﻷوﱃ اﻟﺘﻲﻳﺘﺴﺎءلﻓﻴﻬﺎ اﻟﻨﺎسﻋﻦﻣُﺴﺘﻘﺒﻞ اﻟﺒﴩﻳﺔ
وﻣُﺴﺘﻘﺒﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ. وﻣﻬﻤﺎﻛﺎﻧﺖﺑﻌﺾ اﻷﻓﻜﺎر املﺘﻌﻠﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺒﺪو
ﻏﺮﻳﺒﺔ،ﻓﺈﻧﻨﺎﻳُﻤﻜﻨﻨﺎ اﺳﺘﻜﺸﺎفﺻِﻠﺘﻬﺎﺑﺄﻓﻜﺎر وﴎدﻳﺎت أﻛﺜﺮﺷﻬﺮةﺗﻮﺟَﺪﰲ وﻋﻴﻨﺎ
اﻟﺠﻤﻌﻲ، أوﺑﺸﻜﻞٍ أدق،ﰲ اﻟﻮﻋﻲ اﻟﺠﻤﺎﻋﻲﻟﻠﻐﺮب.
أوﻻً ،ﻫﻨﺎكﺗﺎرﻳﺦﻃﻮﻳﻞﻟﻠﺘﻔﻜريﰲ اﻟﺒﴩ واﻵﻻت أو املﺨﻠﻮﻗﺎت اﻻﺻﻄﻨﺎﻋﻴﺔﰲ
اﻟﺜﻘﺎﻓﺎت اﻟﻐﺮﺑﻴﺔ وﻏري اﻟﻐﺮﺑﻴﺔﻋﲆﺣﺪﱟﺳﻮاء.ﻳُﻤﻜﻦ اﻟﻌﺜﻮرﻋﲆﻓﻜﺮة إﻧﺸﺎءﻛﺎﺋﻨﺎت
ﺣﻴﺔﻣﻦﻣﺎدةﻏريﺣﻴﺔﰲﻗﺼﺺ اﻟﺨﻠﻖﰲ اﻟﺜﻘﺎﻓﺎت اﻟﺴﻮﻣﺮﻳﺔ واﻟﺼﻴﻨﻴﺔ واﻟﻴﻬﻮدﻳﺔ
اﺻﻄﻨﺎﻋﻴني، وﺧﺎﺻﺔ
واملﺴﻴﺤﻴﺔ واﻹﺳﻼﻣﻴﺔ.ﻓﻘﺪﻛﺎﻧﺖﻟﺪى اﻹﻏﺮﻳﻖﻓﻜﺮة إﻧﺸﺎءﺑﴩَ
اﻟﻨﺴﺎء اﻻﺻﻄﻨﺎﻋﻴﺎت.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ اﻹﻟﻴﺎذة،ﻳُﻘﺎل إنﻫﻴﻔﺎﻳﺴﺘﻮسﻳﻘﻮمﻋﲆ
ﺧﺪﻣﺘﻪﺧَﺪَمﻣﺼﻨﻮﻋﻮنﻣﻦ اﻟﺬﻫﺐﻳُﺸﺒﻬﻮن اﻟﻨﺴﺎء. وﰲ أﺳﻄﻮرةﺑﻴﺠﻤﺎﻟﻴﻮن اﻟﺸﻬرية،
ﻳﻘﻊ اﻟﻨﺤﱠﺎتﰲﺣُﺐﺗﻤﺜﺎل اﻣﺮأةﺻﻨَﻌَﻪﻣﻦ اﻟﻌﺎج. وﻳﺘﻤﻨﱠﻰ أنﺗﺪبﱠﻓﻴﻪ اﻟﺮوح وﻳُﺼﺒﺢ
اﻣﺮأةﺣﻘﻴﻘﻴﺔ،ﻓﺘُﺤﻘﱢﻖﻟﻪ اﻹﻟﻬﺔ أﻓﺮودﻳﺖ أُﻣﻨﻴﺘﻪ:ﻓﺘﺼﺒﺢﺷﻔﺘﺎﻫﺎ داﻓﺌﺘَني وﺟﺴﺪُﻫﺎﻧﺎﻋﻤًﺎ.
وﻳُﻤﻜﻨﻨﺎﺑﺴﻬﻮﻟﺔﻫﻨﺎﻣﻼﺣﻈﺔ اﻟﺼﱢﻠﺔﺑني ذﻟﻚ وﺑني اﻟﺮوﺑﻮﺗﺎت اﻟﺠﻨﺴﻴﺔ املﻌﺎﴏة.
ﻫﺬه اﻟﴪدﻳﱠﺎتﻻﺗﺄﺗﻲﻓﻘﻂﻣﻦ اﻷﺳﺎﻃري:ﻓﻔﻲﻛﺘﺎﺑﻪ »اﻷوﺗﻮﻣﺎﺗﺎ«،ﻗﺪﱠمﻋﺎﻟِﻢ
اﻟﺮﻳﺎﺿﻴﺎت واملﻬﻨﺪس اﻹﻏﺮﻳﻘﻲﻫريون اﻟﺴﻜﻨﺪري )وﻟﺪﻋﺎم ٠١( أداة اﻛﺘﺸﻔَﺖﰲ اﻟﺒﺤﺮ،
وﻫﻲ آﻟﻴﺔ »أﻧﺘﻴﻜﻴﺜريا«، اﻟﺘﻲﺗُﺤﺪد أﻧﻬﺎﻛﻤﺒﻴﻮﺗﺮﺗﻨﺎﻇُﺮي إﻏﺮﻳﻘﻲﻳﻌﺘﻤﺪﻋﲆ آﻟﻴﺔﻣُﻌﻘﱠﺪة
ﻣﻦ اﻟﱰوس واملُﺴﻨﱠﻨﺎت. وﻟﻜﻦ اﻟﻘﺼﺺ اﻟﺨﻴﺎﻟﻴﺔ اﻟﺘﻲﺗﺠﻌﻞ اﻵﻻتﺗُﺸﺒِﻪ اﻟﺒﴩﺗﺴﻠُﺐ
أﻟﺒﺎﺑﻨﺎﺑﺸﻜﻞٍﺧﺎص.ﻓﻠﻨﺄﺧﺬ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل، أﺳﻄﻮرة اﻟﺠﻮﻟﻴﻢ: وﺣﺶﻣﺼﻨﻮعﻣﻦ
اﻟﻄنيﺻﻨَﻌَﻪﺣﺎﺧﺎمﰲ اﻟﻘﺮن اﻟﺴﺎدسﻋﴩ،ﺛﻢﻓﻘَﺪَ اﻟﺴﻴﻄﺮةﻋﻠﻴﻪ.ﻫﻨﺎﻧﻮاﺟِﻪُﻧﺴﺨﺔ
ﻣُﺒﻜﱢﺮةﻣﻦﻣﺸﻜﻠﺔ اﻟﺘﺤﻜﱡﻢ. وﻳﻤﻜﻦﺗﻔﺴري أﺳﻄﻮرةﺑﺮوﻣﻴﺜﻴﻮسﺑﻬﺬه اﻟﻄﺮﻳﻘﺔ أﻳﻀًﺎ؛ إذ
ﻳﴪق اﻟﻨﺎرﻣﻦ اﻵﻟﻬﺔ وﻳُﻌﻄﻴﻬﺎ إﱃ اﻟﺒﴩ،ﻟﻜﻨﻪﻳُﻌﺎﻗَﺐﺑﻌﺪ ذﻟﻚ. وﻋﻘﻮﺑﺘﻪ اﻷﺑﺪﻳﺔﻫﻲ أن
ﻳُﺮﺑﻂﺑﺼﺨﺮةٍﺑﻴﻨﻤﺎﻳﺄﻛﻞ اﻟﻨﴪﻛﺒِﺪَهﻛﻞﱠﻳﻮم. وﻗﺪﻛﺎن اﻟﺪرس اﻟﻘﺪﻳﻢﻣﻦﻫﺬه اﻷﺳﻄﻮرة
ﻫﻮ اﻟﺘﺤﺬﻳﺮﻣﻦ اﻟﻐﻄﺮﺳﺔ:ﻓﻬﺬه اﻟﻘﺪراتﻟﻴﺴﺖﻣُﻘﺪﱠرةﻟﻠﺒﴩ.
وﻣﻊ ذﻟﻚ،ﰲ رواﻳﺔﻣﺎريﺷﻴﲇ »ﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ« — اﻟﺘﻲﺗﺤﻤﻞ اﻟﻌﻨﻮان اﻟﻔﺮﻋﻲ
اﻟﺪال »ﺑﺮوﻣﻴﺜﻴﻮس اﻟﺤﺪﻳﺚ« —ﻳُﺼﺒﺢ إﻧﺸﺎءﺣﻴﺎة ذﻛﻴﺔﻣﻦﻣﺎدةﻏريﺣﻴﱠﺔﻣﴩوﻋًﺎ
23</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻋﻠﻤﻴٍّﺎﺣﺪﻳﺜًﺎ.ﺣﻴﺚﻳﻨﺸﺊ اﻟﻌﺎﻟﻢﻓﻴﻜﺘﻮرﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦﻛﺎﺋﻨًﺎﺷﺒﻴﻬًﺎﺑﺎﻹﻧﺴﺎنﻣﻦ أﺟﺰاء
اﻟﺠﺜﺚ،ﻟﻜﻨﻪﻳﻔﻘﺪ اﻟﺴﻴﻄﺮةﻋﻠﻴﻪ. وﻣﻊ أن اﻟﺤﺎﺧﺎم اﺳﺘﻄﺎع أنﻳُﺴﻴﻄﺮﻋﲆ اﻟﺠﻮﻟﻴﻢﰲ
اﻟﻨﻬﺎﻳﺔ،ﻓﺈن اﻷﻣﺮﻟﻴﺲﻛﺬﻟﻚﰲﻫﺬه اﻟﺤﺎﻟﺔ. وﻳﻤﻜﻦ اﻋﺘﺒﺎرﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ رواﻳﺔ روﻣﺎﻧﺴﻴﺔ
ﺗُﺤﺬﱢرﻣﻦ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺤﺪﻳﺜﺔ، وﻟﻜﻨﻬﺎﺗﺴﺘﻨﺪ إﱃ اﻟﻌﻠﻢﰲ زﻣﻨِﻬﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻠﻌﺐ
اﺳﺘﺨﺪام اﻟﻜﻬﺮﺑﺎء — وﻫﻲﺗﻘﻨﻴﺔﺟﺪﻳﺪةﺟﺪٍّاﰲ ذﻟﻚ اﻟﻮﻗﺖ — دورًاﻣﻬﻤٍّﺎ؛ إذﺗُﺴﺘﺨﺪَم
ﻹﺣﻴﺎء اﻟﺠﺜﺔ.ﻛﻤﺎ أﻧﻬﺎﺗُﺸري إﱃ املﻐﻨﺎﻃﻴﺴﻴﺔ وﻋِﻠﻢ اﻟﺘﴩﻳﺢ.ﰲ ذﻟﻚ اﻟﻮﻗﺖ،ﻛﺎن املﻔﻜﱢﺮون
واﻟﻜﺘﱠﺎبﻳﻨﺎﻗﺸﻮنﻃﺒﻴﻌﺔ اﻟﺤﻴﺎة وأﺻﻠﻬﺎ.ﻣﺎﻗﻮة اﻟﺤﻴﺎة؟ﻟﻘﺪﺗﺄﺛﺮتﻣﺎريﺷﻴﲇﺑﻌﻠﻮم
وﺗُﻈﻬﺮ اﻟﻘﺼﺔﻛﻴﻒﻛﺎن اﻟﺮوﻣﺎﻧﺴﻴﻮنﰲ اﻟﻘﺮن اﻟﺘﺎﺳﻊﻋﴩﻣﻔﺘﻮﻧنيﰲﻛﺜريٍ2.ﻋﴫﻫﺎ
ﻣﻦ اﻷﺣﻴﺎنﺑﺎﻟﻌﻠﻢ،ﻓﻀﻼًﻋﻦ أﻣﻠﻬﻢﰲ أنﻳُﺤﺮﱢرﻧﺎ اﻟﺸﱢﻌﺮ واﻷدبﻣﻦ اﻟﺠﻮاﻧﺐ اﻷﻛﺜﺮﻇُﻠﻤﺔً
(.ﻳﺠﺐ أﻻﱠﻧﻌﺘﱪﻫﺬه اﻟﺮواﻳﺔﺑﺎﻟﴬورةﺿﺪ اﻟﻌﻠﻢCoeckelbergh 2017)ﰲ اﻟﺤﺪاﺛﺔ
واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ؛ إذﻳﺒﺪو أن اﻟﺮﺳﺎﻟﺔ اﻟﺮﺋﻴﺴﻴﺔ اﻟﺘﻲﺗﺤﺮصﻋﲆﺗﻮﺻﻴﻠﻬﺎﻫﻲ أن اﻟﻌﻠﻤﺎء
ﻳﻨﺒﻐﻲ أنﻳﺘﺤﻤﻠﻮاﻣﺴﺌﻮﻟﻴﺔ اﺧﱰاﻋﺎﺗﻬﻢ.ﻳﻬﺮب اﻟﻮﺣﺶ، وﻟﻜﻨﻪﻳﻔﻌﻞ ذﻟﻚﻷنﺻﺎﻧﻌﻪ
ﻳﺮﻓﻀﻪ.ﻳﺠﺐ أنﻧﺘﺬﻛﱠﺮﻫﺬا اﻟﺪرسﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖﺑﺄﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻣﻊ ذﻟﻚ،
ﺗﺆﻛﱢﺪ اﻟﺮواﻳﺔﺑﻮﺿﻮحﺧﻄﺮ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺘﻲﺗﺨﺮجﻋﻦ اﻟﺴﻴﻄﺮة، وﻋﲆ وﺟﻪ اﻟﺨﺼﻮص
ﺧﻄﺮ اﻟﺒﴩ اﻻﺻﻄﻨﺎﻋﻴني اﻟﺬﻳﻦﻳُﺼﻴﺒﻬﻢ اﻟﺠﻨﻮن.ﺗﻌﻮدﻫﺬه املﺨﺎوفﻟﻠﻈﻬﻮرﻋﲆ اﻟﺴﻄﺢ
ﰲ اﻟﻘﻠﻖ املُﻌﺎﴏﻣﻦ أنﻳﺨﺮج اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﻦ اﻟﺴﻴﻄﺮة.
— «ﰲ رواﻳﺔﻣﺎريﺷﻴﲇ »ﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ« — اﻟﺘﻲﺗﺤﻤﻞ اﻟﻌﻨﻮان اﻟﻔﺮﻋﻲ اﻟﺪال »ﺑﺮوﻣﻴﺜﻴﻮس اﻟﺤﺪﻳﺚ
ﻳُﺼﺒﺢ إﻧﺸﺎءﺣﻴﺎة ذﻛﻴﺔﻣﻦﻣﺎدةﻏريﺣﻴﺔﻣﴩوﻋًﺎﻋﻠﻤﻴٍّﺎﺣﺪﻳﺜًﺎ.
وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻛﻤﺎﻫﻮ اﻟﺤﺎلﰲ رواﻳﺔ »ﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ« وأﺳﻄﻮرة »اﻟﺠﻮﻟﻴﻢ«،ﺗﻈﻬﺮ
ﴎدﻳﺔ املﻨﺎﻓﺴﺔ:ﻓﺎملﺨﻠﻮﻗﺎت اﻻﺻﻄﻨﺎﻋﻴﺔﺗﺘﻨﺎﻓﺲﻣﻊ اﻹﻧﺴﺎن. وﺗﺴﺘﻤﺮﱡﻫﺬه اﻟﴪدﻳﺔﰲ
ﺗﺸﻜﻴﻞﺧﻴﺎﻟﻨﺎ اﻟﻌﻠﻤﻲﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻨﻬﺎ أﻳﻀًﺎﺗﺆﺛﱢﺮﻋﲆﺗﻔﻜريﻧﺎ املُﻌﺎﴏ
ﰲ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻣﺜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺮوﺑﻮﺗﺎت.ﻓﻠﻨﺄﺧُﺬﻣﴪﺣﻴﺔ »روﺑﻮﺗﺎت روﺳﻮم
اﻟﻌﺎملﻴﺔ« اﻟﺘﻲﻛﺘﺒﺖﻋﺎم ٠٢٩١ﻣﺜﺎﻻً ، وﻫﻲﺗﺘﻨﺎولﻗﺼﺔ اﻟﺮوﺑﻮﺗﺎت اﻟﻌﺒﻴﺪ اﻟﺘﻲﺗﺘﻤﺮﱠد
ﻋﲆﺳﻴﺪﻫﺎ وﺗﺜﻮرﻋﻠﻴﻪ، أوﻓﻴﻠﻢ »١٠٠٢:ﺳﺒﻴﺲ أودﻳﴘ« )١٠٠٢: أودﻳﺴﺔ اﻟﻔﻀﺎء(
اﻟﺬي أﻧﺘﺞﻋﺎم ٨٦٩١ واﻟﺬي ذﻛﺮﻧﺎهﻣﻦﻗﺒﻞُ، وﻳﺘﺤﺪﱠثﻋﻦ ذﻛﺎء اﺻﻄﻨﺎﻋﻲﻳﺒﺪأﰲﻗﺘﻞ
ﻃﺎﻗﻢ املﺮﻛﺒﺔ اﻟﻔﻀﺎﺋﻴﺔﻟﺘﺤﻘﻴﻖﻣﻬﻤﱠﺘﻪ، أوﻓﻴﻠﻢ »إﻛﺲﻣﺎﻛﻴﻨﺎ« اﻟﺬي أﻧﺘﺞﻋﺎم ٥١٠٢
24</p>
<p>اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻟﻮﺣﻮش وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻳﺮويﻗﺼﺔ روﺑﻮت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ »أﻓﺎ« اﻟﺘﻲﺗﻨﻘﻠﺐﻋﲆﺻﺎﻧﻌﻬﺎ.ﻛﻤﺎﻳﻨﺪرجﺗﺤﺖ
ﴎدﻳﺔ اﻵﻻت اﻟﺘﻲﺗﺘﻤﺮﱠدﻋﻠﻴﻨﺎﻣﺠﻤﻮﻋﺔ أﻓﻼم »املُﺪﻣﱢﺮ« )ﺗﺮﻣﻴﻨﻴﺘﻮر(. وﻗﺪ وﺻﻒﻛﺎﺗﺐ
اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ أﻳﺰاك أﺳﻴﻤﻮفﻫﺬا اﻟﺨﻮفﺑ »ﻋﻘﺪةﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ«: اﻟﺨﻮفﻣﻦ اﻟﺮوﺑﻮﺗﺎت.
وﻳﺮﺗﺒﻂﻫﺬا أﻳﻀًﺎﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻴﻮم. وﻫﻮ أﻣﺮﻳﺘﻌنيﱠﻋﲆ اﻟﻌﻠﻤﺎء واملُﺴﺘﺜﻤﺮﻳﻦ
اﻟﺘﻌﺎﻣُﻞﻣﻌﻪ.ﻓﺒﻌﻀﻬﻢﻳُﺤﺎرﺑﻮنﻫﺬا اﻟﺨﻮف؛ وﺑﻌﻀﻬﻢﻳﺴﺎﻋﺪﰲﺧﻠﻘﻪ واﻟﺤﻔﺎظﻋﻠﻴﻪ.
وﻗﺪ أﴍتُﺑﺎﻟﻔﻌﻞ إﱃﻣﺜﺎل »ﻣﺎﺳﻚ«. وﺛﻤﱠﺔﻣﺜﺎل آﺧَﺮﻋﲆﺷﺨﺼﻴﺔﻣﺆﺛﺮةﺳﺎﻫﻤﺖﰲ
ﻧﴩ اﻟﺨﻮفﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻫﻮﻋﺎﻟﻢ اﻟﻔﻴﺰﻳﺎءﺳﺘﻴﻔﻦﻫﻮﻛﻴﻨﺞ، اﻟﺬيﴏﱠحﰲ
ﻋﺎم ٧١٠٢ﺑﺄنﺧﻠﻖ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻤﻜﻦ أنﻳﻜﻮن أﺳﻮأﺣﺪَثٍﰲﺗﺎرﻳﺦﺣﻀﺎرﺗﻨﺎ
(. إن »ﻋﻘﺪةﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ«ﻣﻨﺘﴩة وﻋﻤﻴﻘﺔ اﻟﺠﺬورﰲ اﻟﺜﻘﺎﻓﺔ واﻟﺤﻀﺎرةKharpal 2017)
.اﻟﻐﺮﺑﻴﺔ
اﻟﺘﺴﺎﻣﻲ وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﺑﺴﺒﺐ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺛﻤﺔﻣﻘﺪﻣﺎتﻷﻓﻜﺎرﻣﺜﻞ »ﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ« و»اﻟﺘﻔﺮﱡد اﻟﺘﻜﻨﻮﻟﻮﺟﻲ«ﰲﺗﺎرﻳﺦ اﻟﺘﻔﻜري
اﻟﺪﻳﻨﻲ واﻟﻔﻠﺴﻔﻲ اﻟﻐﺮﺑﻲ أوﻋﲆ اﻷﻗﻞﺗﻮﺟَﺪ أﻓﻜﺎرﻣﺸﺎﺑﻬﺔﻟﻬﺎ، وﻻﺳﻴﻤﺎﰲ اﻟﺘﻘﺎﻟﻴﺪ
اﻟﻴﻬﻮدﻳﺔ املﺴﻴﺤﻴﺔ وﰲ اﻟﻔﻜﺮ اﻷﻓﻼﻃﻮﻧﻲ. وﻋﲆﻋﻜﺲﻣﺎﻳﻌﺘﻘﺪه اﻟﻜﺜريون،ﻓﺈن اﻟﺪﻳﻦ
واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻛﺎﻧﺎ داﺋﻤًﺎﻣُﱰاﺑﻄَنيﰲﺗﺎرﻳﺦ اﻟﺜﻘﺎﻓﺔ اﻟﻐﺮﺑﻴﺔ. ودﻋﻮﻧﻲ أﺣﴫﻧﻘﺎﳾﻫﻨﺎﰲ
اﻟﺘﺴﺎﻣﻲ وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢ.
ﰲ اﻟﺪﻳﻦ اﻟﻼﻫﻮﺗﻲ،ﻳﻘﺼﺪﺑﺎﻟﺘﱠﺴﺎﻣﻲ أن اﻹﻟﻪ »ﻓﻮق« اﻟﻌﺎﻟﻢ املﺎدي واﻟﺠﺴﺪي وﻣُﺴﺘﻘﻞ
ﻋﻨﻪ، وﻫﻲﻓﻜﺮةﻣُﻨﺎﻗﻀﺔﻟﻔﻜﺮة أﻧﻪﻣﻮﺟﻮدﰲ اﻟﻌﺎﻟَﻢ وأﻧﻪﺟﺰءﻣﻨﻪ )اﻟﺤﻠﻮﻟﻴﺔ(.ﰲ اﻟﺘﻘﻠﻴﺪ
اﻟﻴﻬﻮدي املﺴﻴﺤﻲ اﻷﺣﺎدي اﻟﻼﻫﻮﺗﻲ،ﻳُﺮىﷲﻋﲆ أﻧﻪﻳﺘﺴﺎﻣﻰﻓﻮقﺧﻠﻘﻪ. وﻳُﻤﻜﻦﰲ
اﻟﻮﻗﺖﻧﻔﺴﻪ أﻳﻀًﺎ أنﻳُﺮىﻋﲆ أﻧﻪﻣُﺘﻐﻠﻐﻞﰲﻛﻞﻣﺨﻠﻮﻗﺎﺗِﻪ وﰲﻛﻞ اﻟﻜﺎﺋﻨﺎت )أي إﻧﻪ
ﻳﺤﻞﱡﻓﻴﻬﺎ(، وﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ اﻟﻼﻫﻮت اﻟﻜﺎﺛﻮﻟﻴﻜﻲ،ﻳُﻔﻬﻢﷲﻛﻤﺎﻳﺘﺠﲆﱠﻣﻦﺧﻼل
اﺑﻨﻪ )املﺴﻴﺢ( واﻟﺮوح اﻟﻘﺪس. وﻳﺒﺪو أنﴎدﻳﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺘﻲﺗﺘﺠﲆﻓﻴﻬﺎ
»ﻋﻘﺪةﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ«ﺗﺆﻛﺪﻓﻜﺮة اﻟﺘﺴﺎﻣﻲﺑﻤﻌﻨﻰ أنﻫﻨﺎك اﻧﻔﺼﺎﻻً أوﻓﺠﻮةﺑني اﻟﺨﺎﻟﻖ
واملﺨﻠﻮق )ﺑني اﻹﻧﺴﺎن اﻹﻟﻪ واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ(، دون إﻋﻄﺎء اﻟﻜﺜريﻣﻦ اﻷﻣﻞﰲ إﻣﻜﺎﻧﻴﺔ
ﺗﺠﺎوزﻫﺬه اﻟﻔﺠﻮة.
25</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻋﲆﻋﻜﺲﻣﺎﻳﻌﺘﻘﺪه اﻟﻜﺜريون،ﻓﺈن اﻟﺪﻳﻦ واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻛﺎﻧﺎ داﺋﻤًﺎﻣُﱰاﺑﻄَنيﰲﺗﺎرﻳﺦ اﻟﺜﻘﺎﻓﺔ
اﻟﻐﺮﺑﻴﺔ.
اﻟﺘﺴﺎﻣﻲﻳﻤﻜﻦ أﻳﻀًﺎ أنﻳُﺸري إﱃﺗﺠﺎوز اﻟﺤﺪود، أوﺗﺨﻄﱢﻲﳾءٍﻣﺎ.ﰲ اﻟﺘﺎرﻳﺦ
اﻟﺪﻳﻨﻲ واﻟﻔﻠﺴﻔﻲ اﻟﻐﺮﺑﻲ، اﺗﺨﺬتﻫﺬه اﻟﻔﻜﺮةﰲﻛﺜريٍﻣﻦ اﻷﺣﻴﺎنﺷﻜﻞَ اﻟﺴﻤﻮﻓﻮق
اﻟﻌﺎﻟﻢ املﺎدي واﻟﺠﺴﺪي وﺗﺠﺎوُزﺣﺪوده.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﻣﻨﻄﻘﺔ اﻟﺒﺤﺮ املﺘﻮﺳﱢﻂﰲ
اﻟﻘﺮن اﻟﺜﺎﻧﻲ املﻴﻼدي،ﻛﺎﻧﺖ اﻟﻐﻨﻮﺻﻴﺔﺗﻨﻈﺮ إﱃ املﺎدﱠةﺟﻤﻴﻌﻬﺎﺑﺎﻋﺘﺒﺎرﻫﺎﴍٍّا، وﺗﻬﺪف إﱃ
ﺗﺤﺮﻳﺮ اﻟﺸﻌﻠﺔ اﻹﻟﻬﻴﺔﻣﻦ اﻟﺠﺴﺪ اﻟﺒﴩي. وﰲ وﻗﺖٍ أﺳﺒَﻖ، رأى أﻓﻼﻃﻮن اﻟﺠﺴﺪﺳﺠﻨًﺎ
ﻟﻠﺮوح. وﻋﲆﻋﻜﺲ اﻟﺠﺴﺪ،ﻛﺎنﻳﻨﻈﺮ إﱃ اﻟﺮوحﻋﲆ أﻧﻬﺎﺧﺎﻟﺪة. وﰲ املﻴﺘﺎﻓﻴﺰﻳﻘﺎ اﻟﺨﺎﺻﺔ
ﺑﻪ،ﻣﻴﱠﺰ أﻓﻼﻃﻮنﺑني اﻷﺷﻜﺎل، اﻟﺘﻲﻫﻲ أﺑﺪﻳﺔ، واﻷﺷﻴﺎء املﻮﺟﻮدةﰲ اﻟﻌﺎﻟﻢ، اﻟﺘﻲﺗﺘﻐري؛
ﻓﺎﻷوﱃﺗﺘﺴﺎﻣﻰﻓﻮق اﻷﺧرية وﺗﺘﺠﺎوزﻫﺎ. وﻫﻨﺎك أﻓﻜﺎرﰲﻣﺒﺪأﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﺗُﺬﻛﱢﺮﻧﺎ
ﺑﻬﺬا.ﻓﻬﻲﺗُﺤﺎﻓﻆﻋﲆﻫﺪف اﻟﺘﺴﺎﻣﻲﺑﻤﻌﻨﻰﺗﺠﺎوز اﻟﻘﻴﻮد اﻟﺒﴩﻳﺔ، وﻟﻴﺲﻫﺬاﻓﺤﺴﺐ،
ﺑﻞ إن اﻟﻄﺮق اﻟﺨﺎﺻﺔ اﻟﺘﻲﻳُﻔﱰض أنﻳﺤﺪثﺑﻬﺎﻫﺬا اﻟﺘﺴﺎﻣﻲﺗﺴﺘﺤﴬ أﻓﻼﻃﻮن
واﻟﻐﻨﻮﺻﻴﺔ:ﻟﺘﺤﻘﻴﻖ اﻟﺨﻠﻮد،ﻳﺠﺐ اﻟﺘﺴﺎﻣﻲﻓﻮق اﻟﺠﺴﺪ اﻟﺒﻴﻮﻟﻮﺟﻲﻋﻦﻃﺮﻳﻖﺗﺤﻤﻴﻞ
أدواتٍ اﺻﻄﻨﺎﻋﻴﺔ وﺗﻄﻮﻳﺮﻫﺎ.ﺑﺸﻜﻞٍ أﻛﺜﺮﻋﻤﻮﻣﻴﺔ،ﻋﻨﺪﻣﺎﻳَﺴﺘﺨﺪِم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
واﻟﻌﻠﻮم واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ ذات اﻟﺼﻠﺔ اﻟﺮﻳﺎﺿﻴﺎتﻻﺳﺘﺨﻼص أﺷﻜﺎلٍ أﻛﺜﺮﻧﻘﺎءًﻣﻦ اﻟﻌﺎﻟَﻢ
املﺎدي اﻟﻔﻮﺿﻮي،ﻳﻤﻜﻦﺗﻔﺴري ذﻟﻚﻋﲆ أﻧﻪﺑﺮﻧﺎﻣﺞ أﻓﻼﻃﻮﻧﻲﻳﺘﺤﻘﱠﻖﺑﻮاﺳﻄﺔ وﺳﺎﺋﻞ
ﺗﻜﻨﻮﻟﻮﺟﻴﺔ. وﻣﻦﻫﻨﺎﻳﺘﺒنيﱠ أنﺧﻮارزﻣﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻲ آﻟﺔ أﻓﻼﻃﻮﻧﻴﺔﺗﺴﺘﺨﻠِﺺ
ﺷﻜﻼً )أوﻧﻤﻮذﺟًﺎ(ﻣﻦﻋﺎﻟَﻢ اﻟﻈﻮاﻫﺮ )اﻟﺒﻴﺎﻧﺎت(.
اﻟﺘﺴﺎﻣﻲﻳﻤﻜﻦ أﻳﻀًﺎ أنﻳﻌﻨﻲﺗﺠﺎوز اﻟﺤﺎﻟﺔ اﻹﻧﺴﺎﻧﻴﺔ.ﰲ اﻟﺘﻘﻠﻴﺪ املﺴﻴﺤﻲ،ﻳﻤﻜﻦ
أنﻳﺄﺧﺬﻫﺬاﺷﻜﻞﻣﺤﺎوﻟﺔ رأب اﻟﻔﺠﻮةﺑنيﷲ واﻟﺒﴩﻣﻦﺧﻼلﺗﺤﻮﻳﻞ اﻟﺒﴩ إﱃ آﻟﻬﺔ،
(. وﻟﻜﻦNoble 1997)رﺑﻤﺎﻋﻦﻃﺮﻳﻖ اﺳﺘﻌﺎدةﺗﺸﺎﺑُﻬﻬﻢﻣﻊ اﻵﻟﻬﺔ وﻛﻤﺎﻟﻬﻢ اﻷﺻﲇ
ﺳَﻌْﻲﻣﺆﻳﺪيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﻟﻠﺨﻠﻮدﻟﻴﺲﺟﺪﻳﺪًا،ﺑﻞﻳﻤﻜﻦﺗﺘﺒﱡﻌﻪ إﱃ اﻟﻌﺼﻮر اﻟﻘﺪﻳﻤﺔ.
إذﻳُﻤﻜﻨﻨﺎ أنﻧﺠﺪهﰲ املﻴﺜﻮﻟﻮﺟﻴﺎ املﻴﺰوﺑﻮﺗﺎﻣﻴﺔ )اﻷﺳﺎﻃري اﻟﺘﻲﺗﺄﺗﻲﻣﻦﻣﻨﻄﻘﺔﻣﺎﺑني
اﻟﻨﻬﺮَﻳﻦ(:ﺗﺤﻜﻲﻟﻨﺎﻗﺼﺔ »ﻣﻠﺤﻤﺔﺟﻠﺠﺎﻣﺶ«، وﻫﻲ واﺣﺪةﻣﻦ أﻗﺪم اﻟﻘﺼﺺ املﻜﺘﻮﺑﺔﻋﻦ
اﻟﺒﴩﻳﺔ،ﻋﻦﻣﻠﻚ أوروك )ﺟﻠﺠﺎﻣﺶ(، اﻟﺬيﻳﺒﺤﺚﻋﻦ اﻟﺨﻠﻮدﺑﻌﺪ وﻓﺎةﺻﺪﻳﻘﻪ إﻧﻜﻴﺪو.
وﻟﻜﻨﻪﻳﻔﺸﻞﰲ اﻟﻌﺜﻮرﻋﻠﻴﻪ: وﻣﻊ ذﻟﻚ،ﻳﻨﺠﺢﰲ اﻟﺤﺼﻮلﻋﲆﻧﺒﺘﺔٍﻳُﻘﺎل إﻧﻬﺎﺗُﻌﻴﺪ
اﻟﺸﺒﺎب، وﻟﻜﻦﺗﴪﻗﻬﺎ أﻓﻌﻰ، وﰲ اﻟﻨﻬﺎﻳﺔ،ﻳﺘﻌنيﱠﻋﻠﻴﻪ أنﻳﺘﻌﻠﱠﻢ اﻟﺪرسﺑﺄنﻋﻠﻴﻪﻣﻮاﺟﻬﺔ
26</p>
<p>اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻟﻮﺣﻮش وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺣﻘﻴﻘﺔﻣﻮﺗِﻪﻫﻮﺷﺨﺼﻴٍّﺎ؛ إذ إنﺳﻌﻴﻪ إﱃ اﻟﺨﻠﻮدﺑﻼﺟﺪوى.ﻋﲆﻣﺮﱢ اﻟﺘﺎرﻳﺦ،ﻛﺎن اﻟﻨﺎس
ﻳﺒﺤﺜﻮنﻋﻦ إﻛﺴري اﻟﺤﻴﺎة. واﻟﻴﻮم،ﺗﺒﺤﺚ اﻟﻌﻠﻮمﻋﻦﻋﻼﺟﺎتٍﻣﻀﺎدﱠةﻟﻠﺸﻴﺨﻮﺧﺔ. وﻣِﻦ
ﻫﺬا املﻨﻄﻠﻖ،ﻓﺈنﺳﻌﻲﻣﺆﻳﺪيﻣﺒﺪأﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ إﱃ اﻟﺨﻠﻮد أو إﱃ إﻃﺎﻟﺔ اﻟﻌﻤﺮﻟﻴﺲ
ﺟﺪﻳﺪًا أوﻏﺮﻳﺒًﺎ؛ﺑﻞﻫﻮ واﺣﺪﻣﻦ أﻗﺪم أﺣﻼم اﻟﺒﴩﻳﺔ وأﻫﺪاف اﻟﻌﻠﻢ املُﻌﺎﴏ. وﰲ أﻳﺪي
ﻣﺆﻳﺪيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ،ﻳُﺼﺒﺢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻮ أداة اﻟﺘﺠﺎوز اﻟﺘﻲﺗَﻌِﺪﻧﺎﺑﺎﻟﺨﻠﻮد.
ﻣﻦ املﻔﺎﻫﻴﻢ اﻟﻘﺪﻳﻤﺔ اﻷﺧﺮى اﻟﺘﻲﺗﺴﺎﻋﺪﻧﺎﻋﲆ وﺿﻊ أﻓﻜﺎرﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﰲ
ﺳﻴﺎﻗﻬﺎ، وﻻﺳﻴﻤﺎﻓﻜﺮة اﻟﺘﻔﺮﱡد اﻟﺘﻜﻨﻮﻟﻮﺟﻲ،ﻣﻔﻬﻮمﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢ )أﺑﻮﻛﺎﻟﻴﺒﺲ( واﻷﺧﺮوﻳﺔ.
وﻣﺼﻄﻠﺢ »أﺑﻮﻛﺎﻟﻴﺒﺲ«ﻋﻨﺪ اﻹﻏﺮﻳﻖ اﻟﻘﺪﻣﺎء، اﻟﺬيﻳﻠﻌﺐ أﻳﻀًﺎ دورًاﰲ اﻟﻔﻜﺮ اﻟﻴﻬﻮدي
واملﺴﻴﺤﻲ،ﻳُﺸري إﱃﻛﺸﻒ اﻟﺤﺠﺎب. وﰲ اﻟﻮﻗﺖ اﻟﺤﺎﴐ،ﻳُﺸريﻫﺬا املﺼﻄﻠﺢﻏﺎﻟﺒًﺎ إﱃ
ﻧﻮعﻣﻌنيﱠﻣﻦ اﻟﻜﺸﻒ: وﻫﻮﻛﺸﻒﺳﻴﻨﺎرﻳﻮﻧﻬﺎﻳﺔ اﻟﺰﻣﺎن أوﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢ. وﰲ اﻟﺴﻴﺎﻗﺎت
اﻟﺪﻳﻨﻴﺔ،ﻧﺠﺪﻣﺼﻄﻠﺢ »اﻷﺧﺮوﻳﺔ«: وﻫﻮﺟﺰءﻣﻦﻋﻠﻢ اﻟﻼﻫﻮتﻳﺘﻌﻠﱠﻖﺑﺎﻷﺣﺪاث اﻟﻨﻬﺎﺋﻴﺔ
ﻟﻠﺘﺎرﻳﺦ واملﺼري اﻟﻨﻬﺎﺋﻲﻟﻠﺒﴩﻳﺔ. وﺗﻨﻄﻮيﻣﻌﻈﻢ اﻷﻓﻜﺎر اﻷﺧﺮوﻳﺔ وﺗﻠﻚ اﻟﺘﻲﺗﺘﻌﻠﱠﻖ
ﺑﻨﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﻋﲆﺗﺨﺮﻳﺐ أوﺗﺪﻣريﺟِﺬري وﻏﺎﻟﺒًﺎﻋﻨﻴﻒﻟﻠﻌﺎﻟﻢ، واﻻﺗﺠﺎهﻧﺤﻮﻣﺴﺘﻮى
أﻋﲆﻣﻦ اﻟﻮاﻗﻊ واﻟﻜﻴﻨﻮﻧﺔ واﻟﻮﻋﻲ. وﻳُﺬﻛﺮﻧﺎ ذﻟﻚ أﻳﻀًﺎﺑﺎﻟﻄﻮاﺋﻒ واﻟﺠﻤﺎﻋﺎت املﺘﻄﺮﻓﺔ
املﺘﺸﺎﺋﻤﺔ اﻟﺘﻲﻛﺎﻧﺖ وﻣﺎﺗﺰالﺗﺘﻨﺒﱠﺄﺑﺎﻟﻜﻮارث وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢ. ورﻏﻢ أنﻣﺆﻳﺪيﺗﺠﺎوز
اﻹﻧﺴﺎﻧﻴﺔﰲ اﻟﻌﺎدةﻟﻴﺲﻟﻬﻢﻋﻼﻗﺔﺑﻤﺜﻞﻫﺬه اﻟﻄﻮاﺋﻒ واملﻤﺎرﺳﺎت اﻟﺪﻳﻨﻴﺔ،ﻓﺈنﻓﻜﺮة
اﻟﺘﻔﺮد اﻟﺘﻜﻨﻮﻟﻮﺟﻲﺗُﺸﺒﻪ إﱃﺣﺪﱟﻣﺎﴎدﻳﺎتﻧﻬﺎﻳﺔ اﻟﻌﺎﻟَﻢ واﻷﺧﺮوﻳﺔ واﻟﺘﻨﺒﺆﺑﺎﻟﻜﻮارث،
وﻫﺬا أﻣﺮ واﺿﺢ.
ﺑﺎﻟﺘﺎﱄ،ﺑﻴﻨﻤﺎﻳﺴﺘﻨﺪﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﻋﻠﻢٍﻣﻦ املُﻔﱰَض أﻧﻪﻻﺧﻴﺎﱄ وﻻ
دﻳﻨﻲ، وﺑﻴﻨﻤﺎﻳﻨﺄىﻣﺆﻳﺪوﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﺑﺄﻧﻔﺴﻬﻢﻋﺎدةًﻋﻦ اﻟﺪﻳﻦ وﻳﺮﻓﻀﻮن أيﱠ اﻗﱰاحٍ
ﺑﺄن أﻋﻤﺎﻟﻬﻢﺗﺴﺘﻨِﺪ إﱃ اﻟﺨﻴﺎل، إﻻ أن اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ واﻷﻓﻜﺎر اﻟﺪﻳﻨﻴﺔ واﻟﻔﻠﺴﻔﻴﺔ اﻟﻘﺪﻳﻤﺔ
ﺗﻠﻌﺐﺑﺎﻟﴬورة دورًاﻣُﻬﻤٍّﺎﻋﻨﺪﻣﺎﻧﻨﺎﻗﺶﻣُﺴﺘﻘﺒﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦﻫﺬا املﻨﻄﻠﻖ.
ﻛﻴﻔﻴﺔﺗﺠﺎوزﴎدﻳﺎت املﻨﺎﻓﺴﺔ وﺗﺠﺎوز اﻟﻀﺠﱠﺔ املُﺜﺎرةﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﻤﻜﻦﻟﻠﻤﺮء أنﻳﺘﺴﺎءل اﻵن:ﻫﻞﻫﻨﺎكﺳﺒُﻞﻟﻠﻨﺠﺎة؟ﻫﻞﻳُﻤﻜﻨﻨﺎﺗﺠﺎوزﴎدﻳﺎت املﻨﺎﻓﺴﺔ
وإﻳﺠﺎدﻃﺮقٍ أﻛﺜﺮ رﺳﻮﺧًﺎﻟﻔﻬﻢﻣﺴﺘﻘﺒﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ املُﻤﺎﺛﻠﺔ؟ أم
إن اﻟﺘﻔﻜري اﻟﻐﺮﺑﻲﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺤﻜﻮمﻋﻠﻴﻪﺑﺎﻟﺒﻘﺎءﰲﺳﺠﻦﻫﺬه املﺨﺎوف
27</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﻌﴫﻳﺔ وﺟﺬورﻫﺎ اﻟﻘﺪﻳﻤﺔ؟ﻫﻞﻳُﻤﻜﻨﻨﺎﺗﺠﺎوز اﻟﻀﺠﺔ املﺜﺎرةﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟
أمﺳﺘﻈﻞﱡ املﻨﺎﻗﺸﺔﻣُﻨﺼَﺒﱠﺔﻋﲆ اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ؟ أﻋﺘﻘﺪ أنﻟﺪَﻳﻨﺎﺳﺒﻼًﻟﻠﻨﺠﺎة.
،رﻏﻢ أنﻣﺆﻳﺪيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﰲ اﻟﻌﺎدةﻟﻴﺲﻟﻬﻢﻋﻼﻗﺔﺑﻤﺜﻞﻫﺬه اﻟﻄﻮاﺋﻒ واملُﻤﺎرﺳﺎت اﻟﺪﻳﻨﻴﺔ
ﻓﺈنﻓﻜﺮة اﻟﺘﻔﺮﱡد اﻟﺘﻜﻨﻮﻟﻮﺟﻲﺗُﺸﺒﻪ إﱃﺣﺪﱟﻣﺎﴎدﻳﺎتﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢ واﻷﺧﺮوﻳﺔ واﻟﺘﻨﺒﺆﺑﺎﻟﻜﻮارث.
أوﻻً ،ﻳﻤﻜﻨﻨﺎﺗﺠﺎوز اﻟﺜﻘﺎﻓﺔ اﻟﻐﺮﺑﻴﺔﻟﻠﻌﺜﻮرﻋﲆ أﻧﻮاعﻣﺨﺘﻠﻔﺔﻣﻦ اﻟﴪدﻳﱠﺎتﻏري
املَﺒﻨﻴﺔﻋﲆ »ﻋﻘﺪةﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ«ﻓﻴﻤﺎﻳﺨﺺ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻃﺮق اﻟﺘﻔﻜريﻏري اﻷﻓﻼﻃﻮﻧﻴﺔ.
ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ اﻟﻴﺎﺑﺎنﺣﻴﺚﺗﺘﺄﺛﺮﺛﻘﺎﻓﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺑﺪﻳﺎﻧﺎت اﻟﻄﺒﻴﻌﺔ أﻛﺜﺮﻣﻦ
اﻟﻐﺮب، وﺗﺤﺪﻳﺪًاﺑﺪﻳﺎﻧﺔ اﻟﺸﻨﺘﻮ، وﺣﻴﺚﺻﻮﱠرت اﻟﺜﻘﺎﻓﺔ اﻟﺸﻌﺒﻴﺔ اﻵﻻتﻛﻤُﺴﺎﻋﺪﻳﻦ،ﻧﺠﺪ
ﻣﻮﻗﻔًﺎ أﻛﺜﺮ ودٍّاﺗﺠﺎه اﻟﺮوﺑﻮﺗﺎت واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻫﻨﺎ،ﻻﻧﺠﺪﻋﻘﺪةﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ.
وﺗﻨﻄﻮيﻃﺮﻳﻘﺔ اﻟﺘﻔﻜري اﻟﺘﻲﻳُﻄﻠﻖﻋﻠﻴﻬﺎ أﺣﻴﺎﻧًﺎ »اﻷرواﺣﻴﺔ«ﻋﲆ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﻤﻜﻦ أﻳﻀًﺎﻣﻦﺣﻴﺚ املﺒﺪأ أنﻳﻤﺘﻠﻚ روﺣًﺎ أوﻧﻔﺴًﺎ، وﻳﻤﻜﻦ أنﻳُﻌﺘﱪَﻣﻘﺪﺳًﺎ. وﻫﺬاﻳﻌﻨﻲ
ﻋﺪم وﺟﻮدﴎدﻳﺔﺗﻨﺎﻓُﺴﻴﺔ؛ وﻋﺪم وﺟﻮد رﻏﺒﺔ أﻓﻼﻃﻮﻧﻴﺔﰲﺗﺠﺎوز املﺎدﻳﺔ واﻟﺪﻓﺎع املُﺴﺘﻤﺮ
ﻋﻦ اﻹﻧﺴﺎنﺑﻮﺻﻔﻪﻛﺎﺋﻨًﺎﻳﺴﻤﻮﻓﻮق اﻵﻟﺔ وﻳﺘﺠﺎوزﻫﺎ، أوﻳﺨﺘﻠﻒﻋﻨﻬﺎ اﺧﺘﻼﻓًﺎﺟﻮﻫﺮﻳٍّﺎ.
ﰲﺣﺪودﻣﻌﺮﻓﺘﻲ،ﻻﺗﺸﺘﻤِﻞ اﻟﺜﻘﺎﻓﺔ اﻟﴩﻗﻴﺔﻋﲆ أﻓﻜﺎرﺣﻮلﻧﻬﺎﻳﺔ اﻟﺰﻣﺎن. وﻋﲆﻋﻜﺲ
اﻟﺪﻳﺎﻧﺎت اﻟﺘﻮﺣﻴﺪﻳﺔ،ﺗﺤﻤﻞ دﻳﺎﻧﺎت اﻟﻄﺒﻴﻌﺔﻓﻬﻤًﺎ دورﻳٍّﺎﻟﻠﺰﻣﻦ. وﺑﺎﻟﺘﺎﱄ،ﻳﻤﻜﻦ أنﻳﺴﺎﻋﺪ
اﻟﻨﻈﺮ إﱃﻣﺎﻫﻮ أﺑﻌﺪﻣﻦ اﻟﺜﻘﺎﻓﺔ اﻟﻐﺮﺑﻴﺔ )أوﰲ واﻗﻊ اﻷﻣﺮ إﱃ املﺎﴈ اﻟﻘﺪﻳﻢﻟﻠﻐﺮب،ﺣﻴﺚ
ﻧﺠﺪ أﻳﻀًﺎ دﻳﺎﻧﺎتﻃﺒﻴﻌﺔ(ﰲ اﻟﺘﻘﻴﻴﻢ اﻟﻨﻘﺪيﻟﻠﴪدﻳﺎت اﻟﺴﺎﺋﺪةﺣﻮلﻣﺴﺘﻘﺒﻞ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ.
ﺛﺎﻧﻴًﺎ:ﻟﺘﺠﺎوز اﻟﻀﺠﺔ املُﺜﺎرةﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺗﺠﻨﱡﺐﺣﴫﻣﻨﺎﻗﺸﺔ أﺧﻼﻗﻴﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ أﺣﻼم املﺴﺘﻘﺒﻞ اﻟﺒﻌﻴﺪ وﻛﻮاﺑﻴﺴﻪ،ﻳُﻤﻜﻨﻨﺎ )١( اﺳﺘﺨﺪام اﻟﻔﻠﺴﻔﺔ
واﻟﻌﻠﻢﻟﻔﺤﺺ وﻣﻨﺎﻗﺸﺔ اﻻﻓﱰاﺿﺎت املﺘﻌﻠﱢﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻹﻧﺴﺎن اﻟﺬيﻳﻠﻌﺐ
دورًاﰲﻫﺬه اﻟﺴﻴﻨﺎرﻳﻮﻫﺎت واملﻨﺎﻗﺸﺎت )ﻣﺜﻞ:ﻫﻞ اﻟﺬﻛﺎء اﻟﻌﺎمﻣُﻤﻜﻦ؟ﻣﺎ اﻟﻔﺎرق
ﺑني اﻹﻧﺴﺎن واﻵﻟﺔ؟ﻣﺎ اﻟﻌﻼﻗﺔﺑني اﻹﻧﺴﺎن واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ؟ﻣﺎ اﻟﻮﺿﻊ اﻷﺧﻼﻗﻲﻟﻠﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ؟(؛ و)٢( اﻟﻨﻈﺮﺑﺘﻔﺼﻴﻞٍ أﻛﺜﺮ إﱃﻣﺎﻫﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﻮﺟﻮد وﻣﺎ
ﻳﻔﻌﻠﻪ اﻟﻴﻮمﰲ اﻟﺘﻄﺒﻴﻘﺎت املﺨﺘﻠﻔﺔ؛ و)٣(ﻣﻨﺎﻗﺸﺔ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ واﻻﺟﺘﻤﺎﻋﻴﺔ اﻷﻛﺜﺮ
واﻗﻌﻴﺔً وإﻟﺤﺎﺣًﺎ اﻟﺘﻲﻳُﺜريﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻛﻤﺎﻳُﻄﺒﻖ اﻟﻴﻮم؛ و)٤( اﻟﺘﻔﻜريﰲﺳﻴﺎﺳﺔ
28</p>
<p>اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻟﻮﺣﻮش وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻠﻤﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ؛ و)٥(ﻃﺮحﺗﺴﺎؤلﻋﻤﺎ إذاﻛﺎن اﻟﱰﻛﻴﺰﻋﲆ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﰲ اﻟﺨﻄﺎب اﻟﺠﻤﺎﻫريي اﻟﺤﺎﱄﻣُﻔﻴﺪًاﰲﺿﻮء املﺸﻜﻼت اﻷﺧﺮى اﻟﺘﻲﺗُﻮاﺟﻬﻨﺎ،
وﻣﺎ إذاﻛﺎنﺗﺮﻛﻴﺰﻧﺎﻳﻨﺒﻐﻲ أنﻳﻨﺼﺐﱠﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺣﺪَه. وﺳﻮفﻧﺘﺒﻊﻫﺬه
املﺴﺎراتﰲ اﻟﻔﺼﻮل اﻟﻘﺎدﻣﺔﻣﻦ اﻟﻜﺘﺎب.
29</p>
</section>
<section id="section-4">
    <h2>كل ما له علاقة بالبشر</h2>
    <div class="page-range">Pages 31-40</div>
    <p>اﻟﻔﺼﻞ اﻟﺜﺎﻟﺚ
ﻛﻞﻣﺎﻟﻪﻋﻼﻗﺔﺑﺎﻟﺒﴩ
ﻫﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎمﻣُﻤﻜﻦ؟
ﻫﻞﻫﻨﺎكﻓﺮوقﺟﻮﻫﺮﻳﺔﺑني اﻹﻧﺴﺎن واﻵﻟﺔ؟
ﺗﻔﱰض رؤﻳﺔ أﻧﺼﺎرﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﻟﻠﻤُﺴﺘﻘﺒﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻲ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم
)أو اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﻮي(ﻣﻤﻜﻦ، وﻟﻜﻦﻫﻞﻫﻮﻛﺬﻟﻚ؟ﺑﻌﺒﺎرةٍ أﺧﺮى،ﻫﻞﻳُﻤﻜﻨﻨﺎ
إﻧﺸﺎء آﻻتﺗﺘﻤﺘﱠﻊﺑﻘﺪراتﻣﻌﺮﻓﻴﺔﺗُﺸﺒﻪﺗﻠﻚ اﻟﺨﺎﺻﺔﺑﺎﻟﺒﴩ؟ إذاﻛﺎﻧﺖ اﻹﺟﺎﺑﺔﻻ،ﻓﺈن
رؤﻳﺔ اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖﺑﺎﻟﻜﺎﻣﻞﺗُﺼﺒﺢﻏري ذاتﺻِﻠﺔﺑﺄﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻓﺈذا
ﻛﺎنﻣِﻦ املُﺴﺘﺤﻴﻞ أنﺗﺘﻤﺘﱠﻊ اﻵﻻتﺑﺎﻟﺬﻛﺎء اﻟﺒﴩي اﻟﻌﺎم،ﻓﺈﻧﻨﺎﻏريﻣُﻀﻄﺮﻳﻦ إﱃ أنﻧﻘﻠﻖ
ﺑﺸﺄن اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ.ﺑﺸﻜﻞٍﻋﺎم،ﻳﺒﺪو أنﺗﻘﻴﻴﻤﻨﺎﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻌﺘﻤِﺪﻋﲆﻓﻬﻤﻨﺎ
ملﺎﻫﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄ وﻣﺎﻳُﻤﻜﻦ أنﻳﺼﺒﺢﻋﻠﻴﻪﰲ املﺴﺘﻘﺒﻞ،ﻛﻤﺎﻳﻌﺘﻤﺪ
ﻋﲆ رؤﻳﺘﻨﺎﻟﻠﻔﺮوقﺑني اﻹﻧﺴﺎن واﻵﻟﺔ.ﻋﲆ اﻷﻗﻞﻣﻨﺬﻣﻨﺘﺼﻒ اﻟﻘﺮن اﻟﻌﴩﻳﻦ،ﻧﺎﻗﺶ
اﻟﻔﻼﺳﻔﺔ واﻟﻌﻠﻤﺎءﻣﺎﺗﺴﺘﻄﻴﻊ أﺟﻬﺰة اﻟﻜﻤﺒﻴﻮﺗﺮ أنﺗﻘﻮمﺑﻪ وﻣﺎﻳُﻤﻜﻦ أنﺗُﺼﺒﺢﻋﻠﻴﻪ،
واﻟﻔﺮوقﺑني اﻹﻧﺴﺎن واﻵﻟﺔ اﻟﺬﻛﻴﺔ. دﻋﻮﻧﺎﻧُﻠﻘﻲﻧﻈﺮةًﻋﲆﺑﻌﺾﻫﺬه اﻟﻨﻘﺎﺷﺎت، اﻟﺘﻲ
ﺗﺘﻨﺎولﻣﺎﻫﻴﺔ اﻹﻧﺴﺎن وﻣﺎﻳﺠﺐ أنﻳﻜﻮنﻋﻠﻴﻪ،ﺑﻘﺪْرﻣﺎﺗﺘﻨﺎولﻣﺎﻫﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻣﺎﻳﺠﺐ أنﻳﻜﻮنﻋﻠﻴﻪ.
ﻫﻞﻳﻤﻜﻦﻷﺟﻬﺰة اﻟﻜﻤﺒﻴﻮﺗﺮ أنﺗﺘﻤﺘﱠﻊﺑﺎﻟﺬﻛﺎء واﻟﻮﻋﻲ واﻹﺑﺪاع؟ﻫﻞﻳُﻤﻜﻨﻬﺎﻓﻬﻢ
اﻷﺷﻴﺎء وإدراك املﻌﺎﻧﻲ؟ﻫﻨﺎكﺗﺎرﻳﺦﻣﻦ اﻟﻨﻘﺪ واﻟﺸﻚﰲ إﻣﻜﺎﻧﻴﺔ وﺟﻮد ذﻛﺎء اﺻﻄﻨﺎﻋﻲ
ﻣُﺸﺎﺑِﻪٍﻟﺬﻛﺎء اﻹﻧﺴﺎن.ﰲﻋﺎم ٢٧٩١،ﻧﴩﻫﻴﻮﺑﺮت درﻳﻔﻮس،ﻓﻴﻠﺴﻮف ذوﺧﻠﻔﻴﺔﰲﻋﻠﻢ
ﻣﻨﺬ اﻟﺴﺘﻴﻨﻴﱠﺎت،ﻛﺎن1.«اﻟﻈﻮاﻫﺮ،ﻛﺘﺎﺑًﺎﺑﻌﻨﻮان »ﻣﺎﻻﺗﺴﺘﻄﻴﻊ أﺟﻬﺰة اﻟﻜﻤﺒﻴﻮﺗﺮﻓﻌﻠﻪ
درﻳﻔﻮسﻳُﻈﻬﺮ اﻧﺘﻘﺎدًاﺷﺪﻳﺪًاﻟﻸﺳﺎس اﻟﻔﻠﺴﻔﻲﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺷﻜﱠﻚﰲ وﻋﻮده:
وﻗﺎل إنﺑﺮﻧﺎﻣﺞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺒﺤﺜﻲﻣﺤﻜﻮمﻋﻠﻴﻪﺑﺎﻟﻔﺸﻞ. وﻗﺒﻞ أنﻳﻨﺘﻘﻞ إﱃ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺑريﻛﲇ،ﻛﺎنﻳﻌﻤﻞﰲﻣﻌﻬﺪﻣﺎﺳﺎﺗﺸﻮﺳﺘﺲﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎ، وﻫﻮﻣﻜﺎنﻣُﻬﻢﻟﺘﻄﻮﻳﺮ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ، واﻟﺬيﻛﺎنﻳﻌﺘﻤﺪ أﺳﺎﺳًﺎﰲ ذﻟﻚ اﻟﻮﻗﺖﻋﲆ املُﻌﺎﻟﺠﺔ اﻟﺮﻣﺰﻳﺔ. رأى درﻳﻔﻮس
أن اﻟﺪﻣﺎغﻟﻴﺲﺟﻬﺎزﻛﻤﺒﻴﻮﺗﺮ وأن اﻟﻌﻘﻞﻻﻳﻌﻤﻞﻋﻦﻃﺮﻳﻖ املُﻌﺎﻟﺠﺔ اﻟﺮﻣﺰﻳﺔ. إنﻟﺪَﻳﻨﺎ
ﺧﻠﻔﻴﺔﻻ واﻋﻴﺔﻣﻦ املﻌﺮﻓﺔ املﺸﱰﻛﺔ اﻟﻘﺎﺋﻤﺔﻋﲆ اﻟﺨﱪة وﻣﺎﻳﻤﻜﻦ أنﻳُﻄﻠِﻖﻋﻠﻴﻪﻫﺎﻳﺪﺟﺮ
»ﻛﻴﻨﻮﻧﺘﻨﺎﰲ اﻟﻌﺎﻟﻢ«، وﻫﺬه املﻌﺮﻓﺔﺿِﻤﻨﻴﺔ وﻻﻳﻤﻜﻦﺗﺸﻜﻴﻠﻬﺎ. وﺗﻌﺘﻤﺪﺧﱪة اﻹﻧﺴﺎن،
ﺣﺴﺐ رأي درﻳﻔﻮس،ﻋﲆ املُﻤﺎرﺳﺔﺑﺪﻻًﻣﻦ املﻌﺮﻓﺔ. وﻻﻳﺴﺘﻄﻴﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟْﺘِﻘﺎطﻫﺬا املﻌﻨﻰ واملﻌﺮﻓﺔ اﻟﻀﻤﻨﻴﺔ؛ وإذاﻛﺎنﻫﺬاﻫﻮﻫﺪف اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﻬﺬا
ﻣﺤﺾُ أﺳﺎﻃري.ﻓﺎﻟﺒﴩ وﺣﺪَﻫﻢﻗﺎدرونﻋﲆ رؤﻳﺔﻣﺎﻫﻮ ذوﺻﻠﺔﻷﻧﻬﻢ،ﺑﻮﺻﻔِﻬﻢﻛﺎﺋﻨﺎت
ﻣُﺘﺠﺴﱢﺪة ووﺟﻮدﻳﺔ،ﻳﺸﺎرﻛﻮنﰲ اﻟﻌﺎﻟﻢ وﻗﺎدرونﻋﲆ اﻻﺳﺘﺠﺎﺑﺔ ملﺘﻄﻠﺒﺎت اﻟﻮﺿﻊ.
.ﻫﻨﺎكﺗﺎرﻳﺦﻣﻦ اﻟﻨﻘﺪ واﻟﺸﻚﰲ إﻣﻜﺎﻧﻴﺔ وﺟﻮد ذﻛﺎء اﺻﻄﻨﺎﻋﻲﻣُﺸﺎﺑِﻪٍﻟﺬﻛﺎء اﻹﻧﺴﺎن
ﰲ ذﻟﻚ اﻟﻮﻗﺖ، واﺟﻪَ درﻳﻔﻮس اﻟﻜﺜريﻣﻦ املﻌﺎرﺿﺔ، وﻟﻜﻦﰲ وﻗﺖٍﻻﺣﻖ،ﻟﻢﻳﻌُﺪ
اﻟﻜﺜريونﻣﻦﺑﺎﺣﺜﻲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻌِﺪُونﺑﺘﺤﻘﻴﻖ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم أو
ﻳﺘﻮﻗﱠﻌﻮنﺗﺤﻘﻴﻘﻪ. واﻧﺘﻘﻠﺖ أﺑﺤﺎث اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦ اﻻﻋﺘﻤﺎدﻋﲆﻣُﻌﺎﻟﺠﺔ اﻟﺮﻣﻮز إﱃ
ﻧﻤﺎذجﺟﺪﻳﺪة، وﻣﻨﻬﺎﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﻘﺎﺋﻢﻋﲆ اﻹﺣﺼﺎء. وﰲﺣنيﻛﺎﻧﺖﻫﻨﺎكﻓﺠﻮةﻫﺎﺋﻠﺔ
ﰲ وﻗﺖ درﻳﻔﻮسﺑنيﻋِﻠﻢ اﻟﻈﻮاﻫﺮ واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﺈن اﻟﻌﺪﻳﺪﻣﻦﺑﺎﺣﺜﻲ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻟﻴﻮمﻳﻌﺘﻨِﻘﻮنﻣﻨﺎﻫﺞ اﻟﻌﻠﻮم املﻌﺮﻓﻴﺔ املﺘﺠﺴﱢﺪة واملﻮﺟﻮدة، اﻟﺘﻲﺗﺪﱠﻋﻲ أﻧﻬﺎ
أﻗﺮب إﱃﻋﻠﻢ اﻟﻈﻮاﻫﺮ.
وﻣﻊ ذﻟﻚ،ﻓﺈن اﻋﱰاﺿﺎت درﻳﻔﻮسﻻﺗﺰالﺻﺎﺋﺒﺔً وﺗُﻈﻬﺮﻛﻴﻒﻳﻤﻜﻦ أنﺗﺘﻌﺎرَض
وﺟﻬﺎتﻧﻈﺮ اﻹﻧﺴﺎنﻏﺎﻟﺒًﺎﻣﻊ اﻵراء اﻟﻌﻠﻤﻴﺔ،ﺧﺎﺻﺔ — وﻟﻜﻦﻟﻴﺲﺣﴫﻳٍّﺎ —ﻓﻴﻤﺎﻳُﺴﻤﱠﻰ
ﺑﺎﻟﻔﻠﺴﻔﺔ اﻟﻘﺎرﻳﺔ.ﻳُﺸﺪﱢد اﻟﻔﻼﺳﻔﺔ اﻟﻘﺎرﻳﻮنﻋﺎدةًﻋﲆ أن اﻟﺒﴩ واﻟﻌﻘﻮل اﻟﺒﴩﻳﺔﻣﺨﺘﻠﻔﺔ
اﺧﺘﻼﻓًﺎﺟﻮﻫﺮﻳٍّﺎﻋﻦ اﻵﻻت، وﻳُﺮﻛﱢﺰونﻋﲆ اﻟﺘﺠﺮﺑﺔ اﻹﻧﺴﺎﻧﻴﺔ اﻟﻮاﻋﻴﺔ واﻟﻮﺟﻮد اﻹﻧﺴﺎﻧﻲ،
اﻟﺬيﻻﻳﻤﻜﻦ وﻻﻳﻨﺒﻐﻲ اﺧﺘﺰاﻟﻪﰲ أوﺻﺎفﺷﻜﻠﻴﺔ أوﺗﻔﺴرياتﻋﻠﻤﻴﺔ.ﻣﻦﺟﻬﺔ أﺧﺮى،
ﻳﺆﻳﺪﺑﻌﺾ اﻟﻔﻼﺳﻔﺔ —ﻏﺎﻟﺒًﺎﻣﻦﻣﻨﻄﻠﻖ اﻟﺘﻘﻠﻴﺪ اﻟﺘﺤﻠﻴﲇﻟﻠﻔﻠﺴﻔﺔ — رؤﻳﺔﻟﻺﻧﺴﺎن
ﺗﺪﻋﻢ اﻟﺒﺎﺣﺜنيﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬﻳﻦﻳﻌﺘﻘﺪون أن اﻟﺪﻣﺎغ واﻟﻌﻘﻞ اﻟﺒﴩي
ﻳُﺸﺒﻬﺎن وﻳﻌﻤﻼنﺣﻘٍّﺎﻣﺜﻞﻧﻤﺎذج اﻟﻜﻤﺒﻴﻮﺗﺮ اﻟﺨﺎﺻﺔﺑﻬﻢ. وﻣﻦ أﻣﺜﻠﺔﻫﺆﻻء اﻟﻔﻼﺳﻔﺔ
32</p>
<p>ﻛﻞﻣﺎﻟﻪﻋﻼﻗﺔﺑﺎﻟﺒﴩ
ﺑﻮلﺗﺸريﺷﻼﻧﺪ وداﻧﻴﻴﻞ دﻧﻴﺖ.ﻳﻌﺘﻘﺪﺗﺸريﺷﻼﻧﺪ أن اﻟﻌﻠﻢ، وﺧﺎﺻﺔﻋِﻠﻢ اﻷﺣﻴﺎء اﻟﺘﻄﻮﱡري
وﻋﻠﻢ اﻷﻋﺼﺎب، واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳُﻤﻜﻨﻬﻤﺎﺗﻔﺴري اﻟﻮﻋﻲ اﻟﺒﴩيﺗﻔﺴريًاﻛﺎﻣﻼً . وﻳﻌﺘﻘﺪ
أن اﻟﺪﻣﺎغﻋﺒﺎرةﻋﻦﺷﺒﻜﺔٍﻋﺼﺒﻴﺔﻣُﺘﻜﺮﱢرة. وﻳﻨﻜﺮ وﺟﻮد أﻓﻜﺎر أوﺗﺠﺎربﻏريﻣﺎدﱢﻳﺔﻓﻴﻤﺎ
ﻳُﻄﻠَﻖﻋﻠﻴﻪ املﺎدﻳﺔ اﻹﻗﺼﺎﺋﻴﺔ.ﻓﻤﺎﻧُﺴﻤﱢﻴﻪ أﻓﻜﺎرًا وﺗﺠﺎربﻣﺎﻫﻮ إﻻﺣﺎﻻتﻟﻠﺪﻣﺎغ. وﻳﻨﻜﺮ
دﻧﻴﺖ أﻳﻀًﺎ وﺟﻮد أيﳾءٍﺑﺨﻼفﻣﺎﻳﺤﺪُثﰲ اﻟﺠﺴﻢ: وﻳﺮى أﻧﻨﺎ »ﻧﺤﻦ أﻧﻔﺴﻨﺎﻧﻮعﻣﻦ
(. وإذاﻛﺎن اﻹﻧﺴﺎنﰲ اﻷﺳﺎس آﻟﺔ واﻋﻴﺔ،ﻓﺈنﻣﺜﻞﻫﺬهDennett 1997) «اﻟﺮوﺑﻮﺗﺎت
اﻵﻻتﻣُﻤﻜﻨﺔ، وﻟﻴﺲﻓﻘﻂﻣﻦﺣﻴﺚ املﺒﺪأ وﻟﻜﻦﰲ اﻟﻮاﻗﻊ.ﻳُﻤﻜﻨﻨﺎ أنﻧﺤﺎولﺻﻨﻌﻬﺎ. وﻣﻦ
اﻷﻫﻤﻴﺔﺑﻤﻜﺎنٍ أنﻛﻼٍّﻣﻦ اﻟﻔﻼﺳﻔﺔ اﻟﻘﺎرﻳني واﻟﺘﺤﻠﻴﻠﻴنيﻳُﻌﺎرﺿﺎن اﻟﺜﻨﺎﺋﻴﺔ اﻟﺪﻳﻜﺎرﺗﻴﺔ
اﻟﺘﻲﺗﻔﺼﻞﺑني اﻟﻌﻘﻞ واﻟﺠﺴﻢ، وﻟﻜﻦﻷﺳﺒﺎبٍﻣﺨﺘﻠﻔﺔ:ﻓﺎﻟﻔﻼﺳﻔﺔ اﻟﻘﺎرﻳﻮنﻳﻌﺘﻘﺪون أن
وﺟﻮد اﻹﻧﺴﺎنﻳﺘﻌﻠﱠﻖﺑﻜﻮﻧﻪﰲ اﻟﻌﺎﻟَﻢ اﻟﺬيﻻﻳُﻔﺼﻞﻓﻴﻪ اﻟﻌﻘﻞﻋﻦ اﻟﺠﺴﻢ، أﻣﺎ اﻟﻔﻼﺳﻔﺔ
اﻟﻘﺎرﻳﻮنﻓﻴﻌﺘﻘﺪونﻷﺳﺒﺎبٍﻣﺎدﻳﺔ أن اﻟﻌﻘﻞﻟﻴﺲﺷﻴﺌًﺎﻣُﺴﺘﻘﻼٍّﻋﻦ اﻟﺠﺴﻢ.
وﻟﻜﻦﻟﻴﺲﺟﻤﻴﻊ اﻟﻔﻼﺳﻔﺔ اﻟﺘﺤﻠﻴﻠﻴﱢنيﻳﺮَون أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم أو اﻟﻘﻮي
ﻣُﻤﻜﻦ.ﻣﻦ وﺟﻬﺔﻧﻈﺮ اﻟﻔﻴﻠﺴﻮفﻓﻴﺘﺠﻨﺸﺘﺎﻳﻦ )ﰲ وﻗﺖٍﻻﺣﻖ(،ﻳﻤﻜﻦﻟﻠﺸﺨﺺ أنﻳُﺠﺎدل
ﺑﺄﻧﻪﰲﺣنيﻳﻤﻜﻦ ملﺠﻤﻮﻋﺔٍﻣﻦ اﻟﻘﻮاﻋﺪ أنﺗﺼﻒﻇﺎﻫﺮةًﻣﻌﺮﻓﻴﺔ،ﻓﺈن ذﻟﻚﻻﻳﻌﻨﻲ
(.ﻛﻤﺎArkoudas and Bringsjord 2014)ﺑﺎﻟﴬورة أنﻟﺪَﻳﻨﺎﻓﻌﻠﻴٍّﺎﻗﻮاﻋﺪﰲ رءوﺳﻨﺎ
ﻫﻮ اﻟﺤﺎلﻣﻊ اﻧﺘﻘﺎد درﻳﻔﻮس،ﻳُﺜريﻫﺬاﻣﺸﻜﻠﺔﻟﻨﻮعٍ واﺣﺪﻣﻦ أﻧﻮاع اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،
وﻫﻮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺮﻣﺰي، إذا اﻓﱰض أنﻫﺬهﻫﻲ اﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳُﻔﻜﱢﺮﺑﻬﺎ اﻟﺒﴩ.
ﺛﻤﱠﺔ اﻧﺘﻘﺎدﻓﻠﺴﻔﻲ آﺧَﺮﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺄﺗﻲﻣﻦﺟﻮنﺳريل، اﻟﺬيﻳُﻌﺎرضﻓﻜﺮة أن
Searle)ﺑﺮاﻣﺞ اﻟﻜﻤﺒﻴﻮﺗﺮﻳﻤﻜﻦ أنﺗﻜﻮنﻟﺪﻳﻬﺎﺣﺎﻻتﻣﻌﺮﻓﻴﺔﺣﻘﻴﻘﻴﺔ أوﻓﻬﻢﻟﻠﻤﻌﻨﻰ
(. وﻓﻴﻤﺎﻳﲇ اﻟﺘﺠﺮﺑﺔ اﻟﻔﻜﺮﻳﺔ اﻟﺘﻲﻳُﻘﺪﱢﻣﻬﺎ، واﻟﺘﻲﺗُﻌﺮَفﺑﺎﺳﻢﺣﺠﱠﺔ اﻟﻐﺮﻓﺔ1980
اﻟﺼﻴﻨﻴﺔ:ﻳُﺤﺒَﺲﺳريلﰲﻏﺮﻓﺔ وﻳُﻌﻄﻰﻛﺘﺎﺑﺎتﺻﻴﻨﻴﺔ وﻟﻜﻨﻪﻻﻳﻌﺮف اﻟﺼﻴﻨﻴﺔ. وﻣﻊ
ذﻟﻚ،ﻳﺴﺘﻄﻴﻊ اﻟﺮدﻋﲆ اﻷﺳﺌﻠﺔ اﻟﺘﻲﻳﻄﺮﺣﻬﺎ أﺷﺨﺎصٌﺧﺎرج اﻟﻐﺮﻓﺔﻳﺘﺤﺪﺛﻮنﺑﺎﻟﺼﻴﻨﻴﺔ
ﻷﻧﻪﻳﺴﺘﺨﺪمﻛُﺘﻴﱢﺐ اﻟﻘﻮاﻋﺪ اﻟﺬيﻳُﻤﻜﱢﻨﻪﻣﻦ إﻧﺘﺎج اﻹﺟﺎﺑﺎت اﻟﺼﺤﻴﺤﺔ )ﻣُﺨﺮﺟﺎت( اﺳﺘﻨﺎدًا
إﱃ املﺴﺘﻨﺪات )املﺪﺧﻼت( اﻟﺘﻲﻳﺘﻠﻘﱠﺎﻫﺎ. وﻫﻮﻳﺴﺘﻄﻴﻊ اﻟﻘﻴﺎمﺑﺬﻟﻚﺑﻨﺠﺎحٍ دونﻓﻬﻢ اﻟﻠﻐﺔ
اﻟﺼﻴﻨﻴﺔ. وﺑﺎملﺜﻞ،ﻳُﺠﺎدلﺳريل،ﻳُﻤﻜﻦﻟﱪاﻣﺞ اﻟﻜﻤﺒﻴﻮﺗﺮ إﻧﺘﺎجﻣُﺨﺮﺟَﺎت اﺳﺘﻨﺎدًا إﱃ
ﻣﺪﺧﻼتﺑﺎﻻﺳﺘﻌﺎﻧﺔﺑﺎﻟﻘﻮاﻋﺪ اﻟﺘﻲﺗُﺰوﱠدﺑﻬﺎ، وﻟﻜﻨﻬﺎﻻﺗﻔﻬﻢﺷﻴﺌًﺎ.ﺑﻤﺼﻄﻠﺤﺎتﻓﻠﺴﻔﻴﺔ
أﻛﺜﺮﺗﺨﺼﱡﺼًﺎ:ﻻﺗﻤﺘﻠﻚﺑﺮاﻣﺞ اﻟﻜﻤﺒﻴﻮﺗﺮﻗﺼﺪﻳﺔ، وﻻﻳﻤﻜﻦﺧﻠﻖﻓﻬﻢﺣﻘﻴﻘﻲﺑﻮاﺳﻄﺔ
اﻟﺤﻮﺳﺒﺔ اﻟﺸﻜﻠﻴﺔ. أوﻛﻤﺎﻳﻘﻮلﺑﻮدن )٦١٠٢(، اﻟﻔﻜﺮةﻫﻲ أن املﻌﻨﻰﻳﺄﺗﻲﻣﻦ اﻟﺒﴩ.
33</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻋﲆ اﻟﺮﻏﻢﻣﻦ أنﺑﺮاﻣﺞ اﻟﻜﻤﺒﻴﻮﺗﺮ اﻟﺤﺎﻟﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻏﺎﻟﺒًﺎﻣﺎﺗﺨﺘﻠﻒﻋﻦ
ﺗﻠﻚ اﻟﺘﻲ اﻧﺘﻘﺪﻫﺎ درﻳﻔﻮس وﺳريل،ﻓﺈن اﻟﻨﻘﺎشﻻﻳﺰالﻣُﺴﺘﻤﺮٍّا.ﻳﻌﺘﻘﺪ اﻟﻌﺪﻳﺪﻣﻦ
اﻟﻔﻼﺳﻔﺔ أنﻫﻨﺎكﻓﺮوﻗًﺎﺣﺎﺳﻤﺔﺑنيﻃﺮﻳﻘﺔﺗﻔﻜري اﻟﺒﴩ وأﺟﻬﺰة اﻟﻜﻤﺒﻴﻮﺗﺮ.ﻋﲆﺳﺒﻴﻞ
املﺜﺎل،ﻳﻤﻜﻦﻟﻠﻤﺮء اﻟﻴﻮم أنﻳُﺠﺎدلﺑﺄﻧﻨﺎﻛﺎﺋﻨﺎتﻗﺎدرةﻋﲆﺧَﻠْﻖ املﻌﻨﻰ، وواﻋﻴﺔ وﻣُﺘﺠﺴﱢﺪة
وﺣﻴﺔ، وﻻﻳﻤﻜﻦﺗﻔﺴريﻃﺒﻴﻌﺘﻨﺎ وﻋﻘﻮﻟﻨﺎ وﻣﻌﺮﻓﺘﻨﺎﺑﺎملﻘﺎرﻧﺔﺑﺎﻵﻻت. وﻣﻊ ذﻟﻚ،ﻋﻠﻴﻚ أن
ﺗﻼﺣﻆ أﻧﻪﺣﺘﻰ اﻟﻌﻠﻤﺎء واﻟﻔﻼﺳﻔﺔ اﻟﺬﻳﻦﻳﻌﺘﻘﺪون أنﻫﻨﺎك اﻟﻜﺜريﻣﻦ اﻟﺘﺸﺎﺑُﻪﺑني اﻟﺒﴩ
واﻵﻻتﻣﻦﺣﻴﺚ املﺒﺪأ، وأن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎمﻣُﻤﻜﻦﻧﻈﺮﻳٍّﺎ،ﻳﺮﻓﻀﻮنﰲﻛﺜريٍﻣﻦ
اﻷﺣﻴﺎن رؤﻳﺔﺑﻮﺳﱰومﻟﻠﺬﻛﺎء اﻟﻔﺎﺋﻖ وأﻓﻜﺎرﻣُﻤﺎﺛﻠﺔﺗَﻌﺘﱪِ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺸﺎﺑﻪ
ﻟﺬﻛﺎء اﻹﻧﺴﺎنﻗﺪ أﺻﺒﺢﻗﺎبﻗﻮﺳني أو أدﻧﻰﻣﻦ اﻟﺘﺤﻘﱡﻖ.ﻓﺒﻮدن ودﻧﻴﺖﻛﻼﻫﻤﺎﻳﻌﺘﻘﺪان
أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎمﺻﻌﺐﺟﺪٍّاﺗﺤﻘﻴﻘﻪﻋﻤﻠﻴٍّﺎ، وﺑﺎﻟﺘﺎﱄﻟﻴﺲﺷﻴﺌًﺎﻳﺠﺐ اﻟﻘﻠﻖ
ﺑﺸﺄﻧﻪﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄ.
ﻧﺤﻦﻛﺎﺋﻨﺎتﻗﺎدرةﻋﲆﺧَﻠْﻖ املﻌﻨﻰ، وواﻋﻴﺔ وﻣﺘﺠﺴﺪة وﺣﻴﺔ، وﻻﻳﻤﻜﻦﺗﻔﺴريﻃﺒﻴﻌﺘﻨﺎ وﻋﻘﻮﻟﻨﺎ
وﻣﻌﺮﻓﺘﻨﺎﺑﺎملﻘﺎرﻧﺔﺑﺎﻵﻻت.
وﺑﻨﺎءًﻋﻠﻴﻪﻳﻤﻜﻨﻨﺎ اﻟﻘﻮل إنﻫﻨﺎك،ﰲﺧﻠﻔﻴﺔ اﻟﻨﻘﺎشﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺗﺒﺎﻳُﻦ
ﻋﻤﻴﻖﰲ اﻵراءﺣﻮلﻃﺒﻴﻌﺔ اﻹﻧﺴﺎن واﻟﺬﻛﺎء اﻟﺒﴩي واﻟﻌﻘﻞ واﻟﻔﻬﻢ واﻟﻮﻋﻲ واﻹﺑﺪاع
واملﻌﻨﻰ واملﻌﺮﻓﺔ اﻟﺒﴩﻳﺔ واﻟﻌﻠﻮم، وﻫﻜﺬا.ﻓﺈذاﻛﺎنﺛﻤﺔ »ﻣﻌﺮﻛﺔ«ﻣﻦ اﻷﺳﺎس،ﻓﻬﻲ
ﻣﻌﺮﻛﺔﺗﺘﻌﻠﱠﻖﺑﺎﻹﻧﺴﺎنﺑﻘﺪْرﻣﺎﺗﺘﻌﻠﱠﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
اﻟﺤﺪاﺛﺔ و)ﻣﺎﺑﻌﺪ( اﻹﻧﺴﺎﻧﻴﺔ وﻣﺎﺑﻌﺪ اﻟﻈﺎﻫﺮﻳﺔ
ﻣﻦ وﺟﻬﺔﻧﻈﺮٍ أوﺳَﻊﰲ اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ،ﻣﻦ املﻬﻢ أنﻧﻀﻊﻫﺬه اﻟﻨﻘﺎﺷﺎتﺣﻮل
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻹﻧﺴﺎنﰲﺳﻴﺎقٍ أوﺳَﻊﻟﻠﻮﻗﻮفﻋﲆﻣﺎﻫﻴﺘﻬﺎ وﻣﺎﺗﻨﻄﻮيﻋﻠﻴﻪ.ﻓﻬﺬه
اﻟﻨﻘﺎﺷﺎتﻻﺗﺘﻌﻠﱠﻖﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ واﻹﻧﺴﺎنﻓﺤﺴﺐ، وﻟﻜﻨﻬﺎﺗﻌﻜﺲ اﻧﻘﺴﺎﻣﺎتٍﻋﻤﻴﻘﺔﰲ
اﻟﺤﺪاﺛﺔ. دﻋﻮﻧﻲ أﻣﺮﱡﻣﺮور اﻟﻜﺮامﻋﲆﺛﻼﺛﺔ اﻧﻘﺴﺎﻣﺎتﺗُﺴﺎﻫﻢﺑﺸﻜﻞٍﻏريﻣﺒﺎﴍﰲ
ﺗﺸﻜﻴﻞ املﻨﺎﻗﺸﺎت اﻷﺧﻼﻗﻴﺔﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. اﻻﻧﻘﺴﺎم اﻷولﻫﻮ اﻧﻘﺴﺎمﻇﻬَﺮَﰲ
ﻣُﺴﺘﻬَﻞﱢﻋﴫ اﻟﺤﺪاﺛﺔﺑنيﺣﺮﻛﺘَﻲ اﻟﺘﻨﻮﻳﺮ واﻟﺮوﻣﺎﻧﺴﻴﺔ. أﻣﺎ اﻵﺧَﺮانﻓﻬﻤﺎﺗﻄﻮﱡراتﺣﺪﻳﺜﺔ
34</p>
<p>ﻛﻞﻣﺎﻟﻪﻋﻼﻗﺔﺑﺎﻟﺒﴩ
ﻧﺴﺒﻴٍّﺎ: اﻷولﺑني اﻹﻧﺴﺎﻧﻴﺔ وﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ، وﻳﺒﻘﻰﺣﺒﻴﺲﺗﻮﺗﺮات اﻟﺤﺪاﺛﺔ، واﻟﺜﺎﻧﻲﺑني
اﻹﻧﺴﺎﻧﻴﺔ وﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ، واﻟﺬيﻳُﺤﺎولﺗﺨﻄﱢﻲ اﻟﺤﺪاﺛﺔ.
إﺣﺪى وﺳﺎﺋﻞﻓﻬﻢ اﻟﻨﻘﺎشﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻹﻧﺴﺎنﻫﻲ أنﻧﻀﻊﰲ اﻻﻋﺘﺒﺎر
اﻟﺘﻮﺗﱡﺮ اﻟﻘﺎﺋﻢﺑني اﻟﺘﻨﻮﻳﺮ واﻟﺮوﻣﺎﻧﺴﻴﺔﰲ اﻟﺤﺪاﺛﺔ.ﰲ اﻟﻘﺮﻧَني اﻟﺜﺎﻣﻦﻋﴩ واﻟﺘﺎﺳﻊﻋﴩ،
ﺗﺤﺪى اﻟﻌﻠﻤﺎء واملُﻔﻜﺮون اﻟﺘﻨﻮﻳﺮﻳﻮن اﻵراء اﻟﺪﻳﻨﻴﺔ اﻟﺘﻘﻠﻴﺪﻳﺔ وزﻋﻤﻮا أن اﻟﻌﻘﻞ واﻟﺸﻚ
واﻟﻌﻠﻢﺗُﻈﻬِﺮﻟﻨﺎﻣﺎﻫﻴﺔ اﻹﻧﺴﺎن واﻟﻌﺎﻟﻢ اﻟﺤﻘﻴﻘﻴﺔ،ﻋﲆﻋﻜﺲ املُﻌﺘﻘﺪات املُﺴﻠﱠﻢﺑﻬﺎﻏري
املُﱪرةﺑﺎﻟﺤﺠﺞ أوﻏري املﺪﻋﻮﻣﺔﺑﺎﻷدﻟﺔ. وﻛﺎﻧﻮاﻣﺘﻔﺎﺋﻠنيﺣﻴﺎلﻣﺎﻳﻤﻜﻦ أنﻳﻘﺪﱢﻣﻪ اﻟﻌﻠﻢ
ﻟﺼﺎﻟﺢ اﻹﻧﺴﺎﻧﻴﺔ. ردٍّاﻋﲆ ذﻟﻚ،ﻗﺎل اﻟﺮوﻣﺎﻧﺴﻴﻮن إن اﻟﻌﻘﻞ املﺠﺮﱠد واﻟﻌﻠﻢ اﻟﺤﺪﻳﺚﻗﺪ
أﻓﻘﺪا اﻟﻌﺎﻟَﻢﺳِﺤﺮه وأﻧﻨﺎﰲﺣﺎﺟﺔ إﱃ إﻋﺎدة اﻟﻐﻤﻮض واﻟﺴﺤﺮ اﻟﻠﺬَﻳﻦﻳُﺮﻳﺪ اﻟﻌﻠﻢ اﻟﻘﻀﺎء
ﻋﻠﻴﻬﻤﺎ.ﻋﻨﺪ اﻟﻨﻈﺮ إﱃ اﻟﻨﻘﺎشﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻳﺒﺪوﻟﻨﺎ أﻧﻨﺎﻟﻢﻧﺒﺘﻌِﺪﻛﺜريًا
ﻋﻦ ذﻟﻚ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﺴﺘﻬﺪفﻋﻤﻞ دﻧﻴﻴﺖﺣﻮل اﻟﻮﻋﻲ وﻋﻤﻞﺑﻮدﻳﻦﺣﻮل اﻹﺑﺪاع
ﺗﻘﺪﻳﻢﺗﻔﺴرياتٍﻟﻜﻞﳾء، أوﻛﻤﺎﻳﻘﻮل دﻧﻴﻴﺖ »ﻓﻚ اﻟﺴﺤﺮ«.ﻓﻬﺬان اﻟﻔﻴﻠﺴﻮﻓﺎنﻣُﺘﻔﺎﺋﻼن
ﺑﺄن اﻟﻌﻠﻢﻳُﻤﻜﻨﻪﻛﺸﻒﻏﻤﻮض اﻟﻮﻋﻲ واﻹﺑﺪاع وﻏريﻫﻤﺎ. إﻧﻬﻤﺎﻳُﻌﺎرﺿﺎنﻛﻞﱠﻣَﻦﻳﻘﺎوم
ﺟﻬﻮدﻓﻚﺳﺤﺮ اﻹﻧﺴﺎن،ﻣﺜﻞ اﻟﻔﻼﺳﻔﺔ اﻟﻘﺎرﻳني اﻟﺬﻳﻦﻳﺴريونﰲ رﻛﺐﻣﺎﺑﻌﺪ اﻟﺤﺪاﺛﺔ
وﻳُﺸﺪﱢدونﻋﲆﻏﻤﻮضﻣﻌﻨﻰ أنﺗﻜﻮن إﻧﺴﺎﻧًﺎ؛ﺑﻌﺒﺎرة أﺧﺮى: اﻟﺮوﻣﺎﻧﺴﻴني اﻟﺠُﺪد.ﻳﺒﺪو
أنﺳﺆال »ﻫﻞﻧﻔﻚﱡ اﻟﺴﺤﺮ أمﻧﺤﺘﻔﻆﺑﻐﻤﻮض اﻹﻧﺴﺎن؟«ﻫﻮ اﻟﺴﺆال اﻟﺮﺋﻴﴘﰲ املﻨﺎﻗﺸﺎت
اﻟﺘﻲﺗﺘﻨﺎول اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم وﻣُﺴﺘﻘﺒﻠﻪ.
أﻣﺎ اﻟﺘﻮﺗﺮ اﻟﺜﺎﻧﻲﻓﻬﻮﺑنيﻣﺆﻳﺪي اﻹﻧﺴﺎﻧﻴﺔ وﻣﺆﻳﺪيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ.ﻣﺎﻫﻮ
»اﻹﻧﺴﺎن«، وﻣﺎذاﻳﺠﺐ أنﻳﻜﻮن؟ﻫﻞﻣﻦ املُﻬﻢ اﻟﺪﻓﺎعﻋﻦ اﻹﻧﺴﺎنﻛﻤﺎﻫﻮ، أمﻳﺘﻌنيﱠ
ﻋﻠﻴﻨﺎﺗﻌﺪﻳﻞﺗﺼﻮﱡرﻧﺎﻟﻪ؟ﻳﺤﺘﻔﻲ دُﻋﺎة اﻹﻧﺴﺎﻧﻴﺔﺑﺎﻹﻧﺴﺎنﻛﻤﺎﻫﻮ. وﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔ،
ﻳُﺸﺪﱢدونﻋﲆ اﻟﻘﻴﻤﺔ اﻟﺠﻮﻫﺮﻳﺔ واملﺘﻔﻮﱢﻗﺔﻟﻠﺒﴩ. وﻳُﻤﻜﻨﻨﺎ اﻟﻌﺜﻮرﻋﲆ أﻓﻜﺎر دﻋﺎة اﻹﻧﺴﺎﻧﻴﺔ
ﰲ اﻟﻨﻘﺎش اﻟﺪاﺋﺮﻋﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ اﻟﺤﺠﺞ اﻟﺘﻲﺗُﺪاﻓﻊﻋﻦﺣﻘﻮق اﻹﻧﺴﺎن وﻛﺮاﻣﺘﻪ
ﻷﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، أوﰲ اﻟﺤﺠﺔ املﺆﻳﺪةﻷنﻳﻜﻮن اﻟﺒﴩ وﻗِﻴَﻤُﻬﻢﰲ
ﻛﺄﺳﺎسٍ
ﻗﻠﺐ وﰲﻣﺮﻛﺰﻣﺴﺄﻟﺔﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣُﺴﺘﻘﺒﻠﻪ.ﻫﻨﺎﻏﺎﻟﺒًﺎﻣﺎﺗﺘﱠﻔﻖ اﻹﻧﺴﺎﻧﻴﺔ
ﻣﻊ اﻟﺘﻔﻜري اﻟﺘﻨﻮﻳﺮي. وﻟﻜﻦﻳُﻤﻜﻦ أنﺗﺄﺧﺬ أﻳﻀًﺎ أﺷﻜﺎﻻً أﻛﺜﺮﺗﺤﻔﻈًﺎ أو روﻣﺎﻧﺴﻴﺔ.ﻛﺬﻟﻚ
ﻳُﻤﻜﻨﻨﺎ أنﻧﻌﺜﺮﻋﲆ اﻹﻧﺴﺎﻧﻴﺔﰲﻣﻘﺎوﻣﺔﻣﴩوع دُﻋﺎةﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ.ﻓﺒﻴﻨﻤﺎﻳﻌﺘﻘﺪ
ﻗﺪﻣًﺎﻧﺤﻮﻧﻮعﺟﺪﻳﺪٍﻣﻦ اﻹﻧﺴﺎنﻳﺘﻢﺗﺤﺴﻴﻨُﻪ
دُﻋﺎةﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ أنﱠﻋﻠﻴﻨﺎ املُﴤُ
ﺑﻮاﺳﻄﺔ اﻟﻌﻠﻢ واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ،ﻳﺪاﻓﻊ اﻹﻧﺴﺎﻧﻴﻮنﻋﻦ اﻹﻧﺴﺎنﻛﻤﺎﻫﻮ، وﻳﺸﺪدونﻋﲆﻗﻴﻤﺘﻪ
وﻛﺮاﻣﺘﻪ، اﻟﺘﻲﻳُﻘﺎل إﻧﻬﺎﻣﻬﺪﱠدةﻣﻦﻗِﺒﻞﻋﻠﻮم دﻋﺎةﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ وﻓﻠﺴﻔﺘﻬﻢ.
35</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ردود اﻟﻔﻌﻞ اﻟﺪﻓﺎﻋﻴﺔﺗﺠﺎه اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺠﺪﻳﺪةﻟﻬﺎﺗﺎرﻳﺨﻬﺎ اﻟﺨﺎص.ﻓﻔﻲ اﻟﻌﻠﻮم
اﻻﺟﺘﻤﺎﻋﻴﺔ واﻹﻧﺴﺎﻧﻴﺔ،ﻛﺜريًاﻣﺎﺗُﻨﺘﻘَﺪ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺑﺎﻋﺘﺒﺎرﻫﺎﺗﻬﺪﻳﺪًاﻟﻺﻧﺴﺎﻧﻴﺔ واملﺠﺘﻤﻊ.
ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻛﺎنﻛﺜريٌﻣﻦﻓﻼﺳﻔﺔ اﻟﻘﺮن اﻟﻌﴩﻳﻦﺷﺪﻳﺪي اﻟﺘﺸﺎؤمﺣﻴﺎل اﻟﻌﻠﻢ،
وﺣﺬرواﻣﻦﺳﻴﻄﺮة اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻋﲆ املﺠﺘﻤﻊ. وﻟﻜﻦ اﻟﴫاع اﻵنﻻﻳﺘﻌﻠﱠﻖﻓﻘﻂﺑﺤﻴﺎة
اﻹﻧﺴﺎن واملﺠﺘﻤﻊ،ﺑﻞﻳﺘﻌﻠﱠﻖﺑﺎﻹﻧﺴﺎنﻧﻔﺴﻪ:ﻫﻞﻧﺤﻦﺑﺼﺪدﺗﺤﺴﻴﻨﻪ وﺗﻄﻮﻳﺮه أمﻻ؟ﻫﺬا
ﻫﻮ اﻟﺴﺆال.ﻓﻤﻦﺟﻬﺔ،ﻳُﺼﺒﺢ اﻹﻧﺴﺎنﻧﻔﺴﻪﻣﴩوﻋًﺎﻋﻠﻤﻴٍّﺎﺗﻜﻨﻮﻟﻮﺟﻴٍّﺎ،ﻗﺎﺑﻼًﻟﻠﺘﺤﺴني
واﻟﺘﻄﻮﻳﺮ. وﺑﻤﺠﺮﱠد أنﻳُﻔَﻚﺳﺤﺮ اﻹﻧﺴﺎن —ﻣﻦﺧﻼل داروﻳﻦ وﻋﻠﻢ اﻷﻋﺼﺎب واﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ —ﻳُﻤﻜﻨﻨﺎ أنﻧﺒﺪأﰲﺗﺤﺴﻴﻨﻪ. وﻳﻤﻜﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنﻳُﺴﺎﻋﺪﻧﺎﰲ
ﺗﺤﺴني اﻹﻧﺴﺎن. وﻣﻦﺟﻬﺔ أﺧﺮى،ﻳﺠﺐﻋﻠﻴﻨﺎ أنﻧﺤﺘﻀِﻦ اﻹﻧﺴﺎنﻛﻤﺎﻫﻮ. ورﺑﻤﺎﻳﻘﻮل
اﻟﺒﻌﺾ: داﺋﻤًﺎﻣﺎﻳﻔﻮﺗﻨﺎ أنﻧُﺪركﻣﺎﻫﻴﺔ اﻹﻧﺴﺎن.ﻓﻨﺤﻦﻻﻧﺴﺘﻄﻴﻊ أنﻧﻔﻬﻤﻪﻓﻬﻤًﺎﺗﺎﻣٍّﺎ
ﺑﻮاﺳﻄﺔ اﻟﻌﻠﻢ.
ﺗﺴﺘﻤﺮﻫﺬه اﻟﺘﻮﺗﱡﺮاتﰲﺗﻘﺴﻴﻢ اﻟﻌﻘﻮل واﻟﻘﻠﻮبﰲﻫﺬا اﻟﻨﻘﺎش.ﻓﻬﻞﻳُﻤﻜﻨﻨﺎﺗﺨﻄﱢﻴﻬﺎ؟
ﻋﻤﻠﻴٍّﺎ،ﻳﻤﻜﻦﻟﻠﻤﺮء أنﻳﺘﺨﲆﱠﻋﻦﻫﺪف إﻧﺸﺎء ذﻛﺎءٍ اﺻﻄﻨﺎﻋﻲﺷﺒﻴﻪﺑﺎﻹﻧﺴﺎن. وﻟﻜﻦﺣﺘﻰ
ﰲﻫﺬه اﻟﺤﺎﻟﺔ،ﺗﻈﻞﱡﻫﻨﺎكﺧﻼﻓﺎتﺑﺸﺄن وﺿﻊ »آﻻت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻛﻨﻤﺎذجﻟﻠﺒﴩ«
املُﺴﺘﺨﺪَمﰲﻋﻠﻢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻫﻞﺗُﻌﻠﱢﻤﻨﺎﺣﻘٍّﺎﺷﻴﺌًﺎﻋﻦﻛﻴﻔﻴﺔﺗﻔﻜري اﻟﺒﴩ؟ أم
إﻧﻬﺎﺗُﻌﻠﱢﻤﻨﺎﻓﻘﻂﺷﻴﺌًﺎﻋﻦﻧﻮعٍﻣﻌنيﱠﻣﻦ اﻟﺘﻔﻜري،ﻋﲆﺳﺒﻴﻞ املﺜﺎلﺗﻔﻜريﻳﻤﻜﻦﺻﻴﺎﻏﺘﻪ
ﺑﻮاﺳﻄﺔ اﻟﺮﻳﺎﺿﻴﺎت، أوﺗﻔﻜريﻳﻬﺪف إﱃ اﻟﺴﻴﻄﺮة واﻟﺘﻼﻋُﺐ؟ إﱃ أيﻣﺪًىﻳُﻤﻜﻨﻨﺎﺣﻘٍّﺎ
اﻟﺘﻌﻠﱡﻢﻣﻦﻫﺬه اﻟﺘﻘﻨﻴﺎتﻋﻦ اﻹﻧﺴﺎن؟ﻫﻞ اﻟﺒﴩﻳﺔ أﻛﱪﻣﻤﺎﻳﺴﺘﻄﻴﻊ اﻟﻌﻠﻢ أنﻳُﺪرك؟
ﺣﺘﻰﰲ املﻨﺎﻗﺸﺎت اﻷﻛﺜﺮ اﻋﺘﺪاﻻً ،ﺗﻈﻬﺮ اﻟﴫاﻋﺎتﺑﺸﺄن اﻟﺤﺪاﺛﺔ.
ﻟﻠﺨﺮوجﻣﻦﻫﺬا املﺄزق،ﻳُﻤﻜﻦﻟﻠﻤﺮء اﺗﺒﺎعﻧﻬﺞِ دارﳼ اﻟﻌﻠﻮم اﻻﺟﺘﻤﺎﻋﻴﺔ واﻹﻧﺴﺎﻧﻴﺔ
اﻟﺬﻳﻦ اﺳﺘﻜﺸﻔﻮاﻃﺮﻗًﺎ »ﻏريﺣﺪﻳﺜﺔ«ﻟﻠﺘﻔﻜريﺧﻼل اﻟﺨﻤﺴنيﻋﺎﻣًﺎ املﺎﺿﻴﺔ. أوﺿﺢﻛﺘﱠﺎبٌ
أﻣﺜﺎلﺑﺮوﻧﻮﻻﺗﻮر وﺗﻴﻢ إﻧﺠﻮﻟﺪ أﻧﻪﻳﻤﻜﻨﻨﺎ اﻟﻌﺜﻮرﻋﲆﻃﺮق أﻗﻞﻣﻴﻼًﻟﻠﻤُﻘﺎرﻧﺔﺑنيﺛﻨﺎﺋﻴﺎت
وأﻛﺜﺮﻣﻴﻼًﻟﻠﱡﺠﻮء إﱃ اﻟﻼﺣﺪاﺛﺔﻋﻨﺪ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﻌﺎﻟَﻢﻣﻦ أﺟﻞﺗﺠﺎوز اﻟﺨﻼفﻣﺎﺑني
اﻟﺘﻨﻮﻳﺮ واﻟﺮوﻣﺎﻧﺴﻴﺔ.ﻳُﻤﻜﻨﻨﺎﻋﻨﺪﺋﺬٍ أنﻧُﺤﺎول اﺟﺘﻴﺎز اﻟﻔﺠﻮة اﻟﺤﺪﻳﺜﺔﺑني اﻟﺒﴩ وﻏري
اﻟﺒﴩﻟﻴﺲﻣﻦﺧﻼل اﻟﻌِﻠﻢ اﻟﺤﺪﻳﺚ أوﻣﻦﺧﻼلﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ، اﻟﺘﻲﺗﺮىﻣﻦ وﺟﻬﺔ
ﻧﻈﺮﻫﺎ أن اﻟﺒﴩ واﻵﻻتﻟﻴﺴﺎﰲﴏاعٍ أﺳﺎﳼ، وﻟﻜﻦﻣﻦﺧﻼل اﻟﻔﻜﺮﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻲ
ﻣﻦ وﺟﻬﺔ اﻟﻨﻈﺮ )ﻣﺎﺑﻌﺪ( اﻹﻧﺴﺎﻧﻴﺔ. وﻫﺬاﻳﺆدي إﱃ اﻟﺘﻮﺗﺮ اﻟﺜﺎﻟﺚ:ﺑني اﻹﻧﺴﺎﻧﻴﺔ وﻣﺎﺑﻌﺪ
اﻹﻧﺴﺎﻧﻴﺔ.ﻳُﺸﻜﱢﻚﻣﺆﻳﺪوﻣﺎﺑﻌﺪَ اﻹﻧﺴﺎﻧﻴﺔ، اﻟﺬﻳﻦﻳُﻌﺎرﺿﻮن اﻹﻧﺴﺎﻧﻴني املُﺘﻬﻤنيﺑﺎﻟﻌُﻨﻒ
36</p>
<p>ﻛﻞﻣﺎﻟﻪﻋﻼﻗﺔﺑﺎﻟﺒﴩ
ﻣﻊﻏري اﻟﺒﴩ،ﻣﺜﻞ اﻟﺤﻴﻮاﻧﺎت،ﺗﺤﺖﻣُﺴﻤﱠﻰ اﻟﻘﻴﻤﺔ اﻟﻔﺎﺋﻘﺔﻟﻺﻧﺴﺎن،ﻳُﺸﻜﱢﻜﻮنﰲﻣﺮﻛﺰﻳﺔ
اﻹﻧﺴﺎنﰲ اﻷﻧﻈﻤﺔ اﻷﻧﻄﻮﻟﻮﺟﻴﺔ واﻷﺧﻼﻗﻴﺔ اﻟﺤﺪﻳﺜﺔ.ﻓﻬﻢﻳﺮَون أنﻏري اﻟﺒﴩﻣُﻬﻤﱡﻮن
أﻳﻀًﺎ، وأﻧﻨﺎﻳﺠﺐ أﻻﻧﺨﺎفﻣﻦﻋﺒﻮر اﻟﺤﺪودﺑني اﻟﺒﴩ وﻏري اﻟﺒﴩ. وﻫﺬا اﺗﺠﺎهﻣُﺜري
ﻟﻼﺳﺘﻜﺸﺎفﻷﻧﻪﻳﺄﺧُﺬﻧﺎﺧﺎرجﴎدﻳﺔ املﻨﺎﻓﺴﺔﺑني اﻟﺒﴩ واﻵﻻت.
ﻳُﻘﺪمﻣﻨﺎﴏوﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ،ﻣﻦ أﻣﺜﺎل دوﻧﺎﻫﺎراواي، رؤﻳﺔًﺗﺼﻮﱢر أن اﻟﻌﻴﺶ
ﻣﻊ اﻵﻻت،ﺑﻞ رﺑﻤﺎ اﻻﻧﺪﻣﺎجﻣﻌﻬﺎ،ﻟﻢﻳﻌُﺪﻳُﺮىﻛﺘﻬﺪﻳﺪٍ أوﻛﻜﺎﺑﻮس،ﻛﻤﺎﻛﺎنﻳﺮىﻣﻦ
ﻗﺒﻞ دﻋﺎة اﻹﻧﺴﺎﻧﻴﺔ، أوﻛﺤﻠﻢٍﻳﺘﺤﻘﱠﻖ ملﻨﺎﴏيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ، وﻟﻜﻨﻪ وﺳﻴﻠﺔﻳُﻤﻜﻦﻣﻦ
ﺧﻼﻟﻬﺎﻋﺒﻮر اﻟﺤﺪود اﻷﻧﻄﻮﻟﻮﺟﻴﺔ واﻟﺴﻴﺎﺳﻴﺔﺑني اﻟﺒﴩ وﻏري اﻟﺒﴩ. وﻣﻦﺛَﻢﻳﻤﻜﻦ أن
ﻳﻜﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺟﺰءًاﻟﻴﺲﻣﻦﻣﴩوع دُﻋﺎةﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ، وﻟﻜﻦﻣﻦﻣﴩوع
دُﻋﺎةﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ املُﻬﻢ، اﻟﺬيﻳﺪﺧﻞﻣﻦﺟﺎﻧﺐ اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ واﻟﻔﻨﻮنﺑﺪﻻًﻣﻦ
اﻟﻌﻠﻢ.ﻳﺘﻢﻋﺒﻮر اﻟﺤﺪودﻟﻴﺲﺑﺎﺳﻢ اﻟﻌﻠﻢ واﻟﺘﻘﺪﱡم اﻟﻌﺎملﻲ،ﻛﻤﺎﻗﺪﻳﺮﻏﺐﺑﻌﺾﻣﻨﺎﴏي
ﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ اﻟﺘﻨﻮﻳﺮﻳنيﰲ اﻟﻘﻮل، وﻟﻜﻦﺑﺎﺳﻢﺳﻴﺎﺳﺔﻣﻨﺎﴏيﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ
وأﻳﺪﻳﻮﻟﻮﺟﻴﺔﻋﺒﻮر اﻟﺤﺪود. وﻳﻤﻜﻦ ملﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ أﻳﻀًﺎ أنﺗُﻘﺪﱢمﺷﻴﺌًﺎ آﺧَﺮﻳﺘﻌﻠﱠﻖ
ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ:ﻳﻤﻜﻨﻬﺎ أنﺗﺤُﺜﱠﻨﺎﻋﲆ اﻻﻋﱰافﺑﺄﻧﻪ »ﻟﻴﺲﺛﻤﺔﺣﺎﺟﺔﻷنﻳﻜﻮنﻏري
اﻟﺒﴩﻣُﻤﺎﺛِﻠنيﻟﻨﺎ وﻳﺠﺐﻋﺪمﺟﻌﻠﻬﻢﻣُﻤﺎﺛِﻠنيﻟﻨﺎ«.ﻳﺒﺪو أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻤﻜﻨﻪ،
ﺑﺎﻻﺳﺘﻨﺎد إﱃ آراءﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ، أنﻳُﺤﺮﱢرﻧﻔﺴﻪﻣﻦﻋﺐءﺗﻘﻠﻴﺪ اﻹﻧﺴﺎن أو إﻋﺎدة
ﺑﻨﺎﺋﻪ وﻳﻤﻜﻨﻪ اﺳﺘﻜﺸﺎف أﺷﻜﺎلٍﻣﺨﺘﻠﻔﺔﻣﻦ اﻟﻮﺟﻮد واﻟﺬﻛﺎء واﻹﺑﺪاع، وﻣﺎ إﱃ ذﻟﻚ.ﻟﻴﺲ
ﻫﻨﺎكﺣﺎﺟﺔﻷنﻳُﺼﻨﱠﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆﺻﻮرﺗﻨﺎ.ﻓﺎﻟﺘﻘﺪﱡمﻫﻨﺎﻳﻌﻨﻲﺗﺠﺎوز اﻹﻧﺴﺎن
وﻗﺒﻮلﻏري اﻟﺒﴩﻟﻜﻲﻧﺘﻌﻠﱠﻢﻣﻨﻬﻢ. وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻳﻤﻜﻦ أنﻳﺘﻔﻖﻛﻞﱞﻣﻦ دﻋﺎةﺗﺠﺎوز
اﻹﻧﺴﺎﻧﻴﺔ وﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔﻋﲆ أﻧﻪﺑﺪﻻًﻣﻦ اﻟﺘﻨﺎﻓُﺲﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻷداءﻣﻬﻤﺔ
ﻣﻌﻴﱠﻨﺔ،ﻳُﻤﻜﻨﻨﺎ أﻳﻀًﺎﺗﺤﺪﻳﺪﻫﺪفٍﻣﺸﱰك،ﻳﺘﻢ اﻟﺘﻮﺻﱡﻞ إﻟﻴﻪﻣﻦﺧﻼل اﻟﺘﻌﺎون وﺣﺸﺪ
أﻓﻀﻞﻣﺎﻳﻤﻜﻦ أنﻳﻘﺪﱢﻣﻪ اﻟﺒﴩ واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦ أﺟﻞ اﻟﺘﻮﺟﱡﻪﻧﺤﻮﺗﺤﻘﻴﻖ ذﻟﻚ
اﻟﻬﺪف املﺸﱰك.
وﺳﻴﻠﺔ أﺧﺮىﻟﺘﺠﺎوزﴎدﻳﺔ املﻨﺎﻓﺴﺔ — وﻫﻲ وﺳﻴﻠﺔﺗﻘﱰبﰲﺑﻌﺾ اﻷﺣﻴﺎنﻣﻦ
ﻣﻔﺎﻫﻴﻢﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ —ﻫﻲﻧﻬﺞﰲﻓﻠﺴﻔﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻳُﺴﻤﱠﻰﻣﺎﺑﻌﺪ اﻟﻈﺎﻫﺮﻳﺔ.
ﻳﺴﺘﻨِﺪ درﻳﻔﻮس إﱃﻋﻠﻢ اﻟﻈﻮاﻫﺮ أو اﻟﻈﺎﻫﺮﻳﺔ، وﻻﺳﻴﻤﺎ أﻋﻤﺎلﻫﺎﻳﺪﺟﺮ. وﻟﻜﻦ اﻷﻓﻜﺎر
ﻣﺎﺑﻌﺪ اﻟﻈﺎﻫﺮﻳﺔ، اﻟﺘﻲﺑﺪأﻫﺎ اﻟﻔﻴﻠﺴﻮف دون إﻳﺪه،ﺗﺘﺠﺎوزﻓﻠﺴﻔﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﻈﺎﻫﺮﻳﺔ
اﻟﺘﻲ اﺑﺘﻜﺮﻫﺎﻫﺎﻳﺪﺟﺮﺑﺎﻟﱰﻛﻴﺰﻋﲆﻛﻴﻔﻴﺔﺗﻔﺎﻋﻞ اﻟﺒﴩﻣﻊﺗﻘﻨﻴﺎتﺑِﻌَﻴﻨﻬﺎ وﻻﺳﻴﻤﺎ
37</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
املﺼﻨﻮﻋﺎت املﺎدﻳﺔ.ﻳُﺮﻛﱢﺰﻫﺬا اﻟﻨﻬﺞ، اﻟﺬيﻳﺘﻌﺎونﰲﻛﺜريٍﻣﻦ اﻷﺣﻴﺎنﻣﻊ دراﺳﺎت اﻟﻌﻠﻮم
واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ،ﻋﲆ اﻟﺒُﻌﺪ املﺎديﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻗﺪﻳُﻨﻈَﺮ إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ
ﺑﻌﺾ اﻷﺣﻴﺎنﻋﲆ أﻧﻪ ذوﻃﺎﺑﻊٍﻣُﺠﺮﱠد أوﺷﻜﲇ،ﻏريﻣُﺘﺼﻞﺑﻤﺼﻨﻮﻋﺎتٍﻣﺎدﻳﺔ وﺑِﻨﻴﺎت
أﺳﺎﺳﻴﺔﻣُﺤﺪﱠدة. وﻟﻜﻦﺟﻤﻴﻊ اﻟﺸﻜﻠﻴﺎت واﻟﺘﺠﺮﻳﺪات واﻟﻌﻤﻠﻴﺎت اﻟﺮﻣﺰﻳﺔ املﺬﻛﻮرةﺳﺎﺑﻘًﺎ
ﺗﻌﺘﻤِﺪﻋﲆ أدواتٍﻣﺎدﻳﺔ وﺑِﻨﻴﺎت أﺳﺎﺳﻴﺔﻣﺎدﻳﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻛﻤﺎﺳﻨﺮىﰲ اﻟﻔﺼﻞ
اﻟﺘﺎﱄ،ﻳﻌﺘﻤِﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺤﺎﱄﺑﺸﻜﻞٍﻛﺒريﻋﲆ اﻟﺸﺒﻜﺎت وإﻧﺘﺎجﻛﻤﻴﱠﺎتﺿﺨﻤﺔ
ﻣﻦ اﻟﺒﻴﺎﻧﺎتﺑﺎﺳﺘﺨﺪام اﻷﺟﻬﺰة اﻹﻟﻜﱰوﻧﻴﺔ.ﺗﻠﻚ اﻟﺸﺒﻜﺎت واﻷﺟﻬﺰةﻟﻴﺴﺖﻣﺠﺮد أﺷﻴﺎء
»اﻓﱰاﺿﻴﺔ« وﻟﻜﻦﻳﺘﻌنيﱠ إﻧﺘﺎﺟﻬﺎ وﺻﻴﺎﻧﺘﻬﺎﺑﺸﻜﻞٍﻣﺎدي. وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻳﺘﺤﺪﱠثﻣﺎﺑﻌﺪ
اﻟﻈﺎﻫِﺮﻳﱢني،ﻣﺜﻞﺑﻴﱰﺑﻮلﻓريﺑﻴﻚ،ﻋﻜﺲ اﻟﺘﻘﺴﻴﻢ اﻟﺤﺪﻳﺚﺑني املﻮﺿﻮع واملﺤﻤﻮل،ﻋﻦ
اﻟﺘﺸﻜﻴﻞ املُﺘﺒﺎدلﺑني اﻟﺒﴩ واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ، أوﻋﲆ اﻷﺣﺮى اﻟﺘﺸﻜﻴﻞ املُﺘﺒﺎدلﺑني املﻮﺿﻮع
واملﺤﻤﻮل. وﺑﺪﻻًﻣﻦ رؤﻳﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻛﺘﻬﺪﻳﺪ،ﻳﺆﻛﱢﺪون أن اﻟﺒﴩﻣَﻴﱠﺎﻟﻮن إﱃ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
)ﺑﻤﻌﻨﻰ أﻧﻬﻢﻛﺎﻧﻮا داﺋﻤًﺎﻳﺴﺘﺨﺪﻣﻮن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ؛ أي إﻧﻬﺎﺟﺰءﻣﻦ وﺟﻮدﻧﺎ وﻟﻴﺴﺖ
ﺷﻴﺌًﺎﺧﺎرﺟﻴٍّﺎﻳُﻬﺪﱢدﻫﺬا اﻟﻮﺟﻮد(، وأن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺗُﺴﺎﻋﺪ اﻟﺒﴩﻋﲆ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﻌﺎﻟﻢ.
ﺑﺎﻟﻨﺴﺒﺔ إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻳﺒﺪو أنﻫﺬه اﻟﺮؤﻳﺔﺗَﻌﻨﻲ أن املﻌﺮﻛﺔ اﻹﻧﺴﺎﻧﻴﺔﻟﻠﺪﻓﺎع
ﻋﻦ اﻹﻧﺴﺎنﺿﺪ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻫﻲﻣﻌﺮﻛﺔﻣُﻀﻠﻠَﺔ. وﺑﺪﻻًﻣﻦ ذﻟﻚ، وﻓﻘًﺎﻟﻬﺬا اﻟﻨﻬﺞ،ﻛﺎن
اﻹﻧﺴﺎن داﺋﻤًﺎﻣﻴﱠﺎﻻً إﱃ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ، وﻟﻬﺬاﻋﻠﻴﻨﺎ أنﻧﺴﺄلﻛﻴﻒﻳُﺴﺎﻋﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺒﴩﰲ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﻌﺎﻟﻢ وﻧﺤﺎولﺗﺸﻜﻴﻞﻫﺬه املُﺴﺎﻋﺪاتﺑﺸﻜﻞٍﺗﻔﺎﻋُﲇﺑﻴﻨﻤﺎﻻﻳﺰال
ﺑﺈﻣﻜﺎﻧﻨﺎ: إﻧﻨﺎﻧﺴﺘﻄﻴﻊﻣﻨﺎﻗﺸﺔ اﻷﺧﻼﻗﻴﺎتﰲﻣﺮﺣﻠﺔﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺑﻞﻳﺘﻌنيﱠ
ﻋﻠﻴﻨﺎ ذﻟﻚ،ﺑﺪﻻًﻣﻦ أنﻧﺸﻜﻮﻓﻴﻤﺎﺑﻌﺪُﻣﻦ املﺸﻜﻼت اﻟﺘﻲﻳُﺴﺒﱢﺒﻬﺎ.
ﻳﺒﺪو أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳُﻤﻜﻨﻪ،ﺑﺎﻻﺳﺘﻨﺎد إﱃ آراءﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ، أنﻳُﺤﺮﱢرﻧﻔﺴﻪﻣﻦﻋﺐء
ﺗﻘﻠﻴﺪ اﻹﻧﺴﺎن أو إﻋﺎدةﺑﻨﺎﺋﻪ وﻳُﻤﻜﻨﻪ اﺳﺘﻜﺸﺎف أﺷﻜﺎلٍﻣﺨﺘﻠﻔﺔﻣﻦ اﻟﻮﺟﻮد واﻟﺬﻛﺎء واﻹﺑﺪاع، وﻣﺎ
إﱃ ذﻟﻚ.
وﻣﻊ ذﻟﻚ، رﺑﻤﺎﻳﺸﻌُﺮ املﺮءﺑﺎﻟﻘﻠﻖﻣﻦ أنﱠ رُؤىﻣُﻨﺎﴏيﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ وﻣﺎﺑﻌﺪ
اﻟﻈﺎﻫﺮﻳﺔﻟﻴﺴﺖﻧﺎﻗﺪةًﺑﻤﺎﻓﻴﻪ اﻟﻜﻔﺎﻳﺔ؛ﻷﻧﻬﺎﺷﺪﻳﺪة اﻟﺘﻔﺎؤل وﺷﺪﻳﺪة اﻟﺒُﻌﺪﻋﻦ املﻤﺎرﺳﺔ
اﻟﻌﻠﻤﻴﺔ واﻟﻬﻴﻜﻠﻴﺔ، وﺑﺎﻟﺘﺎﱄﻓﻬﻲﻟﻴﺴﺖﺣﺴﱠﺎﺳﺔﺑﻤﺎﻓﻴﻪ اﻟﻜﻔﺎﻳﺔﺗﺠﺎه اﻷﺧﻄﺎر اﻟﺤﻘﻴﻘﻴﺔ
واﻟﻌﻮاﻗﺐ اﻷﺧﻼﻗﻴﺔ واملُﺠﺘﻤﻌﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. إنﻋﺒﻮر اﻟﺤﺪود اﻟﺘﻲﻟﻢﻳﺴﺒﻖﻋﺒﻮرﻫﺎ
38</p>
<p>ﻛﻞﻣﺎﻟﻪﻋﻼﻗﺔﺑﺎﻟﺒﴩ
ﻻﻳﻜﻮنﺑﺎﻟﴬورةﻣﻦ دونﻣﺸﻜﻼت، وﰲ املﻤﺎرﺳﺔ اﻟﻌﻤﻠﻴﺔﻗﺪﻻﺗﻔﻴﺪ أﻓﻜﺎرﻣﺎﺑﻌﺪ
اﻹﻧﺴﺎﻧﻴﺔ وﻣﺎﺑﻌﺪ اﻟﻈﺎﻫﺮﻳﺔﰲﺣﻤﺎﻳﺘﻨﺎﻣﻦ اﻟﺘﺴﻠﱡﻂ واﻻﺳﺘﻐﻼل اﻟﺬيﻗﺪﻧُﻌﺎﻧﻲﻣﻨﻪﺟﺮﱠاء
اﺳﺘﺨﺪامﺗﻘﻨﻴﺎتﻛﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻳُﻤﻜﻦﻟﻠﻤﺮء أﻳﻀًﺎ أنﻳُﺪاﻓﻊﻋﻦ رؤﻳﺔ أﻛﺜﺮﺗﻘﻠﻴﺪﻳﺔ
ﻟﻺﻧﺴﺎن أوﻳُﻄﺎﻟﺐﺑﻨﻮعٍﺟﺪﻳﺪﻣﻦ اﻹﻧﺴﺎﻧﻴﺔ،ﺑﺪﻻًﻣﻦ أنﻳﺪﻋﻢﻣﺎﺑﻌﺪَ اﻹﻧﺴﺎﻧﻴﺔ. وﻫﻜﺬا
ﻳﺴﺘﻤﺮ اﻟﻨﻘﺎش.
39</p>
</section>
<section id="section-5">
    <h2>٤ - أهي حقًّا مجرد آلات؟</h2>
    <div class="page-range">Pages 41-50</div>
    <p>اﻟﻔﺼﻞ اﻟﺮاﺑﻊ
أﻫﻲﺣﻘĢﺎﳎﺮد آﻻت؟
اﻟﺘﺸﻜﻴﻚﰲ املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ:
اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ واﻛﺘﺴﺎب املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ
.إﺣﺪى اﻟﻘﻀﺎﻳﺎ اﻟﺘﻲ أُﺛريَتﰲ اﻟﻔﺼﻞ اﻟﺴﺎﺑﻖﺗﺘﻌﻠﱠﻖﺑﻤﺎ إذاﻛﺎنﻏري اﻟﺒﴩﻣُﻬﻤﱢني أﻳﻀًﺎ
ﻳﻌﺘﻘﺪ اﻟﻜﺜريون اﻟﻴﻮم أن اﻟﺤﻴﻮاﻧﺎتﻣُﻬﻤﱠﺔﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔ. وﻟﻜﻦﻟﻢﻳﻜُﻦ اﻷﻣﺮﻛﺬﻟﻚ
داﺋﻤًﺎ.ﻋﲆﻣﺎﻳﺒﺪو،ﻛﻨﱠﺎﻣُﺨﻄﺌنيﰲ املﺎﴈﺑﺸﺄن اﻟﺤﻴﻮاﻧﺎت.ﻓﺈذاﻛﺎن اﻟﻜﺜريون اﻟﻴﻮم
ﻳﻌﺘﻘﺪون أن اﻵﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺠﺮد آﻻت،ﻓﻬﻞﻳﺮﺗﻜِﺒﻮنﺧﻄﺄًﻣُﻤﺎﺛﻼً ؟
ﻫﻞﺗﺴﺘﺤِﻖﱡ اﻵﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻔﺎﺋﻘﺔ اﻟﺬﻛﺎءﻣﻜﺎﻧﺔً أﺧﻼﻗﻴﺔ؟ﻫﻞﻳﻨﺒﻐﻲ
أنﻧُﻌﻄﻴﻬﺎﺣﻘﻮﻗًﺎ؟ أم إﻧﻪﻣﻦ اﻟﺨﻄﻮرةﺑﻤﻜﺎنٍ أنﻧُﻔﻜﱢﺮﺣﺘﻰﰲﻣﺴﺄﻟﺔﻣﺎ إذاﻛﺎﻧﺖ اﻵﻻت
ﻳُﻤﻜﻦ أنﺗﺤﻈﻰﺑﻤﻜﺎﻧﺔٍ أﺧﻼﻗﻴﺔ؟
إﺣﺪى اﻟﻄﺮق ملﻨﺎﻗﺸﺔﻣﺎﻫﻮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣﺎﻳﻤﻜﻦ أنﻳُﺼﺒﺢﻋﻠﻴﻪﻫﻲ
اﻟﺴﺆالﻋﻦ املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻧﺤﻦﻫﻨﺎﻧﺘﻄﺮﱠق إﱃ أﺳﺌﻠﺔٍﻓﻠﺴﻔﻴﺔ
ﻣُﺘﻌﻠﱢﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻟﻴﺲﻋﱪ املﻴﺘﺎﻓﻴﺰﻳﻘﺎ أو اﻹﺑﺴﺘﻤﻮﻟﻮﺟﻴﺎ أوﺗﺎرﻳﺦ اﻷﻓﻜﺎر،
وﻟﻜﻦﻋﱪﻓﻠﺴﻔﺔ اﻷﺧﻼق.ﻳﻤﻜﻦ أنﻳُﺸريﻣﺼﻄﻠﺢ »املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ« )وﻳُﺴﻤﻰ أﺣﻴﺎﻧًﺎ
»اﻷﻫﻤﻴﺔ اﻷﺧﻼﻗﻴﺔ«( إﱃﻧﻮﻋَنيﻣﻦ اﻷﺳﺌﻠﺔ. اﻷولﻳﺘﻌﻠﱠﻖﺑﻤﺎﻳُﻤﻜِﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﻘﻴﺎمﺑﻪﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔ؛ﺑﻌﺒﺎرةٍ أﺧﺮى،ﻣﺎ إذاﻛﺎنﻳﻤﻜﻦ أنﻳﺘﻤﺘﱠﻊﺑﻤﺎﻳُﻄﻠﻖ
ﻋﻠﻴﻪ اﻟﻔﻼﺳﻔﺔ »اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ«، وإذاﻛﺎن اﻷﻣﺮﻛﺬﻟﻚ،ﻓﻬﻞﻳﺘﻤﺘﱠﻊﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ
اﻟﻜﺎﻣِﻠﺔ؟ﻣﺎذاﻳﻌﻨﻲﻫﺬا؟ﻳﺒﺪو أن أﻓﻌﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻴﻮمﻟﻬﺎﺑﺎﻟﻔﻌﻞﻋﻮاﻗِﺐ
أﺧﻼﻗﻴﺔ.ﺳﻴﺘﱠﻔﻖﻣﻌﻈﻢ اﻟﻨﺎسﻋﲆ أنﻟﺪى اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺷﻜﻼً »ﺿﻌﻴﻔًﺎ«ﻣﻦ أﺷﻜﺎل
اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔﺑﻬﺬا املﻌﻨﻰ، واﻟﺬيﻳُﺸﺒِﻪ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣُﻌﻈﻢ اﻟﺴﻴﺎرات اﻟﻴﻮم؛ إذ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﻤﻜﻦ أنﻳﻜﻮنﻟﻸﺧرية أﻳﻀًﺎﻋﻮاﻗِﺐ أﺧﻼﻗﻴﺔ. وﻟﻜﻦ إذاﺳﻠﱠﻤﻨﺎﺑﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﺰداد ذﻛﺎءً واﺳﺘﻘﻼﻻً ،ﻓﻬﻞﻳﻤﻜﻦ أنﻳﺘﻤﺘﱠﻊﺑﺸﻜﻞٍ أﻗﻮىﻣﻦ أﺷﻜﺎل اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ؟
ﻫﻞﻳﺠِﺐ أنﻳﺘﻢﻣﻨﺤُﻪ أوﺳﻴﺘﻄﻮﱠرﻟﺪَﻳﻪﺑﻌﺾ اﻟﻘﺪرةﻋﲆ اﻟﺘﻔﻜري اﻷﺧﻼﻗﻲ واﻟﻘﺪرة
ﻋﲆ إﺻﺪار اﻷﺣﻜﺎم واﺗﺨﺎذ اﻟﻘﺮارات؟ﻋﲆﺳﺒﻴﻞ املﺜﺎل:ﻫﻞﻳُﻤﻜﻦ وﻫﻞﻳﺠﺐ أنﻧﻌﺘﱪ
اﻟﺴﻴﺎرات اﻟﺬاﺗﻴﺔ اﻟﻘﻴﺎدة اﻟﺘﻲﺗﺴﺘﺨﺪِم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ ذات وﻛﺎﻟﺔ أﺧﻼﻗﻴﺔ؟ﻫﺬه
اﻷﺳﺌﻠﺔﺗﺘﻌﻠﱠﻖﺑﺄﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺑﻤﻌﻨﻰ أﻧﻬﺎﺗﺘﻄﺮﱠق إﱃﻣﺎﻫﻴﺔ اﻟﻘﺪرات
اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲﻳﻤﻜﻦ أوﻳﻨﺒﻐﻲ أنﻳﺘﻤﺘﱠﻊﺑﻬﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ وﻟﻜﻦ اﻷﺳﺌﻠﺔ املُﺘﻌﻠﻘﺔﺑ
»املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ«ﻳﻤﻜﻦ أﻳﻀًﺎ أنﺗُﺸري إﱃﻛﻴﻒﻳﻨﺒﻐﻲ أنﻧُﻌﺎﻣﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻫﻞ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ »ﻣﺠﺮد آﻟﺔ«، أم أﻧﻪﻳﺴﺘﺤﻖﺷﻜﻼًﻣﻦ أﺷﻜﺎل اﻻﺣﱰام اﻷﺧﻼﻗﻲ؟ﻫﻞ
ﻳﺠﺐﻋﻠﻴﻨﺎﻣُﻌﺎﻣﻠﺘﻪﺑﻄﺮﻳﻘﺔٍﻣﺨﺘﻠﻔﺔﻋﻦ اﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻧﺘﻌﺎﻣﻞﺑﻬﺎﻣﺜﻼًﻣﻊ آﻟﺔ اﻟﺘﺤﻤﻴﺺ
أو املﻐﺴﻠﺔ؟ﻫﻞﻳﺠﺐ أنﻧﻤﻨﺢﺣﻘﻮﻗًﺎﻟﻜﻴﺎنٍﺻﻨﺎﻋﻲ ذﻛﻲﻟﻠﻐﺎﻳﺔ، إذاﺗﻢﺗﻄﻮﻳﺮﻣﺜﻞ
ﻫﺬا اﻟﻜﻴﺎنﻳﻮﻣًﺎﻣﺎ،ﺣﺘﻰﻟﻮﻟﻢﻳﻜُﻦﺑﴩﻳٍّﺎ؟ﻫﺬاﻣﺎﻳُﻄﻠِﻖﻋﻠﻴﻪ اﻟﻔﻼﺳﻔﺔ اﻟﺴﺆال املﺘﻌﻠﻖ
ﺑ »اﻛﺘﺴﺎب املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ«.ﻫﺬا اﻟﺴﺆالﻳﺘﻌﻠﻖﺑﺄﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺬاﺗﻪ،
وﻟﻜﻨﻪﻳﺘﻌﻠﱠﻖﺑﺄﺧﻼﻗﻴﺎﺗﻨﺎﺗﺠﺎﻫﻪ.ﻫﻨﺎﻳﻜﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻮﺿﻊَ اﻫﺘﻤﺎمٍﻣﻦ اﻟﻨﺎﺣﻴﺔ
اﻷﺧﻼﻗﻴﺔ،ﺑﺪﻻًﻣﻦﻛﻮﻧﻪ وﻛﻴﻼً أﺧﻼﻗﻴٍّﺎﻣُﺤﺘﻤﻼًﰲﺣﺪﱢ ذاﺗﻪ.
ﻫﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ »ﻣﺠﺮد آﻟﺔ«؟ﻫﻞﻳﺠﺐﻋﻠﻴﻨﺎﻣﻌﺎﻣﻠﺘﻪﺑﻄﺮﻳﻘﺔٍﻣﺨﺘﻠﻔﺔﻋﻦ اﻟﻄﺮﻳﻘﺔ اﻟﺘﻲ
ﻧﺘﻌﺎﻣﻞﺑﻬﺎﻣﺜﻼًﻣﻊ آﻟﺔ اﻟﺘﺤﻤﻴﺺ أو املﻐﺴﻠﺔ؟
اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ
ﻟﻨﺒﺪأﺑﺎﻟﺘﺤﺪﱡثﻋﻦﺳﺆال اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ. إذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳُﻤﻜﻦ أنﻳُﺼﺒﺢ
أﻛﺜﺮ ذﻛﺎءًﻣﻤﺎﻫﻮﻋﻠﻴﻪ اﻟﻴﻮم،ﻓﻴُﻤﻜﻨﻨﺎ أنﻧﻔﱰض أﻧﻪﻳﺴﺘﻄﻴﻊ أنﻳُﻄﻮﱢرﻗﺪرﺗﻪﻋﲆ اﻟﺘﻔﻜري
اﻷﺧﻼﻗﻲ وأﻧﻪﻳﺴﺘﻄﻴﻊ أنﻳﺘﻌﻠﱠﻢﻛﻴﻒﻳﺘﱠﺨِﺬ اﻟﺒﴩ اﻟﻘﺮاراتﺑﺸﺄن اﻟﻘﻀﺎﻳﺎ اﻷﺧﻼﻗﻴﺔ.
وﻟﻜﻦﻫﻞﺳﻴﻜﻮنﻫﺬاﻛﺎﻓﻴًﺎﻟﻜﻲﻳﺤﻈﻰﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﻜﺎﻣﻠﺔ؛ أي اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ
اﻟﺘﻲﻳﺘﻤﺘﱠﻊﺑﻬﺎ اﻹﻧﺴﺎن؟ﻫﺬا اﻟﺴﺆالﻟﻴﺲﺧﻴﺎﻻًﻋﻠﻤﻴٍّﺎﺑﺎﻟﻜﺎﻣﻞ.ﻓﺈذاﻛﻨﺎﻧﻌﺘﻤِﺪ اﻟﻴﻮمﻋﲆ
اﻟﺨﻮارزﻣﻴﺎتﰲ اﺗﺨﺎذﺑﻌﺾﻗﺮاراﺗﻨﺎ،ﻋﲆﺳﺒﻴﻞ املﺜﺎلﰲ اﻟﺴﻴﺎرات أو املﺤﺎﻛﻢ،ﻓﻴﺒﺪو
أﻧﻪﺳﻴﻜﻮنﻣﻦ املُﻬﻢﱢ أنﺗﻜﻮنﺗﻠﻚ اﻟﻘﺮاراتﺳﻠﻴﻤﺔًﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔ. وﻟﻜﻦﻟﻴﺲ
42</p>
<p>أﻫﻲﺣﻘٍّﺎﻣﺠﺮد آﻻت؟
ﻣﻦ اﻟﻮاﺿﺢﻣﺎ إذاﻛﺎﻧﺖ اﻵﻻتﻳﻤﻜﻦ أنﺗﺘﻤﺘﱠﻊﺑﻨﻔﺲ اﻟﻘﺪرات اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲﻳﺘﻤﺘﱠﻊﺑﻬﺎ
اﻟﺒﴩ. إﻧﻬﺎﺗﺘﻤﺘﱠﻊﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔﺑﻤﻌﻨﻰ أﻧﻬﺎﺗﻘﻮمﺑﺄﻓﻌﺎلٍﰲ اﻟﻌﺎﻟَﻢ، وﻫﺬه اﻷﻓﻌﺎلﻟﻬﺎ
ﻋﻮاﻗﺐ أﺧﻼﻗﻴﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﺗﺘﺴﺒﱠﺐﺳﻴﺎرة ذاﺗﻴﺔ اﻟﻘﻴﺎدةﰲﺣﺎدث، أوﻗﺪﻳﻮﴆ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺴﺠﻦﺷﺨﺺﻣﻌنيﱠ .ﻫﺬه اﻟﺴﻠﻮﻛﻴﺎت واﻟﺨﻴﺎراتﻟﻴﺴﺖﺣﻴﺎدﻳﺔﻣﻦ
اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔ؛ إذ إنﻟﻬﺎﻋﻮاﻗﺐ أﺧﻼﻗﻴﺔ واﺿﺤﺔﻋﲆ اﻷﺷﺨﺎص ذوي اﻟﺼﻠﺔ. وﻟﻜﻦ
ﻟﻠﺘﻌﺎﻣُﻞﻣﻊﻫﺬه املﺸﻜﻠﺔ،ﻫﻞﻳﺠﺐﻣﻨﺢ اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ وﻫﻞﻳﻤﻜﻦ
أنﻳﺘﻤﺘﱠﻊﺑﻮﻛﺎﻟﺔ أﺧﻼﻗﻴﺔﻛﺎﻣﻠﺔ؟
ﻫﻨﺎكﻣﻮاﻗﻒﻓﻠﺴﻔﻴﺔﻣُﺘﻨﻮﱢﻋﺔﺣﻴﺎلﻫﺬه اﻷﺳﺌﻠﺔ.ﻳﻘﻮلﺑﻌﺾ اﻷﺷﺨﺎص إن اﻵﻻتﻻ
ﻳﻤﻜﻦ أنﺗﺘﻤﺘﱠﻊ أﺑﺪًاﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ. وﻳﺮىﻫﺆﻻء أن اﻵﻻتﻟﻴﺲﻟﺪَﻳﻬﺎ اﻟﻘﺪرات اﻟﻼزﻣﺔ
ﻟﻠﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ،ﻣﺜﻞ اﻟﺤﺎﻻت اﻟﻌﻘﻠﻴﺔ أو اﻻﻧﻔﻌﺎﻻت أو اﻹرادة اﻟﺤﺮة. وﻟﺬﻟﻚﻫﻨﺎكﺧﻄﻮرة
ﰲ أنﻧﻔﱰِض أﻧﻬﺎﺗﺴﺘﻄﻴﻊ اﺗﺨﺎذﻗﺮاراتٍﺳﻠﻴﻤﺔ أﺧﻼﻗﻴٍّﺎ وأنﻧﻌﺘﻤِﺪﻋﻠﻴﻬﺎﰲ اﺗﺨﺎذ
ﻣﺜﻞﻫﺬه اﻟﻘﺮارات اﻋﺘﻤﺎدًاﻛﺎﻣﻼً .ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺎﻟﺖ دﻳﺒﻮراﺟﻮﻧﺴﻮن )٦٠٠٢( إن
أﻧﻈﻤﺔ اﻟﻜﻤﺒﻴﻮﺗﺮﻻﺗﺘﻤﺘﱠﻊﺑﻮﻛﺎﻟﺔٍ أﺧﻼﻗﻴﺔﺧﺎﺻﺔﺑﻬﺎ: إﻧﻬﺎﻣﻦ إﻧﺘﺎج اﻟﺒﴩ وﺗُﺴﺘﺨﺪَمﻣﻦ
ﻗِﺒَﻠﻬﻢ، واﻟﺒﴩ وﺣﺪَﻫﻢﻟﺪﻳﻬﻢ اﻟﺤﺮﻳﺔ واﻟﻘﺪرةﻋﲆ اﻟﺘﴫﱡف واﺗﺨﺎذ اﻟﻘﺮاراتﻣﻦ اﻟﻨﺎﺣﻴﺔ
اﻷﺧﻼﻗﻴﺔ. وﺑﺎﻟﻄﺮﻳﻘﺔﻧﻔﺴﻬﺎ،ﻳﻤﻜﻦﻟﻠﻤﺮء أنﻳﻘﻮل إن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦ إﻧﺘﺎج اﻟﺒﴩ،
وﺑﺎﻟﺘﺎﱄﻳﺠﺐ أنﻳﻜﻮن اﺗﺨﺎذ اﻟﻘﺮارات اﻷﺧﻼﻗﻴﺔﰲ املﻤﺎرﺳﺎت اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔﻣﻦ اﺧﺘﺼﺎص
اﻟﺒﴩ.ﻋﲆ اﻟﻨﻘﻴﺾﻣﻦ ذﻟﻚ،ﻫﻨﺎك أوﻟﺌﻚ اﻟﺬﻳﻦﻳﻌﺘﻘﺪون أن اﻵﻻتﻳﻤﻜﻦ أنﺗﺘﻤﺘﱠﻊﺑﻮﻛﺎﻟﺔٍ
أﺧﻼﻗﻴﺔﻛﺎﻣﻠﺔﺗﻤﺎﻣًﺎﻣﺜﻞ اﻟﺒﴩ. وﻳﺰﻋﻢ اﻟﺒﺎﺣﺜﻮنﻣﺜﻞﻣﺎﻳﻜﻞ وﺳﻮزان أﻧﺪرﺳﻮن،ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل، أﻧﻪﻣﻦﺣﻴﺚ املﺒﺪأﻳﻤﻜﻦ،ﺑﻞﻳﺠﺐ، أنﺗُﻤﻨﺢ اﻵﻻتﻧﻮﻋًﺎﻣﻦ اﻷﺧﻼق اﻟﺒﴩﻳﺔ
(. وﻳُﻤﻜﻨﻨﺎﺗﺰوﻳﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎملﺒﺎدئ، ورﺑﻤﺎAnderson and Anderson 2011)
ﺗﻜﻮن اﻵﻻتﺣﺘﻰ أﻓﻀﻞﻣﻦ اﻟﺒﴩﰲ اﻟﻮﺻﻮل إﱃ اﻟﻘﺮارات اﻷﺧﻼﻗﻴﺔﻧﻈﺮًاﻷﻧﻬﺎ أﻛﺜﺮ
ﻋﻘﻼﻧﻴﺔ وﻻﺗﻨﺠﺮف وراءﻋﻮاﻃﻔﻬﺎ. وﻗﺪﺟﺎدل اﻟﺒﻌﺾ،ﻟﺪﺣﺾﻫﺬه اﻟﻔﻜﺮة،ﺑﺄن اﻟﻘﻮاﻋﺪ
اﻷﺧﻼﻗﻴﺔﻛﺜريًاﻣﺎﺗﺘﻀﺎرب )ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻧﻈﺮ إﱃﻗﺼﺺ اﻟﺮوﺑﻮﺗﺎتﻷﺳﻴﻤﻮف،
ﺣﻴﺚﺗﺘﺴﺒﱠﺐ اﻟﻘﻮاﻧني اﻷﺧﻼﻗﻴﺔﻟﻠﺮوﺑﻮﺗﺎت داﺋﻤًﺎﰲﻣﺸﻜﻼتﻟﻠﺒﴩ واﻟﺮوﺑﻮﺗﺎت(، وأن
ﻣﴩوع إﻧﺸﺎء »آﻻت أﺧﻼﻗﻴﺔ«ﻣﻦﺧﻼلﺗﻐﺬِﻳَﺘﻬﺎﺑﺎﻟﻘﻮاﻋﺪﻳﺴﺘﻨﺪ إﱃ اﻓﱰاﺿﺎتٍﺧﺎﻃﺌﺔ
ﺑﺨﺼﻮصﻃﺒﻴﻌﺔ اﻷﺧﻼق.ﻓﺎﻷﺧﻼقﻻﻳﻤﻜﻦ اﺧﺘﺰاﻟﻬﺎﰲ اﺗﱢﺒﺎع اﻟﻘﻮاﻋﺪ،ﻛﻤﺎ أﻧﻬﺎﻟﻴﺴﺖ
ﻣﺴﺄﻟﺔﻋﻮاﻃﻒﺑﴩﻳﺔﻓﺤﺴﺐ؛ وﻟﻜﻦﻫﺬه اﻟﻌﻮاﻃﻒﻗﺪﺗﻜﻮنﴐورﻳﺔﻟﻠﻐﺎﻳﺔﻟﻠﺤُﻜﻢ
اﻷﺧﻼﻗﻲ.ﻓﺈذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎمﻣُﻤﻜﻨًﺎﻋﲆ اﻹﻃﻼق،ﻓﺈﻧﻨﺎﻻﻧُﺮﻳﺪﻧﻮﻋًﺎﻣﻦ
43</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
»اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﺮﻳﺾﻧﻔﺴﻴٍّﺎ« أي اﻟﺬيﻳﺘﻤﺘﱠﻊﺑﺎﻟﻌﻘﻼﻧﻴﺔ اﻟﻜﺎﻣﻠﺔ وﻟﻜﻨﱠﻪﻻﻳﻬﺘﻢﱡ
(.Coeckelbergh 2010)ﺑﺎﻫﺘﻤﺎﻣﺎت اﻹﻧﺴﺎنﻷﻧﻪﻳﻔﺘﻘﺮ إﱃ املﺸﺎﻋﺮ
ﻟﻬﺬه اﻷﺳﺒﺎب،ﻳﻤﻜﻦ أنﻧﺮﻓﺾﻓﻜﺮةﺗﻤﺘﱡﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻮﻛﺎﻟﺔ أﺧﻼﻗﻴﺔﻛﺎﻣﻠﺔ
رﻓﻀًﺎﺗﺎﻣٍّﺎ، أوﻳﻤﻜﻦ أنﻧﺘﱠﺨِﺬﻣﻮﻗﻔًﺎ وﺳﻄًﺎ:ﻳﺠﺐ أنﻧﻤﻨﺢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻧﻮﻋًﺎﻣﻦ
اﻟﻘﻮاﻋﺪ اﻷﺧﻼﻗﻴﺔ، وﻟﻜﻦﻟﻴﺲﻛﻞ اﻟﻘﻮاﻋﺪ اﻷﺧﻼﻗﻴﺔ.ﻳﺴﺘﺨﺪم وﻳﻨﺪﻳﻞﻓﺎﻻخ وﻛﻮﻟني أﻟني
ﻣُﺼﻄﻠﺢ »اﻟﻘﻮاﻋﺪ اﻷﺧﻼﻗﻴﺔ اﻟﻮﻇﻴﻔﻴﺔ« )٩٠٠٢، ٩٣(.ﺗﺤﺘﺎج أﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
إﱃﺑﻌﺾ اﻟﻘﺪرةﻋﲆﺗﻘﻴﻴﻢ اﻟﻌﻮاﻗﺐ اﻷﺧﻼﻗﻴﺔﻷﻓﻌﺎﻟِﻬﺎ. واملﻨﻄﻖ وراءﻫﺬا اﻟﻘﺮار واﺿﺢ
ﰲﺣﺎﻟﺔ اﻟﺴﻴﺎرات ذاﺗﻴﺔ اﻟﻘﻴﺎدة:ﺳﺘﺘﻮرﱠط اﻟﺴﻴﺎرةﻋﲆ اﻷرﺟﺢﰲﻣﻮاﻗﻒﺗﺘﻄﻠﱠﺐ اﺗﺨﺎذ
ﺧﻴﺎرٍ أﺧﻼﻗﻲ وﻟﻜﻦﻻﻳﻮﺟَﺪ وﻗﺖﻟﻼﺳﺘﻌﺎﻧﺔﺑﺎﻟﺒﴩﻻﺗﺨﺎذ اﻟﻘﺮار أو اﻧﺘﻈﺎر اﻟﺘﺪﺧﱡﻞ
اﻟﺒﴩي. وﰲﺑﻌﺾ اﻷﺣﻴﺎن،ﺗﻜﻮنﻫﺬه اﻟﺨﻴﺎراتﻋﺒﺎرةﻋﻦﻣﻌﻀﻠﺔ.ﻳﺘﺤﺪﱠث اﻟﻔﻼﺳﻔﺔﻋﻦ
ﻣﻌﻀﻠﺔﻋﺮﺑﺔ اﻟﱰام، وﻫﻲﺗﺠﺮﺑﺔﻓﻜﺮﻳﺔﺗﺘﻌﻠﻖﺑﺴَ ريﻋﺮﺑﺔﺗﺮامﻋﲆﻣﺴﺎرﺳﻜﻚﺣﺪﻳﺪﻳﺔ
وﻳﺠﺐﻋﻠﻴﻚ اﻻﺧﺘﻴﺎرﺑنيﻋﺪمﻓِﻌﻞ أيﳾء، اﻷﻣﺮ اﻟﺬيﺳﻴﺆدﱢي إﱃﻣَﻮتﺧﻤﺴﺔ أﺷﺨﺎص
ﻣُﻘﻴﱠﺪﻳﻦﺑﺎملﺴﺎر، أوﺳﺤﺐ اﻟﺮاﻓﻌﺔ وإرﺳﺎل اﻟﻌﺮﺑﺔ إﱃﻣﺴﺎرٍ آﺧَﺮ،ﺣﻴﺚﻳﻜﻮنﻫﻨﺎك
ﺷﺨﺺٌ واﺣﺪﻣﻘﻴﱠﺪﺑﻪ وﻟﻜﻨﻪﺷﺨﺺﺗﻌﺮِﻓﻪ.ﻣﺎﻫﻮ اﻟﴚء اﻟﺴﻠﻴﻢ أﺧﻼﻗﻴٍّﺎ اﻟﺬيﻳﺘﻮﺟﱠﺐ
ﻋﻠﻴﻚ اﻟﻘﻴﺎمﺑﻪ؟ﺑﺎملﺜﻞ،ﻳﻘﻮل أﻧﺼﺎرﻫﺬا اﻟﻨﻬﺞ إن اﻟﺴﻴﺎرة اﻟﺬاﺗﻴﺔ اﻟﻘﻴﺎدةﻗﺪﺗُﻀﻄَﺮﱡ إﱃ
اﺗﺨﺎذﺧﻴﺎر أﺧﻼﻗﻲ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺑنيﻗﺘْﻞ املﺸﺎة اﻟﻌﺎﺑﺮﻳﻦﻋﲆ اﻟﻄﺮﻳﻖ واﻻﺻﻄﺪام
ﺑﺤﺎﺋﻂ،ﻣﻤﺎﻳﺆدي إﱃﻣﻮت اﻟﺴﺎﺋﻖ.ﻣﺎ اﻟﺨﻴﺎر اﻟﺬيﻳﺠِﺐ أنﺗﺘﱠﺨِﺬه اﻟﺴﻴﺎرة؟ﻳﺒﺪو أﻧﻪ
ﺳﻴﺘﻌنيﻋﻠﻴﻨﺎ اﺗﺨﺎذﻫﺬه اﻟﻘﺮارات اﻷﺧﻼﻗﻴﺔ )ﻣُﺴﺒﻘًﺎ( واﻟﺘﺄﻛﱡﺪﻣﻦﺗﻐﺬﻳﺔ اﻟﺴﻴﺎراتﺑﻬﺎ
ﻣﻦﻗِﺒَﻞ املُﻄﻮﱢرﻳﻦ. أو رﺑﻤﺎﻧﺤﺘﺎج إﱃﺑﻨﺎءﺳﻴﺎراتﻣﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺘﻌﻠﱠﻢﻣﻦ
اﺧﺘﻴﺎرات اﻟﺒﴩ. وﻣﻊ ذﻟﻚ،ﻗﺪﻳُﺜﺎرﺳﺆالﻋﻤﺎ إذاﻛﺎن إﻋﻄﺎء اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﻮاﻋﺪﻫﻮ
وﺳﻴﻠﺔﺟﻴﺪةﻟﺘﻤﺜﻴﻞ اﻷﺧﻼق اﻟﺒﴩﻳﺔ،ﻫﺬا إنﻛﺎنﻣﻦ املُﻤﻜﻦ »ﺗﻤﺜﻴﻞ« اﻷﺧﻼقﻣﻦ اﻷﺳﺎس،
وإذاﻛﺎﻧﺖﻣُﻌﻀﻠﺔﻋﺮﺑﺔ اﻟﱰامﺗﺒنيﺷﻴﺌًﺎﺟﻮﻫﺮﻳٍّﺎﰲ اﻟﺤﻴﺎة واﻟﺘﺠﺮﺑﺔ اﻷﺧﻼﻗﻴﺔ. أو،ﻣﻦ
ﻣﻨﻈﻮرٍﻣﺨﺘﻠﻒﺗﻤﺎﻣًﺎ،ﻳﻤﻜﻦﻟﻠﻤﺮء أنﻳﺘﺴﺎءلﻋﻤﺎ إذاﻛﺎن اﻟﺒﴩﰲ اﻟﻮاﻗﻊﻗﺎدِرﻳﻦﻋﲆ
اﺗﺨﺎذﻗﺮارات أﺧﻼﻗﻴﺔﺑﻜﻔﺎءة. وملﺎذاﻧُﻘﻠﺪ أﺧﻼق اﻟﺒﴩﻣﻦ اﻷﺳﺎس؟ إنﻣُﻨﺎﴏيﺗﺠﺎوز
اﻹﻧﺴﺎﻧﻴﺔ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﺮَون أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺳﻮفﻳﺘﻤﺘﻊﺑﺄﺧﻼقٍﻓﺎﺋﻘﺔﻷﻧﻪ
ﺳﻴﻜﻮن أﻛﺜﺮ ذﻛﺎءًﻣﻨﱠﺎ.
ﻫﺬا اﻟﺘﺸﻜﻴﻚﰲ اﻟﱰﻛﻴﺰﻋﲆ اﻹﻧﺴﺎنﻳُﻮﺟﱢﻬﻨﺎ إﱃﻣﻮﻗﻒٍ آﺧَﺮ،ﻻﻳﺘﻄﻠﱠﺐ وﻛﺎﻟﺔً أﺧﻼﻗﻴﺔ
ﻛﺎﻣﻠﺔ وﻳُﺤﺎولﺗﺮك املﻮﻗﻒ اﻷﺧﻼﻗﻲ املُﺘﻤﺤﻮِرﺣﻮل اﻹﻧﺴﺎن. وﻗﺪ داﻓﻊﻟﻮﺗﺸﻴﺎﻧﻮﻓﻠﻮرﻳﺪي
44</p>
<p>أﻫﻲﺣﻘٍّﺎﻣﺠﺮد آﻻت؟
وﺟﻴﻪ دﺑﻠﻴﻮﺳﺎﻧﺪرز )٤٠٠٢(ﻋﻦ أﺧﻼقٍﻻﻋﻘﻞﻟﻬﺎ وﻏريﻣُﺴﺘﻨﺪة إﱃﺧﺼﺎﺋﺺﻳﻤﺘﻠﻜﻬﺎ
اﻟﺒﴩ. وﻳُﻤﻜﻨﻨﺎﺟﻌﻞ اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔﺗﻌﺘﻤِﺪﻋﲆ اﻟﺘﻤﺘﱡﻊﺑﻤﺴﺘﻮًىﻛﺎفٍﻣﻦ اﻟﺘﻔﺎﻋﻞ
واﻻﺳﺘﻘﻼل واﻟﻘﺪرةﻋﲆ اﻟﺘﻜﻴﱡﻒ وﻛﺬﻟﻚ اﻟﻘﺪرةﻋﲆ اﻟﻘﻴﺎمﺑﺘﴫﱡﻓﺎت ذاتﻃﺎﺑﻊ أﺧﻼﻗﻲ.
ووﻓﻘًﺎﻟﻬﺬه املﻌﺎﻳري،ﻓﺈنﻛﻠﺐ اﻟﺒﺤﺚ واﻹﻧﻘﺎذﻳﺘﻤﺘﱠﻊﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ، وﻟﻜﻦﻛﺬﻟﻚ روﺑﻮت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳﺘﻮﱃﱠﺗﺼﻔﻴﺔ اﻟﺮﺳﺎﺋﻞ اﻟﱪﻳﺪﻳﺔﻏري املﺮﻏﻮبﻓﻴﻬﺎ. وﺑﺎملِﺜﻞ،ﻳﻤﻜﻦ
ﺗﻄﺒﻴﻖﻣﻌﺎﻳريﻻﺗﺘﻤﺤﻮَرﺣﻮل اﻹﻧﺴﺎن ملﻨﺢ اﻟﺮوﺑﻮﺗﺎت اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ،ﻛﻤﺎ اﻗﱰحﺟﻮن
ﺳﺎﻟﻴﻨﺰ )٦٠٠٢(: إذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣُﺴﺘﻘﻼٍّﻋﻦ املُﱪﻣﺠني وﻳﻤﻜﻨﻨﺎﺗﻔﺴريﺳﻠﻮﻛﻪ
ﺑﺄنﻧﻌﺰو إﻟﻴﻪ اﻟﻘﺼﺪ اﻷﺧﻼﻗﻲ )ﻣﺜﻞﻗﺼﺪﻓﻌﻞ اﻟﺨري أو اﻟﴩ(، وإذاﻧﻢﱠﺳﻠﻮﻛﻪﻋﻦ
ﻓَﻬﻢﻣﺴﺌﻮﻟﻴﺘﻪﺗﺠﺎه وﻛﻼء أﺧﻼﻗِﻴﱢني آﺧﺮِﻳﻦ،ﻓﺈنﻫﺬا اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺘﻤﺘﱠﻊﺑﺎﻟﻮﻛﺎﻟﺔ
اﻷﺧﻼﻗﻴﺔ. وﻣﻦﺛَﻢ،ﻓﺈنﻫﺬه اﻵراءﻻﺗﺘﻄﻠﱠﺐ اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﻜﺎﻣﻠﺔ إذاﻛﺎن ذﻟﻚﻳﻌﻨﻲ
اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﺒﴩﻳﺔ، وﻟﻜﻨﻬﺎﺗُﻌﺮﱢف اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔﺑﻄﺮﻳﻘﺔٍﺗﻜﻮنﻣﻦﺣﻴﺚ املﺒﺪأ
ﻣُﺴﺘﻘﻠﺔًﻋﻦ اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﻜﺎﻣﻠﺔﻟﻠﺒﴩ واﻟﻘُﺪرات اﻟﺒﴩﻳﺔ املﻄﻠﻮﺑﺔﻟﺬﻟﻚ. وﻣﻊ ذﻟﻚ،
ﻫﻞﺳﺘﻜﻮنﻣﺜﻞﻫﺬه اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻻﺻﻄﻨﺎﻋﻴﺔﻛﺎﻓﻴﺔً إذاﺣُﻜِﻢَﻋﻠﻴﻬﺎ وﻓﻘًﺎﻟﻠﻤﻌﺎﻳري
اﻷﺧﻼﻗﻴﺔ اﻟﺒﴩﻳﺔ؟ﻋﻤﻠﻴٍّﺎ،ﻳﻜﻤﻦ اﻟﻘﻠﻖ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ أن اﻟﺴﻴﺎرات ذاﺗﻴﺔ اﻟﻘﻴﺎدة
ﻗﺪﻻﺗُﻄﺒﻖ اﻟﻘﻮاﻋﺪ اﻷﺧﻼﻗﻴﺔ اﻟﻜﺎﻓﻴﺔ. أﻣﺎﻣﻦﺣﻴﺚ املﺒﺪأ،ﻓﻴﻜﻤﻦ اﻟﻘﻠﻖﰲ أﻧﻨﺎﻧﺒﺘﻌِﺪ
ﻛﺜريًاﻋﻦ اﻷﺧﻼق اﻟﺒﴩﻳﺔﻫﻨﺎ. وﻳﻌﺘﻘﺪ اﻟﻜﺜريون أن اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔﻣُﺮﺗﺒﻄﺔ وﻳﺠﺐ أن
ﺗﻜﻮنﻣﺮﺗﺒﻄﺔﺑﺎﻹﻧﺴﺎﻧﻴﺔ واﻟﺸﺨﺼﻴﺔ. وﻫﺆﻻءﻻﻳﻤﻴﻠﻮن إﱃ اﻋﺘﻨﺎق أﻓﻜﺎرﻣﺆﻳﱢﺪيﻣﺎﺑﻌﺪ
اﻹﻧﺴﺎﻧﻴﺔ أوﻣﺆﻳﺪيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ.
اﻛﺘﺴﺎب املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ
ﺛﻤﺔﻣﻮﺿﻮع آﺧَﺮﻣُﺜريﻟﻠﺠﺪَل وﻳﺘﻌﻠﱠﻖﺑﺎﻛﺘﺴﺎب اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ ملﻜﺎﻧﺔٍ أﺧﻼﻗﻴﺔ.ﺗﺨﻴﱠﻞ
أنﻟﺪَﻳﻨﺎ ذﻛﺎءً اﺻﻄﻨﺎﻋﻴٍّﺎﻓﺎﺋﻘًﺎ.ﻫﻞﻣﻦ املَﻘﺒﻮل أﺧﻼﻗﻴٍّﺎ إﻳﻘﺎفﺗﺸﻐﻴﻠِﻪ، أو »ﻗﺘﻠﻪ«؟ وإذا
ﻣﺎﻧﻈﺮﻧﺎﻋﻦﻛﺜَﺐ إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺤﺎﱄ:ﻫﻞﻣﻦ املﻘﺒﻮل رﻛﻞﻛﻠﺐٍ آﱄﻣُﺰود
إذاﻛﺎﻧﺖ اﻵﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺳﺘﻜﻮنﺟﺰءًاﻣﻦ1ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟
اﻟﺤﻴﺎة اﻟﻴﻮﻣﻴﺔ،ﻛﻤﺎﻳﺘﻮﻗﱠﻊ اﻟﻌﺪﻳﺪﻣﻦ اﻟﺒﺎﺣﺜني،ﻓﺈنﻣﺜﻞﻫﺬه اﻟﺤﺎﻻتﺳﺘﻈﻬﺮﺑﺎﻟﴬورة
وﺗُﺜريﻣﺴﺄﻟﺔﻛﻴﻒﻳﺠِﺐﻋﲆ اﻟﺒﴩ اﻟﺘﴫﱡفﺗﺠﺎهﻫﺬه اﻟﻜﻴﺎﻧﺎت اﻻﺻﻄﻨﺎﻋﻴﺔ. وﻣﻊ ذﻟﻚ،
ﻟﻴﺲﻋﻠَﻴﻨﺎ أنﻧﻨﻈُﺮ إﱃ املُﺴﺘﻘﺒﻞ اﻟﺒﻌﻴﺪ أو إﱃ اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ.ﻓﻘﺪ أﻇﻬﺮت اﻷﺑﺤﺎث أن
اﻟﻨﺎسﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄﻳﺘﻌﺎﻃﻔﻮنﻣﻊ اﻟﺮوﺑﻮﺗﺎت وﻳﱰدﱠدونﰲ »ﻗﺘﻠﻬﺎ« أو »ﺗﻌﺬﻳﺒﻬﺎ«
45</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
(،ﺣﺘﻰ إذاﻟﻢﺗﻜُﻦSuzuki et al. 2015; Darling, Nandy, and Breazeal 2015)
ﻣﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻳﺒﺪو أن اﻟﺒﴩﻻﻳﺤﺘﺎﺟﻮنﻣﻦ اﻟﻜﻴﺎﻧﺎت اﻻﺻﻄﻨﺎﻋﻴﺔﺳﻮى
اﻟﻘﻠﻴﻞﺟﺪٍّاﻣﻦ أﺟﻞ إﺿﻔﺎء اﻹﻧﺴﺎﻧﻴﺔ أو اﻟﺸﺨﺼﻴﺔﻋﻠﻴﻬﻢ واﻟﺘﻌﺎﻃُﻒﻣﻌﻬﻢ.ﻓﺈذا أﺻﺒﺤﺖ
ﻫﺬه اﻟﻜﻴﺎﻧﺎت اﻵنﻣﺰودةًﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻣﻤﺎﻳﺠﻌﻠﻬﺎ أﺷﺒَﻪﺑﺎﻹﻧﺴﺎن )أوﺑﺎﻟﺤﻴﻮان(،
ﻳﺒﺪو أنﻫﺬاﻳﺠﻌﻞﻣﺴﺄﻟﺔ إﻛﺴﺎب املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ أﻛﺜﺮ إﻟﺤﺎﺣًﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﺎذا
ﻳﻨﺒﻐﻲ أنﻳﻜﻮن ردﱡﻓﻌﻠﻨﺎﺗﺠﺎه اﻷﺷﺨﺎص اﻟﺬﻳﻦﻳﺘﻌﺎﻃﻔﻮنﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ﻫﻞ
ﻫُﻢﻣُﺨﻄﺌﻮن؟
رﺑﻤﺎﻳﻜﻮنﻗﻮل إن اﻵﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻲﻣﺠﺮد آﻻت وإن اﻷﺷﺨﺎص
اﻟﺬﻳﻦﻳﺘﻌﺎﻃﻔﻮنﻣﻌﻬﺎﺑﺒﺴﺎﻃﺔٍﻣُﺨﻄﺌﻮنﰲﺗﻘﺪﻳﺮﻫﻢﻟﻸﻣﻮر وﰲﻋﻮاﻃﻔﻬﻢ وﺗﺠﺮﺑﺘِﻬﻢ
اﻷﺧﻼﻗﻴﺔﻫﻮ اﻷﻗﺮب إﱃ اﻟﺒﺪﻳﻬﺔ. إذﻳﺒﺪوﻟﻨﺎ،ﻋﻨﺪ اﻟﻨﻈﺮة اﻷوﱃ، أﻧﻨﺎﻻﻧﺪﻳﻦﺑﴚءٍ
إﱃ اﻵﻻت.ﻓﻬﻲ أﺷﻴﺎء، وﻟﻴﺴﺖ أﺷﺨﺎﺻًﺎ. وﻳُﻔﻜﺮ اﻟﻜﺜريﻣﻦ اﻟﺒﺎﺣِﺜنيﰲﻣﺠﺎل اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﺑﻬﺬا املﻨﻄﻖ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗﺮىﺟﻮاﻧﺎﺑﺮاﻳﺴﻮن أن اﻟﺮوﺑﻮﺗﺎتﻫﻲ أدوات
(.ﻗﺪﻳﺘﻔﻖ اﻟﺬﻳﻦﻳﺘﺒﻨﱠﻮنBryson 2010)وﻣُﻤﺘﻠﻜﺎت وأﻧﻪﻟﻴﺲﻟﺪَﻳﻨﺎ أي اﻟﺘﺰاﻣﺎتٍﺗﺠﺎﻫﻬﺎ
ﻫﺬا املﻮﻗﻒﺑﺸﺪﱠةﻋﲆ أﻧﻪ إذاﻛﺎنﻟﺪى اﻵﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘُﺪرةﻋﲆ
اﻟﻮﻋﻲ، وﻟﺪَﻳﻬﺎﺣﺎﻻتﻋﻘﻠﻴﺔ، وﻣﺎ إﱃ ذﻟﻚ،ﻓﺈﻧﻨﺎﻣُﻄﺎﻟﺒﻮنﺑﺄنﻧﻤﻨﺤﻬﺎﻣﻜﺎﻧﺔً أﺧﻼﻗﻴﺔ.
وﻟﻜﻨﻬﻢﺳﻴﻘﻮﻟﻮن إنﻫﺬا اﻟﴩطﻻﻳﺘﺤﻘﱠﻖ اﻟﻴﻮم. وﻛﻤﺎ رأﻳﻨﺎﰲ اﻟﻔﺼﻮل اﻟﺴﺎﺑﻘﺔ،ﻗﺪ
ﻳﻘﻮل اﻟﺒﻌﺾ إﻧﻪﻟﻦﻳﺘﺤﻘﱠﻖ أﺑﺪًا؛ وﻳﻘﻮل آﺧَﺮون إﻧﻪﻳﻤﻜﻦﺗﺤﻘﻴﻘُﻪﻣﻦﺣﻴﺚ املﺒﺪأ، وﻟﻜﻦ
ﻫﺬاﻟﻦﻳﺤﺪثﰲ املﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ. وﻟﻜﻦ اﻟﻨﺘﻴﺠﺔ املُﱰﺗﱢﺒﺔﻋﲆ اﻟﺴﺆال املُﺘﻌﻠﻖﺑﺎملﻜﺎﻧﺔ
اﻷﺧﻼﻗﻴﺔﻫﻲ أﻧﻪﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄ وﰲ املﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ،ﻳُﻔﱰَض أنﻧﺘﻌﺎﻣَﻞﻣﻊ اﻵﻻت
املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻛﺄﺷﻴﺎء، إﻻ إذاﺛﺒﺖﺧﻼف ذﻟﻚ.
ﻋﲆ اﻟﺮﻏﻢﻣﻦ ذﻟﻚ،ﻓﺜﻤﱠﺔﻣﺸﻜﻠﺔ واﺣﺪةﺗﻮاﺟِﻬﻨﺎﻋﻨﺪ اﺗﺨﺎذﻫﺬا املﻮﻗﻒ، وﻫﻲ أﻧﻪ
ﻻﻳﻔﴪ وﻻﻳُﱪر إﺣﺴﺎﺳﻨﺎ اﻟﺒﺪﻳﻬﻲ اﻷﺧﻼﻗﻲ وﻻﺗﺠﺎرﺑﻨﺎ اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲﺗُﺨﱪﻧﺎﺑﺄنﺛﻤﱠﺔ
ﺷﻴﺌًﺎﺧﺎﻃﺌًﺎﰲ »إﺳﺎءةﻣﻌﺎﻣﻠﺔ« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺣﺘﻰ إذاﻟﻢﺗﻜُﻦﻟﺪَﻳﻪﺧﺼﺎﺋﺺ
ﺷﺒﻴﻬﺔﺑﺎﻟﺒﴩ أو اﻟﺤﻴﻮاﻧﺎتﻣﺜﻞ اﻟﻮﻋﻲ أو اﻹﺣﺴﺎس.ﻟﻠﻌﺜﻮرﻋﲆﻣﺜﻞﻫﺬه اﻟﺘﱪﻳﺮات،
ﻳُﻤﻜﻦﻟﻠﻤﺮء اﻟﻠﺠﻮء إﱃﻛﺎﻧﻂ، اﻟﺬي اﻋﺘﱪ أﻧﻪﻣﻦ اﻟﺨﻄﺄ إﻃﻼق اﻟﻨﺎرﻋﲆﻛﻠﺐ؛ﻟﻴﺲﻷن
إﻃﻼق اﻟﻨﺎرﻋﲆﻛﻠﺐٍﻳﻨﺘﻬﻚ أي اﻟﺘﺰاﻣﺎتٍﺗﺠﺎهﻫﺬا اﻟﻜﻠﺐ، وﻟﻜﻦﻷنﻣﺜﻞﻫﺬا اﻟﺸﺨﺺ
»ﻳﴬﱡﺑﺼﻔﺎت اﻟﺮﺣﻤﺔ واﻹﻧﺴﺎﻧﻴﺔﰲﻧﻔﺴﻪ، واﻟﺘﻲﻳﺠﺐ أنﻳُﻤﺎرﺳﻬﺎﺑﻨﺎءًﻋﲆ واﺟﺒﺎﺗﻪ
(. أﻣﺎ اﻟﻴﻮمﻓﻨﺤﻦﻧﻤﻴﻞ إﱃ اﻟﺘﻔﻜريﺑﻄﺮﻳﻘﺔٍﻣﺨﺘﻠﻔﺔﺗﺠﺎهKant 1997) «ﺗﺠﺎه اﻟﺒﴩ
46</p>
<p>أﻫﻲﺣﻘٍّﺎﻣﺠﺮد آﻻت؟
اﻟﻜﻼب )ﻋﲆ اﻟﺮﻏﻢﻣﻦ أنﻫﺬاﻟﻴﺲﺣﺎل اﻟﺠﻤﻴﻊ وﻟﻴﺲ اﻟﺤﺎلﰲﻛﻞﻣﻜﺎن(. وﻟﻜﻦ
ﻳﺒﺪو أﻧﻪﻳُﻤﻜﻦﺗﻄﺒﻴﻖ اﻟﺤﺠﱠﺔﻧﻔﺴﻬﺎﻋﲆ اﻵﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ:ﻳُﻤﻜﻨﻨﺎ أن
ﻧﻘﻮل إﻧﻨﺎﻻﻧﺪﻳﻦﺑﴚءٍ إﱃ اﻵﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻨﱠﻨﺎﻣﻊ ذﻟﻚﻳﻨﺒﻐﻲ
ﻟﻨﺎﻋﺪم رﻛْﻞ أو »ﺗﻌﺬﻳﺐ« آﻟﺔﻣﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؛ﻷن ذﻟﻚﻳﺠﻌﻠﻨﺎﻏري رﺣﻤﺎء
ﺗﺠﺎه اﻟﺒﴩ.ﻳُﻤﻜﻦ أﻳﻀًﺎ اﺳﺘﺨﺪامﺣﺠﱠﺔِ أﺧﻼﻗﻴﺎت اﻟﻔﻀﻴﻠﺔ، وﻫﻲﺣُﺠﱠﺔﻏريﻣﺒﺎﴍة أﻳﻀًﺎ
وﻟﻴﺲﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ: »إﺳﺎءةﻣﻌﺎﻣﻠﺔ« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺧﻄﺄ
ﻷﻧﻬﺎﺗﺘﻌﻠﱠﻖﺑﺎﻟﺒﴩَ
ﻟﻴﺲﻷنﺛﻤﱠﺔﴐرًاﺳﻴﻠﺤﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻦﻷنﻃﺎﺑﻌﻨﺎ اﻷﺧﻼﻗﻲﺳﻴﺘﺄذﱠى إذا
ﻣﺎﻓﻌﻠﻨﺎ ذﻟﻚ. وﻫﺬاﻻﻳﺠﻌﻠﻨﺎ أﺷﺨﺎﺻًﺎ أﻓﻀﻞ. وﻋﲆ اﻟﻨﻘﻴﺾﻣﻦﻫﺬا اﻟﻨﻬﺞﻳُﻤﻜﻨﻨﺎ أن
ﻧﻘﻮل إﻧﻪﰲ املُﺴﺘﻘﺒﻞﻗﺪﺗﺘﻤﺘﱠﻊﺑﻌﺾ اﻵﻻت املﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻘﻴﻤﺔٍﺟﻮﻫﺮﻳﺔ
وﺗﺴﺘﺤﻖﱡ اﻫﺘﻤﺎﻣﻨﺎ اﻷﺧﻼﻗﻲ،ﺑﴩط أنﺗﻜﻮنﻟﺪَﻳﻬﺎﺧﺼﺎﺋﺺﻣﺜﻞ اﻹﺣﺴﺎس. وﻻﻳﺒﺪو
أن اﻟﻨﻬﺞﻏري املﺒﺎﴍﻟﻠﻮاﺟﺐ أو اﻟﻔﻀﻴﻠﺔﻳﺄﺧﺬﻫﺬا اﻟﺠﺎﻧﺐ »اﻵﺧَﺮ«ﻣﻦ اﻟﻌﻼﻗﺔ اﻷﺧﻼﻗﻴﺔ
ﻋﲆﻣﺤﻤﻞ اﻟﺠﺪ.ﻓﻬﻮﻳُﻌﻨﻰﻓﻘﻂﺑﺎﻟﺒﴩ.ﻓﻤﺎذاﻋﻦ اﻵﻻت املﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟
وﻟﻜﻦﻫﻞﻳُﻤﻜﻦﻟﻶﻻت املﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أو اﻟﺮوﺑﻮﺗﺎت أنﺗﻜﻮنﻫﻲ »اﻵﺧﺮ«
ﻛﻤﺎﺳﺄل دﻳﻔﻴﺪﺟﻨﻜﻞ )٨١٠٢(؟ﻣﺮة أﺧﺮى،ﻳﺒﺪو أن املﻨﻄﻖﻳﻘﻮل:ﻻ، اﻵﻻت املﺰوﱠدة
ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺴﺖﻟﺪَﻳﻬﺎ اﻟﺨﺼﺎﺋﺺ املﻄﻠﻮﺑﺔ.
»إﺳﺎءةﻣﻌﺎﻣﻠﺔ« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺧﻄﺄ؛ﻟﻴﺲﻷنﺛﻤﺔﴐرًاﺳﻴﻠﺤﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻦ
ﻷنﻃﺎﺑﻌﻨﺎ اﻷﺧﻼﻗﻲﺳﻴﺘﺄذﱠى إذاﻣﺎﻓﻌﻠﻨﺎ ذﻟﻚ.
ﺛﻤﺔﻧﻬﺞﻣﺨﺘﻠﻒﺗﻤﺎﻣًﺎﻳﺮى أنﻃﺮﻳﻘﺔﺗﻌﺎﻣُﻠﻨﺎﻣﻊﻣﺴﺄﻟﺔ املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔﻫﻲ
ﻧﻔﺴﻬﺎﺗﻨﻄﻮيﻋﲆ إﺷﻜﺎﻟﻴﺔ.ﻳﻌﺘﻤﺪ اﻟﺘﻔﻜري اﻷﺧﻼﻗﻲ اﻟﺸﺎﺋﻊﺑﺸﺄن املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔﻋﲆﻣﺎ
ﺗﻤﻠِﻜﻪ اﻟﻜﻴﺎﻧﺎتﻣﻦﺧﺼﺎﺋﺺ ذاتﺻﻠﺔٍﺑﺎﻷﺧﻼق؛ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻟﻮﻋﻲ أو اﻹﺣﺴﺎس.
وﻟﻜﻦﻛﻴﻒﻧﻌﻠَﻢﻣﺎ إذاﻛﺎنﻟﺪى اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻓﻌﻼًﺧﺼﺎﺋﺺﻣُﻌﻴﻨﺔ ذاتﺻﻠﺔٍ
ﺑﺎﻷﺧﻼق أمﻻ؟ وﻫﻞﻧﺤﻦﻣﺘﺄﻛﱢﺪونﻣﻦ ذﻟﻚﰲﺣﺎﻟﺔ اﻟﺒﴩ؟ﻳﻘﻮل املُﺘﺸﻜﱢﻜﻮن إﻧﻨﺎﻟﺴﻨﺎ
ﻣﺘﺄﻛﱢﺪﻳﻦ. وﻣﻊ ذﻟﻚ،ﺣﺘﻰ دونﻫﺬا اﻟﻴﻘني املَﻌﺮﰲ،ﻓﺈﻧﻨﺎﻻﻧﺰالﻧُﻀﻔﻲﻋﲆ اﻹﻧﺴﺎنﻣﻜﺎﻧﺔً
أﺧﻼﻗﻴﺔﻋﲆ أﺳﺎس املﻈﻬﺮ. وﻣﻦ املُﺮﺟﱠﺢ أنﻳﺤﺪُث اﻟﴚءﻧﻔﺴﻪ إذاﻗُﺪﱢرﻟﻶﻻت املﺰوﱠدة
ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنﺗﺘﻤﺘﱠﻊﺑﻤﻈﻬﺮٍ وﺳﻠﻮكﺷﺒﻴﻬَنيﺑﺎﻟﺒﴩﰲ املﺴﺘﻘﺒﻞ.ﻳﺒﺪو أﻧﻪﺑﻐﺾﱢ
47</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﻨﻈﺮﻋﻤﱠﺎﻳﻌﺘﱪه اﻟﻔﻼﺳﻔﺔﻣﻦ اﻟﺼﻮاب أﺧﻼﻗﻴٍّﺎ،ﺳﻴُﻀﻔﻲ اﻟﺒﴩ،ﺑﺄﻳﺔﺣﺎل،ﻋﲆﻫﺬه
اﻵﻻتﻣﻜﺎﻧﺔ أﺧﻼﻗﻴﺔ، وﻳﻤﻨﺤﻮﻧﻬﺎﺣﻘﻮﻗًﺎ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل.ﻋﻼوةﻋﲆ ذﻟﻚ، إذاﻧﻈﺮﻧﺎﻋﻦ
ﻛﺜَﺐ إﱃ اﻟﻄﺮﻳﻘﺔِ اﻟﱠﺘﻲﻳُﻀﻔﻲﺑﻬﺎ اﻟﺒﴩ املﻜﺎﻧﺔَ اﻷﺧﻼﻗﻴﺔ »ﰲ اﻟﻮاﻗﻊ«،ﻓﺈﻧﻪﻳﺘﱠﻀﺢﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل أنﻛﻼٍّﻣﻦ اﻟﻌﻼﻗﺎت اﻻﺟﺘﻤﺎﻋﻴﺔ اﻟﻘﺎﺋﻤﺔ واﻟﻠﱡﻐﺔﺗﻠﻌﺐ دورًا.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
إذاﻋﺎﻣَﻠْﻨﺎﻗﻄﱠﺘﻨﺎﺑﻠُﻄﻒ،ﻓﻬﺬاﻟﻴﺲﻷﻧﻨﺎﻧﻨﺨﺮِطﰲﺗﻔﻜريٍ أﺧﻼﻗﻲﺑﺸﺄنﻗِﻄﱠﺘﻨﺎ، وﻟﻜﻦﻷن
ﻟﺪَﻳﻨﺎﺑﺎﻟﻔﻌﻞﻧﻮﻋًﺎﻣﻦ اﻟﻌﻼﻗﺔ اﻻﺟﺘﻤﺎﻋﻴﺔﻣﻌﻬﺎ. إﻧﻬﺎﺑﺎﻟﻔﻌﻞﺣﻴﻮانٌ أﻟﻴﻒ وﻣُﺮاﻓﻖﻟﻨﺎﻗﺒﻞ
أنﻧﻘﻮمﺑﺎﻟﻌﻤﻞ اﻟﻔﻠﺴﻔﻲ اﻟﺬيﻧُﻜﺴِﺒﻬﺎﺑﻤﻮﺟﺒِﻪﻣﻜﺎﻧﺔ أﺧﻼﻗﻴﺔ؛ﻫﺬا إذاﺷﻌﺮﻧﺎﻣﻦ اﻷﺳﺎس
ﺑﺤﺎﺟﺔٍ إﱃﻣﺜﻞﻫﺬه املﻤﺎرﺳﺔ. وإذا أﻃﻠﻘﻨﺎ اﺳﻤًﺎﺧﺎﺻٍّﺎﻋﲆﻛﻠﺒﻨﺎ،ﻓﺈﻧﻨﺎ —ﻋﲆﻋﻜﺲ
اﻟﺤﻴﻮاﻧﺎت اﻟﺘﻲﻻﺗﺤﻤِﻞ اﺳﻤًﺎ اﻟﺘﻲﻧﺄﻛُﻠﻬﺎ —ﻗﺪﻣﻨﺤﻨﺎهﺑﺎﻟﻔﻌﻞﻣﻜﺎﻧﺔً أﺧﻼﻗﻴﺔﺧﺎﺻﱠﺔ،
ﺑﴫْف اﻟﻨﻈﺮﻋﻦﺧﺼﺎﺋﺼﻪ املﻮﺿﻮﻋﻴﺔ.ﺑﺎﺳﺘﺨﺪامﻣﺜﻞﻫﺬا اﻟﻨﻬﺞ اﻟﻌﻼﻗﺎﺗﻲ واﻟﻨﻘﺪي
(،ﻳُﻤﻜﻨﻨﺎ اﻟﻘﻮل إن اﻟﺒﴩﺳﻮفﻳﻤﻨﺤﻮن اﻵﻻتCoeckelbergh 2012)وﻏري املُﺘﺰﻣﱢﺖ
املﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻜﺎﻧﺔً أﺧﻼﻗﻴﺔﺑﻨﺎءًﻋﲆﻛﻴﻔﻴﺔﺗﻀﻤﻴﻨﻬﺎﰲﺣﻴﺎﺗﻨﺎ اﻻﺟﺘﻤﺎﻋﻴﺔ
وﰲﻟُﻐﺘﻨﺎ وﰲﺛﻘﺎﻓﺘﻨﺎ اﻟﺒﴩﻳﺔ.
ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻧﻈﺮًا إﱃ أنﻣﺜﻞﻫﺬه اﻟﻈﺮوفﻣُﺘﻐريةﺗﺎرﻳﺨﻴٍّﺎ —ﻓﻜﺮﻣﺮة أﺧﺮى
ﰲﻛﻴﻔﻴﺔﻣُﻌﺎﻣﻠﺘﻨﺎ وﺗﻔﻜريﻧﺎﺑﺸﺄن اﻟﺤﻴﻮاﻧﺎت — رﺑﻤﺎﺗﻜﻮنﻫﻨﺎكﺣﺎﺟﺔ إﱃ اﺗﺨﺎذﺳﺒُﻞ
اﻟﺤﻴﻄﺔ اﻷﺧﻼﻗﻴﺔﻗﺒﻞ »ﺗﺤﺪﻳﺪ« املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞٍﻋﺎم أوﻵﻟﺔ
ﻣُﻌﻴﱠﻨﺔﻣﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وملﺎذاﺣﺘﻰﻧﺘﺤﺪﱠثﻋﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞٍﻋﺎم
أوﺑﺸﻜﻞٍﻣﺠﺮد؟ﻳﺒﺪو أنﻫﻨﺎكﺷﻴﺌًﺎﺧﺎﻃﺌًﺎﰲ اﻹﺟﺮاء اﻷﺧﻼﻗﻲ ملﻨﺢ املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ:
ﻓﻤﻦ أﺟﻞ اﻟﺤُﻜﻢﻋﲆﻛﻴﺎنٍﻣﺎ،ﻧُﺨﺮجﻫﺬا اﻟﻜﻴﺎنﻣﻦﺳﻴﺎقﻋﻼﻗﺎﺗﻪ، وﻗﺒﻞ أنﻧﺤﺼﻞﻋﲆ
ﻧﺘﻴﺠﺔ إﺟﺮاﺋﻨﺎ اﻷﺧﻼﻗﻲ،ﻧﺘﻌﺎﻣَﻞﻣﻌﻪﺑﻄﺮﻳﻘﺔٍ رﺗﺒﻮﻳﺔ،ﺳﻠﻄﻮﻳﺔ،ﻣُﻬﻴﻤﻨﺔ،ﻛﻜﻴﺎنٍﻧﺘﺨﺬ
ﻧﺤﻦ اﻟﺒﴩ املُﺘﻔﻮﱢﻗنيﻗﺮارًاﺑﺸﺄﻧﻪ. وﻳﺒﺪو أﻧﻨﺎﻗﺒﻞﺣﺘﻰ أنﻧﻔﻜﺮﰲﻣﻜﺎﻧﺘﻪ اﻷﺧﻼﻗﻴﺔ،ﻗﺪ
وﺿﻌﻨﺎهﺑﺎﻟﻔﻌﻞﰲﻣﻨﺰﻟﺔٍﻣُﻌﻴﱠﻨﺔ ورﺑﻤﺎ أﻳﻀًﺎﻣﺎرَﺳْﻨﺎﻋﻠﻴﻪ اﻟﻌﻨﻒﺑﻤﻌﺎﻣﻠﺘﻪﻛﻜﺎﺋﻦٍﻧﺘﱠﺨﺬ
ﻗﺮاراتﺑﺸﺄﻧﻪ، وﻧﺼﱠﺒﻨﺎ أﻧﻔﺴﻨﺎ آﻟﻬﺔًﻣﺤﻮرﻳﺔﻗﻮﻳﺔﻋﺎملﺔﻋﲆ اﻷرضﻳﺤﻖﱡﻟﻬﺎﻣﻨﺢ املﻜﺎﻧﺔ
اﻷﺧﻼﻗﻴﺔﻟﻠﻜﺎﺋﻨﺎتِ اﻷﺧﺮى.ﻟﻘﺪﺟﻌﻠﻨﺎ أﻳﻀًﺎﺟﻤﻴﻊ اﻟﺴﻴﺎﻗﺎت واملﻼﺑﺴﺎت اﻻﺟﺘﻤﺎﻋﻴﺔﻏري
ﻣَﺮﺋﻴﺔ.ﻛﻤﺎﰲﺣﺎﻟﺔﻣُﻌﻀﻠﺔﻋﺮﺑﺔ اﻟﱰام،ﻟﻘﺪ اﺧﺘﺰﻟﻨﺎ اﻷﺧﻼقﰲﺻﻮرةﻛﺎرﻳﻜﺎﺗريﻳﺔ.
ﺑﺎﺳﺘﺨﺪامﻣﺜﻞﻫﺬا اﻟﺘﻔﻜري،ﻳﺒﺪو أنﻓﻼﺳﻔﺔ اﻷﺧﻼقﻳﻔﻌﻠﻮنﻣﺎ اﺗﱡﻬِﻢ اﻟﻔﻼﺳﻔﺔُ املﺆﻳﺪون
ﻟﺪرﻳﻔﻮس اﻟﺒﺎﺣﺜنيﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺮﻣﺰيﺑﻔِﻌﻠﻪ:ﺗﺸﻜﻴﻞ وﺗﺠﺮﻳﺪﺛﺮوةﻣﻦ
اﻟﺘﺠﺮﺑﺔ اﻷﺧﻼﻗﻴﺔ واملﻌﺮﻓﺔ اﻷﺧﻼﻗﻴﺔﻋﲆﺣﺴﺎب اﻟﺘﺨﲇﱢﻋﻤﺎﻳﺠﻌﻠﻨﺎﺑﴩًا، وﻟﻴﺲ ذﻟﻚ
48</p>
<p>أﻫﻲﺣﻘٍّﺎﻣﺠﺮد آﻻت؟
ﻓﺤﺴﺐ،ﺑﻞ وﻋﲆﺣﺴﺎب اﻟﺘﻀﺤﻴﺔﺑﻤﺴﺄﻟﺔ املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔﻟﻐري اﻟﺒﴩ. وﺑﴫف اﻟﻨﻈﺮ
ﻋﻦ املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ اﻟﻔﻌﻠﻴﺔﻟﻶﻻت املﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻛﻤﺎﻟﻮﻛﺎنﻫﺬاﻳﻤﻜﻦ
ﺗﺤﺪﻳﺪهﺑﺸﻜﻞٍﻣُﺴﺘﻘﻞﺗﻤﺎﻣًﺎﻋﻦ ذاﺗﻴﺔ اﻹﻧﺴﺎن،ﻓﻤﻦ اﻷﻫﻤﻴﺔﺑﻤﻜﺎنٍ أنﻧﻔﺤﺺﺗﻮﺟﱡﻬﻨﺎ
اﻷﺧﻼﻗﻲ وﻣﴩوع اﻟﺘﻔﻜري اﻷﺧﻼﻗﻲ املﺠﺮدﻧﻔﺴﻪ،ﺑﺄﺳﻠﻮبﻧﻘﺪي.
»إﺳﺎءةﻣﻌﺎﻣﻠﺔ« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺧﻄﺄ؛ﻟﻴﺲﻷنﺛﻤﺔﴐرًاﺳﻴﻠﺤﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻦ
ﻷنﻃﺎﺑﻌﻨﺎ اﻷﺧﻼﻗﻲﺳﻴﺘﺄذﱠى إذاﻣﺎﻓﻌﻠﻨﺎ ذﻟﻚ.
ﻧﺤﻮﻗﻀﺎﻳﺎ أﺧﻼﻗﻴﺔ أﻛﺜﺮﻋﻤﻠﻴﺔ
ﻛﻤﺎﺗُﻈﻬﺮ املﻨﺎﻗﺸﺎتﰲﻫﺬا اﻟﻔﺼﻞ واﻟﻔﺼﻞ اﻟﺴﺎﺑﻖ،ﻓﺈن اﻟﺘﻔﻜريﰲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳُﻌﻠﱢﻤﻨﺎ أﺷﻴﺎء أﺧﺮى إﱃﺟﺎﻧﺐﻣﺎﻧﺘﻌﻠﱠﻤﻪﺑﺸﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. إﻧﻪﻳُﻌﻠﻤﻨﺎ أﻳﻀًﺎ أﺷﻴﺎء
ﻋﻦ أﻧﻔﺴﻨﺎ:ﻋﻦﻃﺮﻳﻘﺔﺗﻔﻜريﻧﺎ، وﻃﺮﻳﻘﺔﺗﴫﱡﻓﻨﺎﰲ اﻟﻮاﻗﻊ، واﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳﻨﺒﻐﻲ أن
ﻧﺘﻌﺎﻣَﻞﺑﻬﺎﻣﻊﻏري اﻟﺒﴩ.ﻓﺈذاﻧﻈﺮﻧﺎ إﱃ اﻷُﺳﺲ اﻟﻔﻠﺴﻔﻴﺔﻷﺧﻼﻗﻴﺎتِ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،
ﻧﺮىﺧﻼﻓﺎتﻋﻤﻴﻘﺔًﺣﻮلﻃﺒﻴﻌﺔ وﻣﺴﺘﻘﺒﻞ اﻹﻧﺴﺎﻧﻴﺔ واﻟﻌﻠﻢ واﻟﺤﺪاﺛﺔ. إن اﻟﺘﺸﻜﻴﻚﰲ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﱢﻳﻜﺸﻒ اﻟﻠﺜﺎمﻋﻦﻋﺎﻟَﻢﻣُﻈﻠﻢﻣﻦ اﻷﺳﺌﻠﺔ اﻟﻨﻘﺪﻳﺔﺣﻮل املﻌﺮﻓﺔ اﻟﺒﴩﻳﺔ
واملُﺠﺘﻤﻊ اﻟﺒﴩي وﻃﺒﻴﻌﺔ اﻷﺧﻼق اﻟﺒﴩﻳﺔ.
ﻫﺬه املﻨﺎﻗﺸﺎت اﻟﻔﻠﺴﻔﻴﺔ أﻗﻞﺑُﻌﺪًا وأﻗﻞ »أﻛﺎدﻳﻤﻴﺔ«ﻣﻤﺎﻗﺪﻳﻌﺘﻘِﺪ اﻟﺒﻌﺾ. وﺳﺘﻈﻞﱡ
ﺗُﻌﺎود اﻟﻈﻬﻮر أﻣﺎﻣﻨﺎﻋﻨﺪﻣﺎﻧﺘﻨﺎول،ﻻﺣﻘًﺎﰲﻫﺬا اﻟﻜﺘﺎب، املﺰﻳﺪَﻣﻦ املﺴﺎﺋﻞ اﻷﺧﻼﻗﻴﺔ
واﻟﻘﺎﻧﻮﻧﻴﺔ واﻟﺴﻴﺎﺳﻴﺔ اﻷﻛﺜﺮﻋﻤﻠﻴﺔً اﻟﺘﻲﻳُﺜريﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﴎﻋﺎنﻣﺎﺳﺘُﻮاﺟﻬﻨﺎ
ﻣﻦﺟﺪﻳﺪٍﺑﻤﺠﺮﱠد أنﻧُﺤﺎول اﻟﺘﻄﺮﱡق إﱃﻣﻮﺿﻮﻋﺎتٍﻣﺜﻞ املﺴﺌﻮﻟﻴﺔ واﻟﺴﻴﺎرات ذاﺗﻴﺔ اﻟﻘﻴﺎدة،
أوﺷﻔﺎﻓﻴﺔﺗﻌﻠﱡﻢ اﻵﻟﺔ، أو اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺘﺤﻴﺰ، أو أﺧﻼﻗﻴﺎت اﻟﺮوﺑﻮﺗﺎت اﻟﺠﻨﺴﻴﺔ. إذا
ﻛﺎﻧﺖ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗُﺮﻳﺪ أنﺗﻜﻮن أﻛﺜﺮﻣِﻦﻣﺠﺮﱠدﻗﺎﺋﻤﺔﺑﺎﻟﻘﻀﺎﻳﺎ،ﻓﻴﺠﺐ
أنﻳﻜﻮنﻟﺪَﻳﻬﺎﻣﺎﺗﻘﻮﻟﻪﺣﻮلﻣﺜﻞﻫﺬه املﺴﺎﺋﻞ.
ﺑﻌﺪﻛﻞﱢﻣﺎﻗﻴﻞ،ﺣﺎن اﻟﻮﻗﺖ اﻵنﻟﻠﺘﺤﻮﱡل إﱃﻗﻀﺎﻳﺎ أﻛﺜﺮﻋﻤﻠﻴﺔ.ﻫﺬه اﻟﻘﻀﺎﻳﺎﻻ
ﺗﺘﻌﻠﱠﻖﺑﺎملُﺸﻜﻼت اﻟﻔﻠﺴﻔﻴﺔ اﻟﺘﻲﻳﻄﺮﺣُﻬﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم املُﻔﱰض، أوﺑﺎملﺨﺎﻃﺮ
املﺘﱠﺼﻠﺔﺑﺎﻟﺬﻛﺎء اﻟﻔﺎﺋﻖﰲ املﺴﺘﻘﺒﻞ اﻟﺒﻌﻴﺪ، أوﺑﺎﻟﻮﺣﻮش املﺨﻴﻔﺔ اﻷﺧﺮى اﻟﺘﻲﻳﺨﻠﻘﻬﺎ
اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ. إﻧﻬﺎﺗﺘﻌﻠﻖﺑﺤﻘﺎﺋﻖ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺋﻤﺔﺑﺎﻟﻔﻌﻞ، واﻟﺘﻲﻫﻲ أﻗﻞﱡ
49</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﺿﻮﺣًﺎ ورﺑﻤﺎ أﻗﻞﺟﺎذﺑﻴﺔ، وﻟﻜﻨﻬﺎﻻﺗﺰالﺷﺪﻳﺪة اﻷﻫﻤﻴﺔ. إن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ
اﻟﻮﻗﺖ اﻟﺤﺎﱄﻻﻳﺄﺧُﺬ دور وﺣﺶﻓﺮاﻧﻜﻨﺸﺘﺎﻳﻦ أو اﻟﺮوﺑﻮﺗﺎت املُﺬﻫﻠﺔ املﺰوﱠدةﺑﺎﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻟﺘﻲﺗُﻬﺪﱢد اﻟﺤﻀﺎرة،ﻛﻤﺎ أﻧﻪ أﻛﺜﺮﻣﻦﻣﺠﺮدﺗﺠﺮﺑﺔٍﻓﻜﺮﻳﺔﻓﻠﺴﻔﻴﺔ. اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻳﺘﻌﻠﱠﻖﺑﺘﻘﻨﻴﺎتٍﴎﻳﺔٍﻏريﻣﺮﺋﻴﺔ وﻟﻜﻨﻬﺎﻣُﺘﻐﻠﻐﻠﺔ وﻣﻨﺘﴩة وﻗﻮﻳﺔ وﻣﺘﺰاﻳﺪة
اﻟﺬﻛﺎء،ﺗﻠﻚ اﻟﺘﻘﻨﻴﺎت اﻟﺘﻲﺗُﺸﻜﱢﻞﺑﺎﻟﻔﻌﻞﺣﻴﺎﺗﻨﺎ اﻟﻴﻮم. وﻣﻦﺛَﻢﱠ،ﻓﺈن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﺗﺘﻌﻠﱠﻖﺑﺎﻟﺘﺤﺪﻳﺎت اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲﻳُﺜريﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄ وﰲ
املُﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ،ﻛﻤﺎﺗﺘﻌﻠﻖﺑﺘﺄﺛريﻫﺬه اﻟﺘﺤﺪﱢﻳﺎتﻋﲆﻣﺠﺘﻤﻌﺎﺗﻨﺎ ودﻳﻤﻘﺮاﻃﻴﺎﺗﻨﺎ اﻟﻬﺸﱠﺔ.
إن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺘﻌﻠﱠﻖﺑﺤﻴﺎة اﻟﻨﺎس وﺑﺎﻟﺴﻴﺎﺳﺔ. إﻧﻬﺎﺗﺘﻌﻠﻖﺑﺤﺎﺟﺘﻨﺎ،
ﻛﺄﻓﺮادٍ وﻛﻤﺠﺘﻤﻌﺎت، إﱃ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﻘﻀﺎﻳﺎ اﻷﺧﻼﻗﻴﺔ اﻵن.
50</p>
</section>
<section id="section-6">
    <h2>التكنولوجيا</h2>
    <div class="page-range">Pages 51-62</div>
    <p>اﻟﻔﺼﻞ اﻟﺨﺎﻣﺲ
اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
ﻗﺒﻞﻣﻨﺎﻗﺸﺔ اﻟﻘﻀﺎﻳﺎ اﻷﺧﻼﻗﻴﺔ اﻟﻮاﻗﻌﻴﺔ املُﺘﻌﻠﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻤﺰﻳﺪٍﻣﻦ اﻟﺘﻔﺎﺻﻴﻞ،
ﻟﺪَﻳﻨﺎﻣﻬﻤﺔٌ أﺧﺮىﻋﻠﻴﻨﺎ إﻧﺠﺎزﻫﺎﻟﺘﻤﻬﻴﺪ اﻟﻄﺮﻳﻖ:ﺑﻌﻴﺪًاﻋﻦ اﻟﻀﺠﱠﺔ املُﺜﺎرةﺣﻮل
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻋﻠﻴﻨﺎ أنﻧﻔﻬﻢﻫﺬه اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﺗﻄﺒﻴﻘﺎﺗﻬﺎ.ﻓﻠﻨُﻨَﺢﱢﺟﺎﻧﺒًﺎ اﻟﺨﻴﺎلَ
اﻟﻌﻠﻤﻲﱠﻟﺘﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ واﻟﺘﻄﻠﱡﻌﺎت اﻟﻔﻠﺴﻔﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم، وﻟﻨُﻠْﻖِﻧﻈﺮةًﻋﲆ
ﻣﺎﻫﻴﺔﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻛﻴﻔﻴﺔ اﺳﺘﺨﺪاﻣﻬﺎ اﻟﻴﻮم. وﺑﻤﺎ أنﺗﻌﺮﻳﻔﺎت اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ وﻏريﻫﺎﻣﻦ املُﺼﻄﻠَﺤﺎتﻫﻲﻧﻔﺴﻬﺎﻏريﻣُﺘﱠﻔﻖﻋﻠﻴﻬﺎ،ﻓﺈﻧﻨﻲﻟﻦ أﺗﻌﻤﱠﻖﰲ
ﻧﻘﺎﺷﺎتٍﻓﻠﺴﻔﻴﺔ أوﺳﻴﺎﻗﺎتﺗﺎرﻳﺨﻴﺔ. إنﻫﺪﰲ اﻟﺮﺋﻴﴘﻫﻨﺎﻫﻮ أن أُﻋﻄﻲ اﻟﻘﺎرئﻓﻜﺮةً
ﻋﻦ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ املﻌﻨﻴﺔ وﻛﻴﻔﻴﺔ اﺳﺘﺨﺪاﻣﻬﺎ. وﺳﻮف أﺑﺪأﺑﺎﻟﺘﺤﺪﱡثﻋﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺑﺸﻜﻞٍﻋﺎم؛ أﻣﺎ اﻟﻔﺼﻞ اﻟﺘﺎﱄ،ﻓﺴﻴﺘﻨﺎولﺗﻘﻨﻴﺎتﺗﻌﻠﱡﻢ اﻵﻟﺔ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت وﺗﻄﺒﻴﻘﺎﺗﻬﻤﺎ.
ﻣﺎﻫﻮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟
ﻳﻤﻜﻦﺗﻌﺮﻳﻒ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺄﻧﻪ اﻟﺬﻛﺎء اﻟﺬيﺗُﻈﻬﺮه أوﺗُﺤﺎﻛﻴﻪ اﻟﺮﻣﻮز اﻟﱪﻣﺠﻴﺔ
)اﻟﺨﻮارزﻣﻴﺎت( أو اﻵﻻت. وﻳُﺜريﻫﺬا اﻟﺘﻌﺮﻳﻒﺳﺆاﻻًﺣﻮلﻛﻴﻔﻴﺔﺗﻌﺮﻳﻒ اﻟﺬﻛﺎء.ﻣﻦ
اﻟﻨﺎﺣﻴﺔ اﻟﻔﻠﺴﻔﻴﺔ،ﻳُﻌﺘﱪَ اﻟﺬﻛﺎءﻣﻔﻬﻮﻣًﺎﻏﺎﻣﻀًﺎ. وﻳﻤﻜﻦ اﻟﻘﻮلﺑﺄﻧﻪ ذﻛﺎءٌﺷﺒﻴﻪﺑﺎﻟﺬﻛﺎء
اﻟﺒﴩي.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳُﻌﺮﱢفﻓﻴﻠﻴﺐﺟﺎﻧﺴﻦ وآﺧﺮون اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺄﻧﻪ »ﻋﻠﻢ
وﻫﻨﺪﺳﺔ اﻵﻻت ذات اﻟﻘﺪرات اﻟﺘﻲﺗُﻌﺘﱪ ذﻛﻴﺔً وﻓﻘًﺎ ملﻌﺎﻳري اﻟﺬﻛﺎء اﻟﺒﴩي« )٨١٠٢،
٥(. وﻓﻘًﺎﻟﻬﺬا اﻟﺘﻌﺮﻳﻒ،ﻳﺘﻌﻠﻖ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺈﻧﺸﺎء آﻻت ذﻛﻴﱠﺔﺗُﻔﻜﺮ أوﺗﺘﻔﺎﻋﻞ
ﻣﺜﻞ اﻟﺒﴩ. وﻣﻊ ذﻟﻚ،ﻳﻌﺘﻘﺪ اﻟﻌﺪﻳﺪﻣﻦ اﻟﺒﺎﺣﺜنيﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻧﻪﻟﻴﺲ
ﻫﻨﺎك داعٍﻷنﻳﻜﻮن اﻟﺬﻛﺎءﺷﺒﻴﻬًﺎﺑﺎﻟﺬﻛﺎء اﻟﺒﴩي، وﻳﻔﻀﻠﻮنﺗﻌﺮﻳﻔًﺎ أﻛﺜﺮﺣﻴﺎدًاﺻِﻴﻎَ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
.ﺑﺸﻜﻞٍﻣُﺴﺘﻘﻞﻋﻦ اﻟﺬﻛﺎء اﻟﺒﴩي وأﻫﺪاف اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم أو اﻟﻘﻮي ذات اﻟﺼﻠﺔ
وﻳﴪدونﺟﻤﻴﻊ أﻧﻮاع اﻟﻮﻇﺎﺋﻒ املﻌﺮﻓﻴﺔ واملﻬﺎمﻣﺜﻞ اﻟﺘﻌﻠﱡﻢ واﻹدراك واﻟﺘﺨﻄﻴﻂ وﻣُﻌﺎﻟﺠﺔ
اﻟﻠﻐﺔ اﻟﻄﺒﻴﻌﻴﺔ واﻟﺘﻔﻜري واﺗﺨﺎذ اﻟﻘﺮارات وﺣﻞﱢ املﺸﻜﻼت؛ وﻏﺎﻟﺒًﺎﻣﺎﻳُﻌﺎدل ذﻟﻚ اﻟﺬﻛﺎءَ
ﻧﻔﺴﻪ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗﺰﻋﻢﻣﺎرﺟﺮﻳﺖﺑﻮدﻳﻦ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ »ﻳﺴﻌﻰ إﱃﺟﻌﻞ
أﺟﻬﺰة اﻟﻜﻤﺒﻴﻮﺗﺮﺗﻘﻮمﺑﺎﻷﺷﻴﺎء اﻟﺘﻲﻳُﻤﻜﻦﻟﻠﻌﻘﻮل اﻟﺒﴩﻳﺔ اﻟﻘﻴﺎمﺑﻬﺎ«.ﻳﺒﺪو اﻷﻣﺮﰲ
اﻟﺒﺪاﻳﺔ وﻛﺄن اﻟﺒﴩﻫﻢ اﻟﻨﻤﻮذج اﻟﻮﺣﻴﺪ. إﻻ أﻧﻬﺎ،ﺗﴪدﺑﻌﺪ ذﻟﻚﻛﻞ أﻧﻮاع املﻬﺎرات اﻟﻨﻔﺴﻴﺔ
ﻣﺜﻞ اﻹدراك واﻟﺘﻨﺒﱡﺆ واﻟﺘﺨﻄﻴﻂ، اﻟﺘﻲﺗُﺸﻜﻞﺟﺰءًاﻣﻦ »اﻟﻔﻀﺎء اﻟﻐﻨﻲﺑﻘﺪراتﻣُﻌﺎﻟﺠﺔ
املﻌﻠﻮﻣﺎت املﺘﻨﻮﻋﺔ« )٦١٠٢، ١(. وﻳﻤﻜﻦ أنﺗﻜﻮنﻣُﻌﺎﻟﺠﺔ املﻌﻠﻮﻣﺎتﻫﺬهﻟﻴﺴﺖﺣﻜﺮًاﻋﲆ
اﻹﻧﺴﺎن.ﻓﺎﻟﺬﻛﺎء اﻟﻌﺎم، وﻓﻘًﺎ ملﺎرﺟﺮﻳﺖﺑﻮدﻳﻦ،ﻻﻳﻜﻮنﺑﺎﻟﴬورةﺑﴩﻳٍّﺎ.ﻓﻬﻨﺎكﺑﻌﺾ
اﻟﺤﻴﻮاﻧﺎت اﻟﺘﻲﻳُﻤﻜﻨﻨﺎ اﻋﺘﺒﺎرﻫﺎ ذﻛﻴﺔ. وﻳﺤﻠﻢﻣﺆﻳﺪوﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﺑﻌﻘﻮلٍﻣُﺴﺘﻘﺒﻠﻴﺔﻻ
ﺗﻜﻮنﻣﻀﻤﻨﺔﺑﻴﻮﻟﻮﺟﻴٍّﺎﻣﺜﻠﻤﺎﻫﻮ اﻟﺤﺎل اﻵن. وﻣﻊ ذﻟﻚ،ﻛﺎنﻫﺪفﺗﺤﻘﻴﻖﻗﺪراتﺷﺒﻴﻬﺔ
ﺑﻘﺪرات اﻟﺒﴩ ورﺑﻤﺎ ذﻛﺎءﻋﺎمﺷﺒﻴﻪﺑﺬﻛﺎء اﻟﺒﴩﺟﺰءًاﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻨﺬ اﻟﺒﺪاﻳﺔ.
ﻳﺮﺗﺒﻂﺗﺎرﻳﺦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ ارﺗﺒﺎﻃًﺎ وﺛﻴﻘًﺎﺑﺘﺎرﻳﺦﻋﻠﻮم اﻟﻜﻤﺒﻴﻮﺗﺮ واﻟﺘﺨﺼﱡﺼﺎت
ذات اﻟﺼﱢﻠﺔﻣﺜﻞ اﻟﺮﻳﺎﺿﻴﺎت واﻟﻔﻠﺴﻔﺔ، وﻣﻦﺛَﻢﱠﻓﻬﻮﻳﻤﺘﺪﱡﻋﲆ اﻷﻗﻞ إﱃ اﻟﻌﺼﻮر اﻟﺤﺪﻳﺜﺔ
اﻟﺒﺎﻛﺮة )ﻣﺜﻞﺟﻮﺗﻔﺮﻳﺪﻓﻴﻠﻬﻠﻢﻻﻳﺒﻨﻴﺘﺲ ورﻳﻨﻴﻪ دﻳﻜﺎرت( إنﻟﻢﻳﻜﻦ إﱃ اﻟﻌﺼﻮر اﻟﻘﺪﻳﻤﺔ،
ﻓﻴﻬﺎﻗﺼﺺﻋﻦﺣﺮﻓﻴﱢنيﻳﺼﻨﻌﻮنﻛﺎﺋﻨﺎتٍ اﺻﻄﻨﺎﻋﻴﺔ وآﻻتٍ ذﻛﻴﺔﻳُﻤﻜﻨﻬﺎ
اﻟﺘﻲﺗﻨﺘﴩِ
ﺧﺪاع اﻟﻨﺎس )ﺗﺬﻛﱠﺮ اﻟﺸﺨﺼﻴﺎت املُﺘﺤﺮﻛﺔﰲ اﻟﻴﻮﻧﺎن اﻟﻘﺪﻳﻤﺔ أو اﻟﺸﺨﺼﻴﺎت اﻵﻟﻴﺔ
اﻟﺸﺒﻴﻬﺔﺑﺎﻟﺒﴩﰲ اﻟﺼني اﻟﻘﺪﻳﻤﺔ(. وﻟﻜﻦﻋﲆ اﻟﻌﻤﻮمﻳُﻌﺘﱪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺪﺑﺪأ
ﰲ اﻟﺨﻤﺴﻴﻨﻴﺎتﻣﻦ اﻟﻘﺮن اﻟﻌﴩﻳﻦﺑﻮﺻﻔﻪﺗﺨﺼﱡﺼًﺎﻣﺴﺘﻘﻼٍّ ،ﺑﻌﺪ اﺧﱰاع اﻟﻜﻤﺒﻴﻮﺗﺮ
اﻟﺮﻗﻤﻲ اﻟﻘﺎﺑﻞﻟﻠﱪﻣﺠﺔﰲ أرﺑﻌﻴﻨﻴﱠﺎت اﻟﻘﺮن اﻟﻌﴩﻳﻦ ووﻻدةﺗﺨﺼﱡﺺﻋﻠﻢ اﻟﺘﺤﻜﱡﻢ اﻵﱄ
)اﻟﺴﻴﱪاﻧﻴﺔ(، اﻟﺬيﻋﺮﱠﻓﻪﻧﻮرﺑﺮت وﻳﻨﺮﰲﻋﺎم ٨٤٩١ﻋﲆ أﻧﻪ اﻟﺪراﺳﺔ اﻟﻌﻠﻤﻴﺔ »ﻟﻠﺘﺤﻜﱡﻢ
(. وﻛﺎنﻧﴩ ورﻗﺔ أﻻنﺗﻮرﻳﻨﺞ اﻟﺒﺤﺜﻴﺔWiener 1948) «واﻟﺘﻮاﺻُﻞﰲ اﻟﺤﻴﻮان واﻵﻟﺔ
ﻟﻌﺎم ٠٥٩١ﺑﻌﻨﻮان »اﻵﻻت اﻟﺤﺎﺳﺒﺔ واﻟﺬﻛﺎء«ﰲﻣﺠﻠﺔ »ﻣﺎﻳﻨﺪ«، واﻟﺘﻲﻗﺪﻣﺖ اﺧﺘﺒﺎر
ﺗﻮرﻳﻨﺞ اﻟﺸﻬري وﻟﻜﻦﻛﺎﻧﺖﺗﺘﻨﺎولﺑﺸﻜﻞٍﻋﺎمﺳﺆالﻣﺎ إذاﻛﺎﻧﺖ اﻵﻻتﻗﺎدرةًﻋﲆ
اﻟﺘﻔﻜري، وﺳﺒﻘﺖﺑﺎﻟﻔﻌﻞﰲ اﻟﺘﻜﻬﱡﻦﺑﺎﻵﻻت اﻟﺘﻲﻳُﻤﻜﻨﻬﺎ اﻟﺘﻌﻠﱡﻢ وأداءﻣﻬﺎمﻣﺠﺮﱠدة،ﻛﺎﻧﺖ
ﻟﺤﻈﺔﻫﺎﻣﺔﰲﺗﺎرﻳﺦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻣﻊ ذﻟﻚ،ﺗُﻌﺘﱪ ورﺷﺔ اﻟﻌﻤﻞ اﻟﺘﻲﻋُﻘﺪتﰲ
ﺟﺎﻣﻌﺔ دارﺗﻤﻮثﰲﺻﻴﻒﻋﺎم ٦٥٩١ﰲﻫﺎﻧﻮﻓﺮ،ﻧﻴﻮﻫﺎﻣﺒﺸﺎﻳﺮ،ﺑﺸﻜﻞٍﻋﺎمﻫﻲﻣﺤﻞ
ﻣﻴﻼد اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﻌﺎﴏ. وﻗﺪﺻﺎغﻣُﻨﻈﻤﻬﺎﺟﻮنﻣﻜﺎرﺛﻲﻓﻴﻬﺎﻣﺼﻄﻠﺢ اﻟﺬﻛﺎء
52</p>
<p>اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
،اﻻﺻﻄﻨﺎﻋﻲ، وﺷﺎرﻛﺖﻓﻴﻬﺎ أﺳﻤﺎءٌﻣﻬﻤﺔﻣﺜﻞﻣﺎرﻓﻦﻣﻴﻨﺴﻜﻲ، وﻛﻠﻮدﺷﺎﻧﻮن، وأﻟﻦﻧﻴﻮﻳﻞ
وﻫريﺑﺮتﺳﺎﻳﻤﻮن. وﰲﺣنيﻛﺎنﻳُﻨﻈﺮ إﱃﻋﻠﻢ اﻟﺘﺤﻜﱡﻢ اﻵﱄﻋﲆ أﻧﻪﺷﺪﻳﺪ اﻻﻧﺸﻐﺎل
ﺑﺎﻵﻻت اﻟﺘﻨﺎﻇﺮﻳﺔ، اﻫﺘﻤﱠﺖ ورﺷﺔﻋﻤﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ دارﺗﻤﻮثﺑﺎﻵﻻت اﻟﺮﻗﻤﻴﺔ.
ﻛﺎﻧﺖ اﻟﻔﻜﺮةﻫﻲ »ﻣﺤﺎﻛﺎة« اﻟﺬﻛﺎء اﻟﺒﴩي )وﻟﻴﺲ إﻋﺎدةﺧﻠﻘِﻪ:ﻓﺎﻟﻌﻤﻠﻴﺔﻣﺨﺘﻠﻔﺔﻋﻤﺎ
ﻳﺤﺪثﰲ اﻟﺒﴩ(. وﻇﻦﱠ اﻟﻜﺜريﻣﻦ املﺸﺎرﻛنيﰲ ورﺷﺔ اﻟﻌﻤﻞﻫﺬه أن إﻧﺸﺎء آﻟﺔٍﺗﺘﻤﺘﱠﻊﺑﻨﻔﺲ
ذﻛﺎء اﻟﺒﴩ أﻣﺮ وﺷﻴﻚ اﻟﺤﺪوث:ﺗﻮﻗﻌﻮا أﻧﻬﺎﻟﻦﺗﺴﺘﻐﺮقﰲﻇﻬﻮرﻫﺎ أﻛﺜﺮﻣﻦﺟﻴﻞٍ واﺣﺪ.
ﻫﺬاﻫﻮﻫﺪف »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﻮي«. اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ »اﻟﻘﻮي« أو »اﻟﻌﺎم«
ﻗﺎدرﻋﲆ أداء أيﻣﻬﺎمﻣﻌﺮﻓﻴﺔﻳﻤﻜﻦﻟﻠﺒﴩ أداؤﻫﺎ،ﰲﺣني أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
»اﻟﻀﻌﻴﻒ« أو »املﺤﺪود«ﻳﻤﻜﻦ أنﻳﺆديﻓﻘﻂﰲﻣﺠﺎﻻتٍﻣُﺤﺪدةﻣﺜﻞ اﻟﺸﻄﺮﻧﺞ،
وﺗﺼﻨﻴﻒ اﻟﺼﻮر، وﻣﺎ إﱃ ذﻟﻚ.ﺣﺘﻰ اﻟﻴﻮم،ﻟﻢﻧُﺤﻘﱢﻖ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم، وﻛﻤﺎ رأﻳﻨﺎ
ﰲ اﻟﻔﺼﻮل اﻟﺴﺎﺑﻘﺔ،ﻓﺈن اﻟﺸﻜﻮكﺗﺤُﻮمﺣﻮلﻣﺎ إذاﻛﻨﱠﺎﺳﻨُﺤﻘﱢﻘﻪﻋﲆ اﻹﻃﻼق. وﻋﲆ
اﻟﺮﻏﻢﻣﻦ أنﺑﻌﺾ اﻟﺒﺎﺣﺜني واﻟﴩﻛﺎتﻳُﺤﺎوﻟﻮنﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم، وﻻ
ﺳﻴﻤﺎﻫﺆﻻء اﻟﺬﻳﻦﻳﺆﻣِﻨﻮنﺑﻨﻈﺮﻳﺔﺣﺎﺳﻮﺑﻴﺔ اﻟﻌﻘﻞ،ﻓﺈﻧﻪﻟﻦﻳﺘﻢﺗﻄﻮﻳﺮهﰲ املُﺴﺘﻘﺒﻞ
اﻟﻘﺮﻳﺐ. وﻟﺬا،ﺗُﺮﻛﺰ اﻷﺳﺌﻠﺔ اﻷﺧﻼﻗﻴﺔ واﻟﺴﻴﺎﺳﻴﺔﰲ اﻟﻔﺼﻞ اﻟﺘﺎﱄﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﻀﻌﻴﻒ أو املﺤﺪود، املﻮﺟﻮدﺑﺎﻟﻔﻌﻞﺣﺎﻟﻴٍّﺎ واﻟﺬيﻣﻦ املُﺮﺟﱠﺢ أنﻳُﺼﺒﺢ أﻛﺜﺮﻗﻮةً واﻧﺘﺸﺎرًا
ﰲ املﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ.
ﻳﻤﻜﻦﺗﻌﺮﻳﻒ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻋﺘﺒﺎرهﻋﻠﻤًﺎ وﻛﺬﻟﻚﺑﺎﻋﺘﺒﺎرهﺗﻜﻨﻮﻟﻮﺟﻴﺎ.ﻳﻤﻜﻦ
أنﻳﻜﻮن اﻟﻬﺪفﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻮﺗﻔﺴري اﻟﺬﻛﺎء واﻟﻮﻇﺎﺋﻒ املﻌﺮﻓﻴﺔ املﺬﻛﻮرة
ﺗﻔﺴريًاﻋﻠﻤﻴٍّﺎ أدق. وﻳُﻤﻜﻦ أنﻳُﺴﺎﻋﺪﻧﺎﰲﻓﻬﻢ اﻟﺒﴩ وﻏريﻫﻢﻣﻦ اﻟﻜﺎﺋﻨﺎت اﻟﺘﻲﺗﻤﺘﻠﻚ ذﻛﺎءً
ﻃﺒﻴﻌﻴٍّﺎﻓﻬﻤًﺎ أﻓﻀﻞ. وﺑﻬﺬه اﻟﻄﺮﻳﻘﺔ،ﻳﻜﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﻠﻤًﺎ وﺗﺨﺼﱡﺼًﺎﻳﺪرس
(، وأﺣﻴﺎﻧًﺎﻳﺪرس اﻟﻌﻘﻞ أو اﻟﺪﻣﺎغ.Jansen et al. 2018)ﻇﺎﻫﺮة اﻟﺬﻛﺎءﺑﺸﻜﻞٍﻣﻨﻬﺠﻲ
وﻣﻦﻫﺬا املﻨﻄﻠﻖ،ﻳﺮﺗﺒﻂ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻌﻠﻮمٍ أﺧﺮىﻣﺜﻞ اﻟﻌﻠﻮم املﻌﺮﻓﻴﺔ وﻋﻠﻢ اﻟﻨﻔﺲ
وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت )اﻧﻈﺮ اﻟﻘﺴﻢ اﻟﻼﺣﻖ(، وأﺣﻴﺎﻧًﺎ أﻳﻀًﺎﻋِﻠﻢ اﻷﻋﺼﺎب، اﻟﺬيﻳﺴﻌﻰﺣﺜﻴﺜًﺎ إﱃ
ﻓَﻬﻢ اﻟﺬﻛﺎء اﻟﻄﺒﻴﻌﻲ. وﻟﻜﻦﻗﺪﻳﻜﻮن اﻟﻬﺪفﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎﻫﻮﺗﻄﻮﻳﺮ
ﻋﻤﻠﻴﺔﻣُﺨﺘﻠﻔﺔ، أوﻛﻤﺎﻳﻘﻮلﺑﻮدن »ﻹﻧﺠﺎز أﺷﻴﺎءﻣُﻔﻴﺪة«:ﻳﻤﻜﻦ أنﻳﺄﺧﺬ
ﺗﻘﻨﻴﺎتٍﻷﻏﺮاضٍ
ﻋﻤﻠﻴﺔ. وﻳﻤﻜﻦ
ﺷﻜﻞَ أدوات،ﺻﻤﱠﻤﻬﺎ اﻟﺒﴩ، وﺗﺨﻠﻖﻣﻈﻬﺮ اﻟﺬﻛﺎء واﻟﺴﻠﻮك اﻟﺬﻛﻲﻷﻏﺮاضٍ
ﻟﻶﻻت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنﺗﻔﻌﻞ ذﻟﻚﻋﻦﻃﺮﻳﻖﺗﺤﻠﻴﻞ اﻟﺒﻴﺌﺔ )ﰲﺻﻮرة
ﺑﻴﺎﻧﺎت( واﻟﺘﴫﱡفﺑﺪرﺟﺔٍﻛﺒريةﻣﻦ اﻻﺳﺘﻘﻼﻟﻴﺔ.ﰲﺑﻌﺾ اﻷﺣﻴﺎن،ﺗﻠﺘﻘﻲ اﻻﻫﺘﻤﺎﻣﺎت
53</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
،اﻟﻨﻈﺮﻳﺔ واﻷﻏﺮاض اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ،ﻋﲆﺳﺒﻴﻞ املﺜﺎلﰲﻋِﻠﻢ اﻷﻋﺼﺎب اﻟﺤﻮﺳﺒﻲ-اﻟﻌﻠﻤﻴﺔ
اﻟﺬيﻳﺴﺘﺨﺪِم أدواتٍﻣﻦﻋﻠﻮم اﻟﻜﻤﺒﻴﻮﺗﺮﻟﻔﻬﻢ اﻟﺠﻬﺎز اﻟﻌﺼﺒﻲ، أوﰲﻣﴩوﻋﺎتٍﻣُﺤﺪدة
اﻷوروﺑﻲ، اﻟﺬيﻳﺸﻤﻞ اﻟﻌﻠﻮم اﻟﻌﺼﺒﻴﺔ وأﻳﻀًﺎ اﻟﺮوﺑﻮﺗﺎت1«ﻣﺜﻞ »ﻣﴩوع اﻟﺪﻣﺎغ اﻟﺒﴩي
واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؛ وﺗﺠﻤﻊﺑﻌﺾﻣﴩوﻋﺎﺗﻪﻣﺎﺑنيﻋِﻠﻢ اﻷﻋﺼﺎب وﺗﻌﻠﱡﻢ اﻵﻟﺔﻓﻴﻤﺎﻳُﻌﺮَف
ﺑﻌﻠﻢ أﻋﺼﺎب اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ )ﻣﺜﻞﻓﻮ وآﺧﺮﻳﻦ ٨١٠٢(.
ﺑﺸﻜﻞٍ أﻋﻢ،ﻳﻌﺘﻤﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆ اﻟﻌﺪﻳﺪﻣﻦ اﻟﺘﺨﺼﱡﺼﺎت وﻳﺮﺗﺒﻂﺑﻬﺎ،ﺑﻤﺎ
ﰲ ذﻟﻚ اﻟﺮﻳﺎﺿﻴﺎت )ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻹﺣﺼﺎء(، واﻟﻬﻨﺪﺳﺔ، واﻟﻠﻐﻮﻳﺎت، واﻟﻌﻠﻮم املﻌﺮﻓﻴﺔ،
وﻋﻠﻮم اﻟﻜﻤﺒﻴﻮﺗﺮ، وﻋﻠﻢ اﻟﻨﻔﺲ، وﺣﺘﻰ اﻟﻔﻠﺴﻔﺔ. وﻛﻤﺎ رأﻳﻨﺎ،ﻳﻬﺘﻢ اﻟﻔﻼﺳﻔﺔ واﻟﺒﺎﺣﺜﻮنﰲ
ﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆﺣﺪﱟﺳﻮاءﺑﻔﻬﻢ اﻟﻌﻘﻞ وﻇﻮاﻫﺮﻣﺜﻞ اﻟﺬﻛﺎء واﻟﻮﻋﻲ واﻹدراك
واﻟﻔﻌﻞ واﻹﺑﺪاع. وﻗﺪ أﺛﱠﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆ اﻟﻔﻠﺴﻔﺔ واﻟﻌﻜﺲﺻﺤﻴﺢ. وﻗﺪ أﻗﺮﱠﻛﻴﺚ
ﻓﺮاﻧﻜﻴﺶ ووﻳﻠﻴﺎم راﻣﺰيﺑﻬﺬا اﻻرﺗﺒﺎطﺑني اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﻔﻠﺴﻔﺔ، وﺷﺪﱠداﻋﲆ
ﺗﻌﺪﱡدﺗﺨﺼﱡﺼﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﺟﻤﻌﺎ اﻟﺠﺎﻧﺒَني اﻟﻌﻠﻤﻲ واﻟﺘﻜﻨﻮﻟﻮﺟﻲﰲﺗﻌﺮﻳﻔﻬﻤﺎ
ﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻋﺘﺒﺎره »ﻧﻬﺠًﺎﻣُﺘﻌﺪﱢد اﻟﺘﺨﺼﱡﺼﺎتﻟﻔﻬﻢ وﻧﻤﺬﺟﺔ وﻣُﺤﺎﻛﺎة اﻟﺬﻛﺎء
واﻟﻌﻤﻠﻴﺎت املﻌﺮﻓﻴﺔﻋﻦﻃﺮﻳﻖ اﻻﺳﺘﻨﺎد إﱃﻣﺒﺎدئ وأﺟﻬﺰةﺣﻮﺳﺒِﻴﱠﺔ ورﻳﺎﺿﻴﺔ وﻣﻨﻄﻘﻴﺔ
وﻣﻴﻜﺎﻧﻴﻜﻴﺔ وﺣﺘﻰﺑﻴﻮﻟﻮﺟﻴﺔﻣﺘﻨﻮﻋﺔ« )٤١٠٢، ١(.ﻟﺬﻟﻚ،ﻳﻌﺘﱪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻧﻈﺮﻳٍّﺎ
وﻋﻤﻠﻴٍّﺎ،ﻋﻠﻤًﺎ وﺗﻜﻨﻮﻟﻮﺟﻴﺎ. وﻳﺮﻛﺰﻫﺬا اﻟﻜﺘﺎبﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻋﺘﺒﺎرهﺗﻜﻨﻮﻟﻮﺟﻴﺎ،
ﻋﲆ اﻟﺠﺎﻧﺐ اﻷﻛﺜﺮﻋﻤﻠﻴﺔ:ﻟﻴﺲﻓﻘﻂﻷن اﻟﱰﻛﻴﺰ داﺧﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺪﺗﺤﻮﱠلﰲ
ﻫﺬا اﻻﺗﺠﺎه، وﻟﻜﻦ،ﻋﲆ وﺟﻪ اﻟﺨﺼﻮص،ﻷن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﻫﺬه اﻟﺼﻮرةﻟﻪﻋﻮاﻗﺐ
أﺧﻼﻗﻴﺔ واﺟﺘﻤﺎﻋﻴﺔ؛ﻋﲆ اﻟﺮﻏﻢﻣﻦ أن اﻟﺒﺤﺚ اﻟﻌﻠﻤﻲ أﻳﻀًﺎﻟﻴﺲﺧﺎﻟﻴًﺎﺗﻤﺎﻣًﺎﻣﻦ اﻟﻌﻮاﻗﺐ
اﻷﺧﻼﻗﻴﺔ.
ﺑﺎﻋﺘﺒﺎرهﺗﻜﻨﻮﻟﻮﺟﻴﺎ،ﻳُﻤﻜﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنﻳﺄﺧﺬ أﺷﻜﺎﻻًﻣﺨﺘﻠﻔﺔ وﻋﺎدةًﻣﺎ
ﻳﻜﻮنﺟﺰءًاﻣﻦﻧُﻈﻢﺗﻜﻨﻮﻟﻮﺟﻴﺔ أﻛﱪ: اﻟﺨﻮارزﻣﻴﺎت، واﻵﻻت، واﻟﺮوﺑﻮﺗﺎت، وﻣﺎ إﱃ ذﻟﻚ.
ﻟﺬﻟﻚ،ﰲﺣنيﻗﺪﻳﺘﻌﻠﱠﻖ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑ »اﻵﻻت«،ﻓﺈنﻫﺬا املﺼﻄﻠﺢﻻﻳُﺸري إﱃ
اﻟﺮوﺑﻮﺗﺎت وﺣﺪَﻫﺎ،ﻧﺎﻫﻴﻚﻋﻦ اﻟﺮوﺑﻮﺗﺎت اﻟﺘﻲﺗﺘﱠﺨِﺬﺷﻜﻼًﺑﴩﻳٍّﺎ.ﻳُﻤﻜﻦ أنﻳُﻀﻤﱠﻦ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﰲ اﻟﻌﺪﻳﺪﻣﻦ أﻧﻮاع اﻷﻧﻈﻤﺔ واﻷﺟﻬﺰة اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ اﻷﺧﺮى. وﻳﻤﻜﻦﻷﻧﻈﻤﺔ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنﺗﺄﺧُﺬﺷﻜﻞَﺑﺮﻧﺎﻣﺞٍﻳﻌﻤﻞﻋﲆ اﻟﻮﻳﺐ )ﻣﺜﻞ اﻟﺪردﺷﺔ اﻵﻟﻴﺔ وﻣُﺤﺮﻛﺎت
اﻟﺒﺤﺚ وﺗﺤﻠﻴﻞ اﻟﺼﻮر(، وﻟﻜﻦﻳُﻤﻜﻦ أنﻳُﻀﻤﱠﻦ أﻳﻀًﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ اﻷﺟﻬﺰة
ﺑﺎﻟﻨﺴﺒﺔ إﱃ إﻧﱰﻧﺖ2.«املﻠﻤﻮﺳﺔﻣﺜﻞ اﻟﺮوﺑﻮﺗﺎت أو اﻟﺴﻴﺎرات أوﺗﻄﺒﻴﻘﺎت »إﻧﱰﻧﺖ اﻷﺷﻴﺎء
54</p>
<p>اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
املﺎدﻳﺔ«، وﻫﻲﻋﺒﺎرةﻋﻦ أﺟﻬﺰة-اﻷﺷﻴﺎء،ﻳُﺴﺘﺨﺪَم أﺣﻴﺎﻧًﺎﻣﺼﻄﻠﺢ »اﻷﻧﻈﻤﺔ اﻹﻟﻜﱰوﻧﻴﺔ
املﺎدﻳﺔ،-ﺗﻌﻤﻞﰲ اﻟﻌﺎﻟَﻢ املﺎدي وﺗﺘﻔﺎﻋﻞﻣﻌﻪ. وﺗُﻌَﺪ اﻟﺮوﺑﻮﺗﺎتﻧﻮﻋًﺎﻣﻦ اﻷﻧﻈﻤﺔ اﻹﻟﻜﱰوﻧﻴﺔ
(.Lin, Abney, and Bekey 2011)اﻟﺘﻲﺗﺆﺛﱢﺮﺗﺄﺛريًاﻣﺒﺎﴍًاﻋﲆ اﻟﻌﺎﻟﻢ
إذاﺗﻢﱠﺗﻀﻤني اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ روﺑﻮت،ﻓﺈﻧﻪﻳُﻄﻠﻖﻋﻠﻴﻪ أﺣﻴﺎﻧًﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ »املﺘﺠﺴﱢﺪ«. وﺗﻌﺘﻤﺪ اﻟﺮوﺑﻮﺗﺎتﰲﺗﺄﺛريﻫﺎﻋﲆ اﻟﻌﺎﻟَﻢ املﺎديﺗﺄﺛريًاﻣﺒﺎﴍًا
ﻋﲆﻣﻜﻮﱢﻧﺎتﻣﺎدﻳﺔ. وﻟﻜﻦﻛﻞﻧﻈﺎم ذﻛﺎءٍ اﺻﻄﻨﺎﻋﻲ،ﺑﻤﺎﰲ ذﻟﻚ اﻟﱪاﻣﺞ اﻟﻨﺸﻄﺔﻋﲆ
اﻟﻮﻳﺐ، »ﻳﻔﻌﻞ«ﺷﻴﺌًﺎ وﻟﺪَﻳﻪ أﻳﻀًﺎﻣﻜﻮﱢﻧﺎتﻣﺎدﻳﺔﻣﺜﻞ اﻟﻜﻤﺒﻴﻮﺗﺮ اﻟﺬيﻳﻌﻤﻞﻋﻠﻴﻪ، واملُﻜﻮﻧﺎت
املﺎدﻳﺔﻟﻠﺸﺒﻜﺔ واﻟﺒِﻨﻴﺔ اﻷﺳﺎﺳﻴﺔ اﻟﺘﻲﻳﻌﺘﻤِﺪﻋﻠﻴﻬﺎ، وﻣﺎ إﱃ ذﻟﻚ. وﻫﺬاﻳﺠﻌﻞ اﻟﺘﻔﺮﻗﺔﻣﺎﺑني
ﺗﻄﺒﻴﻘﺎت اﻟﻮﻳﺐ »اﻻﻓﱰاﺿﻴﺔ« واﻟﺘﻄﺒﻴﻘﺎت »اﻟﱪﻣﺠﻴﺔ«ﻣﻦﻧﺎﺣﻴﺔ، واﻟﺘﻄﺒﻴﻘﺎت املﺎدﻳﺔ أو
ﺗﻄﺒﻴﻘﺎت »اﻷﺟﻬﺰة«ﻣﻦﻧﺎﺣﻴﺔٍ أﺧﺮىﻣﺴﺄﻟﺔًﺻﻌﺒﺔ وﻣُﺤريﱢ ة. إنﺑﺮاﻣﺞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
املﺎدﻳﺔﻻ-ﺗﺤﺘﺎج إﱃﻣﻜﻮﱢﻧﺎتﻣﺎدﻳﺔ وﺑِﻨﻴﺔ أﺳﺎﺳﻴﺔﻣﺎدﻳﺔﻟﻜﻲﺗﻌﻤﻞ، واﻷﻧﻈﻤﺔ اﻹﻟﻜﱰوﻧﻴﺔ
ﻳﻤﻜﻦ اﻋﺘﺒﺎرﻫﺎ ذﻛﺎءً اﺻﻄﻨﺎﻋﻴٍّﺎ إﻻ إذاﺗﻢﺗﻮﺻﻴﻠﻬﺎﺑﺎﻟﱪاﻣﺞ املﻨﺎﺳﺒﺔ.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻣﻦ
وﺟﻬﺔﻧﻈﺮ اﻟﻈﺎﻫﺮﻳﺔ،ﻗﺪﺗﻨﺪﻣﺞ املﻜﻮﻧﺎت املﺎدﻳﺔ واﻟﱪﻣﺠﻴﺔ أﺣﻴﺎﻧًﺎﰲﺗﺠﺮﺑﺘﻨﺎ واﺳﺘﺨﺪاﻣﻨﺎ
ﻟﻸﺟﻬﺰة:ﻓﻨﺤﻦﻻﻧﺸﻌﺮﺑﺄن اﻟﺮوﺑﻮت اﻟﺘﻔﺎﻋُﲇ اﻟﺬيﻳﺄﺧﺬﺷﻜﻼًﺑﴩﻳٍّﺎ وﻳﻌﻤﻞﺑﻮاﺳﻄﺔ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، أو أنﺟﻬﺎز املﺤﺎدﺛﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺜﻞ أﻟﻴﻜﺴﺎ،ﻋﺒﺎرةﻋﻦ
ﻣﻜﻮﻧﺎتﺑﺮﻣﺠﻴﺔ أوﻣﻜﻮﻧﺎتﻣﺎدﻳﺔ، وﻟﻜﻨﻨﺎﻧﺸﻌﺮ أﻧﻬﻤﺎﺟﻬﺎزﺗﻜﻨﻮﻟﻮﺟﻲ واﺣﺪ )وأﺣﻴﺎﻧًﺎ
ﻧﺸﻌﺮ أﻧﻬﻤﺎﺷِﺒﻪ أﺷﺨﺎص،ﻣﺜﻞ دُﻣﻴﺔ »ﻫﺎﻟﻮﺑﺎرﺑﻲ«(.
ﻣﻦ املُﺮﺟﱠﺢ أنﻳﻜﻮنﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺄﺛريﻛﺒريﻋﲆﻋﻠﻢ اﻟﺮوﺑﻮﺗﺎت، وذﻟﻚﻋﲆ
ﺳﺒﻴﻞ املﺜﺎلﻣﻦﺧﻼل اﻟﺘﻘﺪﱡمﰲﻣﻌﺎﻟﺠﺔ اﻟﻠﻐﺔ اﻟﻄﺒﻴﻌﻴﺔ واﻟﺘﻮاﺻُﻞ اﻟﺸﺒﻴﻪﺑﺘﻮاﺻﻞ اﻹﻧﺴﺎن.
ﰲﻛﺜريٍﻣﻦ اﻷﺣﻴﺎنﻳُﻄﻠَﻖﻋﲆﻫﺬه اﻟﺮوﺑﻮﺗﺎت اﺳﻢ »اﻟﺮوﺑﻮﺗﺎت اﻻﺟﺘﻤﺎﻋﻴﺔ«؛ﻷﻧﻬﺎﻣُﺼﻤﱠﻤﺔ
ﺑﻬﺪف املﺸﺎرﻛﺔﰲ اﻟﺤﻴﺎة اﻻﺟﺘﻤﺎﻋﻴﺔ اﻟﻴﻮﻣﻴﺔﻟﻠﺒﴩ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻛﺮﻓﺎقٍ أوﻣﺴﺎﻋِﺪﻳﻦ،
ﻣﻦﺧﻼل اﻟﺘﻔﺎﻋُﻞﻣﻊ اﻟﺒﴩﺑﻄﺮﻳﻘﺔٍﻃﺒﻴﻌﻴﺔ. وﻣﻦﺛَﻢﱠ،ﻳﻤﻜﻦ أنﻳُﻌﺰز اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻣﺰﻳﺪًاﻣﻦ اﻟﺘﻄﻮراتﰲ اﻟﺮوﺑﻮﺗﺎت اﻻﺟﺘﻤﺎﻋﻴﺔ.
وﻣﻊ ذﻟﻚ،ﺑﻐﺾ اﻟﻨﻈﺮﻋﻦ املﻈﻬﺮ واﻟﺴﻠﻮك اﻟﻜﲇﻟﻠﻨﻈﺎم وﺗﺄﺛريهﻋﲆ اﻟﺒﻴﺌﺔ املُﺤﻴﻄﺔ
ﺑﻪ، وﻫﻮﻣﺎﻳُﻌﺘﱪﻣﻬﻤٍّﺎﺟﺪٍّاﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻟﻈﺎﻫﺮﻳﺔ واﻷﺧﻼﻗﻴﺔ،ﻓﺈن أﺳﺎس »اﻟﺬﻛﺎء«ﰲ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻮﺑﺮﻧﺎﻣﺞ: »ﺧﻮارزﻣﻴﺔ« أوﻣﺠﻤﻮﻋﺔﻣﻦ اﻟﺨﻮارزﻣﻴﺎت. واﻟﺨﻮارزﻣﻴﺔ
ﻫﻲﻣﺠﻤﻮﻋﺔ وﺗﺴﻠﺴُﻞﻣﻦ اﻟﺘﻌﻠﻴﻤﺎت،ﻣﺜﻞ اﻟﻮﺻﻔﺔ،ﺗُﺨﱪ اﻟﻜﻤﺒﻴﻮﺗﺮ أو اﻟﻬﺎﺗﻒ اﻟﺬﻛﻲ أو
اﻵﻟﺔ أو اﻟﺮوﺑﻮت أو أيﳾءٍ آﺧَﺮﻳﺘﻢﺗﻀﻤﻴﻨﻬﺎﻓﻴﻪﺑﻤﺎﻳﺠﺐ أنﻳﻔﻌﻞ. وﻫﻲﺗﺆدي إﱃ
55</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ٍﻣُﺨﺮﺟﺎتﻣُﻌﻴﱠﻨﺔﺑﻨﺎءًﻋﲆ املﻌﻠﻮﻣﺎت املﺘﺎﺣﺔ )املﺪﺧﻼت(. وﺗُﻄﺒﱠﻖ اﻟﺨﻮارزﻣﻴﺔﻟﺤﻞﱢﻣﺸﻜﻠﺔ
ﻣﺎ. وﻟﻜﻲﻧﻔﻬﻢ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻋﻠﻴﻨﺎ أوﻻً أنﻧﻔﻬﻢﻛﻴﻔﻴﺔﻋﻤﻞﺧﻮارزﻣﻴﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣﺎﺗﻘﻮمﺑﻪ. وﺳﻮف أﺗﺤﺪﱠث أﻛﺜﺮﻋﻦﻫﺬا املﻮﺿﻮعﻫﻨﺎ وﰲ اﻟﻔﺼﻞ
اﻟﻘﺎدم.
املﻨﺎﻫﺞ واملﺠﺎﻻت اﻟﻔﺮﻋﻴﺔ املُﺨﺘﻠﻔﺔ
ﻫﻨﺎك أﻧﻮاعﻣﺨﺘﻠﻔﺔﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻳﻤﻜﻦ اﻟﻘﻮل أﻳﻀًﺎ إنﻫﻨﺎكﻣﻨﺎﻫﺞ أوﻧﻤﺎذج
ﺑﺤﺚٍﻣﺨﺘﻠﻔﺔ.ﻛﻤﺎ رأﻳﻨﺎﰲ اﻧﺘﻘﺎد درﻳﻔﻮس،ﻏﺎﻟﺒًﺎﻣﺎﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆﻣﺪار
اﻟﺘﺎرﻳﺦ ذﻛﺎءً اﺻﻄﻨﺎﻋﻴٍّﺎ رﻣﺰﻳٍّﺎ. وﻛﺎنﻫﺬاﻫﻮ اﻟﻨﻤﻮذج اﻟﺴﺎﺋﺪﺣﺘﻰ أواﺧﺮ اﻟﺜﻤﺎﻧﻴﻨﻴﺎت.
وﻳﻌﺘﻤِﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺮﻣﺰيﻋﲆ اﻟﺘﻤﺜﻴﻼت اﻟﺮﻣﺰﻳﺔﻟﻠﻤﻬﺎمﱢ املﻌﺮﻓﻴﺔ اﻟﻌﺎﻟﻴﺔ املُﺴﺘﻮى
ﻣﺜﻞ اﻟﺘﻔﻜري اﻟﺘﺠﺮﻳﺪي واﺗﺨﺎذ اﻟﻘﺮارات.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﻳﺘﱠﺨِﺬﻗﺮارًا اﺳﺘﻨﺎدًا إﱃ
اﻟﻬﻴﻜﻞ اﻟﺸﺠﺮيﻻﺗﺨﺎذ اﻟﻘﺮار؛ وﻫﻮﻋﺒﺎرةﻋﻦﻧﻤﻮذجٍﻟﻠﻘﺮارات وﻋﻮاﻗِﺒﻬﺎ املُﻤﻜﻨﺔ، وﻳُﻤﺜﱠﻞ
ﻏﺎﻟﺒًﺎﺑﺸﻜﻞٍ رﺳﻮﻣﻲﻳُﺸﺒﻪ املُﺨﻄﻂ اﻻﻧﺴﻴﺎﺑﻲ. وﺗﺤﺘﻮي اﻟﺨﻮارزﻣﻴﺔ اﻟﺘﻲﺗﻔﻌﻞ ذﻟﻚﻋﲆ
اﻟﴩط وﻳﲇif،ﺑﺤﻴﺚﻳﲇif … then …ﻋﺒﺎراتٍﴍﻃﻴﺔ:ﻗﻮاﻋﺪﻻﺗﺨﺎذ اﻟﻘﺮارﻋﲆﺻﻮرة
اﻟﻨﺘﻴﺠﺔ. وﻫﺬه اﻟﻌﻤﻠﻴﺔﺣﺎﺳﻤﺔ وﻏريﻋﺸﻮاﺋﻴﺔ. وﺑﺎﻻﺳﺘﻨﺎد إﱃﻗﺎﻋﺪةﺑﻴﺎﻧﺎتٍﺗُﻤﺜﱢﻞthen
املﻌﺮﻓﺔ اﻟﺨﺒرية اﻟﺒﴩﻳﺔ،ﻳُﻤﻜﻦ ملِﺜﻞﻫﺬا اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﺗﺨﺎذ اﻟﻘﺮار،ﻣُﻌﺘﻤﺪًاﻋﲆﻛﻢﱟ
ﻫﺎﺋﻞﻣﻦ املﻌﻠﻮﻣﺎت، واﻟﺘﴫﱡفﻛﻨﻈﺎمٍﺧﺒري. وﻳﺴﺘﻄﻴﻊ أنﻳﺘﱠﺨﺬﻗﺮاراتٍﺣﻜﻴﻤﺔ أوﻳﺼﻞ
إﱃﺗﻮﺻﻴﺎت اﺳﺘﻨﺎدًا إﱃﻛﺘﻠﺔٍﺿﺨﻤﺔﻣﻦ املﻌﺮﻓﺔ،ﻗﺪﻳﻜﻮنﻣﻦ اﻟﺼﻌﺐ أوﻣﻦ املُﺴﺘﺤﻴﻞ
ﺑﺎﻟﻨﺴﺒﺔ إﱃ اﻟﺒﴩ اﻻﻃﻼعﻋﻠﻴﻬﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗُﺴﺘﺨﺪَمﻫﺬه اﻷﻧﻈﻤﺔ اﻟﺨﺒريةﰲ اﻟﻘﻄﺎع
اﻟﻄﺒﱢﻲﻟﺘﺸﺨﻴﺺ املﺮض ووﺿﻊﺧﻄﺔِ اﻟﻌﻼج. وﻗﺪﻇﻠﱠﺖﻫﺬه اﻷﻧﻈﻤﺔﻫﻲ اﻷﻧﺠﺢﰲﻣﺠﺎل
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻔﱰةٍﻃﻮﻳﻠﺔ.
وﻻﻳﺰال اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺮﻣﺰيﻣُﻔﻴﺪًاﺣﺘﻰ اﻟﻴﻮم، وﻟﻜﻦﻇﻬﺮت أﻳﻀًﺎ أﻧﻮاع
ﺟﺪﻳﺪةﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻳُﻤﻜﻦ دﻣﺠﻬﺎ أوﻋﺪم دﻣﺠﻬﺎﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺮﻣﺰي، وﻫﻲﻗﺎدرةﻋﲆ اﻟﺘﻌﻠﱡﻢ ذاﺗﻴٍّﺎﻣﻦ اﻟﺒﻴﺎﻧﺎت،ﻋﲆﻋﻜﺲ اﻷﻧﻈﻤﺔ اﻟﺨﺒرية. وﻳﺘﻢ
ذﻟﻚﻣﻦﺧﻼل اﺳﺘﺨﺪامﻧﻬﺞٍﻣﺨﺘﻠﻒﺗﻤﺎﻣًﺎ. وﻳﻌﺘﻤﺪﻧﻤﻮذج اﻟﺒﺤﺚ »اﻟﺘﺸﺎﺑُﻜﻲ«، اﻟﺬيﺗﻢ
ﺗﻄﻮﻳﺮهﰲ اﻟﺜﻤﺎﻧﻴﻨﻴﺎتﻣﻦ اﻟﻘﺮن اﻟﻌﴩﻳﻦﻛﺒﺪﻳﻞٍ ملﺎ أُﻃﻠِﻖﻋﻠﻴﻪ اﺳﻢ »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
، وﺗﻜﻨﻮﻟﻮﺟﻴﺎ »اﻟﺸﺒﻜﺎت اﻟﻌﺼﺒﻴﺔ«ﻋﲆﻓﻜﺮة أﻧﻨﺎﺑﺪﻻًGOFAIاﻟﻘﺪﻳﻢ« وﻳﻌﺮف اﺧﺘﺼﺎرًاﺑ
56</p>
<p>اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
ٍﻣﻦﺗﻤﺜﻴﻞ اﻟﻮﻇﺎﺋﻒ املﻌﺮﻓﻴﺔ اﻟﻌُﻠﻴﺎ،ﻳﺠﺐﻋﻠﻴﻨﺎﺑﻨﺎءﺷﺒﻜﺎتﻣُﱰاﺑﻄﺔﺑﺎﻻﺳﺘﻨﺎد إﱃ وﺣﺪات
ﺑﺴﻴﻄﺔ. وﻳﺪﻋﻲﻣﺆﻳﺪوﻫﺬا اﻟﻨﻬﺞ أنﻫﺬاﻳُﺸﺒﻪ اﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳﻌﻤﻞﺑﻬﺎ اﻟﺪﻣﺎغ اﻟﺒﴩي؛
إذﻳﻨﺸﺄ اﻹدراكﻣﻦﺗﻔﺎﻋُﻼتﺑني وﺣﺪاتِ املﻌﺎﻟﺠﺔ اﻟﺒﺴﻴﻄﺔ املُﺴﻤﱠﺎة »اﻟﺨﻼﻳﺎ اﻟﻌﺼﺒﻴﺔ«
)وﻣﻊ ذﻟﻚ،ﻓﻬﻲﻻﺗُﺸﺒﻪ اﻟﺨﻼﻳﺎ اﻟﻌﺼﺒﻴﺔ اﻟﺒﻴﻮﻟﻮﺟﻴﺔ(. وﻳُﺴﺘﺨﺪَم اﻟﻌﺪﻳﺪﻣﻦ اﻟﺨﻼﻳﺎ
اﻟﻌﺼﺒﻴﺔ املُﱰاﺑِﻄﺔ.ﻳُﺴﺘﺨﺪَمﻫﺬا اﻟﻨﻬﺞ وﻫﺬه اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻛﺜريًاﰲ »ﺗﻌﻠﱡﻢ اﻵﻟﺔ« )اﻧﻈﺮ
اﻟﻔﺼﻞ اﻟﺘﺎﱄ(، واﻟﺬيﻳُﻄﻠﻖﻋﻠﻴﻪﺑﻌﺪ ذﻟﻚ »اﻟﺘﻌﻠﱡﻢ اﻟﻌﻤﻴﻖ« إذاﻛﺎﻧﺖ اﻟﺸﺒﻜﺎت اﻟﻌﺼﺒﻴﺔ
ﺗﺘﻜﻮﱠنﻣﻦﻋﺪةﻃﺒﻘﺎتٍﻣﻦ اﻟﺨﻼﻳﺎ اﻟﻌﺼﺒﻴﺔ. وﺗُﻌﺘﱪَﺑﻌﺾ اﻷﻧﻈﻤﺔﻫﺠﻴﻨﺔ؛ﻋﲆﺳﺒﻴﻞ
املﺜﺎل،ﻳُﻌﺘﱪَ »أﻟﻔﺎﺟﻮ« اﻟﺬيﻃﻮﱠرَﺗﻪﴍﻛﺔ »دﻳﺐﻣﺎﻳﻨﺪ«ﻧﻈﺎﻣًﺎﻫﺠﻴﻨًﺎ. وﻗﺪ أدﱠى اﻟﺘﻌﻠﱡﻢ
اﻟﻌﻤﻴﻖ إﱃﺣﺪوثﺗﻄﻮﱡرﰲﻣﺠﺎﻻتﻣﺜﻞ رؤﻳﺔ اﻵﻟﺔ وﻣُﻌﺎﻟﺠﺔ اﻟﻠﻐﺔ اﻟﻄﺒﻴﻌﻴﺔ. وﻳﻤﻜﻦ أن
ﻳﻜﻮنﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﺬيﻳَﺴﺘﺨﺪِمﺷﺒﻜﺔﻣُﺤﺎﻳﺪةﺑﻤﻨﺰﻟﺔ »ﺻﻨﺪوق أﺳﻮد«؛ﺑﻤﻌﻨﻰ أﻧﻪﰲﺣني
أن املُﱪﻣِﺠنيﻳﻌﺮﻓﻮنﺗﺼﻤﻴﻢ اﻟﺸﺒﻜﺔ،ﻓﺈﻧﻪﻟﻴﺲ واﺿﺤًﺎﻟﻶﺧﺮﻳﻦﻣﺎذاﻳﺤﺪثﺑﺎﻟﻀﺒﻂ
ﰲﻃﺒﻘﺎﺗﻬﺎ اﻟﻮﺳﻴﻄﺔ )ﺑني املﺪﺧﻼت واملﺨﺮﺟﺎت( وﺑﺎﻟﺘﺎﱄﻛﻴﻒﺗﺘﱠﺨِﺬﻗﺮارًا. وﻫﺬاﻋﻜﺲ
ﻣﺎﻳﺤﺪُثﰲ اﻟﻬﻴﻜﻞ اﻟﺸﺠﺮيﻻﺗﺨﺎذ اﻟﻘﺮار، اﻟﺬيﻳﻜﻮن واﺿﺤًﺎ وﻗﺎﺑﻼًﻟﻠﺘﻔﺴري، وﻣﻦﺛَﻢ
ﻳﻤﻜﻦﻓﺤﺼُﻪ وﺗﻘﻴﻴﻤﻪﻣﻦﻗِﺒﻞ اﻟﺒﴩ.
ﺛﻤﱠﺔﻧﻤﻮذجﻣُﻬﻢ آﺧَﺮﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻫﻮ ذﻟﻚ اﻟﺬيﻳَﺴﺘﺨﺪِمﻣﻨﺎﻫﺞ أﻛﺜﺮ
ﺗﺠﺴﻴﺪﻳﺔً وأﻛﺜﺮ اﻋﺘﻤﺎدًاﻋﲆ املﻮاﻗﻒ،ﻣﺮﻛﺰًاﻋﲆ اﻟﺘﻔﺎﻋُﻞ واملﻬﺎم اﻟﺤﺮﻛﻴﺔﺑﺪﻻًﻣﻤﺎﻧُﻄﻠﻖ
ﻋﻠﻴﻪ املﻬﺎم املﻌﺮﻓﻴﺔ اﻟﻌُﻠﻴﺎ. واﻟﺮوﺑﻮﺗﺎت اﻟﺘﻲﺻﻨﻌﻬﺎﺑﺎﺣﺜﻮنﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻣﺜﻞ رودﻧﻲﺑﺮوﻛﺲﻣﻦ »إم آيﺗﻲ«ﻻﺗﺤﻞﱡ املﺸﻜﻼتﺑﺎﺳﺘﺨﺪامﺗﻤﺜﻴﻼتٍ رﻣﺰﻳﺔ وﻟﻜﻦ
ﻋﻦﻃﺮﻳﻖ اﻟﺘﻔﺎﻋُﻞﻣﻊ اﻟﺒﻴﺌﺔ املُﺤﻴﻄﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺻُﻤﱢﻢَ اﻟﺮوﺑﻮت »ﻛﻮج« اﻟﺸﺒﻴﻪ
ﺑﺎﻟﺒﴩ، اﻟﺬيﺗﻢﱠﺗﻄﻮﻳﺮهﰲ اﻟﺘﺴﻌﻴﻨﻴﺎتﻣﻦ اﻟﻘﺮن اﻟﻌﴩﻳﻦ،ﺑﺤﻴﺚﻳﺘﻌﻠﱠﻢﻣﻦﺧﻼل
اﻟﺘﻔﺎﻋﻞﻣﻊ اﻟﻌﺎﻟﻢ،ﻛﻤﺎﻳﻔﻌﻞ اﻷﻃﻔﺎل. وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻳﻌﺘﻘﺪﺑﻌﺾ اﻷﺷﺨﺎص أن اﻟﻌﻘﻞ
ﻳﻤﻜﻦ أنﻳﻨﺸﺄﻓﻘﻂﻣﻦ اﻟﺤﻴﺎة؛ وﺑﺎﻟﺘﺎﱄ،ﻹﻧﺸﺎء اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻳﺠﺐ أنﻧُﺤﺎول
إﻧﺸﺎءﺣﻴﺎةٍ اﺻﻄﻨﺎﻋﻴﺔ. وﻳﺘﺒﻊﺑﻌﺾ املﻬﻨﺪﺳنيﻧﻬﺠًﺎ أﻗﻞﱠﻣِﻴﺘﺎﻓﻴﺰﻳﻘﻴﺔ وأﻛﺜﺮﻋﻤﻠﻴﺔ؛ إذ
ﻳﺄﺧﺬون اﻷﺣﻴﺎءﻧﻤﻮذﺟًﺎﻟﺘﻄﻮﻳﺮﺗﻄﺒﻴﻘﺎتٍﺗﻜﻨﻮﻟﻮﺟﻴﺔﻋﻤﻠﻴﺔ. وﻫﻨﺎك أﻳﻀًﺎ آﻻتﺗﻄﻮﱡرﻳﺔ
ﻣﺰودةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺴﺘﻄﻴﻊ أنﺗﺘﻄﻮﱠر. وﻳﻤﻜﻦﻟﺒﻌﺾ اﻟﱪاﻣﺞ،ﺑﺎﺳﺘﺨﺪامﻣﺎ
ﻳُﺴﻤﱠﻰﺑﺨﻮارزﻣﻴﺎت اﻟﻮراﺛﺔ،ﺗﻐﻴريﻧﻔﺴﻬﺎ.
ﻫﺬا اﻟﺘﻨﻮﱡعﰲﻣﻨﺎﻫﺞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ ووﻇﺎﺋﻔﻪﻳﺸري إﱃ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﻴﻮمﻟﻪ اﻟﻌﺪﻳﺪﻣﻦ املﺠﺎﻻت اﻟﻔﺮﻋﻴﺔ:ﺗﻌﻠﱡﻢ اﻵﻟﺔ، ورؤﻳﺔ اﻟﻜﻤﺒﻴﻮﺗﺮ، وﻣﻌﺎﻟﺠﺔ اﻟﻠﻐﺔ
57</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﻄﺒﻴﻌﻴﺔ، واﻷﻧﻈﻤﺔ اﻟﺨﺒرية، واﻟﺤﻮﺳﺒﺔ اﻟﺘﻄﻮﱡرﻳﺔ، وﻫﻠﻢﱠﺟﺮٍّا. وﻏﺎﻟﺒًﺎﻣﺎﻳﻜﻮن اﻟﱰﻛﻴﺰ
اﻟﻴﻮمﻋﲆﺗﻌﻠﱡﻢ اﻵﻟﺔ، وﻟﻜﻦﻫﺬاﻟﻴﺲﺳﻮىﻣﺠﺎلٍ واﺣﺪﻣﻦﻣﺠﺎﻻت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،
ﺣﺘﻰ وإنﻛﺎﻧﺖﻫﺬه املﺠﺎﻻت اﻷﺧﺮىﻣُﺘﺼﻠﺔًﻏﺎﻟﺒًﺎﺑﺘﻌﻠﱡﻢ اﻵﻟﺔ. وﻗﺪﺗﻢﺗﺤﻘﻴﻖﺗﻄﻮرات
ﻫﺎﺋﻠﺔﻣﺆﺧﺮًاﰲ رؤﻳﺔ اﻟﻜﻤﺒﻴﻮﺗﺮ وﻣﻌﺎﻟﺠﺔ اﻟﻠﻐﺔ اﻟﻄﺒﻴﻌﻴﺔ وﺗﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔﻋﻦ
ﻃﺮﻳﻖﺗﻌﻠﱡﻢ اﻵﻟﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦ اﺳﺘﺨﺪامﺗﻌﻠﱡﻢ اﻵﻟﺔ ملﻌﺎﻟﺠﺔ اﻟﻠﻐﺔ اﻟﻄﺒﻴﻌﻴﺔ
اﺳﺘﻨﺎدًا إﱃﺗﺤﻠﻴﻞ اﻟﻜﻼم واملﺼﺎدر املﻜﺘﻮﺑﺔﻣﺜﻞ اﻟﻨﺼﻮص املﻮﺟﻮدةﻋﲆ اﻹﻧﱰﻧﺖ. وﻗﺪ
أﺛﻤﺮﻫﺬا اﻟﻌﻤﻞﻋﻦ إﻧﺸﺎء أﺟﻬﺰة املﺤﺎدﺛﺔ اﻟﺤﺪﻳﺜﺔ.ﻣﺜﺎل آﺧَﺮﻫﻮ اﻟﺘﻌﺮﱡفﻋﲆ اﻟﻮﺟﻮه
اﺳﺘﻨﺎدًا إﱃ رؤﻳﺔ اﻟﻜﻤﺒﻴﻮﺗﺮ واﻟﺘﻌﻠﱡﻢ اﻟﻌﻤﻴﻖ، وﻳﻤﻜﻦ اﺳﺘﺨﺪاﻣﻪ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﻣﺠﺎل
املﺮاﻗﺒﺔ.
اﻟﺘﻄﺒﻴﻘﺎت واﻟﺘﺄﺛري
،(ﻳﻤﻜﻦﺗﻄﺒﻴﻖﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﻣﺠﺎﻻتٍﻣﺨﺘﻠﻔﺔ )ﻟﻬﺎﺗﻄﺒﻴﻘﺎتﻣﺘﻨﻮﻋﺔ
ﺗﱰاوحﻣﺎﺑني اﻟﺘﺼﻨﻴﻊ واﻟﺰراﻋﺔ واﻟﻨﻘﻞ، واﻟﺮﻋﺎﻳﺔ اﻟﺼﺤﻴﺔ واﻟﺘﻤﻮﻳﻞ واﻟﺘﺴﻮﻳﻖ واﻟﺠﻨﺲ
واﻟﱰﻓﻴﻪ واﻟﺘﻌﻠﻴﻢ ووﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ.ﰲﻣﺠﺎل اﻟﺒﻴﻊﺑﺎﻟﺘﺠﺰﺋﺔ واﻟﺘﺴﻮﻳﻖ،
ﺗُﺴﺘﺨﺪَم أﻧﻈﻤﺔ اﻟﺘﻮﺻﻴﺔﻟﻠﺘﺄﺛريﰲﻗﺮارات اﻟﴩاء وﻟﺘﻘﺪﻳﻢ إﻋﻼﻧﺎتٍﻣﺴﺘﻬﺪﻓﺔ. أﻣﺎﰲ
ﻣﺠﺎل وﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ،ﻳﻤﻜﻦ أنﻳﺸﻐَﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺮوﺑﻮﺗﺎت: وﻫﻲ
ﺣﻘﻴﻘﻴﻮن وﻟﻜﻨﻬﺎﰲ اﻟﻮاﻗﻊ
ﻋﺒﺎرةﻋﻦﺣﺴﺎﺑﺎتِﻣُﺴﺘﺨﺪﻣنيﺗﻈﻬﺮﻋﲆ أﻧﻬﺎ أﺷﺨﺎصٌ
ﺑﺮاﻣﺞ. وﻳُﻤﻜﻦ ملِﺜﻞﻫﺬه اﻟﺮوﺑﻮﺗﺎت أنﺗﻨﴩﻣﺤﺘﻮًىﺳﻴﺎﺳﻴٍّﺎ أوﺗُﺠﺮي دردﺷﺔًﻣﻊ
ﻣُﺴﺘﺨﺪِﻣنيﻣﻦ اﻟﺒﴩ. وﰲﻣﺠﺎل اﻟﺮﻋﺎﻳﺔ اﻟﺼﺤﻴﺔ،ﻳُﺴﺘﺨﺪَم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﺘﺤﻠﻴﻞ
ﺑﻴﺎﻧﺎتٍﻣﻦﻣﻼﻳني املﺮﴇ. وﻣﺎ زاﻟﺖ اﻷﻧﻈﻤﺔ اﻟﺨﺒريةﺗُﺴﺘﺨﺪَم أﻳﻀًﺎﰲﻫﺬا املﺠﺎل.
ﰲﻣﺠﺎل اﻟﺘﻤﻮﻳﻞ،ﻳُﺴﺘﺨﺪَم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﺘﺤﻠﻴﻞﻣﺠﻤﻮﻋﺎتٍﺿﺨﻤﺔﻣﻦ اﻟﺒﻴﺎﻧﺎت
ﻟﺘﺤﻠﻴﻞ اﻟﺴﻮق وأﺗْﻤَﺘَﺔِ اﻟﺘﻌﺎﻣُﻼت املﺎﻟﻴﺔ. وﻏﺎﻟﺒًﺎﻣﺎﻳﺘﻢﺗﻀﻤنيﻧﻮعﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﰲ اﻟﺮوﺑﻮﺗﺎت املُﺼﻤﱠﻤﺔﻟﺘﻜﻮنﻣﺮاﻓﻘًﺎﻟﻺﻧﺴﺎن. واﻟﻄﻴﺎر اﻵﱄ واﻟﺴﻴﺎرات ذاﺗﻴﺔ اﻟﻘﻴﺎدة
ﺗﺴﺘﺨﺪم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻳﻤﻜﻦﻷﺻﺤﺎب اﻟﻌﻤﻞ اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ ملﺮاﻗﺒﺔ
املﻮﻇﻔني.ﻛﻤﺎ أن أﻟﻌﺎب اﻟﻔﻴﺪﻳﻮﺗﺤﺘﻮيﻋﲆﺷﺨﺼﻴﺎتٍﻣﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
وﺗﺴﺘﻄﻴﻊ اﻵﻻت املﺰوﱠدةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺄﻟﻴﻒ املُﻮﺳﻴﻘﻰ أوﻛﺘﺎﺑﺔﻣﻘﺎﻻت اﻷﺧﺒﺎر.
ﻛﻤﺎﺗﺴﺘﻄﻴﻊﺗﻘﻠﻴﺪَ أﺻﻮات اﻷﺷﺨﺎص وﺣﺘﻰ إﻧﺸﺎءﻣﻘﺎﻃﻊﻓﻴﺪﻳﻮﻣُﺰﻳﻔﺔﻟﺨﻄﺎﺑﺎت.
58</p>
<p>اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
ﻧﻈﺮًا إﱃﺗﻨﻮﱡعﺗﻄﺒﻴﻘﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻣﻦ املُﺮﺟﱠﺢ أنﻳﻜﻮنﻟﻪﺗﺄﺛري واﺳﻊ
اﻟﻨﻄﺎق،ﺳﻮاء اﻟﻴﻮم أوﰲ املُﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ.ﻓﺈذاﻓﻜﱠﺮْﻧﺎﻣﺜﻼًﰲ اﻟﴩﻃﺔ اﻟﺘﻨﺒﱡﺆﻳﺔ وإﻣﻜﺎﻧﻴﺔ
اﻟﺘﻌﺮﱡفﻋﲆ اﻟﻜﻼم، اﻟﻠﺬَﻳﻦﻳﺨﻠﻘﺎن إﻣﻜﺎﻧﻴﺎتﺟﺪﻳﺪةﻟﻸﻣﺎن واملﺮاﻗﺒﺔ، ووﺳﺎﺋﻞ اﻟﻨﻘﻞﺑني
اﻷﻓﺮاد واﻟﺴﻴﺎرات ذاﺗﻴﺔ اﻟﻘﻴﺎدة اﻟﺘﻲﻳُﻤﻜﻦ أنﺗُﺤﺪِثﺗﺤﻮﱡﻻًﰲﻣﺪنٍﺑﺄﻛﻤﻠﻬﺎ، واﻟﺘﺪاول
اﻟﺨﻮارزﻣﻲ اﻟﻌﺎﱄ اﻟﱰدﱡد اﻟﺬيﻳُﺸﻜﱢﻞﺑﺎﻟﻔﻌﻞ اﻷﺳﻮاق املﺎﻟﻴﺔ، أو اﻟﺘﻄﺒﻴﻘﺎت اﻟﺘﺸﺨﻴﺼﻴﺔ
ﰲ اﻟﻘﻄﺎع اﻟﻄﺒﻲ اﻟﺘﻲﺗﺆﺛﺮﰲ اﺗﺨﺎذ اﻟﻘﺮارات اﻟﺴﻠﻴﻤﺔ.ﻳﺠﺐ أﻳﻀًﺎ أﻻﻧﻨﴗ اﻟﻌﻠﻮم
ﻛﺄﺣﺪ املﺠﺎﻻت اﻟﺮﺋﻴﺴﻴﺔ اﻟﺘﻲﺗﺄﺛﱠﺮَت إﱃﺣﺪﱟﻛﺒريﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ:ﻋﻦﻃﺮﻳﻖﺗﺤﻠﻴﻞ
ﻣﺠﻤﻮﻋﺎتٍﺿﺨﻤﺔﻣﻦ اﻟﺒﻴﺎﻧﺎت،ﻳﻤﻜﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺴﺎﻋﺪة اﻟﻌﻠﻤﺎءﰲ اﻛﺘﺸﺎف
ارﺗﺒﺎﻃﺎتﻟﻢﻳﻜﻮﻧﻮاﻟﻴُﺪرﻛﻮﻫﺎﻟﻮﻻه. وﻫﺬاﻳﻨﻄﺒﻖﻋﲆ اﻟﻌﻠﻮم اﻟﻄﺒﻴﻌﻴﺔﻣﺜﻞ اﻟﻔﻴﺰﻳﺎء، وﻟﻜﻦ
أﻳﻀًﺎﻋﲆ اﻟﻌﻠﻮم اﻻﺟﺘﻤﺎﻋﻴﺔ واﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ. وﻣﻦ املُﺆﻛﱠﺪ أنﻳﺆﺛﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ
ﻣﺠﺎل اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ اﻟﺮﻗﻤﻴﺔ اﻟﻨﺎﺷﺊ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻦﻃﺮﻳﻖﺗﻌﻠﻴﻤﻨﺎ املﺰﻳﺪﻋﻦ
اﻟﺒﴩ وﻋﻦ املُﺠﺘﻤﻌﺎت اﻟﺒﴩﻳﺔ.
ﻳﺆﺛﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎﻋﲆ اﻟﻌﻼﻗﺎت اﻻﺟﺘﻤﺎﻋﻴﺔ،ﻛﻤﺎ أنﻟﻪﺗﺄﺛريًا اﺟﺘﻤﺎﻋﻴٍّﺎ
(. وﻣﻦ املُﺮﺟﱠﺢ أنﻳﺸﻜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲJansen et al. 2018)واﻗﺘﺼﺎدﻳٍّﺎ وﺑﻴﺌﻴٍّﺎ أوﺳﻊ
اﻟﺘﻔﺎﻋﻼت اﻟﺒﴩﻳﺔ وﻳﺆﺛﺮﻋﲆ اﻟﺨﺼﻮﺻﻴﺔ. وﻳُﻘﺎل إﻧﻪﻗﺪﻳﺰﻳﺪﻣﻦ اﻟﺘﺤﻴﱡﺰ واﻟﺘﻤﻴﻴﺰ. وﻣﻦ
املﺘﻮﻗﱠﻊ أنﻳﺆدي إﱃﻓﻘﺪان اﻟﻮﻇﺎﺋﻒ ورﺑﻤﺎ إﱃ إﺣﺪاثﺗﺤﻮﱡلٍ اﻗﺘﺼﺎديﻛﺎﻣﻞ.ﻓﻤﻦ املُﻤﻜﻦ
أنﻳﺰﻳﺪ اﻟﻔﺠﻮةﺑني اﻷﻏﻨﻴﺎء واﻟﻔﻘﺮاء وﺑني أﺻﺤﺎب اﻟﻨﻔﻮذ واملُﺴﺘﻀﻌَﻔني،ﻣﻌﺠﻼً اﻟﻈﻠﻢ
واﻟﺘﻔﺎوت اﻻﺟﺘﻤﺎﻋﻲ. أﻣﺎ اﻟﺘﻄﺒﻴﻘﺎت اﻟﻌﺴﻜﺮﻳﺔ،ﻓﻘﺪﺗُﻐريﱢ اﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳﺘﻢﺑﻬﺎﺗﻨﻔﻴﺬ
اﻟﺤﺮوب،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪ اﺳﺘﺨﺪام اﻷﺳﻠﺤﺔ اﻟﻘﺎﺗﻠﺔ ذاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞ.ﻛﺬﻟﻚﻳﺠِﺐ أن
ﻧﺄﺧُﺬﰲ اﻋﺘﺒﺎرﻧﺎ اﻟﺘﺄﺛري اﻟﺒﻴﺌﻲﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، واﻟﺬيﻳﺸﻤﻞ زﻳﺎدة اﺳﺘﻬﻼك اﻟﻄﺎﻗﺔ
واﻟﺘﻠﻮﱡث. وﺳﻮف أُﻧﺎﻗﺶﻻﺣﻘًﺎﺑﻌﺾ اﻵﺛﺎر اﻷﺧﻼﻗﻴﺔ واﻻﺟﺘﻤﺎﻋﻴﺔﺑﻤﺰﻳﺪٍﻣﻦ اﻟﺘﻔﺼﻴﻞ،
ﻣﺮﻛﺰًاﻋﲆﻣﺸﻜﻼت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣَﺨﺎﻃﺮه. وﻟﻜﻦﻳﻤﻜﻦ أنﻳﻜﻮنﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
أﻳﻀًﺎ آﺛﺎر إﻳﺠﺎﺑﻴﺔ؛ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦ أنﻳﺨﻠﻖﻣُﺠﺘﻤﻌﺎتﺟﺪﻳﺪةﻋﻦﻃﺮﻳﻖ وﺳﺎﺋﻞ
اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ، وﻳُﻘﻠﱢﻞ املﻬﺎم املﺘﻜﺮﱢرة واﻟﺨﻄريةﻋﻦﻃﺮﻳﻖﺗﻜﻠﻴﻒ اﻟﺮوﺑﻮﺗﺎتﺑﻬﺎ،
وﻳُﺤﺴﱢﻦﺳﻼﺳﻞ اﻹﻣﺪاد، وﻳُﻘﻠﱢﻞ اﺳﺘﻬﻼك املﻴﺎه، وﻫﻜﺬا.
ﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖﺑﺎﻟﺘﺄﺛري — إﻳﺠﺎﺑﻲ أوﺳﻠﺒﻲ —ﻳﺠﺐ أﻻﻧﺴﺄلﻓﻘﻂﻋﻦﻃﺒﻴﻌﺔ اﻟﺘﺄﺛري
وﻣﺪاه؛ﺑﻞ أنﻧﺴﺄل أﻳﻀًﺎ »ﻣَﻦ«ﻫﻢ املﺘﺄﺛﺮون وﻛﻴﻒﺳﻴﺘﺄﺛﱠﺮون.ﻗﺪﻳﻜﻮن اﻟﺘﺄﺛري أﻛﺜﺮ
إﻳﺠﺎﺑﻴﺔﺑﺎﻟﻨﺴﺒﺔ إﱃ اﻟﺒﻌﺾﻣﻨﻪﺑﺎﻟﻨﺴﺒﺔ إﱃ اﻵﺧَﺮﻳﻦ.ﻓﻬﻨﺎك اﻟﻌﺪﻳﺪﻣﻦ اﻷﻃﺮاف املَﻌﻨﻴﺔ،
59</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺑﺪءًاﻣﻦ اﻟﻌﻤﺎل واملﺮﴇ واملُﺴﺘﻬﻠﻜني، إﱃ اﻟﺤﻜﻮﻣﺎت واملُﺴﺘﺜﻤﺮﻳﻦ واﻟﴩﻛﺎت، وﺟﻤﻴﻌﻬﻢ
ﻗﺪﻳﺘﺄﺛﺮونﺑﻄﺮُقﻣﺨﺘﻠﻔﺔ. وﺗﻨﺸﺄﻫﺬه اﻻﺧﺘﻼﻓﺎتﰲ املﻜﺎﺳﺐ واﻟﺨﺴﺎﺋﺮﻣﻦﺗﺄﺛريات
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺲﻓﻘﻂ داﺧﻞ اﻟﺒﻠﺪان وﻟﻜﻦ أﻳﻀًﺎﺑني اﻟﺒﻠﺪان وأﺟﺰاء اﻟﻌﺎﻟَﻢ.ﻓﻬﻞ
ﺳﻴﻌﻮد اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﻨﱠﻔﻊﻋﲆ اﻟﺒﻠﺪان املﺘﻘﺪﱢﻣﺔ واملُﺘﻄﻮرةﰲ املﻘﺎم اﻷول؟ وﻫﻞ
ﻣﻦ املُﻤﻜﻦ أنﻳﻜﻮنﻣﻔﻴﺪًا أﻳﻀًﺎﻟﻸﺷﺨﺎص ذوي اﻟﺘﻌﻠﻴﻢ املُﻨﺨﻔِﺾ واﻟﺪﺧﻞ املُﻨﺨﻔﺾ،
ﻋﲆﺳﺒﻴﻞ املﺜﺎل؟ﻣَﻦﺳﺘﻜﻮنﻟﺪَﻳﻪ اﻟﻘﺪرةﻋﲆ اﻟﻮﺻﻮل إﱃ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻳﻜﻮنﻗﺎدرًاﻋﲆ
ﺟﻨْﻲﻓﻮاﺋﺪﻫﺎ؟ﻣَﻦﺳﻴﺘﻤﻜﻦﻣﻦﺗﻤﻜنيﻧﻔﺴﻪﺑﺎﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ وﻣَﻦﺳﻴﻜﻮن
ﻣُﺴﺘﺒﻌﺪًاﻣﻦﻫﺬه اﻟﻔﻮاﺋﺪ؟
ﻣَﻦﺳﺘﻜﻮنﻟﺪَﻳﻪ اﻟﻘﺪرةﻋﲆ اﻟﻮﺻﻮل إﱃ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻳﻜﻮنﻗﺎدرًاﻋﲆﺟﻨﻲﻓﻮاﺋﺪﻫﺎ؟ﻣَﻦﺳﻴﺘﻤﻜﱠﻦ
ﻣﻦﺗﻤﻜنيﻧﻔﺴﻪﺑﺎﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ وﻣَﻦﺳﻴﻜﻮنﻣُﺴﺘﺒﻌﺪًاﻣﻦﻫﺬه اﻟﻔﻮاﺋﺪ؟
.اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺲ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺮﻗﻤﻴﺔ اﻟﻮﺣﻴﺪة اﻟﺘﻲﺗُﺜريﻣﺜﻞﻫﺬه اﻷﺳﺌﻠﺔ
ﻓﻬﻨﺎكﺗﻘﻨﻴﺎت رﻗﻤﻴﺔ أﺧﺮىﺧﺎﺻﺔﺑﺎملﻌﻠﻮﻣﺎت واﻻﺗﺼﺎﻻت، وﻫﻲ أﻳﻀًﺎﺗﺆﺛﺮﺗﺄﺛريًاﻛﺒريًا
ﻋﲆﺣﻴﺎﺗﻨﺎ وﻣُﺠﺘﻤﻌﺎﺗﻨﺎ. وﻛﻤﺎﺳﻨﺮى،ﺑﻌﺾ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲﻳُﺜريﻫﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺴﺖﺣﻜﺮًاﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺣﺪَه.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻫﻨﺎكﻣﺸﻜﻼت
ﻣﻮازﻳﺔﰲﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻷﺟﻬﺰة اﻟﺬاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞ.ﺗﺬﻛﱠﺮﻣﺜﻼً اﻟﺮوﺑﻮﺗﺎت اﻟﺼﻨﺎﻋﻴﺔ اﻟﺘﻲﺗﻤﱠﺖ
ﺑﺮﻣﺠﺘﻬﺎ وﻻﺗُﻌﺘﱪَ ذﻛﺎءً اﺻﻄﻨﺎﻋﻴٍّﺎ، وﻟﻜﻨﻬﺎﻻﺗﺰالﻟﻬﺎﺗﺄﺛريات اﺟﺘﻤﺎﻋﻴﺔﻋﻨﺪﻣﺎﺗﺆدي إﱃ
اﻟﺒﻄﺎﻟﺔ. وﺑﻌﺾﻣﺸﻜﻼت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣُﺮﺗﺒﻄﺔﺑﺎﻟﺘﻘﻨﻴﺎت اﻟﺘﻲﻳﺘﱠﺼِﻞﺑﻬﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ،ﻣﺜﻞ وﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ واﻹﻧﱰﻧﺖ، اﻟﺘﻲﺗُﻮاﺟﻬﻨﺎﺑﺘﺤﺪﻳﺎتٍﺟﺪﻳﺪة
ﻋﻨﺪﻣﺎﻳﺘﻢ دﻣﺠُﻬﺎﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪﻣﺎﺗﺴﺘﺨﺪمﻣﻨﺼﱠﺎت
اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲﻣﺜﻞ »ﻓﻴﺴﺒﻮك« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﺘﻌﺮِف املﺰﻳﺪﻋﻦﻣُﺴﺘﺨﺪﻣﻴﻬﺎ،
ﻓﺈنﻫﺬاﻳُﺜريﻣﺨﺎوفﺗﺘﻌﻠﱠﻖﺑﺎﻟﺨﺼﻮﺻﻴﺔ.
ﻫﺬا اﻻﺗﺼﺎلﻣﻊ اﻟﺘﻘﻨﻴﺎت اﻷﺧﺮىﻳﻌﻨﻲ أﻳﻀًﺎ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻜﻮنﻏري
ﻣﻠﺤﻮظٍﰲﻛﺜريﻣﻦ اﻷﺣﻴﺎن. وﻳﺮﺟﻊﻫﺬاﰲ املﻘﺎم اﻷول إﱃﻛﻮﻧﻪ أﺻﺒﺢﺑﺎﻟﻔﻌﻞﺟﺰءًا
ﻻﻳﺘﺠﺰأﻣﻦﺣﻴﺎﺗﻨﺎ اﻟﻴﻮﻣﻴﺔ.ﻓﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻛﺜريًاﻣﺎﻳُﺴﺘﺨﺪَمﰲﺗﻄﺒﻴﻘﺎتﺟﺪﻳﺪة
وﻣﺬﻫﻠﺔﻣﺜﻞ »أﻟﻔﺎﺟﻮ«. وﻟﻜﻨﻨﺎﻳﺠِﺐ أﻻﻧﻨﴗ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳﺸﻐﻞﺑﺎﻟﻔﻌﻞ
ﻣﻨﺼﱠﺎت اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ، وﻣُﺤﺮﻛﺎت اﻟﺒﺤﺚ، وﻏريﻫﺎﻣﻦ اﻟﻮﺳﺎﺋﻂ واﻟﺘﻘﻨﻴﺎت اﻟﺘﻲ
60</p>
<p>اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
أﺿﺤﺖﺟﺰءًاﻣﻦﺗﺠﺮﺑﺘﻨﺎ اﻟﻴﻮﻣﻴﺔ. إن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣُﺘﻮﻏﱢﻞﰲﻛﻞﳾء. وﻳﻤﻜﻦ
أنﻳﻜﻮن اﻟﻔﺎرقﺑني اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻔﻌﲇ وأﺷﻜﺎلٍ أُﺧﺮىﻣﻦ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻏﺎﻣﻀًﺎ،
ﻣﻤﱠﺎﻳﺠﻌﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻏريﻣﺮﺋﻲ: إذاﺗﻢﺗﻀﻤني أﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ
اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ،ﻓﺈﻧﻨﺎﻋﺎدةًﻻﻧُﻼﺣﻈﻬﺎ. وإذاﻛﻨﺎﻧﻌﺮِفﺑﺎﻟﻔﻌﻞ أﻧﻪﻣُﻀﻤﱠﻦ،ﻓﺈﻧﻪﻣﻦ اﻟﺼﻌﺐ
أنﻧﻘﻮلﻣﺎ إذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻮ اﻟﺬيﻳُﺴﺒﱢﺐ املﺸﻜﻠﺔ أو اﻟﺘﺄﺛري، أو إذاﻛﺎﻧﺖ
اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻷﺧﺮى املُﺘﱠﺼﻠﺔﺑﻪﻫﻲ املﺴﺌﻮﻟﺔﻋﻦ ذﻟﻚ.ﺑﻌﺒﺎرة أﺧﺮى،ﻻﻳﻮﺟﺪ »ذﻛﺎء
اﺻﻄﻨﺎﻋﻲ«ﰲﺣﺪﱢ ذاﺗﻪ:ﻓﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻌﺘﻤﺪ داﺋﻤًﺎﻋﲆﺗﻘﻨﻴﺎت أُﺧﺮى وﻳﺘﻢﺗﻀﻤﻴﻨﻪ
ﰲﻣُﻤﺎرﺳﺎت وإﺟﺮاءاتﻋﻠﻤﻴﺔ وﺗﻜﻨﻮﻟﻮﺟﻴﺔ أوﺳﻊ. وﰲﺣني أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎ
ﻳُﺜريﻣﺸﻜﻼتٍ أﺧﻼﻗﻴﺔﺧﺎﺻﺔﺑﻪ،ﻓﺈن »أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ«ﺗﺤﺘﺎج إﱃ أن
ﺗﻜﻮنﻣُﺮﺗﺒﻄﺔﺑﺎﻷﺧﻼﻗﻴﺎت اﻟﻌﺎﻣﺔﻟﻠﻤﻌﻠﻮﻣﺎت اﻟﺮﻗﻤﻴﺔ وﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻻﺗﺼﺎﻻت، وأﺧﻼﻗﻴﺎت
اﻟﻜﻤﺒﻴﻮﺗﺮ، وﻣﺎ إﱃ ذﻟﻚ.
،ﻳﺠﺐ أﻻﻧﻨﴗ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳﺸﻐﻞﺑﺎﻟﻔﻌﻞﻣﻨﺼﱠﺎت اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ، وﻣُﺤﺮﻛﺎت اﻟﺒﺤﺚ
وﻏريﻫﺎﻣﻦ اﻟﻮﺳﺎﺋﻂ واﻟﺘﻘﻨﻴﺎت اﻟﺘﻲ أﺿﺤﺖﺟﺰءًاﻣﻦﺗﺠﺮﺑﺘﻨﺎ اﻟﻴﻮﻣﻴﺔ. إن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣُﺘﻮﻏﱢﻞ
ﰲﻛﻞﱢﳾء.
،ﺛﻤﱠﺔﻣﻨﻄﻖ آﺧَﺮﻳﺆﻛﺪ أﻧﻪﻻﻳﻮﺟﺪﳾءﻳُﻌﺮفﺑﺎﺳﻢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﺣﺪﱢ ذاﺗﻪ
وﻫﻮ أن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ أﻳﻀًﺎ داﺋﻤًﺎﻣﺎﺗﻜﻮن اﺟﺘﻤﺎﻋﻴﺔً وإﻧﺴﺎﻧﻴﺔ:ﻓﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻻﻳﺘﻌﻠﻖ
ﻓﻘﻂﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻟﻜﻦ أﻳﻀًﺎﺑﻤﺎﻳﻔﻌﻠﻪ اﻟﺒﴩﺑﻬﺎ، وﻛﻴﻒﻳﺴﺘﺨﺪﻣﻮﻧﻬﺎ، وﻛﻴﻒﻳُﺪرﻛﻮﻧﻬﺎ
وﻳﻌﻴﺸﻮﻧﻬﺎ، وﻛﻴﻒﻳُﻀﻤﱢﻨﻮﻧﻬﺎﰲﺑﻴﺌﺎتٍ اﺟﺘﻤﺎﻋﻴﺔ وﺗﻘﻨﻴﺔ أوﺳﻊ. وﻫﺬا أﻣﺮﻣُﻬﻢﻟﻸﺧﻼﻗﻴﺎت
— اﻟﺘﻲﺗﺘﻌﻠﻖ أﻳﻀًﺎﺑﻘﺮارات اﻹﻧﺴﺎن — وﻳﻌﻨﻲ أﻳﻀًﺎ أﻧﻪﻳﺠﺐﺗﻀﻤنيﻣﻨﻈﻮرٍﺗﺎرﻳﺨﻲ
واﺟﺘﻤﺎﻋﻲﺛﻘﺎﰲ. اﻟﻀﺠﺔ اﻹﻋﻼﻣﻴﺔ املﺜﺎرةﺣﺎﻟﻴٍّﺎﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺴﺖ اﻟﻀﺠﱠﺔ
اﻷوﱃ اﻟﺘﻲﺗُﺜﺎرﺣﻮل اﻟﺘﻘﻨﻴﺎت املﺘﻘﺪﻣﺔ.ﻗﺒﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻛﺎﻧﺖ »اﻟﺮوﺑﻮﺗﺎت«
أو »اﻵﻻت«ﻫﻲ اﻟﻜﻠﻤﺎت اﻟﺮﺋﻴﺴﻴﺔ.ﻛﻤﺎﺷﻬﺪتﺗﻘﻨﻴﺎتﻣُﺘﻘﺪﻣﺔ أﺧﺮىﻣﺜﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
اﻟﻨﻮوﻳﺔ، وﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﻨﺎﻧﻮ، واﻹﻧﱰﻧﺖ، واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺤﻴﻮﻳﺔ اﻟﻜﺜريﻣﻦ اﻟﺠﺪل. وﻣﻦ املُﻔﻴﺪ
أنﻧﻀﻊ ذﻟﻚﰲ اﻋﺘﺒﺎرﻧﺎﺧﻼلﻣﻨﺎﻗﺸﺎﺗﻨﺎﺣﻮل أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؛ إذ رﺑﻤﺎ
ﻳُﻤﻜﻨﻨﺎ أنﻧﺴﺘﻔﻴﺪﻣﻦﻫﺬه اﻟﻨﻘﺎﺷﺎت واﻟﺠﺪاﻻت. إن اﺳﺘﺨﺪام اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﺗﻄﻮﻳﺮﻫﺎ
61</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﺤﺪثﰲﺳﻴﺎق اﺟﺘﻤﺎﻋﻲ. وﻛﻤﺎﻳﻌﻠَﻢ اﻷﺷﺨﺎص املُﻬﺘﻤﻮنﺑﺘﻘﻴﻴﻢ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ،ﻋﻨﺪﻣﺎ
ﺗﻜﻮن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺟﺪﻳﺪة،ﻳﻤﻴﻞ اﻟﻨﺎس إﱃ أنﻳُﺜريواﺣﻮﻟﻬﺎ اﻟﻜﺜريﻣﻦ اﻟﺠﺪل، وﻟﻜﻦ
ﺑﻤﺠﺮد أنﺗُﺼﺒﺢﺟﺰءًاﻣﻦ اﻟﺤﻴﺎة اﻟﻴﻮﻣﻴﺔ،ﺗﻨﺨﻔِﺾ اﻟﻀﺠﺔ املُﺜﺎرةﺣﻮﻟﻬﺎ واﻟﺠﺪلﺑﺸﺄﻧﻬﺎ
ﺑﺸﻜﻞٍﻛﺒري. وﻣﻦ املُﺮﺟﺢ أنﻳﺤﺪثﻫﺬا أﻳﻀًﺎﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﰲﺣني أنﻣﺜﻞ
ﻫﺬا اﻟﺘﻮﻗﱡﻊﻟﻴﺲﺳﺒﺒًﺎ وﺟﻴﻬًﺎﻟﱰكﻣُﻬﻤﺔﺗﻘﻴﻴﻢ اﻟﺠﻮاﻧﺐ اﻷﺧﻼﻗﻴﺔ واﻟﻌﻮاﻗﺐ اﻻﺟﺘﻤﺎﻋﻴﺔ
ﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﺈﻧﻪﻳُﺴﺎﻋﺪﻧﺎﰲ رؤﻳﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﺳﻴﺎﻗﻪ، وﻣﻦﺛَﻢﱠﻳﺴﺎﻋﺪﻧﺎ
ﰲﻓﻬﻤِﻪﻋﲆﻧﺤﻮٍ أﻓﻀﻞ.
62</p>
</section>
<section id="section-7">
    <h2>٦ - لا تنسَ (علم) البيانات</h2>
    <div class="page-range">Pages 63-70</div>
    <p>اﻟﻔﺼﻞ اﻟﺴﺎدس
ﻻﺗﻨﺲَ )ﻋﻠﻢ( اﻟﺒﻴﺎﻧﺎت
ﺗﻌﻠﱡﻢ اﻵﻟﺔ
ﺑﻤﺎ أن اﻟﻌﺪﻳﺪﻣﻦ اﻷﺳﺌﻠﺔ اﻷﺧﻼﻗﻴﺔﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺘﻌﻠﻖﺑﺘﻘﻨﻴﺎتﺗﻌﺘﻤِﺪﻛﻠﻴٍّﺎ أو
ﺟﺰﺋﻴٍّﺎﻋﲆﺗﻌﻠﱡﻢ اﻵﻟﺔ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت ذي اﻟﺼﱢﻠﺔ،ﻓﺈﻧﻪﻳﺠﺪُرﺑﻨﺎ أنﻧُﻠﻘﻲ اﻟﻀﻮءﻋﲆﻫﺬه
اﻟﺘﻘﻨﻴﺔ واﻟﻌﻠﻢ.
ﻳُﺸري »ﺗﻌﻠﱡﻢ اﻵﻟﺔ« إﱃ اﻟﱪاﻣﺞ اﻟﺘﻲﻳُﻤﻜﻨﻬﺎ »اﻟﺘﻌﻠﱡﻢ«. واملﺼﻄﻠﺢﻣُﺜريﻟﻠﺠﺪل:ﻓﺎﻟﺒﻌﺾ
ﻳﻘﻮﻟﻮن إنﻣﺎﺗﻘﻮمﺑﻪﻟﻴﺲﺗﻌﻠﱡﻤًﺎﺣﻘﻴﻘﻴٍّﺎﻷﻧﻬﺎﻻﺗﺘﻤﺘﱠﻊﺑﺈدراكٍﺣﻘﻴﻘﻲ؛ واﻟﺘﻌﻠﱡﻢﻣﻘﺼﻮر
ﻓﺤﺴﺐ.ﻋﲆ أيﺣﺎل،ﻳﺤﻤﻞﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﺤﺪﻳﺚ »ﺗﺸﺎﺑﻬًﺎﺿﺌﻴﻼً أوﻣُﻨﻌﺪﻣًﺎﻣﻊ
ﻋﲆ اﻟﺒﴩَ
(. وﻫﻮﻳﻌﺘﻤﺪﻋﲆ اﻹﺣﺼﺎءات؛ إذ إﻧﻪBoden 2016, 46) «ﻣﺎﻗﺪﻳﺤﺪُثﰲﻋﻘﻮل اﻟﺒﴩ
ﻋﻤﻠﻴﺔ إﺣﺼﺎﺋﻴﺔ. وﻳُﻤﻜﻦ اﺳﺘﺨﺪاﻣﻪ ملﻬﺎمﱠﻣﺘﻨﻮﻋﺔ، وﻟﻜﻦ املﻬﻤﺔ اﻷﺳﺎﺳﻴﺔﻏﺎﻟﺒًﺎﻣﺎﺗﻜﻮن
ﻫﻲ اﻟﺘﻌﺮﱡفﻋﲆ اﻷﻧﻤﺎط. وﻳُﻤﻜﻦﻟﻠﺨﻮارزﻣﻴﺎت اﻟﺘﻌﺮﱡفﻋﲆ اﻷﻧﻤﺎط أو اﻟﻘﻮاﻋﺪ املﻮﺟﻮدة
ﰲ اﻟﺒﻴﺎﻧﺎت واﺳﺘﺨﺪامﺗﻠﻚ اﻷﻧﻤﺎط أو اﻟﻘﻮاﻋﺪﻟﺘﻔﺴري اﻟﺒﻴﺎﻧﺎت وﺗﻮﻗﱡﻊ اﻟﺒﻴﺎﻧﺎت املُﺴﺘﻘﺒﻠﻴﺔ.
ﻳﺤﺪُث ذﻟﻚ ذاﺗﻴٍّﺎ؛ﺑﻤﻌﻨﻰ أﻧﻪﻳﺤﺪُث دونﺗﻌﻠﻴﻤﺎتٍ وﻗﻮاﻋﺪﻣﺒﺎﴍةﻳُﻌﻄﻴﻬﺎ املﱪﻣﺞ.
وﻋﲆﻋﻜﺲ اﻷﻧﻈﻤﺔ اﻟﺨﺒرية اﻟﺘﻲﺗﻌﺘﻤِﺪﻋﲆﺧﱪاءﺑﴩﻳنيﰲ املﺠﺎلﻳﴩﺣﻮن اﻟﻘﻮاﻋﺪ
ﻟﻠﻤُﱪﻣِﺠني اﻟﺬﻳﻦﻳﺘﻮﻟﱠﻮنﺑﻌﺪ ذﻟﻚﺑﺮﻣﺠﺔﻫﺬه اﻟﻘﻮاﻋﺪ،ﺗﺒﺤﺚﺧﻮارزﻣﻴﺔﺗﻌﻠﱡﻢ اﻵﻟﺔﻋﻦ
ﻗﻮاﻋﺪ أو أﻧﻤﺎطٍﻟﻢﻳُﺤﺪﱢدﻫﺎ املﱪﻣﺞ.ﻛﻞﻣﺎﻋﻠﻴﻚﻫﻮﺗﺤﺪﻳﺪ اﻟﻬﺪف أو املﻬﻤﺔﻓﻘﻂ. وﺳﻮف
ﻳﺴﺘﻄﻴﻊ اﻟﱪﻧﺎﻣﺞ أنﻳُﻜﻴﱢﻒﺳﻠﻮﻛَﻪﺑﻤﺎﻳﺘﻮاﻓﻖﻣﻊﻣُﺘﻄﻠﺒﺎت املﻬﻤﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
ﻳﻤﻜﻦﻟﺘﻌﻠﱡﻢ اﻵﻟﺔ املﺴﺎﻋﺪةﰲ اﻟﺘﻤﻴﻴﺰﺑني اﻟﱪﻳﺪ اﻹﻟﻜﱰوﻧﻲ اﻟﻌﺸﻮاﺋﻲﻏري املﺮﻏﻮبﻓﻴﻪ
واﻟﱪﻳﺪ املُﻬﻢﻣﻦﺧﻼلﻓﺤﺺﻋﺪدٍﻛﺒريﻣﻦ اﻟﺮﺳﺎﺋﻞ وﺗﻌﻠﱡﻢﻣﺎﻳُﻌﺘﱪَﻋﺸﻮاﺋﻴٍّﺎ.ﻣﺜﺎل آﺧَﺮ:</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻹﻧﺸﺎءﺧﻮارزﻣﻴﺔﺗﺘﻌﺮﱠفﻋﲆﺻﻮر اﻟﻘﻄﻂ،ﻻﻳُﻘﺪﱢم املﱪﻣﺠﻮنﻟﻠﻜﻤﺒﻴﻮﺗﺮﻣﺠﻤﻮﻋﺔًﻣﻦ
اﻟﻘﻮاﻋﺪﺗُﻌﺮﱠفﻓﻴﻬﺎﻣﺎﻫﻲ اﻟﻘﻄﻂ، وﻟﻜﻨﻬﻢﻳُﺘﻴﺤﻮنﻟﻠﺨﻮارزﻣﻴﺔ إﻧﺸﺎءﻧﻤﻮذجٍﺧﺎصﱟﺑﻬﺎ
ﻟﺼﻮر اﻟﻘﻄﻂ. وﺗُﺤﺴﱢﻦ اﻟﺨﻮارزﻣﻴﺔﻣﻦ أداﺋﻬﺎ ذاﺗﻴٍّﺎﻟﺘﺤﻘﻴﻖ أﻋﲆ دﻗﱠﺔﺗﻨﺒﺆﺑﺎﻻﺳﺘﻨﺎد إﱃ
ﻣﺠﻤﻮﻋﺔٍﻣﻦﺻﻮر اﻟﻘﻄﻂ وﻏري اﻟﻘﻄﻂ. وﺑﺎﻟﺘﺎﱄ،ﺗﻬﺪف إﱃﺗﻌﻠﱡﻢﻣﺎﻫﻲﺻﻮر اﻟﻘﻄﻂ.
وﻳُﻘﺪﱢم اﻟﺒﴩﺗﻘﺎرﻳﺮ، وﻟﻜﻨﻬﻢﻻﻳُﻐﺬﱡوﻧﻬﺎﺑﺘﻌﻠﻴﻤﺎتٍ أوﻗﻮاﻋﺪﻣُﺤﺪدة.
ﻛﺎن اﻟﻌﻠﻤﺎءﰲ اﻟﺴﺎﺑﻖﻳُﻨﺸﺌﻮنﻧﻈﺮﻳﺎتٍﻟﺘﻔﺴري اﻟﺒﻴﺎﻧﺎت واﻟﺘﻨﺒﱡﺆﺑﻬﺎ؛ﰲﺣنيﻳُﻨﺸﺊ
اﻟﻜﻤﺒﻴﻮﺗﺮﰲﺗﻌﻠﱡﻢ اﻵﻟﺔﻧﻤﺎذجﺧﺎﺻﺔﺑﻪﺗﺘﻨﺎﺳﺐﻣﻊ اﻟﺒﻴﺎﻧﺎت. إذَنﻓﻨﻘﻄﺔ اﻟﺒﺪاﻳﺔﻫﻲ
اﻟﺒﻴﺎﻧﺎت، وﻟﻴﺲ اﻟﻨﻈﺮﻳﺎت. وﻣﻦﻫﺬا املُﻨﻄﻠﻖ،ﻟﻢﺗﻌُﺪ اﻟﺒﻴﺎﻧﺎت »ﺳﻠﺒﻴﺔ«ﺑﻞ »ﻧﺸﻄﺔ«:
Alpaydin 2016,) «»ﻓﺎﻟﺒﻴﺎﻧﺎتﻧﻔﺴﻬﺎﻫﻲ اﻟﺘﻲﺗُﺤﺪﱢدﻣﺎﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪﺑﻌﺪ ذﻟﻚ
(.ﻳُﺪرﱢب اﻟﺒﺎﺣﺜﻮن اﻟﺨﻮارزﻣﻴﺔﺑﺎﺳﺘﺨﺪامﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت املﻮﺟﻮدة )ﻋﲆﺳﺒﻴﻞ11
املﺜﺎل، رﺳﺎﺋﻞ اﻟﱪﻳﺪ اﻹﻟﻜﱰوﻧﻲ اﻟﻘﺪﻳﻤﺔ(، وﻋﻨﺪﺋﺬٍﺗﺴﺘﻄﻴﻊ اﻟﺨﻮارزﻣﻴﺔ اﻟﺘﻨﺒﱡﺆﺑﺎﻟﻨﺘﺎﺋﺞﻣﻦ
(.ﻳُﺸﺎرCDT 2018) (اﻟﺒﻴﺎﻧﺎت اﻟﺠﺪﻳﺪة )ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻟﱪﻳﺪ اﻹﻟﻜﱰوﻧﻲ اﻟﻮارد اﻟﺠﺪﻳﺪ
أﺣﻴﺎﻧًﺎ إﱃ اﻟﺘﻌﺮﱡفﻋﲆ اﻷﻧﻤﺎطﰲﻛﻤﻴﺎتٍﻛﺒريةﻣﻦ املﻌﻠﻮﻣﺎت )اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ(ﺑﺎﺳﻢ
»اﻟﺘﻨﻘﻴﺐﻋﻦ اﻟﺒﻴﺎﻧﺎت«،ﺗﺸﺒﻴﻬًﺎﻟﻪﺑﺎﺳﺘﺨﺮاج املﻌﺎدن اﻟﻘَﻴﱢﻤﺔﻣﻦ اﻷرض. وﻣﻊ ذﻟﻚ،ﻓﺈن
املﺼﻄﻠﺢﻣُﻀﻠﱢﻞﻷن اﻟﻬﺪفﻫﻮ اﺳﺘﺨﺮاج أﻧﻤﺎطٍﻣﻦ اﻟﺒﻴﺎﻧﺎت، وﺗﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎت، وﻟﻴﺲ
اﺳﺘﺨﺮاج اﻟﺒﻴﺎﻧﺎتﻧﻔﺴﻬﺎ.
ﻳﻤﻜﻦ أنﻳﻜﻮنﺗﻌﻠﱡﻢ اﻵﻟﺔ »ﻣُﻮﺟﱠﻬًﺎ«،ﻣﻤﺎﻳَﻌﻨﻲ أن اﻟﺨﻮارزﻣﻴﺔﺗﺮﻛﱢﺰﻋﲆﻣﺘﻐريﱢﻣُﻌنيﱠ
ﻳُﻌﺮَفﺑﺎﺳﻢﻫﺪف اﻟﺘﻨﺒﺆ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إذاﻛﺎن اﻟﻬﺪفﻫﻮﺗﻘﺴﻴﻢ اﻷﺷﺨﺎص إﱃﻓﺌﺘَني
)ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺧﻄﻮرة أﻣﻨﻴﺔﻋﺎﻟﻴﺔ أوﻣﻨﺨﻔﻀﺔ(،ﻓﺈن املُﺘﻐريات اﻟﺘﻲﺗﺘﻨﺒﺄﺑﻬﺎﺗَني
اﻟﻔﺌﺘَنيﻣﻌﺮوﻓﺔﺑﺎﻟﻔﻌﻞ، وﺑﺎﻟﺘﺎﱄﺗﺘﻌﻠﱠﻢ اﻟﺨﻮارزﻣﻴﺔ اﻟﺘﻨﺒﱡﺆﺑﺎﻻﻧﺘﻤﺎء إﱃ إﺣﺪى اﻟﻔﺌﺘَني
)اﻟﺨﻄﻮرة اﻷﻣﻨﻴﺔ اﻟﻌﺎﻟﻴﺔ أو اﻟﺨﻄﻮرة اﻷﻣﻨﻴﺔ املﻨﺨﻔﻀﺔ(.ﻳُﺪرﱢب املﱪﻣﺞ اﻟﻨﻈﺎمﻋﻦﻃﺮﻳﻖ
ﺗﻮﻓري أﻣﺜﻠﺔ وﻏريﻫﺎ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺻﻮرﻟﻸﺷﺨﺎص اﻟﺬﻳﻦﻳُﺸﻜﱢﻠﻮنﺧﻄﻮرة أﻣﻨﻴﺔ
ﻋﺎﻟﻴﺔ وأﻣﺜﻠﺔﻟﻸﺷﺨﺎص اﻟﺬﻳﻦﻻﻳُﺸﻜﻠﻮنﺧﻄﻮرة أﻣﻨﻴﺔ.ﻳﻜﻮن اﻟﻬﺪف أنﻳﺘﻌﻠﱠﻢ اﻟﻨﻈﺎم
اﻟﺘﻨﺒﱡﺆﺑﻤَﻦﻳﻨﺘﻤﻲ إﱃﻛﻞﻓﺌﺔ، أيﻣَﻦﻳُﺸﻜﻞﺧﻄﻮرةً أﻣﻨﻴﺔﻋﺎﻟﻴﺔ وﻣَﻦﻻﻳﺸﻜﻞﺑﻨﺎءًﻋﲆ
اﻟﺒﻴﺎﻧﺎت اﻟﺠﺪﻳﺪة. إذا أُﻋﻄِﻲ اﻟﻨﻈﺎمﻣﺎﻳﻜﻔﻲﻣﻦ اﻷﻣﺜﻠﺔ،ﻓﺈﻧﻪﺳﻴﻜﻮنﻗﺎدرًاﻋﲆ اﻟﺘﻌﻤﻴﻢ
ﻣﻦﻫﺬه اﻷﻣﺜﻠﺔ وﻣﻌﺮﻓﺔﻛﻴﻔﻴﺔﺗﺼﻨﻴﻒ اﻟﺒﻴﺎﻧﺎت اﻟﺠﺪﻳﺪة،ﻣﺜﻞﺻﻮرةٍﺟﺪﻳﺪةﻟﺮاﻛﺐٍﻳﻤﺮﱡ
ﻋَﱪْ أﻣﻦ املﻄﺎر. أﻣﺎﺗﻌﻠﱡﻢ اﻵﻟﺔ »ﻏري املُﻮﺟﱠﻪ«ﻓﻴﻌﻨﻲﻋﺪمﺗﻘﺪﻳﻢﻫﺬا اﻟﻨﻮعﻣﻦ اﻟﺘﺪرﻳﺐ،
وأن اﻟﻔﺌﺎتﻏريﻣﻌﺮوﻓﺔ: وﻣﻦﺛَﻢﺗُﻨﺸﺊ اﻟﺨﻮارزﻣﻴﺎتﻓﺌﺎتٍﺧﺎﺻﱠﺔﺑﻬﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
64</p>
<p>ﻻﺗﻨﺲَ )ﻋﻠﻢ( اﻟﺒﻴﺎﻧﺎت
ﻳُﻨﺸﺊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻓﺌﺎتٍ أﻣﻨﻴﺔًﺧﺎﺻﺔًﺑﻪ اﺳﺘﻨﺎدًا إﱃ املُﺘﻐريات اﻟﺘﻲﻳُﺤﺪدﻫﺎ؛ﻻ
اﻟﺘﻲﻳُﻘﺪﻣﻬﺎ إﻟﻴﻪ املﱪﻣﺞ. ورﺑﻤﺎﻳﻌﺜﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆ أﻧﻤﺎطٍﻟﻢﻳُﺤﺪﱢدﻫﺎﺧﱪاء
املﺠﺎل )ﰲﻫﺬا اﻟﺴﻴﺎق: اﻟﺨﱪاء اﻷﻣﻨﻴﻮن(. وﻳﻤﻜﻦ أنﺗﺒﺪو اﻟﻔﺌﺎت اﻟﺘﻲ أﻧﺸﺄﻫﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻣﻦﻣﻨﻈﻮر اﻟﺒﴩﻋﺸﻮاﺋﻴﺔﻟﻠﻐﺎﻳﺔ. ورﺑﻤﺎﻻﻳﻜﻮنﻟﻬﺎﻣﻌﻨﻰ. وﻟﻜﻨﻬﺎﻣﻮﺟﻮدة
ﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻹﺣﺼﺎﺋﻴﺔ. وﰲﺑﻌﺾ اﻷﺣﻴﺎنﻳﻜﻮنﻟﻬﺎﻣﻌﻨﻰ، وﰲﻫﺬه اﻟﺤﺎﻟﺔﻳﻤﻜﻦﻟﻬﺬه
اﻟﻄﺮﻳﻘﺔ أنﺗُﻌﻄﻴﻨﺎﻣﻌﺮﻓﺔًﺟﺪﻳﺪةﺣﻮل اﻟﻔﺌﺎتﰲ اﻟﻌﺎﻟﻢ اﻟﻮاﻗﻌﻲ. أﻣﺎ اﻟﺘﻌﻠﱡﻢ »املُﻌﺰﱠز«،
ﻓﺈﻧﻪﻳﺘﻄﻠﺐﺗﻘﻴﻴﻤًﺎﻟﻠﻤُﺨﺮﺟﺎت إنﻛﺎﻧﺖﺟﻴﺪة أمﺳﻴﺌﺔ. وﻫﺬاﻳُﺸﺒﻪﻓﻜﺮة اﻟﺜﻮاب واﻟﻌﻘﺎب.
ﻓﺎﻟﱪﻧﺎﻣﺞﻻﻳُﺨﱪَ أيﱡ اﻹﺟﺮاءاتﻳﺠﺐ أنﻳُﺘﺨَﺬ، وﻟﻜﻨﻪ »ﻳﺘﻌﻠﻢ«ﻣﻦﺧﻼلﻋﻤﻠﻴﺔﺗﻜﺮارﻳﺔ
أي اﻹﺟﺮاءات اﻟﺘﻲﺗﺆدي إﱃ اﻟﺜﻮاب.ﻓﻔﻲ املﺜﺎل اﻷﻣﻨﻲ اﻟﺴﺎﺑﻖ،ﻳﺘﻠﻘﻰ اﻟﻨﻈﺎمﺗﻘﺮﻳﺮًا )أو
ﺑﻴﺎﻧﺎت(ﻣﻦ اﻟﺨﱪاء اﻷﻣﻨِﻴﱢنيﺑﺤﻴﺚ »ﻳﻌﺮف«ﻣﺎ إذاﻛﺎنﻗﺪﻗﺎمﺑﻌﻤﻞٍﺟﻴﺪﻋﻨﺪﻣﺎﻳﺠﺮي
ﺗﻨﺒﺆًاﻣﻌﻴﻨًﺎ.ﻓﺈذاﻟﻢﻳُﺴﺒﺐ اﻟﺸﺨﺺ اﻟﺬيﺗﻨﺒﺄ اﻟﻨﻈﺎمﺑﺄﻧﻪ ذوﺧﻄﻮرة أﻣﻨﻴﺔﻣﻨﺨﻔﻀﺔ
أيﱠﻣﺸﻜﻼتٍ أﻣﻨﻴﺔ،ﻓﺈن اﻟﻨﻈﺎمﻳﺘﻠﻘﻰﺗﻘﺮﻳﺮًاﺑﺄنﻣﺨﺮﺟﺎﺗﻪﻛﺎﻧﺖﺟﻴﺪة وﻣﻦﺛَﻢ »ﻳﺘﻌﻠﻢ«
ﻣﻨﻪ.ﻳﺠﺐﻣﻼﺣﻈﺔ أنﻫﻨﺎك داﺋﻤًﺎﻧﺴﺒﺔًﻣﻦ اﻟﺨﻄﺄ:ﻓﺎﻟﻨﻈﺎمﻟﻴﺲ دﻗﻴﻘًﺎﺑﻨﺴﺒﺔ ٠٠١ﰲ
املﺎﺋﺔ.ﻳﺠﺐ أﻳﻀًﺎﻣﻼﺣﻈﺔ أن املُﺼﻄﻠَﺤَني اﻟﻔﻨﱢﻴﱠني »ﻣﻮﺟﱠﻪ« و»ﻏريﻣﻮﺟﱠﻪ«ﻻﻋﻼﻗﺔﻟﻬﻤﺎ
ﺑﻤﺪى اﻟﺘﺪﺧﱡﻞ اﻟﺒﴩيﰲ اﺳﺘﺨﺪام اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ:ﻓﻔﻲﺣني أن اﻟﺨﻮارزﻣﻴﺔﺗﺘﻤﺘﱠﻊﺑﺒﻌﺾ
اﻻﺳﺘﻘﻼﻟﻴﺔ،ﻓﺈن اﻟﺒﴩﰲﺟﻤﻴﻊ أﻧﻮاعﺗﻌﻠﱡﻢ اﻵﻟﺔﻳﺘﺪﺧﱠﻠﻮنﺑﻄﺮقٍﻣﺨﺘﻠﻔﺔ.
اﻟﺒﻴﺎﻧﺎتﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺑﻤﺎﰲ ذﻟﻚ
ﻫﺬاﺻﺤﻴﺢ أﻳﻀًﺎﻓﻴﻤﺎﻳﺨﺺﱡ
ﻣﺎﻳُﺴﻤﱠﻰﺑ »اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ«. اﻛﺘﺴﺐﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﻘﺎﺋﻢﻋﲆ اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ اﻟﻜﺜري
ﻣﻦ اﻻﻫﺘﻤﺎمﺑﺴﺒﺐﺗﻮﻓﺮﻛﻤﻴﺎتﻛﺒريةﻣﻦ اﻟﺒﻴﺎﻧﺎت وزﻳﺎدةﻗﺪرة اﻟﻜﻤﺒﻴﻮﺗﺮ )اﻷرﺧﺺ(.
(.ﻧﺤﻦﺟﻤﻴﻌًﺎﻧُﻨﺘِﺞAlpaydin 2016, x) «ﻳﺘﺤﺪﱠثﺑﻌﺾ اﻟﺒﺎﺣﺜنيﻋﻦ »زﻟﺰال اﻟﺒﻴﺎﻧﺎت
ﺑﻴﺎﻧﺎتﻣﻦﺧﻼل أﻧﺸﻄﺘﻨﺎ اﻟﺮﻗﻤﻴﺔ،ﻣﺜﻠﻤﺎﻳﺤﺪُثﻋﲆﺳﺒﻴﻞ املﺜﺎلﻋﻨﺪﻣﺎﻧﺴﺘﺨﺪِم وﺳﺎﺋﻞ
اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ أوﻋﻨﺪﻣﺎﻧﺸﱰيﻣﻨﺘﺠﺎتٍﻋﱪ اﻹﻧﱰﻧﺖ.ﻫﺬه اﻟﺒﻴﺎﻧﺎتﻣﻬﻤﺔﺑﺎﻟﻨﺴﺒﺔ
إﱃ اﻟﺠﻬﺎت اﻟﺘﺠﺎرﻳﺔ وأﻳﻀًﺎﺑﺎﻟﻨﺴﺒﺔ إﱃ اﻟﺤﻜﻮﻣﺎت واﻟﻌﻠﻤﺎء.ﻟﻘﺪﺻﺎرﺟﻤﻊ اﻟﺒﻴﺎﻧﺎت
(.Kelleher and Tierney 2018)وﺗﺨﺰﻳﻨﻬﺎ وﻣﻌﺎﻟﺠﺘﻬﺎ أﺳﻬﻞﺑﻜﺜريﻋﲆ املﺆﺳﺴﺎت
وﻟﻴﺲ ذﻟﻚﺑﺴﺒﺐﺗﻌﻠﱡﻢ اﻵﻟﺔﻓﻘﻂ:ﻓﺎﻟﺒﻴﺌﺔ اﻟﺮﻗﻤﻴﺔ اﻷوﺳﻊ وﺗﻘﻨﻴﺎت اﻟﻮﺳﺎﺋﻂ اﻟﺮﻗﻤﻴﺔ
اﻷﺧﺮىﺗﻠﻌﺐ دورًاﻣُﻬﻤٍّﺎﰲﻫﺬا اﻟﺼﺪد. إذﺗﻴﴪ اﻟﺘﻄﺒﻴﻘﺎتﻋﱪ اﻹﻧﱰﻧﺖ ووﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ
اﻻﺟﺘﻤﺎﻋﻲﺟﻤﻊ اﻟﺒﻴﺎﻧﺎتﻣﻦ اﻷﻓﺮاد.ﻛﻤﺎ أنﺗﺨﺰﻳﻦ اﻟﺒﻴﺎﻧﺎت أﺻﺒﺢ أﻗﻞﱠﺗﻜﻠﻔﺔ، وأﺻﺒﺤﺖ
65</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ٍأﺟﻬﺰة اﻟﻜﻤﺒﻴﻮﺗﺮ ذات إﻣﻜﺎﻧﻴﺎتٍ أﻛﱪ.ﻛﻞﻫﺬاﻛﺎنﻣُﻬﻤٍّﺎﻟﺘﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞ
ﻋﺎم، وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎتﺑﺸﻜﻞﺧﺎص.
ﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت
ﻧﺴﺘﻨﺘِﺞﻣﻤﺎﺳﺒﻖ أنﺗﻌﻠﱡﻢ اﻵﻟﺔﻳﺮﺗﺒﻂﺑ »ﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت«. إذﻳﻬﺪفﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت إﱃ
اﺳﺘﺨﺮاج أﻧﻤﺎطٍﻣﻔﻴﺪة وذاتﻣﻌﻨًﻰﻣﻦﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت، وﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄﻫﺬه
املﺠﻤﻮﻋﺎتﻛﺒريةﺟﺪٍّا.ﻳﺴﺘﻄﻴﻊﺗﻌﻠﱡﻢ اﻵﻟﺔﺗﺤﻠﻴﻞﻫﺬه املﺠﻤﻮﻋﺎت اﻟﻜﺒريةﻣﻦ اﻟﺒﻴﺎﻧﺎت آﻟﻴٍّﺎ.
وﻳﻌﺘﻤِﺪﺗﻌﻠﱡﻢ اﻵﻟﺔ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎتﻋﲆ اﻹﺣﺼﺎءات، أوﻋﲆ اﻻﻧﺘﻘﺎلﻣﻦ املﻼﺣﻈﺎت اﻟﻔﺮدﻳﺔ
إﱃﺗﻮﺻﻴﻔﺎتٍﻋﺎﻣﺔ.ﻓﻌﻠﻤﺎء اﻹﺣﺼﺎءﻳﻬﺘﻤﱡﻮنﺑﺎﻟﻌﺜﻮرﻋﲆ ارﺗﺒﺎﻃﺎتٍﰲ اﻟﺒﻴﺎﻧﺎتﻣﻦﺧﻼل
اﻟﺘﺤﻠﻴﻞ اﻹﺣﺼﺎﺋﻲ. وﺗﺒﺤﺚﻋﻤﻠﻴﺎت إﻧﺸﺎء اﻟﻨﻤﺎذج اﻹﺣﺼﺎﺋﻴﺔﻋﻦ اﻟﻌﻼﻗﺎت اﻟﺮﻳﺎﺿﻴﺔﺑني
املﺪﺧﻼت واملﺨﺮﺟﺎت. وﻫﺬاﻫﻮﻣﺎﺗﺴﺎﻋﺪﻓﻴﻪﺧﻮارزﻣﻴﺎتﺗﻌﻠﱡﻢ اﻵﻟﺔ.
ﻧﺤﻦﺟﻤﻴﻌًﺎﻧُﻨﺘﺞﺑﻴﺎﻧﺎتﻣﻦﺧﻼل أﻧﺸﻄﺘﻨﺎ اﻟﺮﻗﻤﻴﺔ،ﻛﻤﺎﻳﺤﺪثﻋﲆﺳﺒﻴﻞ املﺜﺎلﻋﻨﺪﻣﺎﻧﺴﺘﺨﺪِم
وﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ أوﻋﻨﺪﻣﺎﻧﺸﱰيﻣُﻨﺘﺠﺎتﻋﱪ اﻹﻧﱰﻧﺖ.
وﻟﻜﻦﻋﻠﻢ اﻟﺒﻴﺎﻧﺎتﻳﻨﻄﻮيﻋﲆ أﻛﺜﺮﻣﻦﻣﺠﺮدﺗﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎتﺑﻮاﺳﻄﺔﺗﻌﻠﱡﻢ اﻵﻟﺔ. إذ
ﻳﺠﺐﺟﻤﻊ اﻟﺒﻴﺎﻧﺎت وإﻋﺪادﻫﺎﻗﺒﻞﺗﺤﻠﻴﻠﻬﺎ، وﺑﻌﺪ ذﻟﻚﻳﺠﺐﺗﻔﺴريﻧﺘﺎﺋﺞ اﻟﺘﺤﻠﻴﻞ. وﻳﻨﻄﻮي
ﻋﻠﻢ اﻟﺒﻴﺎﻧﺎتﻋﲆﺗﺤﺪﱢﻳﺎتﻣﺜﻞﻛﻴﻔﻴﺔ اﻟﺤﺼﻮلﻋﲆ اﻟﺒﻴﺎﻧﺎت وﺗﻨﻘﻴﺘﻬﺎ )ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
ﻣﻦ وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ واﻟﻮﻳﺐ(، وﻛﻴﻔﻴﺔ اﻟﻮﺻﻮل إﱃﻛﻤﻴﺔٍﻛﺎﻓﻴﺔﻣﻦ اﻟﺒﻴﺎﻧﺎت،
وﻛﻴﻔﻴﺔﺟﻤﻊﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎتﻣﻌًﺎ، وﻛﻴﻔﻴﺔ إﻋﺎدةﻫﻴﻜﻠﺔﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت، وﻛﻴﻔﻴﺔ
اﺧﺘﻴﺎرﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت ذات اﻟﺼﻠﺔ، وأيﻧﻮعﻣﻦ اﻟﺒﻴﺎﻧﺎتﻳﺘﻢ اﺳﺘﺨﺪاﻣﻪ.ﻟﺬﻟﻚﻻﻳﺰال
ﻳﻠﻌﺒﻮن دورًاﻣﻬﻤٍّﺎﰲﺟﻤﻴﻊ املﺮاﺣﻞ وﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺠﻤﻴﻊﻫﺬه اﻟﺠﻮاﻧﺐ،ﺑﻤﺎﰲ ذﻟﻚ
اﻟﺒﴩَ
ﺻﻴﺎﻏﺔ املﺸﻜﻠﺔ، واﻟﺤﺼﻮلﻋﲆ اﻟﺒﻴﺎﻧﺎت، وإﻋﺪاد اﻟﺒﻴﺎﻧﺎت )ﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﺗﺘﺪرﱠب
ﻋﻠﻴﻬﺎ اﻟﺨﻮارزﻣﻴﺔ وﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﺳﺘُﻄﺒﻖﻋﻠﻴﻬﺎ(، وإﻧﺸﺎءﺧﻮارزﻣﻴﺔ اﻟﺘﻌﻠﱡﻢ أو
Kelleher and)اﺧﺘﻴﺎرﻫﺎ، وﺗﻔﺴري اﻟﻨﺘﺎﺋﺞ، واﺗﺨﺎذﻗﺮارﺣﻮل اﻹﺟﺮاء اﻟﺬيﻳﺠﺐ اﺗﺨﺎذه
(.Tierney 2018
66</p>
<p>ﻻﺗﻨﺲَ )ﻋﻠﻢ( اﻟﺒﻴﺎﻧﺎت
ﺗﻈﻬﺮ اﻟﺘﺤﺪﱢﻳﺎت اﻟﻌﻠﻤﻴﺔﰲﻛﻞﻣﺮﺣﻠﺔﻣﻦﻫﺬه اﻟﻌﻤﻠﻴﺔ، وﻋﲆ اﻟﺮﻏﻢﻣﻦ أن اﻟﱪاﻣﺞ
ﻗﺪﺗﻜﻮنﺳﻬﻠﺔ اﻻﺳﺘﺨﺪام،ﻓﺈنﻣﻮاﺟﻬﺔﻫﺬه اﻟﺘﺤﺪﻳﺎتﺗﺘﻄﻠﱠﺐ وﺟﻮد املﻌﺮﻓﺔ اﻟﺒﴩﻳﺔ
اﻟﺨﺒرية املُﺘﺨﺼﱢﺼﺔ. وﻋﺎدةًﻣﺎﻳﻜﻮن اﻟﺘﻌﺎونﺑني اﻟﺒﴩ أﻣﺮًاﴐورﻳٍّﺎ أﻳﻀًﺎ،ﻋﲆﺳﺒﻴﻞ
املﺜﺎل،ﺑنيﻋﻠﻤﺎء اﻟﺒﻴﺎﻧﺎت واملﻬﻨﺪﺳني. وﻣﻦ اﻟﻮاردﺣﺪوث أﺧﻄﺎءﻃﻮال اﻟﻮﻗﺖ،ﻟﺬاﻓﺈن
اﻻﺧﺘﻴﺎر اﻟﺒﴩي واملﻌﺮﻓﺔ اﻟﺒﴩﻳﺔ واﻟﺘﻔﺴري اﻟﺒﴩي أﻣﺮﺣﺎﺳﻢ اﻷﻫﻤﻴﺔ.ﻓﺎﻟﺒﴩﻣﻬﻤﱡﻮنﰲ
ﻫﺬا اﻟﺴﻴﺎقﻟﺘﻔﺴري اﻷﻣﻮرﻋﲆﻧﺤﻮٍﻣﻌﻘﻮل وﺗﻮﺟﻴﻪ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻧﺤﻮ اﻟﺒﺤﺚﻋﻦﻋﻮاﻣﻞ
وﻋﻼﻗﺎتﻣﺨﺘﻠﻔﺔ. واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻣﻦ وﺟﻬﺔﻧﻈﺮﺑﻮدن )٦١٠٢(،ﻳﻔﺘﻘﺮ إﱃﻓﻬﻤﻨﺎ
ﻟﻠﺼﱢﻼت واﻟﻌﻼﻗﺎت. وﻳﻤﻜﻨﻨﺎ أنﻧُﻀﻴﻒ أﻧﻪﻳﻔﺘﻘﺮ أﻳﻀًﺎ إﱃ اﻟﻔﻬﻢ واﻟﺘﺠﺮﺑﺔ واﻟﺤﺴﺎﺳﻴﺔ
واﻟﺤﻜﻤﺔ. وﻫﺬهﺣﺠﺔﺟﻴﺪةﺗﺪﻋﻢﻧﻈﺮﻳٍّﺎ وﻣﺒﺪﺋﻴٍّﺎﴐورةﻣﺸﺎرﻛﺘﻨﺎﻧﺤﻦ اﻟﺒﴩﰲ
اﻷﻣﺮ. وﻟﻜﻦﺛﻤﺔﺣﺠﺔﻋﻤﻠﻴﺔ أﻳﻀًﺎﺗﺪﻋﻢﻋﺪمﺧﺮوج اﻟﺒﴩﻣﻦ املﺸﻬﺪ؛ وﻫﻲ أن اﻟﺒﴩ
ﻳﺸﺎرﻛﻮنﺑﺎﻟﻔﻌﻞﻋﻤﻠﻴٍّﺎﰲ اﻷﻣﺮ.ﻓﺪون املﱪﻣﺠني وﻋﻠﻤﺎء اﻟﺒﻴﺎﻧﺎت،ﻟﻦﺗﺴﺘﻄﻴﻊ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
اﻟﻘﻴﺎمﺑﻮﻇﻴﻔﺘﻬﺎﺑﺒﺴﺎﻃﺔ.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻛﺜريًاﻣﺎﻳﺘﻢ دﻣﺞ اﻟﺨﱪة اﻟﺒﴩﻳﺔﻣﻊ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪﻣﺎﻳﺴﺘﺨﺪم اﻟﻄﺒﻴﺐ اﺳﱰاﺗﻴﺠﻴﺔﻋﻼجﴎﻃﺎنﻳﻮﴆﺑﻬﺎ
اﻟﺬﻛﺎءُ اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻨﻪﰲ اﻟﻮﻗﺖﻧﻔﺴﻪﻳﻌﺘﻤﺪﻋﲆﺗﺠﺎرﺑﻪ وﺣﺪﺳﻪﻛﺨﺒري.ﻓﺈذا أﻟﻐﻲ
اﻟﺘﺪﺧﻞ اﻟﺒﴩي،ﻳﻤﻜﻦ أنﺗﺴﻮء اﻷﻣﻮر أوﺗﻔﻘﺪﻣﻌﻨﺎﻫﺎ أوﺑﺒﺴﺎﻃﺔﺗُﺼﺒﺢﻏريﻣﻨﻄﻘﻴﺔ.
وﻟﻨﴬبﻣﺜﻼًﺑﺎملﺸﻜﻠﺔ املﻌﺮوﻓﺔ اﻟﺘﺎﻟﻴﺔﻣﻦ اﻹﺣﺼﺎء، واﻟﺘﻲﺗﺆﺛﺮﺑﺪَورﻫﺎﻋﲆ
اﺳﺘﺨﺪامﺗﻌﻠﱡﻢ اﻵﻟﺔ: اﻻرﺗﺒﺎﻃﺎتﻻﺗﻌﻨﻲﺑﺎﻟﴬورةﻋﻼﻗﺎتٍﺳﺒﺒﻴﺔ.ﻳُﻘﺪمﺗﺎﻳﻠﺮﻓﻴﺠنيﰲ
ﻛﺘﺎﺑﻪ »اﻻرﺗﺒﺎﻃﺎت اﻟﺰاﺋﻔﺔ« )٥١٠٢(ﺑﻌﺾ اﻷﻣﺜﻠﺔ اﻟﺠﻴﺪةﻋﲆ ذﻟﻚ.ﰲ اﻹﺣﺼﺎء، اﻻرﺗﺒﺎط
اﻟﺰاﺋﻒﻫﻮ اﻻرﺗﺒﺎط اﻟﺬيﺗﻜﻮنﻓﻴﻪ املُﺘﻐرياتﻏريﻣﺮﺗﺒﻄﺔﻓﻴﻤﺎﺑﻴﻨﻬﺎﺑﻌﻼﻗﺎتٍﺳﺒﺒﻴﺔ
وﻟﻜﻨﻬﺎﻗﺪﺗﺒﺪوﻛﺬﻟﻚ؛ وﻳﻜﻮن اﻻرﺗﺒﺎطﻧﺎﺟﻤًﺎﻋﻦ وﺟﻮدﻋﺎﻣﻞٍﺛﺎﻟﺚﻏريﻣﺮﺋﻲ.ﻣﻦﺑني
اﻷﻣﺜﻠﺔ اﻟﺘﻲﻳُﻘﺪﱢﻣﻬﺎﻓﻴﺠني اﻻرﺗﺒﺎطﺑنيﻣﻌﺪل اﻟﻄﻼقﰲ وﻻﻳﺔﻣني وﻣﻌﺪل اﺳﺘﻬﻼك
اﻟﺴﻤﻦ اﻟﻨﺒﺎﺗﻲﻟﻠﻔﺮد اﻟﻮاﺣﺪ، أو اﻻرﺗﺒﺎطﺑنيﻣﻌﺪل اﺳﺘﻬﻼكﺟﺒﻦ املﻮﺗﺰارﻳﻼﻟﻠﻔﺮد اﻟﻮاﺣﺪ
رﺑﻤﺎﻳﻌﺜﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆﻣﺜﻞﻫﺬه1.واﻟﺤﺼﻮلﻋﲆ دﻛﺘﻮراهﰲ اﻟﻬﻨﺪﺳﺔ املَﺪﻧﻴﺔ
اﻻرﺗﺒﺎﻃﺎت، وﻟﻜﻦﻳﺠﺐ أنﻳﺘﺪﺧﱠﻞ اﻟﺒﴩﻟﺘﻘﺮﻳﺮ اﻻرﺗﺒﺎﻃﺎت اﻟﺘﻲﺗﺴﺘﺤﻖﱡﻣﺰﻳﺪًاﻣﻦ
اﻟﺪراﺳﺔﻣﻦ أﺟﻞ اﻟﻌﺜﻮرﻋﲆﻋﻼﻗﺎتٍﺳﺒﺒﻴﺔ.
ﻓﻀﻼًﻋﻦ ذﻟﻚ،ﰲ املﺮﺣﻠﺔ اﻟﺘﻲﻳﺘﻢﻓﻴﻬﺎﺟﻤﻊ اﻟﺒﻴﺎﻧﺎت وﺗﺼﻤﻴﻢ أو إﻧﺸﺎءﻣﺠﻤﻮﻋﺔ
Kelleher and Tierney)اﻟﺒﻴﺎﻧﺎت،ﻧﺠﺮي اﺧﺘﻴﺎراتٍﻓﻴﻤﺎﻳﺨﺺﱡﻛﻴﻔﻴﺔ اﻟﺘﺠﺮﻳﺪﻋﻦ اﻟﻮاﻗﻊ
(. واﻟﺘﺠﺮﻳﺪﻋﻦ اﻟﻮاﻗﻊﻻﻳﻜﻮنﻣُﺤﺎﻳﺪًا أﺑﺪًا، واﻟﺘﺠﺮﻳﺪﻧﻔﺴﻪﻟﻴﺲ واﻗﻌًﺎ؛ وإﻧﻤﺎﻫﻮ2018
67</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺗﻤﺜﻴﻞﻟﻠﻮاﻗﻊ. وﻫﺬاﻳَﻌﻨﻲ أﻧﻪﻳُﻤﻜﻨﻨﺎﻣﻨﺎﻗﺸﺔﻣﺪىﺟﻮدةﻫﺬا اﻟﺘﻤﺜﻴﻞ وﻣﻼءﻣﺘﻪ،ﻓﻴﻤﺎﻳﺘﻌﻠﻖ
ﺑﻐﺮَضﻣُﻌني.ﻗﺎرنﻫﺬاﺑﺄﻳﺔﺧﺮﻳﻄﺔ: اﻟﺨﺮﻳﻄﺔﻧﻔﺴﻬﺎﻟﻴﺴﺖﻫﻲ اﻹﻗﻠﻴﻢ، وﻗﺪ اﺧﺘﺎر اﻟﺒﴩَ
ﻣُﻌني )ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺧﺮﻳﻄﺔ ملﻼﺣﺔ اﻟﺴﻴﺎراتﻣﻘﺎﺑﻞ
ﻃﺮﻳﻘﺔﺗﺼﻤﻴﻢ اﻟﺨﺮﻳﻄﺔﻟﻐﺮَضٍ
ﺧﺮﻳﻄﺔﻃﻮﺑﻮﻏﺮاﻓﻴﺔﻟﻠﺘﻨﺰﱡهﺳريًاﻋﲆ اﻷﻗﺪام(.ﰲﺗﻌﻠﱡﻢ اﻵﻟﺔ،ﻳﻌﻤﻞ اﻟﺘﺠﺮﻳﺪﺑﺎﺳﺘﺨﺪام
اﻷﺳﺎﻟﻴﺐ اﻹﺣﺼﺎﺋﻴﺔﻋﲆ إﻧﺸﺎءﻧﻤﻮذجﻟﻠﻮاﻗﻊ؛ إﻧﻪﻟﻴﺲ اﻟﻮاﻗﻊ اﻟﻔﻌﲇ.ﻛﻤﺎﻳﺘﻀﻤﱠﻦ ذﻟﻚ
اﺧﺘﻴﺎرات: اﺧﺘﻴﺎراتﺑﺸﺄن اﻟﺨﻮارزﻣﻴﺔﻧﻔﺴﻬﺎ اﻟﺘﻲﺗُﻮﻓﱢﺮ اﻟﻌﻤﻠﻴﺔ اﻹﺣﺼﺎﺋﻴﺔ اﻟﺘﻲﺗﺄﺧﺬﻧﺎ
ﻣﻦ اﻟﺒﻴﺎﻧﺎت إﱃ اﻟﻨﻤﻂ/اﻟﻘﺎﻋﺪة، وﻟﻜﻦ أﻳﻀًﺎ اﺧﺘﻴﺎراتﺑﺸﺄنﺗﺼﻤﻴﻢﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت
اﻟﺘﻲﺗﺘﺪرﱠبﻋﻠﻴﻬﺎ اﻟﺨﻮارزﻣﻴﺔ.ﻳﻌﻨﻲﻫﺬا اﻟﺠﺎﻧﺐ اﻻﺧﺘﻴﺎري، وﻣﻦﺛَﻢ اﻟﺠﺎﻧﺐ اﻟﺒﴩي،ﰲ
ﺗﻌﻠﱡﻢ اﻵﻟﺔ أﻧﻪﻳُﻤﻜﻨﻨﺎ أنﻧﻄﺮح أﺳﺌﻠﺔًﻧﻘﺪﻳﺔﺣﻮل اﻻﺧﺘﻴﺎرات اﻟﺘﻲﺗُﺘﱠﺨَﺬ،ﺑﻞﻳﺠﺐﻋﻠﻴﻨﺎ
أنﻧﻔﻌﻞ ذﻟﻚ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻫﻞﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﺳﻴﺘﻢ اﻟﺘﺪرﻳﺐﻋﻠﻴﻬﺎﺗُﻤﺜﻞ
اﻟﺴﻜﺎنﺗﻤﺜﻴﻼًﺟﻴﺪًا؟ﻫﻞﻫﻨﺎك أيﺗﺤﻴﱡﺰاتﰲ اﻟﺒﻴﺎﻧﺎت؟ﻛﻤﺎﺳﻨﺮىﰲ اﻟﻔﺼﻞ اﻟﻘﺎدم،
ﻫﺬه اﻻﺧﺘﻴﺎرات واﻟﻘﻀﺎﻳﺎﻟﻴﺴﺖﻣﺠﺮد أﺳﺌﻠﺔﻓﻨﻴﺔ وﻟﻜﻦﻟﻬﺎ أﻳﻀًﺎﺟﺎﻧﺐ أﺧﻼﻗﻲﺷﺪﻳﺪ
اﻷﻫﻤﻴﺔ.
اﻟﺘﻄﺒﻴﻘﺎت
ﻟﺘﻌﻠﱡﻢ اﻵﻟﺔ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎتﺗﻄﺒﻴﻘﺎتٌﻋﺪﻳﺪة، ذَﻛﺮتُﺑﻌﻀﻬﺎﺑﺎﻟﻔﻌﻞﺗﺤﺖ اﻟﻌﻨﻮان اﻷﻋﻢ
املُﺘﻤﺜﻞﰲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻫﺬه اﻟﺘﻘﻨﻴﺎتﻳُﻤﻜﻦ اﺳﺘﺨﺪاﻣﻬﺎﻟﻠﺘﻌﺮﱡفﻋﲆ اﻟﻮﺟﻮه
)ﺑﻞﻟﻠﺘﻌﺮﱡفﻋﲆ اﻻﻧﻔﻌﺎﻻتﺑﻨﺎءًﻋﲆﺗﺤﻠﻴﻞ اﻟﻮﺟﻮه(، أوﺗﻘﺪﻳﻢ اﻗﱰاﺣﺎتﺑﺤﺚ، أو
ﻗﻴﺎدة اﻟﺴﻴﺎرة، أو إﺟﺮاءﺗﻮﻗﱡﻌﺎتﺷﺨﺼﻴﺔ، أو اﻟﺘﻨﺒﱡﺆﺑﻤَﻦﺳﻴﻌﺎود ارﺗﻜﺎب اﻟﺠﺮﻳﻤﺔ،
أو اﻟﺘﻮﺻﻴﺔﺑﻤﻮﺳﻴﻘﻰﻣُﻌﻴﻨﺔﻟﻼﺳﺘﻤﺎع إﻟﻴﻬﺎ. وﺗﺴﺘﺨﺪَمﰲﻣﺠﺎل املﺒﻴﻌﺎت واﻟﺘﺴﻮﻳﻖ،
ﻟﻠﺘﻮﺻﻴﺔﺑﻤﻨﺘﺠﺎت وﺧﺪﻣﺎت.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪﻣﺎﺗﺸﱰيﺷﻴﺌًﺎﻋﲆﻣﻮﻗﻊ أﻣﺎزون،
ﺳﻴﺠﻤﻊ املﻮﻗﻊﺑﻴﺎﻧﺎتٍﻋﻨﻚﺛﻢﻳُﻘﺪمﺗﻮﺻﻴﺎتﻋﲆ أﺳﺎسﻧﻤﻮذج إﺣﺼﺎﺋﻲﻳﺴﺘﻨﺪ إﱃ
ﺑﻴﺎﻧﺎتٍﻣﻦﺟﻤﻴﻊ اﻟﻌﻤﻼء. اﺳﺘﺨﺪﻣﺖﴍﻛﺔ ووملﺎرتﰲﻣﺘﺎﺟﺮﻫﺎﺗﻘﻨﻴﺔ اﻟﺘﻌﺮﱡفﻋﲆ
اﻟﻮﺟﻮهﻟﻠﺘﺼﺪيﻟﻠﴪﻗﺔ؛ وﻗﺪﺗﺴﺘﺨﺪمﰲ املُﺴﺘﻘﺒﻞ اﻟﺘﻘﻨﻴﺔﻧﻔﺴﻬﺎﻟﺘﺤﺪﻳﺪﻣﺎ إذاﻛﺎن
املُﺘﺴﻮﻗﻮنﺳﻌﺪاء أمﻣُﺤﺒَﻄني.ﻛﻤﺎ أنﻟﻠﺘﻘﻨﻴﺎتﺗﻄﺒﻴﻘﺎتﻣﺨﺘﻠﻔﺔﰲﻣﺠﺎل اﻟﺘﻤﻮﻳﻞ.
ﺗﻌﺎوﻧﺖ وﻛﺎﻟﺔ إﻛﺴﱪﻳﺎنﻟﻠﻤﺮﺟﻌﻴﺔ اﻻﺋﺘﻤﺎﻧﻴﺔﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﺪﻋﻮمﺑﺘﻌﻠﱡﻢ اﻵﻟﺔ
ﻟﺘﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎت املُﺘﻌﻠﻘﺔﺑﺎملُﻌﺎﻣﻼت واﻟﻘﻀﺎﻳﺎ املﻨﻈﻮرةﰲ املﺤﺎﻛﻢﻣﻦ أﺟﻞ اﻟﺘﻮﺻﻴﺔﺑﻤﺎ
ملُﻘﺪﱢمﻃﻠﺐﻟﺮﻫﻦﻋﻘﺎري. وﺗﺴﺘﺨﺪم أﻣﺮﻳﻜﺎن إﻛﺴﱪﻳﺲﺗﻌﻠﱡﻢ
إذاﻛﺎنﻳﺠﺐﺗﻘﺪﻳﻢﻗﺮضٍ
68</p>
<p>ﻻﺗﻨﺲَ )ﻋﻠﻢ( اﻟﺒﻴﺎﻧﺎت
اﻵﻟﺔﻟﺘﻮﻗﻊ املﻌﺎﻣﻼت اﻻﺣﺘﻴﺎﻟﻴﺔ. وﰲﻣﺠﺎل اﻟﻨﻘﻞ،ﻳُﺴﺘﺨﺪَم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺒﻴﺎﻧﺎت
اﻟﻀﺨﻤﺔﻹﻧﺸﺎءﺳﻴﺎرات ذاﺗﻴﺔ اﻟﻘﻴﺎدة.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗﺴﺘﺨﺪِمﴍﻛﺔﺑﻲ إم دﺑﻠﻴﻮﻧﻮﻋًﺎ
ﻣﻦﺗﻘﻨﻴﺔ اﻟﺘﻌﺮﱡفﻋﲆ اﻟﺼﻮرﻟﺘﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎت اﻟﻮاردةﻣﻦ أﺟﻬﺰة اﻻﺳﺘﺸﻌﺎر واﻟﻜﺎﻣريات
ﰲ اﻟﺴﻴﺎرة. وﰲﻣﺠﺎل اﻟﺮﻋﺎﻳﺔ اﻟﺼﺤﻴﺔ،ﻳﻤﻜﻦ أنﻳُﺴﺎﻋﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﺪﻋﻮمﺑﺘﻌﻠﱡﻢ
اﻵﻟﺔﰲﺗﺸﺨﻴﺺ اﻟﴪﻃﺎن )ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﺗﺤﻠﻴﻞﺻﻮر اﻷﺷﻌﺔﻟﺘﺸﺨﻴﺺﻣﺮض
اﻟﴪﻃﺎن( أو اﻛﺘﺸﺎف اﻷﻣﺮاض املُﻌﺪﻳﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، أﺟﺮىﻧﻈﺎم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻟﴩﻛﺔ دﻳﺐﻣﺎﻳﻨﺪﺗﺤﻠﻴﻼً ملﻠﻴﻮنﺻﻮرةﻣﻦﺻﻮر أﺷﻌﺔ اﻟﻌﻴﻮن وﺑﻴﺎﻧﺎت املﺮﴇ،ﻣُﺪرﺑًﺎ
ﻧﻔﺴﻪﻋﲆﺗﺸﺨﻴﺺ أﻋﺮاضﺣﺎﻻت اﻟﻌﻴﻮن املﺮﺿﻴﺔ املُﺘﺪﻫﻮرة. وﻗﺪﺗﺠﺎوزﻧﻈﺎم واﺗﺴﻮن
اﻟﺬي أﻧﺸﺄﺗﻪﴍﻛﺔ آيﺑﻲ إمﻣُﻤﺎرﺳﺔﻟﻌﺒﺔ »ﺟﻴﻮﺑﺎردي« وﻳﺴﺘﺨﺪمﻟﺘﻘﺪﻳﻢﺗﻮﺻﻴﺎتٍﺑﺸﺄن
ﻋﻼج اﻟﴪﻃﺎن.ﻛﻤﺎﺗُﺰوﱢد أﺟﻬﺰة اﻟﺮﻳﺎﺿﺔ واﻟﺼﺤﺔ اﻟﺘﻲﻳﻤﻜﻦ ارﺗﺪاؤﻫﺎﺗﻄﺒﻴﻘﺎتﺗﻌﻠﱡﻢ
اﻵﻟﺔﺑﺎﻟﺒﻴﺎﻧﺎت. وﰲﻣﺠﺎل اﻟﺼﺤﺎﻓﺔ،ﻳﻤﻜﻦﻟﺘﻌﻠﱡﻢ اﻵﻟﺔﻛﺘﺎﺑﺔﺗﻘﺎرﻳﺮ إﺧﺒﺎرﻳﺔ.ﻋﲆﺳﺒﻴﻞ
املﺜﺎل،ﰲ املﻤﻠﻜﺔ املﺘﺤﺪة،ﺗﺴﺘﺨﺪِم وﻛﺎﻟﺔ أﻧﺒﺎء »ﺑﺮﻳﺲ أﺳﻮﺳﻴﻴﺸﻦ« اﻟﺮوﺑﻮﺗﺎتﰲﻛﺘﺎﺑﺔ
ﺗﻘﺎرﻳﺮ اﻷﺧﺒﺎر املﺤﻠﻴﺔ. وﻳﺪﺧﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎ إﱃ املﻨﺰل واملﺠﺎل اﻟﺸﺨﴢ،ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل،ﰲﺷﻜﻞ روﺑﻮﺗﺎتﺗﺘﻮﱃﱠﺟﻤﻊ اﻟﺒﻴﺎﻧﺎت وأﺟﻬﺰةﺗﻔﺎﻋُﻠﻴﺔﻣﺴﺎﻋﺪةﻣﺘﱠﺼﻠﺔ
ﺑﻤﻌﺎﻟﺠﺔ اﻟﻠﻐﺔ اﻟﻄﺒﻴﻌﻴﺔ.ﺗﺘﺤﺪﱠث دُﻣﻴﺔ »ﻫﺎﻟﻮﺑﺎرﺑﻲ« إﱃ اﻷﻃﻔﺎلﺑﺎﺳﺘﺨﺪامﻣُﻌﺎﻟﺠﺔ اﻟﻠﻐﺔ
اﻟﻄﺒﻴﻌﻴﺔ اﻟﺘﻲﺗُﺤﻠﻞ املﺤﺎدﺛﺎت املﺴﺠﻠﺔ.ﻓﻜﻞﱡﻣﺎﻳﻘﻮﻟﻪ اﻷﻃﻔﺎلﻳﺘﻢﺗﺴﺠﻴﻠُﻪ وﺗﺨﺰﻳﻨﻪ
وﺗﺤﻠﻴﻠﻪﰲ وﺣﺪات اﻟﺨﺪﻣﺔ اﻟﺨﺎﺻﺔﺑ »ﺗﻮيﺗﻮك«.ﺛﻢﻳُﺮﺳﻞ ردٍّا إﱃ اﻟﺠﻬﺎز: وﺗﺠﻴﺐ دﻣﻴﺔ
»ﻫﺎﻟﻮﺑﺎرﺑﻲ«ﻋﲆ أﺳﺎسﻣﺎ »ﺗﻌﻠﻤﺘﻪ«ﻋﻦﻣُﺴﺘﺨﺪﻣﻬﺎ. وﻳﺴﺘﺨﺪِمﻓﻴﺴﺒﻮكﺗﻘﻨﻴﺎت اﻟﺘﻌﻠﱡﻢ
اﻟﻌﻤﻴﻖ واﻟﺸﺒﻜﺎت اﻟﻌﺼﺒﻴﺔﻟﻬﻴﻜﻠﺔ وﺗﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎت اﻵﺗﻴﺔﻣﻤﺎﻳﻘﺮُبﻣﻦﻣﻠﻴﺎرَيﻣﺴﺘﺨﺪم
ﻟﻠﻤﻨﺼﱠﺔﻳُﻨﺘﺠﻮنﺑﻴﺎﻧﺎتٍﻏريﻣُﻬﻴﻜﻠﺔ. وﻫﺬاﻳﺴﺎﻋﺪ اﻟﴩﻛﺔﰲﺗﻘﺪﻳﻢ إﻋﻼﻧﺎتﻣُﺴﺘﻬﺪﻓﺔ.
وﻳﺤﻠﱢﻞ إﻧﺴﺘﺠﺮامﺻﻮر ٠٠٨ﻣﻠﻴﻮنﻣُﺴﺘﺨﺪِمﺑﻬﺪفﺑﻴﻊ اﻹﻋﻼﻧﺎت إﱃ اﻟﴩﻛﺎت. وﻳﺴﺘﺨﺪم
ﻧﺘﻔﻠﻴﻜﺲﻣﺤﺮﻛﺎت اﻟﺘﻮﺻﻴﺔ اﻟﺘﻲﺗُﺤﻠﱢﻞﺑﻴﺎﻧﺎت اﻟﻌﻤﻼء،ﻟﻜﻲﻳُﺤﻮﱢلﻧﻔﺴﻪﻣﻦﻣﻮزع إﱃ
ﻣﻨﺘﺞﻣﺤﺘﻮى:ﻓﺈذاﻛﻨﺖَﺗﺴﺘﻄﻴﻊ اﻟﺘﻨﺒﱡﺆﺑﻤﺎﻳﺮﻏﺐ اﻟﻨﺎسﰲﻣﺸﺎﻫﺪﺗﻪ،ﻓﻴُﻤﻜﻨﻚ إﻧﺘﺎﺟﻪ
ﺑﻨﻔﺴﻚ وﺗﺤﻘﻴﻖ رﺑﺢﻣﻨﻪ.ﺑﻞ إنﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت اﺳﺘُﺨﺪِمﰲﻣﺠﺎل اﻟﻄﻬﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
ﺑﻨﺎءًﻋﲆﺗﺤﻠﻴﻞﻧﺤﻮ ٠٠٠٠١ وﺻﻔﺔ،ﻳُﻨﺸﺊﻧﻈﺎمﺷﻴﻒ واﺗﺴﻮن اﻟﺬي أﻧﺘﺠﺘﻪﴍﻛﺔ آي
وﻳﻤﻜﻦ أﻳﻀًﺎ اﺳﺘﺨﺪام2.ﺑﻲ إم وﺻﻔﺎﺗﻪ اﻟﺨﺎﺻﺔ اﻟﺘﻲﺗﻘﱰحﺗﻮﻟﻴﻔﺎتﺟﺪﻳﺪةﻟﻠﻤﻜﻮﻧﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﺪﻋﻮمﺑﺘﻌﻠﱡﻢ اﻵﻟﺔﰲ اﻟﺘﻌﻠﻴﻢ، واﻟﺘﻮﻇﻴﻒ، واﻟﻌﺪاﻟﺔ اﻟﺠﻨﺎﺋﻴﺔ، واﻷﻣﻦ
69</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
،)ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻟﴩﻃﺔ اﻟﺘﻨﺒﺆﻳﺔ(، واﺳﱰﺟﺎع املﻮﺳﻴﻘﻰ، واﻷﻋﻤﺎل املﻜﺘﺒﻴﺔ، واﻟﺰراﻋﺔ
واﻷﺳﻠﺤﺔ اﻟﻌﺴﻜﺮﻳﺔ، وﻣﺎ إﱃ ذﻟﻚ.
ﰲ املﺎﴈ،ﻛﺎﻧﺖ اﻹﺣﺼﺎءﻣﻦ املﺠﺎﻻتﻏري اﻟﺠﺬاﺑﺔ. أﻣﺎ اﻟﻴﻮم،ﻓﺒﻌﺪ أن أﺻﺒﺤﺖﺟﺰءًا
ﻣﻦﻋِﻠﻢ اﻟﺒﻴﺎﻧﺎت وﰲﺷﻜﻞٍﻳُﺪﻣَﺞﻓﻴﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻊ اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ، أﺻﺒﺤﺖ
اﻹﺣﺼﺎءﺷﺪﻳﺪة اﻟﺠﺎذﺑﻴﺔ. إﻧﻬﺎ اﻟﺴﺤﺮ اﻟﺠﺪﻳﺪ. إﻧﻬﺎ املﺠﺎل اﻟﺬيﺗُﻔﻀﱢﻠﻪ وﺳﺎﺋﻞ اﻹﻋﻼم.
ﻛﻤﺎ أﻧﻬﺎﺗُﻌﺘﱪﻣﺠﺎلَ أﻋﻤﺎلﺿﺨﻤًﺎ.ﻓﺎﻟﺒﻌﺾﻳﺘﺤﺪﱠﺛﻮنﻋﻦﻧﻮعٍﺟﺪﻳﺪﻣﻦ اﻟﺘﻨﻘﻴﺐﻋﻦ
اﻟﺬﻫﺐ؛ واﻟﺘﻮﻗﻌﺎتﻫﺎﺋﻠﺔ.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻓﻬﺬا اﻟﻨﻮعﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺲﺧﻴﺎﻻً
ﻋﻠﻤﻴٍّﺎ أوﻣﺤﺾَﻧﺒﻮءة،ﻛﻤﺎﺗُﺒني اﻷﻣﺜﻠﺔ اﻟﺘﻲﴐﺑﻨﺎﻫﺎ أنﻣﺎﻳُﺴﻤﱠﻰﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
املﺤﺪود أو اﻟﻀﻌﻴﻒﻣﻮﺟﻮدﺑﺎﻟﻔﻌﻞ وواﺳﻊ اﻻﻧﺘﺸﺎر. وﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺘﺄﺛريه املُﺤﺘﻤَﻞ،ﻓﻠﻴﺲ
ﻫﻨﺎكﻣﺎﻳُﻤﻜﻨﻨﺎ أنﻧﺼِﻔﻪﺑﺄﻧﻪﻣﺤﺪود أوﺿﻌﻴﻒ.ﻟﺬﻟﻚ،ﻓﺈﻧﻪﻣﻦ اﻟﴬوريﺟﺪٍّا أنﻧُﺤﻠﱢﻞ
وﻧُﻨﺎﻗﺶ اﻟﻌﺪﻳﺪﻣﻦ اﻟﻘﻀﺎﻳﺎ اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲ أﺛﺎرﺗﻬﺎﺗﻘﻨﻴﺎتﺗﻌﻠﱡﻢ اﻵﻟﺔ وﻏريﻫﺎﻣﻦﺗﻘﻨﻴﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺗﻄﺒﻴﻘﺎﺗﻬﺎ. وﻫﺬاﻫﻮﻣﻮﺿﻮع اﻟﻔﺼﻮل اﻟﻘﺎدﻣﺔ.
ﰲ املﺎﴈ،ﻛﺎﻧﺖ اﻹﺣﺼﺎءﻣﻦ املﺠﺎﻻتﻏري اﻟﺠﺬﱠاﺑﺔ. أﻣﺎ اﻟﻴﻮم،ﻓﺒﻌﺪ أن أﺻﺒﺤﺖﺟﺰءًاﻣﻦﻋﻠﻢ
اﻟﺒﻴﺎﻧﺎت وﰲﺷﻜﻞٍﻳُﺪﻣﺞﻓﻴﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻊ اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ، أﺻﺒﺤﺖ اﻹﺣﺼﺎءﺷﺪﻳﺪة
اﻟﺠﺎذﺑﻴﺔ. إﻧﻬﺎ اﻟﺴﺤﺮ اﻟﺠﺪﻳﺪ.
70</p>
</section>
<section id="section-8">
    <h2>الخصوصية وغيرها من القضايا</h2>
    <div class="page-range">Pages 71-78</div>
    <p>اﻟﻔﺼﻞ اﻟﺴﺎﺑﻊ
اﳋﺼﻮﺻﻴﺔ وﻏﲑﻫﺎﻣﻦ اﻟﻘﻀﺎﻳﺎ
إن اﻟﻌﺪﻳﺪﻣﻦ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ املُﺘﻌﻠﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻌﺮوﻓﺔﻣﻦﻣﺠﺎل أﺧﻼﻗﻴﺎت
اﻟﺮوﺑﻮﺗﺎت واﻷﺗﻤﺘﺔ أو،ﺑﺸﻜﻞٍ أﻋﻢ،ﻣﻦﻣﺠﺎل أﺧﻼﻗﻴﺎت اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺮﻗﻤﻴﺔ وﺗﻜﻨﻮﻟﻮﺟﻴﺎ
اﻻﺗﺼﺎﻻت. وﻟﻜﻦﻫﺬاﰲﺣﺪﱢ ذاﺗﻪﻻﻳُﻘﻠﱢﻞﻣﻦ أﻫﻤﻴﺘﻬﺎ. وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻓﺈنﻫﺬه اﻟﻘﻀﺎﻳﺎ
—ﺑﺴﺒﺐ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻃﺮﻳﻘﺔ ارﺗﺒﺎﻃﻬﺎﺑﺘﻘﻨﻴﺎتٍ أﺧﺮى —ﺗﻜﺘﺴﺐﺑُﻌﺪًاﺟﺪﻳﺪًا وﺗُﺼﺒﺢ
أﻛﺜﺮ أﻫﻤﻴﺔ وإﻟﺤﺎﺣًﺎ.
اﻟﺨﺼﻮﺻﻴﺔ وﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت
ﻓﻠﻨُﻔﻜﺮ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﻣﺴﺄﻟﺔ اﻟﺨﺼﻮﺻﻴﺔ وﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت.ﻳﻨﻄﻮي اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ، وﻻﺳﻴﻤﺎﺗﻄﺒﻴﻘﺎتﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﺘﻲﺗﺘﻌﺎﻣَﻞﻣﻊ اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ،ﻏﺎﻟﺒًﺎ
ﻋﲆﺟﻤﻊ املﻌﻠﻮﻣﺎت اﻟﺸﺨﺼﻴﺔ واﺳﺘﺨﺪاﻣﻬﺎ. وﻳُﻤﻜﻦ أﻳﻀًﺎ اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻟﻠﻤُﺮاﻗﺒﺔ،ﰲ اﻟﺸﺎرع وأﻳﻀًﺎﰲﻣﻜﺎن اﻟﻌﻤﻞ وﰲﻛﻞﻣﻜﺎن، وذﻟﻚﻣﻦﺧﻼل اﻟﻬﻮاﺗﻒ اﻟﺬﻛﻴﺔ
ووﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ. وﰲﻛﺜريٍﻣﻦ اﻷﺣﻴﺎن،ﻻﻳﻌﻠﻢ اﻟﻨﺎسﺣﺘﻰ أن اﻟﺒﻴﺎﻧﺎت
ﺗُﺠﻤَﻊ، أو أن اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﻗﺪﻣﻮﻫﺎﰲﺳﻴﺎقٍﻣﺎﺗُﺴﺘﺨﺪَمﺑﻮاﺳﻄﺔ أﻃﺮاف أﺧﺮىﰲﺳﻴﺎقٍ
آﺧﺮ.ﻛﻤﺎ أن اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔﻏﺎﻟﺒًﺎﻣﺎﺗَﻌﻨﻲ أن )ﻣﺠﻤﻮﻋﺎت( اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﺗﺤﺼﻞﻋﻠﻴﻬﺎ
املﻨﻈﻤﺎت املﺨﺘﻠﻔﺔﻳﺘﻢ دﻣﺠﻬﺎﻣﻌًﺎ.
ﻳﺘﻄﻠﱠﺐ اﻻﺳﺘﺨﺪام اﻷﺧﻼﻗﻲﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺟﻤﻊ اﻟﺒﻴﺎﻧﺎت وﻣﻌﺎﻟﺠﺘﻬﺎ وﻣﺸﺎرﻛﺘﻬﺎ
ﺑﻄﺮﻳﻘﺔٍﺗﺤﱰمﺧﺼﻮﺻﻴﺔ اﻷﻓﺮاد وﺣﻘﱠﻬﻢﰲﻣﻌﺮﻓﺔﻣﺎﻳﺤﺪثﻟﺒﻴﺎﻧﺎﺗﻬﻢ، واﻟﻮﺻﻮل إﱃ
ﺑﻴﺎﻧﺎﺗﻬﻢ، واﻻﻋﱰاضﻋﲆﺟﻤﻊﺑﻴﺎﻧﺎﺗِﻬﻢ أوﻋﲆﻣُﻌﺎﻟﺠﺘﻬﺎ، وﻣﻌﺮﻓﺔ أنﺑﻴﺎﻧﺎﺗﻬﻢﺗُﺠﻤﻊ
وﺗُﻌﺎﻟﺞ وأﻧﻬﻢﺑﻌﺪﺋﺬٍﻳﺨﻀﻌﻮنﻟﻘﺮاراتٍﻳﺘﺨﺬﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ )ﰲﺣﺎﻟﺔﺣﺪوث ذﻟﻚ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺑﺎﻟﻔﻌﻞ(. وﺗُﺜﺎر اﻟﻌﺪﻳﺪﻣﻦﻫﺬه اﻟﻘﻀﺎﻳﺎ أﻳﻀًﺎﰲﺳﻴﺎﻗﺎتﺗﻜﻨﻮﻟﻮﺟﻴﺎ املﻌﻠﻮﻣﺎت وﺗﻜﻨﻮﻟﻮﺟﻴﺎ
اﻻﺗﺼﺎﻻت اﻷﺧﺮى، وﻛﻤﺎﺳﻨﺮىﻓﻴﻤﺎﺑﻌﺪُﰲﻫﺬا اﻟﻔﺼﻞ،ﺗﻌﺘﱪ اﻟﺸﻔﺎﻓﻴﺔﴍﻃًﺎﻣُﻬﻤٍّﺎ أﻳﻀًﺎ
ﰲﺗﻠﻚ اﻟﺤﺎﻻت )اﻧﻈﺮﻻﺣﻘًﺎﰲﻫﺬا اﻟﻔﺼﻞ(.ﻛﻤﺎﺗُﺜﺎرﻗﻀﺎﻳﺎﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎتﰲ أﺧﻼﻗﻴﺎت
اﻟﺒﺤﺚ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ أﺧﻼﻗﻴﺎتﺟﻤﻊ اﻟﺒﻴﺎﻧﺎتﻷﺑﺤﺎث اﻟﻌﻠﻮم اﻻﺟﺘﻤﺎﻋﻴﺔ.
وﻣﻊ ذﻟﻚ،ﻋﻨﺪ اﻟﻨﻈﺮ إﱃ اﻟﺴﻴﺎﻗﺎت اﻟﺘﻲﻳُﺴﺘﺨﺪَمﻓﻴﻬﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻴﻮم،
ﺗُﺼﺒﺢﻗﻀﺎﻳﺎ اﻟﺨﺼﻮﺻﻴﺔ وﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت أﻛﺜﺮﺗﻌﻘﻴﺪًا.ﻓﺈن اﺣﱰامﻫﺬه اﻟﻘِﻴَﻢ واﻟﺤﻘﻮق
ﻳﻜﻮنﺳﻬﻼً إﱃﺣﺪﱟﻣﺎﻋﻨﺪ إﺟﺮاء اﺳﺘﺒﻴﺎنٍﻛﻌﺎﻟِﻢ اﺟﺘﻤﺎع: إذﻳﻤﻜﻦﻟﻠﺒﺎﺣﺚ إﺑﻼغ املﺸﺎرﻛني
ﰲ اﻻﺳﺘﺒﻴﺎن وﻃﻠﺐﻣﻮاﻓﻘﺘﻬﻢﺑﺸﻜﻞٍﴏﻳﺢ، وﻣِﻦﺛَﻢﺳﻴﻜﻮنﻣﻦ املﻌﺮوفﻧﺴﺒﻴٍّﺎﻣﺎ
ﺳﻴﺤﺪثﻟﻠﺒﻴﺎﻧﺎت. وﻟﻜﻦ اﻟﺒﻴﺌﺔ اﻟﺘﻲﻳُﺴﺘﺨﺪَمﻓﻴﻬﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت اﻟﻴﻮم
ﻋﺎدةًﻣﺎﺗﻜﻮنﻣﺨﺘﻠﻔﺔًﺗﻤﺎﻣًﺎ.ﻓﻠﻨﺘﻨﺎولﻣﺜﻼً وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ:ﻋﲆ اﻟﺮﻏﻢﻣﻦ
ﻣﻌﻠﻮﻣﺎت اﻟﺨﺼﻮﺻﻴﺔ واﻟﺘﻄﺒﻴﻘﺎت اﻟﺘﻲﺗﻄﻠُﺐﻣﻦ املُﺴﺘﺨﺪِﻣني املﻮاﻓﻘﺔ،ﻓﺈن املُﺴﺘﺨﺪِﻣني
ﻻﻳﻌﺮﻓﻮنﺑﻮﺿﻮحﻣﺎﻳﺤﺪُثﻟﺒﻴﺎﻧﺎﺗﻬﻢ أوﺣﺘﻰ أيﺑﻴﺎﻧﺎتﻳﺘﻢﺟﻤﻌﻬﺎ؛ وإذاﻛﺎﻧﻮاﻳﺮﻏﺒﻮن
ﰲ اﺳﺘﺨﺪام اﻟﺘﻄﺒﻴﻖ واﻻﺳﺘﻤﺘﺎعﺑﻔﻮاﺋﺪه،ﻓﻌﻠﻴﻬﻢ أنﻳﻮاﻓﻘﻮا. وﰲﻛﺜريٍﻣﻦ اﻷﺣﻴﺎن،ﻻ
ﻳﻌﻠﻢ املُﺴﺘﺨﺪﻣﻮنﺣﺘﻰ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳُﺸﻐﱢﻞ اﻟﺘﻄﺒﻴﻖ اﻟﺬيﻳﺴﺘﺨﺪﻣﻮﻧﻪ. وﻏﺎﻟﺒًﺎ
ﻣﺎﺗُﻨﻘَﻞ اﻟﺒﻴﺎﻧﺎت املُﻌﻄﺎةﰲﺳﻴﺎقٍﻣﺎ إﱃﻧﻄﺎقٍ آﺧَﺮ واﺳﺘﺨﺪاﻣﻬﺎﻷﻏﺮاضﻣﺨﺘﻠﻔﺔ )إﻋﺎدة
أﺧﺮى(،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪﻣﺎﺗﺒﻴﻊ اﻟﴩﻛﺎتﺑﻴﺎﻧﺎﺗﻬﺎ إﱃ
اﺳﺘﺨﺪام اﻟﺒﻴﺎﻧﺎتﰲ أﻏﺮاضٍ
ﴍﻛﺎت أﺧﺮى أوﺗﻨﻘﻞ اﻟﺒﻴﺎﻧﺎتﺑني أﺟﺰاءٍﻣﺨﺘﻠﻔﺔﻣﻦﻧﻔﺲ اﻟﴩﻛﺔ دونﻋِﻠﻢ املﺴﺘﺨﺪِﻣني
ﺑﻬﺬا.
اﻟﺘﻼﻋُﺐ واﻻﺳﺘﻐﻼل واملُﺴﺘﺨﺪِﻣني املُﺴﺘﻬﺪﻓني
ﺗُﺸريﻫﺬه اﻟﻈﺎﻫﺮة اﻷﺧرية أﻳﻀًﺎ إﱃ اﺣﺘﻤﺎﻟﻴﺔ اﻟﺘﻼﻋُﺐﺑﺎملُﺴﺘﺨﺪﻣني واﺳﺘﻐﻼﻟﻬﻢ.ﻳُﺴﺘﺨﺪَم
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻠﺘﺤﻜﻢﻓﻴﻤﺎﻧﺸﱰﻳﻪ، وﰲ اﻷﺧﺒﺎر اﻟﺘﻲﻧُﺘﺎﺑﻌﻬﺎ، وﰲ اﻵراء اﻟﺘﻲﻧﺜِﻖ
ﺑﻬﺎ، وﻏري ذﻟﻚ. وﻗﺪ أﺷﺎر اﻟﺒﺎﺣﺜﻮنﰲ اﻟﻨﻈﺮﻳﺔ اﻟﻨﻘﺪﻳﺔ إﱃ اﻟﺴﻴﺎق اﻟﺮأﺳﻤﺎﱄ اﻟﺬيﻳﺤﺪث
ﻓﻴﻪ اﺳﺘﺨﺪام وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦ اﻟﻘﻮل إنﻣُﺴﺘﺨﺪﻣﻲ
(ﻣﻦﺧﻼل إﻧﺘﺎجFuchs 2014)وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲﻳﺆدﱡون »ﻋﻤﻼً رﻗﻤﻴٍّﺎ«ﻣﺠﺎﻧﻴٍّﺎ
اﻟﺒﻴﺎﻧﺎتﻟﺼﺎﻟﺢ اﻟﴩﻛﺎت. وﻳُﻤﻜﻦ أنﻳﺸﻤﻞﻫﺬا اﻟﺸﻜﻞﻣﻦ أﺷﻜﺎل اﻻﺳﺘﻐﻼل أﻳﻀًﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ.ﻓﺒﻮﺻﻔﻨﺎﻣُﺴﺘﺨﺪﻣنيﻟﻮﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ،ﻧﺤﻦﻧﺘﻌﺮضﻟﺨﻄﺮ أن
ﻧﺼﺒﺢ اﻟﻘﻮة اﻟﻌﺎﻣﻠﺔ املُﺴﺘﻐﻠﱠﺔﻏري املﺄﺟﻮرة، اﻟﺘﻲﺗﻨﺘﺞ اﻟﺒﻴﺎﻧﺎتﻟﺼﺎﻟﺢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
72</p>
<p>اﻟﺨﺼﻮﺻﻴﺔ وﻏريﻫﺎﻣﻦ اﻟﻘﻀﺎﻳﺎ
اﻟﺬيﻳُﺤﻠﻞﺑﻴﺎﻧﺎﺗﻨﺎﺑﻌﺪ ذﻟﻚﻟﺼﺎﻟﺢ اﻟﴩﻛﺎت اﻟﺘﻲﺗﺴﺘﺨﺪم اﻟﺒﻴﺎﻧﺎت، واﻟﺘﻲﻋﺎدةًﻣﺎ
ﺗﺘﻀﻤﱠﻦ أﻃﺮاﻓًﺎ أﺧﺮى أﻳﻀًﺎ. وﻫﺬاﻳُﺬﻛﱢﺮﻧﺎ أﻳﻀًﺎﺑﺘﺤﺬﻳﺮﻫريﺑﺮتﻣﺎرﻛﻮزهﰲﺳﺘﻴﻨﻴﺎت
اﻟﻘﺮن اﻟﻌﴩﻳﻦﺑﺄﻧﻪﺣﺘﻰﰲ املﺠﺘﻤﻌﺎت املُﺴﻤﱠﺎةﻣﺠﺘﻤﻌﺎت »ﺣﺮة«، و»ﻏريﺷﻤﻮﻟﻴﺔ«،ﻫﻨﺎك
(.ﻳﻜﻤﻦMarcuse 1991)أﺷﻜﺎلﺧﺎﺻﺔﻣﻦ اﻟﺴﻴﻄﺮة، وﺧﺎﺻﺔ اﺳﺘﻐﻼل املُﺴﺘﻬﻠﻜني
اﻟﺨﻄﺮﻫﻨﺎﰲ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺪﻳﺆديﺣﺘﻰﰲ اﻟﺪﻳﻤﻘﺮاﻃﻴﺎت اﻟﺤﺪﻳﺜﺔ إﱃ أﺷﻜﺎلٍ
ﺟﺪﻳﺪةﻣﻦ اﻟﺘﻼﻋُﺐ واملﺮاﻗﺒﺔ واﻻﺳﺘﺒﺪاد،ﻟﻴﺲﺑﺎﻟﴬورةﰲﺷﻜﻞﺳﻴﺎﺳﺎت اﺳﺘﺒﺪادﻳﺔ
وﻟﻜﻦﺑﻄﺮﻳﻘﺔ أﻛﺜﺮﺧﻔﺎءً وﻓﻌﺎﻟﻴﺔ:ﻣﻦﺧﻼلﺗﻐﻴري اﻻﻗﺘﺼﺎدﺑﻄﺮﻳﻘﺔﺗُﺤﻮﱢﻟﻨﺎﺟﻤﻴﻌًﺎ —
ﰲ اﺳﺘﺨﺪاﻣﻨﺎﻟﻠﻬﻮاﺗﻒ اﻟﺬﻛﻴﺔ واﻟﺘﻔﺎﻋﻼت اﻟﺮﻗﻤﻴﺔ اﻷﺧﺮى — إﱃﻣﺎﻳُﺸﺒﻪ اﻷﺑﻘﺎر اﻟﺘﻲﻳﺘﻢ
ﺣﻠﺒﻬﺎﻟﻠﺤﺼﻮلﻋﲆﺑﻴﺎﻧﺎﺗﻬﺎ. وﻟﻜﻦﻳﻤﻜﻦ أﻳﻀًﺎ اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻠﺘﻼﻋُﺐﰲ
اﻟﺴﻴﺎﺳﺔﺑﺸﻜﻞٍ أﻛﺜﺮﻣﺒﺎﴍة،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﻦﺧﻼلﺗﺤﻠﻴﻞﺑﻴﺎﻧﺎت وﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ
اﻻﺟﺘﻤﺎﻋﻲﻟﺪﻋﻢﺣﻤﻼتﺳﻴﺎﺳﻴﺔﻣُﻌﻴﻨﺔ )ﻛﻤﺎﰲ اﻟﺤﺎﻟﺔ اﻟﺸﻬريةﻟﴩﻛﺔﻛﺎﻣﱪﻳﺪج أﻧﺎﻟﻴﺘﻴﻜﺎ،
اﻟﺘﻲ اﺳﺘﺨﺪﻣﺖﺑﻴﺎﻧﺎتﻣُﺴﺘﺨﺪﻣﻲﻓﻴﺴﺒﻮك — دونﻣﻮاﻓﻘﺘﻬﻢ —ﻷﻏﺮاضﺳﻴﺎﺳﻴﺔﰲ
اﻧﺘﺨﺎﺑﺎت اﻟﺮﺋﺎﺳﺔ اﻷﻣﺮﻳﻜﻴﺔﻋﺎم ٦١٠٢(، أوﻋﻦﻃﺮﻳﻖ اﺳﺘﺨﺪام روﺑﻮﺗﺎتﻟﻨﴩ رﺳﺎﺋﻞ
ﺳﻴﺎﺳﻴﺔﻋﲆ وﺳﺎﺋﻞ اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲ اﺳﺘﻨﺎدًا إﱃﺗﺤﻠﻴﻞﺑﻴﺎﻧﺎت اﻷﻓﺮادﻣﻦﺣﻴﺚ
ﺗﻔﻀﻴﻼﺗﻬﻢ اﻟﺴﻴﺎﺳﻴﺔﻟﻠﺘﺄﺛريﻋﲆﻋﻤﻠﻴﺎت اﻟﺘﺼﻮﻳﺖ.ﻛﻤﺎ أن اﻟﺒﻌﺾﻳُﺴﺎورﻫﻢ اﻟﻘﻠﻖﻣﻦ
أنﻳُﺤﻮﱢل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻣﻦﺧﻼلﺗﻮﻟﱢﻴﻪ املﻬﺎم املﻌﺮﻓﻴﺔﻧﻴﺎﺑﺔًﻋﻦ اﻟﺒﴩ،ﻗﺪﻳُﺤﻮﱢل
ﻣُﺴﺘﺨﺪِﻣﻴﻪ إﱃ أﻃﻔﺎلﻋﲆ املﺴﺘﻮى اﻟﻌﻘﲇﻋﻦﻃﺮﻳﻖ »ﺗﻘﻠﻴﻞﻗﺪرﺗﻬﻢﻋﲆ اﻟﺘﻔﻜريﺑﻤﺤﺾ
(.ﻋﻼوةًﻋﲆShanahan 2015, 170) «أﻧﻔﺴﻬﻢ أو اﺗﺨﺎذﻗﺮاراﺗﻬﻢ اﻟﺨﺎﺻﺔﺑﻤﺎﻳﺠﺐﻓﻌﻠﻪ
ذﻟﻚ،ﻻﻳﻜﻤﻦﺧﻄﺮ اﻻﺳﺘﻐﻼلﰲﺟﺎﻧﺐ املﺴﺘﺨﺪمﻓﺤﺴﺐ:ﻓﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻌﺘﻤﺪﻋﲆ
أﺟﻬﺰةﺻﻨﻌﻬﺎ أﺷﺨﺎص، وﻗﺪﻳﻨﻄﻮي إﻧﺸﺎءﻫﺬه اﻷﺟﻬﺰةﻋﲆ اﺳﺘﻐﻼلﻫﺆﻻء اﻷﺷﺨﺎص.
وﻗﺪﻳﺪﺧﻞ اﻻﺳﺘﻐﻼل أﻳﻀًﺎﰲﺗﺪرﻳﺐ اﻟﺨﻮارزﻣﻴﺎت وإﻧﺘﺎج اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﺗُﺴﺘﺨﺪَمﻟﺼﺎﻟﺢ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻋﻦﻃﺮﻳﻘﻪ. إن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ رﺑﻤﺎﻳﺠﻌﻞ اﻟﺤﻴﺎة أﻳﴪﺑﺎﻟﻨﺴﺒﺔ
إﱃﻣُﺴﺘﺨﺪِﻣﻴﻪ، وﻟﻜﻦﻟﻴﺲﺑﺎﻟﴬورةﺑﺎﻟﻨﺴﺒﺔ إﱃ أوﻟﺌﻚ اﻟﺬﻳﻦﻳُﻨﻘﱢﺒﻮنﻋﻦ املﻌﺎدن، أو
ﺑﺎﻟﻨﺴﺒﺔ إﱃﻣَﻦﻳﺘﻌﺎﻣﻠﻮنﻣﻊ املُﺨﻠﻔﺎت اﻹﻟﻜﱰوﻧﻴﺔ، أو إﱃﻣَﻦﻳُﺪرﺑﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻻﻳﻘﺘﴫﻣﺎﻳﻘﻮمﺑﻪﺗﻄﺒﻴﻖ »أﻟﻴﻜﺴﺎ« اﻟﺬيﻃﻮﱠرﺗﻪ أﻣﺎزون إﻛﻮﻋﲆ
إﻧﺸﺎءﻣُﺴﺘﺨﺪِﻣنيﻳﺆدﱡونﻋﻤﻼًﻣﺠﺎﻧﻴٍّﺎ وﻳُﺼﺒﺤﻮنﻣﺼﺎدرﻟﻠﺒﻴﺎﻧﺎت وﻳُﺒﺎﻋﻮنﻛﻤﻨﺘﺠﺎت؛
ﺑﻞﻫﻨﺎكﻋﺎﻟَﻢﻣﻦ اﻟﻌﻤﻞ اﻟﺒﴩيﻳﻜﻤُﻦﺧﻠﻒ اﻟﻜﻮاﻟﻴﺲ:ﻓﻌُﻤﱠﺎل اﻟﺘﻨﻘﻴﺐﻋﻦ املﻌﺎدن،
واﻟﻌﻤﺎلﻋﲆ اﻟﺴﻔﻦ، واﻟﻌﻤﺎل اﻟﺬﻳﻦﻳُﺼﻨﻔﻮنﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت،ﻛﻞﻫﺆﻻءﰲﺧﺪﻣﺔ
(.Schwab 2018)ﺗﺠﻤﻴﻊ رءوس اﻷﻣﻮال وﺗﺮاﻛُﻤﻬﺎﻟﺪىﻋﺪدﻗﻠﻴﻞﺟﺪٍّاﻣﻦ اﻷﺷﺨﺎص
73</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻗﺪﻳﺆدي اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃ أﺷﻜﺎلٍﺟﺪﻳﺪةﻣﻦ اﻟﺘﻼﻋُﺐ واملﺮاﻗﺒﺔ واﻻﺳﺘﺒﺪاد،ﻟﻴﺲﺑﺎﻟﴬورةﰲ
ﺷﻜﻞﺳﻴﺎﺳﺎتٍ اﺳﺘﺒﺪادﻳﺔ وﻟﻜﻦﺑﻄﺮﻳﻘﺔٍ أﻛﺜﺮﺧﻔﺎءً وﻓﻌﺎﻟﻴﺔ.
ﺑﻌﺾﻣُﺴﺘﺨﺪﻣﻲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻛﺜﺮﺗﻌﺮﱡﺿًﺎﻟﻠﺨﻄﺮﻣﻦﻏريﻫﻢ. وﻧﻈﺮﻳﺎت
اﻟﺨﺼﻮﺻﻴﺔ واﻻﺳﺘﻐﻼلﻏﺎﻟﺒًﺎﻣﺎﺗﻔﱰض أن املﺴﺘﺨﺪِمﺷﺨﺺﺑﺎﻟِﻎﺳﻠﻴﻢ اﻟﺠﺴﻢ،ﺻﻐري
اﻟﺴﻦﻧﺴﺒﻴٍّﺎ،ﰲﻛﺎﻣﻞﻗﻮاه اﻟﻌﻘﻠﻴﺔ.ﻟﻜﻦﱠ اﻟﻌﺎﻟَﻢ اﻟﺤﻘﻴﻘﻲﻣﲇءﺑﺎﻷﻃﻔﺎل وﻛﺒﺎر اﻟﺴﻦ
واﻷﺷﺨﺎص اﻟﺬﻳﻦﻻﻳﺘﻤﺘﻌﻮنﺑﻘﻮًىﻋﻘﻠﻴﺔ »ﻃﺒﻴﻌﻴﺔ« أو »ﻛﺎﻣﻠﺔ«، وﻏريﻫﻢ.ﻣﺜﻞﻫﺆﻻء
املُﺴﺘﺨﺪﻣني اﻟﻀﻌﻔﺎء أﻛﺜﺮﻋُﺮﺿﺔًﻟﻠﺨﻄﺮ. وﻳﻤﻜﻦ اﻧﺘﻬﺎكﺧﺼﻮﺻﻴﺘﻬﻢ أو اﻟﺘﻼﻋﺐﺑﻬﻢ
ﺑﺴﻬﻮﻟﺔ، وﻳﻮﻓﱢﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻓﺮﺻًﺎﺟﺪﻳﺪةﻟﻬﺬه اﻻﻧﺘﻬﺎﻛﺎت وﻋﻤﻠﻴﺎت اﻟﺘﻼﻋﺐ.ﻓﻜﱢﺮ
ﻣﺜﻼًﰲ اﻷﻃﻔﺎل اﻟﺼﻐﺎر اﻟﺬﻳﻦﻳﺘﺤﺪﺛﻮنﻣﻊ دﻣﻴﺔٍﻣﺘﺼﻠﺔﺑﻨﻈﺎمﺗﻜﻨﻮﻟﻮﺟﻲﻣﺪﻋﻮمﺑﺎﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ:ﻋﲆ اﻷرﺟﺢ،ﻫﺆﻻء اﻷﻃﻔﺎلﻻﻳﻌﻠﻤﻮنﺷﻴﺌًﺎﻋﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺴﺘﺨﺪَم
أوﻋﻦﺟﻤﻊﺑﻴﺎﻧﺎﺗﻬﻢ،ﻓﻤﺎﺑﺎﻟﻚﺑﻤﺎﻳُﻔﻌَﻞﺑﻤﻌﻠﻮﻣﺎﺗﻬﻢ اﻟﺸﺨﺼﻴﺔ. إن روﺑﻮت اﻟﺪردﺷﺔ
أو اﻟﺪﻣﻴﺔ اﻟﺬﻛﻴﺔ املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻻﺗﺴﺘﻄﻴﻊﻓﻘﻂ أنﺗﺠﻤﻊ اﻟﻜﺜريﻣﻦ
املﻌﻠﻮﻣﺎت اﻟﺸﺨﺼﻴﺔﻋﻦ اﻟﻄﻔﻞ وأﺑﻮﻳﻪﺑﻬﺬه اﻟﻄﺮﻳﻘﺔ،ﺑﻞﻳُﻤﻜﻨﻬﺎ أﻳﻀًﺎ اﻟﺘﻼﻋُﺐﺑﺎﻟﻄﻔﻞ
ﺑﺎﺳﺘﺨﺪام واﺟﻬﺔ اﻟﻠﻐﺔ واﻟﺼﻮت. وﻣﻊﺗﺤﻮﱡل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﺟﺰءٍﻣﻦ »إﻧﱰﻧﺖ
( وإﻧﱰﻧﺖ اﻷﺷﻴﺎء )اﻷﺧﺮى(،ﺗُﺼﺒﺢﻫﺬهﻣﺸﻜﻠﺔDruga and Williams 2017) «اﻷﻟﻌﺎب
أﺧﻼﻗﻴﺔ وﺳﻴﺎﺳﻴﺔ. إنﺷﺒﺢ اﻟﺸﻤﻮﻟﻴﺔ واﻻﺳﺘﺒﺪادﻳُﻌﺎود اﻟﻈﻬﻮرﻣﺠﺪدًا:ﻟﻴﺲﰲﻗﺼﺺ
اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ املُﺘﺸﺎﺋﻤﺔ أوﰲﻛﻮاﺑﻴﺲﻣﺎﺑﻌﺪ اﻟﺤﺮوب اﻟﻘﺪﻳﻤﺔ، وﻟﻜﻦﰲ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
اﻻﺳﺘﻬﻼﻛﻴﺔ املﻮﺟﻮدةﺑﺎﻟﻔﻌﻞﰲ اﻷﺳﻮاق.
اﻷﺧﺒﺎر اﻟﻜﺎذﺑﺔ، وﺧﻄﺮ اﻟﺸﻤﻮﻟﻴﺔ، وﺗﺄﺛريﻫﺎﻋﲆ اﻟﻌﻼﻗﺎت اﻟﺸﺨﺼﻴﺔ
،ﻳﻤﻜﻦ أنﻳُﺴﺘﺨﺪَم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎﰲ إﻧﺘﺎجﺧﻄﺎب اﻟﻜﺮاﻫﻴﺔ واملﻌﻠﻮﻣﺎت اﻟﺰاﺋﻔﺔ
وﻟﻜﻨﻬﺎﰲ اﻟﻮاﻗﻊﻣﺠﺮدﺑﺮاﻣﺞﻣﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء
أوﰲ إﻧﺸﺎء روﺑﻮﺗﺎتﺗﺒﺪوﻛﺄﺷﺨﺎصٍ
اﻻﺻﻄﻨﺎﻋﻲ. وﻗﺪﺳﺒﻖ وأﴍتﺑﺎﻟﻔﻌﻞ إﱃ روﺑﻮت اﻟﺪردﺷﺔ »ﺗﺎي« وﺧﻄﺎب أوﺑﺎﻣﺎ اﻟﺰاﺋﻒ.
ﻗﺪﻳﺆدي ذﻟﻚ إﱃﻋﺎﻟَﻢٍﻻﻳﻤﻜﻦﻓﻴﻪ اﻟﺘﻤﻴﻴﺰﺑﻮﺿﻮحﺑنيﻣﺎﻫﻮﺣﻘﻴﻘﻲ وﻣﺎﻫﻮ زاﺋﻒ،
ﻋﺎﻟﻢﺗﺘﺪاﺧَﻞﻓﻴﻪ اﻟﺤﻘﺎﺋﻖﻣﻊ اﻟﺨﻴﺎل. وﺳﻮاءﻛﺎنﻳﺠِﺐﺗﺴﻤﻴﺘﻬﺎ »ﻣﺎﺑﻌﺪ اﻟﺤﻘﻴﻘﺔ«
(،ﺗﺴﺎﻫﻢﻫﺬه اﻟﺘﻄﺒﻴﻘﺎتﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞٍ واﺿﺢﰲMcIntyre 2018)أمﻻ
74</p>
<p>اﻟﺨﺼﻮﺻﻴﺔ وﻏريﻫﺎﻣﻦ اﻟﻘﻀﺎﻳﺎ
.املﺸﻜﻠﺔ.ﺑﺎﻟﻄﺒﻊ،ﻛﺎنﻳُﻮﺟَﺪﺗﻼﻋﺐ وﻣﻌﻠﻮﻣﺎتﻛﺎذﺑﺔﻗﺒﻞﻇﻬﻮر اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻓﺎﻷﻓﻼم،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻛﺎﻧﺖ داﺋﻤًﺎﺗﺨﻠُﻖ أوﻫﺎﻣًﺎ، واﻟﺼﺤﻒﻛﺎﻧﺖﺗﻨﴩ اﻟﺪﻋﺎﻳﺔ
اﻟﻜﺎذﺑﺔ. وﻟﻜﻦﺑﻌﺪﻇﻬﻮر اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺟﻨﺒًﺎ إﱃﺟﻨﺐٍﻣﻊ إﻣﻜﺎﻧﻴﺎت وﺑﻴﺌﺔ اﻹﻧﱰﻧﺖ
ووﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ اﻟﺮﻗﻤﻴﺔ،ﻳﺒﺪو أن املﺸﻜﻠﺔﺗﺰدادﺗﻌﻘﻴﺪًا وﺣِﺪﱠة. وﻳﺒﺪو أن
ﻫﻨﺎك املﺰﻳﺪﻣﻦ اﻟﻔُﺮَصﻟﻠﺘﻼﻋُﺐ،ﻣﻤﺎﻳﻌﺮض اﻟﺘﻔﻜري اﻟﻨﻘﺪيﻟﻠﺨﻄﺮ. وﻛﻞﻫﺬاﻳُﺬﻛﺮﻧﺎﻣﺮة
أﺧﺮىﺑﺨﻄﻮرة اﻟﺸﻤﻮﻟﻴﺔ، اﻟﺘﻲﺗﺴﺘﻔﻴﺪﻣﻦ اﻟْﺘﺒﺎس اﻟﺤﻘﻴﻘﺔ وﺗﻨﺘﺞ أﺧﺒﺎرًا زاﺋﻔﺔﻷﻏﺮاض
أﻳﺪﻳﻮﻟﻮﺟﻴﺔ.
وﻣﻊ ذﻟﻚ،ﺣﺘﻰﰲ اﻟﻴﻮﺗﻮﺑﻴﺎ اﻟﻠﻴﱪاﻟﻴﺔﻗﺪﻻﺗﻜﻮن اﻟﺤﻴﺎةﻏﺎﻳﺔﰲ اﻹﴍاق واﻟﺒﻬﺎء. إذ
إن املﻌﻠﻮﻣﺎت اﻟﻜﺎذﺑﺔﺗﻨﺨﺮﰲﺟﺪار اﻟﺜﻘﺔ وﻣﻦﺛَﻢﺗﻔﺴﺪ اﻟﻨﺴﻴﺞ اﻻﺟﺘﻤﺎﻋﻲ. وﻳُﻤﻜﻦ أن
ﻳﺆدي اﻻﺳﺘﺨﺪام املُﻔﺮطﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎ إﱃﺗﻘﻠﻴﻞ اﻟﺘﻮاﺻُﻞ، أوﻋﲆ اﻷﻗﻞ اﻟﺘﻮاﺻﻞ اﻟﻬﺎدف،
ﺑني اﻷﻓﺮاد.ﰲﻋﺎم ١١٠٢،ﻗﺪﻣﺖﺷرييﺗريﻛﻞ ادﻋﺎءًﻳﺘﻌﻠﻖﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻣﺜﻞ أﺟﻬﺰة
اﻟﻜﻤﺒﻴﻮﺗﺮ واﻟﺮوﺑﻮﺗﺎت:ﻟﻘﺪ اﻧﺘﻬﻰﺑﻨﺎ اﻷﻣﺮ إﱃﺗﻮﻗﱡﻊ املﺰﻳﺪﻣﻦ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ، واﻟﻘﻠﻴﻞﻣﻦ
أﻧﻔﺴﻨﺎ. وﻳﻤﻜﻦ أﻳﻀًﺎ اﺳﺘﺨﺪامﻫﺬه اﻟﺤﺠﱠﺔﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ:ﺗﻜﻤُﻦ املﺸﻜﻠﺔ
ﰲ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﰲﺷﻜﻞ وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲ أوﰲﺷﻜﻞ »اﻟﺮﻓﺎق«
اﻟﺮﻗﻤﻴني،ﻳُﻌﻄﻴﻨﺎ وﻫْﻢ اﻟﺮﻓﻘﺔ وﻟﻜﻨﻪﻳُﺰﻋﺰع اﺳﺘﻘﺮار اﻟﻌﻼﻗﺎت اﻟﺤﻘﻴﻘﻴﺔﻣﻊ اﻷﺻﺪﻗﺎء
واﻷﺣﺒﺎء واﻟﻌﺎﺋﻼت. وﻋﲆ اﻟﺮﻏﻢﻣﻦ أنﻫﺬه املﺸﻜﻠﺔﻛﺎﻧﺖﻣﻮﺟﻮدةًﺑﺎﻟﻔﻌﻞﻗﺒﻞ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ وﺗﺰدادﺗﻔﺎﻗﻤًﺎﻣﻊﻇﻬﻮرﻛﻞ وﺳﻴﻂٍﺟﺪﻳﺪﻣﻦ اﻟﻮﺳﺎﺋﻂ )ﻗﺮاءة اﻟﺼﺤﻒ أو
ﻣﺸﺎﻫﺪة اﻟﺘﻠﻔﻴﺰﻳﻮنﺑﺪﻻًﻣﻦ اﻟﺘﺤﺪﱡث وإدارةﺣﻮار(،ﻓﺈﻧﻪﻳﻤﻜﻦ اﻟﻘﻮل إن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
اﻵن،ﰲ وﺟﻮد اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺗﻄﺒﻴﻘﻪ،ﻗﺪ أﺻﺒﺤﺖ أﻓﻀﻞﺑﻜﺜريٍﰲﺧﻠﻖ وﻫْﻢ اﻟﺮﻓﻘﺔ،
وأنﻫﺬاﻳﺰﻳﺪﻣﻦﺧﻄﺮ اﻟﻮﺣﺪة أوﺗﺪﻫﻮر اﻟﻌﻼﻗﺎت اﻟﺸﺨﺼﻴﺔ.
اﻟﺴﻼﻣﺔ واﻷﻣﺎن
ﻫﻨﺎك أﻳﻀًﺎﻣﺨﺎﻃﺮ أوﺿﺢ.ﻓﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻻﺳﻴﱠﻤﺎﰲﺣﺎلﺗﻀﻤﻴﻨﻪﰲ أﻧﻈﻤﺔ
اﻷﺟﻬﺰة اﻟﺘﻲﺗﻌﻤﻞﰲ اﻟﻌﺎﻟَﻢ اﻟﻔﻌﲇ،ﻳﺤﺘﺎج أﻳﻀًﺎ إﱃ أنﻳﻜﻮن آﻣﻨًﺎ. وﻟﻨﴬبﻣﺜﻼًﻋﲆ
ذﻟﻚﺑﺎﻟﺮوﺑﻮﺗﺎت اﻟﺼﻨﺎﻋﻴﺔ:ﻳﻔﱰض أﻻﺗُﻠﺤِﻖﻫﺬه اﻟﺮوﺑﻮﺗﺎت اﻷذىﺑﺎﻟﻌﻤﺎل. وﻣﻊ ذﻟﻚ،
ﺗﺤﺪث أﺣﻴﺎﻧًﺎﺣﻮادثﰲ املﺼﺎﻧﻊ. وﻳﻤﻜﻦﻟﻠﺮوﺑﻮﺗﺎت أنﺗﻘﺘُﻞ،ﺣﺘﻰﻟﻮﻛﺎن ذﻟﻚﻧﺎدرًا
ﻧﺴﺒﻴٍّﺎ. وﻣﻊ ذﻟﻚ،ﰲ اﻟﺮوﺑﻮﺗﺎت اﻟﺘﻲﺗﻌﺘﻤِﺪﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺗُﺼﺒﺢﻣﺸﻜﻠﺔ اﻟﺴﻼﻣﺔ
أﻛﺜﺮﺗﺤﺪﱢﻳًﺎ:ﻓﻬﺬه اﻟﺮوﺑﻮﺗﺎتﻗﺪﺗﺘﻤﻜﱠﻦﻣﻦ اﻟﻌﻤﻞﺟﻨﺒًﺎ إﱃﺟﻨﺐٍﻣﻊ اﻟﺒﴩ، وﻗﺪﺗﺘﻤﻜﱠﻦ
75</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻣﻦﺗﺠﻨﱡﺐ إﻟﺤﺎق اﻷذىﺑﺎﻟﺒﴩ »ﻋﲆﻧﺤﻮٍ ذﻛﻲ«. وﻟﻜﻦﻣﺎذاﻳﻌﻨﻲ ذﻟﻚﺑﺎﻟﻀﺒﻂ؟ﻫﻞﻳﺠﺐ
أنﺗﺘﺤﺮكﺑﺒﻂءٍ أﻛﱪﻋﻨﺪﻣﺎﺗﻜﻮنﻗﺮﻳﺒﺔًﻣﻦ اﻟﺒﴩ،ﻣﻤﺎﻳُﺒﻄﺊ اﻟﻌﻤﻠﻴﺔ، أم أﻧﻪﻣﻦ املﻘﺒﻮل
اﻟﺘﺤﺮكﺑﴪﻋﺔٍﻋﺎﻟﻴﺔﻣﻦ أﺟﻞ إﻧﺠﺎز اﻟﻌﻤﻞﺑﻜﻔﺎءة وﴎﻋﺔ؟ﻫﻨﺎك داﺋﻤًﺎ اﺣﺘﻤﺎﻻتﻟﺤﺪوث
ﺧﻄﺄﻣﻦﻧﻮعﻣﺎ.ﻓﻬﻞﻳﺠﺐ أنﺗﻨﻄﻮي أﺧﻼﻗﻴﺎت اﻟﺴﻼﻣﺔﻋﲆ اﻟﻮﺻﻮل إﱃﺣﻠﻮل وﺳﻂ؟
ﺗُﺜري اﻟﺮوﺑﻮﺗﺎت املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﺑﻴﺌﺔ املﻨﺰل أوﰲ اﻷﻣﺎﻛﻦ اﻟﻌﺎﻣﺔ أﻳﻀًﺎ
ﻗﻀﺎﻳﺎﺗﺘﻌﻠﱠﻖﺑﺎﻟﺴﻼﻣﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻫﻞﻳﺠﺐﻋﲆ اﻟﺮوﺑﻮت داﺋﻤًﺎﺗﺠﻨﱡﺐ اﻻﺻﻄﺪام
ﺑﺎﻟﺒﴩ أم أﻧﻪﻣﻦ املﻘﺒﻮل أﺣﻴﺎﻧًﺎ أنﻳُﻌﺮﻗﻞ اﻟﺮوﺑﻮتﺷﺨﺼًﺎﻣﻦ أﺟﻞ اﻟﻮﺻﻮل إﱃﻫﺪﻓﻪ؟
ﻫﺬهﻟﻴﺴﺖﻣﺴﺎﺋﻞﺗﻘﻨﻴﺔﺑﺤﺘﺔ وﻟﻜﻦﻟﻬﺎﺟﺎﻧﺐ أﺧﻼﻗﻲ: إﻧﻬﺎﻣﺴﺄﻟﺔﺣﻴﺎةﺑﴩﻳﺔ وﻗِﻴَﻢﻣﺜﻞ
اﻟﺤﺮﻳﺔ واﻟﻜﻔﺎءة.ﻛﻤﺎ أﻧﻬﺎﺗُﺜريﻣﺸﻜﻼتٍﺗﺘﻌﻠﱠﻖﺑﺎملﺴﺌﻮﻟﻴﺔ )ﺳﻨﺘﺤﺪثﻋﻦﻫﺬاﺑﺘﻔﺼﻴﻞ
أﻛﺜﺮﻻﺣﻘًﺎ(.
ﺛﻤﱠﺔﻣﺸﻜﻠﺔ أﺧﺮىﻛﺎﻧﺖﻣﻮﺟﻮدةﺑﺎﻟﻔﻌﻞﻗﺒﻞﻇﻬﻮر اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ املﺸﻬﺪ،
وﻟﻜﻨﻬﺎﺗﺴﺘﺤﻖﱡﺗﺠﺪﻳﺪ اﻫﺘﻤﺎﻣﻨﺎﺑﻬﺎ؛ أﻻ وﻫﻲﻣﺸﻜﻠﺔ اﻷﻣﺎن.ﰲﻋﺎﻟﻢﻣُﺘﺼﻞﺑﺎﻟﺸﺒﻜﺎت،
ﻳﻤﻜﻦ اﺧﱰاق أيﺟﻬﺎز إﻟﻜﱰوﻧﻲ أوﺑﺮﻧﺎﻣﺞ واﺧﱰاﻗﻪ واﻟﺘﻼﻋُﺐﺑﻪﻣﻦﻗﺒﻞ أﺷﺨﺎصﻟﺪﻳﻬﻢ
ﻧﻮاﻳﺎﺧﺒﻴﺜﺔ.ﻓﻜﻠﱡﻨﺎﻧﻌﻠﻢﺑﺸﺄنﻓريوﺳﺎت اﻟﻜﻤﺒﻴﻮﺗﺮ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻟﺘﻲﻳﻤﻜﻦ أنﺗُﺨﺮﱢب
ﺟﻬﺎز اﻟﻜﻤﺒﻴﻮﺗﺮ اﻟﺨﺎصﺑﻚ. وﻟﻜﻦﻋﻨﺪﺗﺰوﻳﺪ أﺟﻬﺰﺗﻨﺎ وﺑﺮاﻣﺠﻨﺎﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،
ﻳﻤﻜﻦ أنﺗﺰﻳﺪ إﻣﻜﺎﻧﻴﺎﺗﻬﺎ وﻗﺪراﺗﻬﺎ، وﻋﻨﺪﻣﺎﺗﺤﻈﻰﺑﻮﻛﺎﻟﺔٍ أﺧﻼﻗﻴﺔ أﻛﱪ وﻳﻜﻮنﻟﻬﺬا
ﻋﻮاﻗﺐﻣﺎدﻳﺔﰲ اﻟﻌﺎﻟﻢ اﻟﻔﻌﲇ،ﺗُﺼﺒﺢﻣﺸﻜﻠﺔ اﻷﻣﺎن أﻛﱪﺑﻜﺜري.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إذا
اﺧﱰُﻗَﺖﺳﻴﺎرﺗﻚ اﻟﺬاﺗﻴﺔ اﻟﻘﻴﺎدة اﻟﺘﻲﺗﻌﻤﻞﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﺴﻮفﺗُﻌﺎﻧﻲﻣﻤﺎﻫﻮ
أﻛﺜﺮﻣﻦﻣﺠﺮد »ﻣﺸﻜﻠﺔﰲ اﻟﻜﻤﺒﻴﻮﺗﺮ« أو »ﻣﺸﻜﻠﺔﰲ اﻟﱪﻧﺎﻣﺞ«؛ﻗﺪﺗﻠﻘﻰﺣﺘﻔﻚ. وإذا
اﺧﱰُ ِقﺑﺮﻧﺎﻣﺞ إﺣﺪى اﻟﺒَﻨﻰ اﻟﺘﺤﺘﻴﺔ املﻬﻤﺔ )ﻣﺜﻞ اﻹﻧﱰﻧﺖ، أو املﻴﺎه، أو اﻟﻄﺎﻗﺔ … إﻟﺦ( أو
ﺟﻬﺎزﻋﺴﻜﺮي ذيﻗﺪراتٍﻣﺪﻣﺮة،ﻓﻤﻦ املﺮﺟﱠﺢ أنﻳﺘﻌﺮض املﺠﺘﻤﻊﺑﺄﻛﻤﻠﻪ إﱃ اﺿﻄﺮابٍ
ﻛﺒري وﺳﻮفﻳﺘﻌﺮض اﻟﻜﺜريﻣﻦ اﻷﺷﺨﺎصﻟﻠﴬر.ﰲ اﻟﺘﻄﺒﻴﻘﺎت اﻟﻌﺴﻜﺮﻳﺔ،ﻳﺸﻜﱢﻞ
اﺳﺘﺨﺪام اﻷﺳﻠﺤﺔ اﻟﻔﺘﺎﻛﺔ اﻟﺬاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞﺧﻄﻮرة أﻣﻨﻴﺔ واﺿﺤﺔ،ﻻﺳﻴﱠﻤﺎﻋﲆ املُﺴﺘﻬﺪَﻓني
ﺑﺎﻟﻄﺒﻊﺑﻬﺬه اﻷﺳﻠﺤﺔ )وﻋﺎدةﻣﺎﻻﻳﻜﻮﻧﻮنﻣﻦ اﻟﻐﺮب( وﻟﻜﻨﻪﻳﺸﻜﱢﻞﺧﻄﻮرة أﻳﻀًﺎﻋﲆ
أوﻟﺌﻚ اﻟﺬﻳﻦﻳﻨﴩوﻧﻬﺎ: إذﻳﻤﻜﻦ داﺋﻤًﺎ اﺧﱰاﻗﻬﺎ وﺗﺤﻮﻳﻠﻬﺎﺿﺪﻫﻢ.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻗﺪ
ﻳﺆديﺳﺒﺎق اﻟﺘﺴﻠﱡﺢ اﻟﺬيﻳﺸﻤﻞﻫﺬه اﻷﺳﻠﺤﺔ إﱃﺣﺮبٍﻋﺎملﻴﺔﺟﺪﻳﺪة. وﻻﻳﻠﺰﻣﻨﺎ أنﻧﻨﻈﺮ
ﺑﻌﻴﺪًاﰲ املُﺴﺘﻘﺒﻞ:ﻓﺈذاﻛﺎﻧﺖ اﻟﻄﺎﺋﺮات دونﻃﻴﺎر )ﻏري املُﺰودةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ(
ﻳُﻤﻜﻨﻬﺎﺑﺎﻟﻔﻌﻞﺣﺎﻟﻴٍّﺎ اﻟﺴﻴﻄﺮةﻋﲆﻣﻄﺎرٍﻛﺒريﰲﻟﻨﺪن،ﻓﺈﻧﻪﻟﻴﺲﻣﻦ اﻟﺼﻌﺐﺗﺨﻴﱡﻞﻣﺪى
76</p>
<p>اﻟﺨﺼﻮﺻﻴﺔ وﻏريﻫﺎﻣﻦ اﻟﻘﻀﺎﻳﺎ
ﻫﺸﺎﺷﺔﻣﻨﺸﺂتﺑِﻨﻴﺘﻨﺎ اﻷﺳﺎﺳﻴﺔ اﻟﻴﻮﻣﻴﺔ وﻛﻴﻒﻳﻤﻜﻦﻟﻼﺳﺘﺨﺪام املﺆذي أوﻻﺧﱰاق اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ أنﻳُﺴﺒﺐ اﺿﻄﺮاﺑﺎتٍﺟﺴﻴﻤﺔ وﻋﻤﻠﻴﺎتٍﺗﺪﻣريﻳﺔًﻫﺎﺋﻠﺔ.ﻻﺣﻆ أﻳﻀًﺎ أﻧﻪ،ﻋﲆ
ﻋﻜﺲ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﻨﻮوﻳﺔﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻓﺈن اﺳﺘﺨﺪامﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺤﺎﻟﻴﺔﻻﻳﺘﻄﻠﱠﺐﻣﻌﺪﱠاتﺑﺎﻫﻈﺔ اﻟﺜﻤﻦ أوﺗﺪرﻳﺒًﺎﻃﻮﻳﻼً ؛ وﻣِﻦﺛَﻢﻓﺎﻟﻌﺎﺋﻖ أﻣﺎم اﺳﺘﺨﺪام
ﺧﺒﻴﺜﺔﻣُﻨﺨﻔﺾﻧﺴﺒﻴٍّﺎ.
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻷﻏﺮاضٍ
ﺗُﺬﻛﺮﻧﺎ أﻳﻀًﺎ املﺸﻜﻼت اﻟﻌﺎدﻳﺔ املﺘﻌﻠﻘﺔﺑﺎﻷﻣﺎنﻣﻊ اﻟﺴﻴﺎرات وﻣﻨﺸﺂت اﻟﺒﻨﻴﺔ اﻟﺘﺤﺘﻴﺔ
ﻣﺜﻞ املﻄﺎراتﺑﺄﻧﻪﻋﲆ اﻟﺮﻏﻢﻣﻦ أنﺑﻌﺾ اﻷﺷﺨﺎص أﻛﺜﺮﻋﺮﺿﺔًﻟﻠﺨﻄﺮﻣﻦﻏريﻫﻢ،
ﻓﺈﻧﻨﺎ »ﺟﻤﻴﻌًﺎ«ﻣُﻌﺮﱠﺿﻮنﻟﻠﺨﻄﺮﰲﻇﻞﱢﺗﻘﻨﻴﺎتٍﻣﺜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻷﻧﻨﺎ،ﻣﻊ زﻳﺎدة
ﺗﻤﺘﱡﻊﻫﺬه اﻟﺘﻘﻨﻴﺎتﺑﺎﻟﻮﻛﺎﻟﺔ وزﻳﺎدةﺗﻔﻮﻳﻀﻨﺎﻟﻬﺎﻟﺘﺄدﻳﺔ املﺰﻳﺪﻣﻦ املﻬﺎم،ﻧُﺼﺒﺢﺟﻤﻴﻌًﺎ
أﻛﺜﺮ اﻋﺘﻤﺎدًاﻋﻠﻴﻬﻢ. وﻫﻨﺎك اﺣﺘﻤﺎلٌ داﺋﻢ أنﺗﺴري اﻷﻣﻮرﻋﲆﻏريﻣﺎﻧﺮوم. وﻣﻦﺛَﻢ،ﻳُﻤﻜﻨﻨﺎ
اﻟﻘﻮل إن املﺨﺎﻃﺮ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ اﻟﺠﺪﻳﺪةﻟﻴﺴﺖﻣﺠﺮدﻣﺨﺎﻃﺮﺗﻜﻨﻮﻟﻮﺟﻴﺔ، وإﻧﻤﺎﺗﺘﺠﺎوز
(.ﻳﻤﻜﻦ رؤﻳﺔCoeckelbergh 2013)ذﻟﻚﻟﺘُﺼﺒﺢﻣﺨﺎﻃﺮﺗﻬﺪﱢد وﺟﻮدﻧﺎﺑﺼﻔﺘﻨﺎﺑﴩًا
املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ املﻄﺮوﺣﺔﻫﻨﺎﻋﲆ أﻧﻬﺎﻣﺨﺎﻃﺮ إﻧﺴﺎﻧﻴﺔ:ﻓﺎملﺨﺎﻃﺮ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔﺗُﻬﺪد
وﺟﻮدﻧﺎﻛﺒﴩٍﰲﻧﻬﺎﻳﺔ املﻄﺎف. وﺑﻘﺪْرﻣﺎﻧﻌﺘﻤﺪﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﺑﻘﺪْرﻣﺎﻳﻜﻮن
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻛﺜﺮﻣﻦﻣﺠﺮد أداةٍﻧﺴﺘﺨﺪﻣﻬﺎ؛ﻓﺈﻧﻪﻳُﺼﺒﺢﺟﺰءًاﻣﻦﻫﻮﻳﺘﻨﺎ وﻣﻦ
املﺨﺎﻃﺮ اﻟﺘﻲﺗﺤﻴﻖﺑﻨﺎﰲ اﻟﻌﺎﻟﻢ.
ﰲﻋﺎﻟﻢٍﻣُﺘﺼﻞﺑﺎﻟﺸﺒﻜﺎت،ﻳﻤﻜﻦ اﺧﱰاق أيﺟﻬﺎز إﻟﻜﱰوﻧﻲ أوﺑﺮﻧﺎﻣﺞ واﺧﱰاﻗﻪ واﻟﺘﻼﻋُﺐﺑﻪﻣﻦ
ﻗﺒﻞ أﺷﺨﺎصﻟﺪﻳﻬﻢﻧﻮاﻳﺎﺧﺒﻴﺜﺔ.
ﻛﺬﻟﻚﻳُﺜريﺗﻤﺘﱡﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ،ﻻﺳﻴﻤﺎ إذاﻛﺎﻧﺖﺗﺤﻞﱡﻣﺤﻞﱠ
اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﺒﴩﻳﺔ،ﻣﺸﻜﻠﺔ أﺧﻼﻗﻴﺔ أﺧﺮىﺗﺰداد أﻫﻤﻴﺔًﻣﻊﻣﺮور اﻟﻮﻗﺖ: أﻻ وﻫﻲ
املﺴﺌﻮﻟﻴﺔ. وﻫﺬاﻫﻮﻣﻮﺿﻮع اﻟﻔﺼﻞ اﻟﻘﺎدم.
77</p>
</section>
<section id="section-9">
    <h2>لامسئوليةُ الآلات والقرارات غير المبررة</h2>
    <div class="page-range">Pages 79-88</div>
    <p>اﻟﻔﺼﻞ اﻟﺜﺎﻣﻦ
ﻻﻣﺴﺌﻮﻟﻴﺔُ اﻵﻻت واﻟﻘﺮاراتﻏﲑ اﳌُﱪرة
ﻛﻴﻒﻳﻤﻜﻦ أنﻧﺴﻨﺪ املﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔ وﻣﺎ اﻟﻜﻴﻔﻴﺔ اﻟﻮاﺟﺒﺔﻟﺬﻟﻚ؟
ُﻋﻨﺪ اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻻﺗﺨﺎذﻗﺮارات وﻟﻠﻘﻴﺎمﺑﺄﺷﻴﺎءﺑﺎﻟﻨﻴﺎﺑﺔﻋﻨﱠﺎ،ﻓﺈﻧﻨﺎﻧﻮاﺟِﻪ
ﻣﺸﻜﻠﺔﻣﺸﱰﻛﺔﰲﺟﻤﻴﻊﺗﻘﻨﻴﺎت اﻷﺗﻤﺘﺔ،ﻏري أنﻫﺬه املﺸﻜﻠﺔﺗﺰداد أﻫﻤﻴﺔًﻋﻨﺪﻣﺎﻳُﻤﻜﱢﻨﻨﺎ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦﺗﻔﻮﻳﺾ املﺰﻳﺪ واملﺰﻳﺪﻣﻦ اﻟﻘﺮارات إﱃ اﻵﻻت أﻛﺜﺮﺑﻜﺜريٍﻣﻤﺎﻛﻨﺎ
إذاﻣُﻨﺢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻛﺎﻟﺔ1.ﻧﻔﻌﻞﰲ املﺎﴈ: وﻫﺬه املﺸﻜﻠﺔﻫﻲ إﺳﻨﺎد املﺴﺌﻮﻟﻴﺔ
أﻛﱪ وأﺧﺬﻋﲆﻋﺎﺗﻘﻪﻣﺎﻛﺎنﻳﺘﻮﻻﱠه اﻟﺒﴩﰲ املﺎﴈ،ﻓﻜﻴﻒﻧُﺴﻨﺪ املﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔﻋﻦ
أﻓﻌﺎﻟﻪ؟ﻣَﻦ املﺴﺌﻮلﻋﻦ اﻷﴐار واﻟﻔﻮاﺋﺪ اﻟﺘﻲﺗﻨﺸﺄﻋﻦ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻋﻨﺪﻣﺎﻳﻔﻮض اﻟﺒﴩ
اﻟﻮﻛﺎﻟﺔ واﻟﻘﺮارات إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ وﻓﻴﻤﺎﻳﺨﺺﱡ املﺨﺎﻃﺮﺗﺤﺪﻳﺪًا:ﻣَﻦ املﺴﺌﻮلﻋﻨﺪ
ﺣﺪوثﺧﻄﺄﻣﺎ؟
ﺑﺄداءﻣﻬﺎمﱠ واﺗﺨﺎذﻗﺮارات،ﻓﻨﺤﻦﻋﺎدةًﻣﺎﻧﺮﺑﻂ اﻟﻮﻛﺎﻟﺔﺑﺎملﺴﺌﻮﻟﻴﺔ
ﻋﻨﺪﻣﺎﻳﻘﻮم اﻟﺒﴩَ
اﻷﺧﻼﻗﻴﺔ.ﻓﺄﻧﺖﻣﺴﺌﻮلﻋﻤﺎﺗﻔﻌﻠﻪ وﻋﻦ اﻟﻘﺮارات اﻟﺘﻲﺗﺘﱠﺨﺬﻫﺎ. وإذاﻛﺎنﻟﺪَﻳﻚﺗﺄﺛريﻋﲆ
اﻟﻌﺎﻟﻢ وﻋﲆ اﻵﺧﺮﻳﻦ،ﻓﺄﻧﺖﻣﺴﺌﻮلﻋﻦﻋﻮاﻗﺐ أﻓﻌﺎﻟﻚ. وﻓﻘًﺎﻷرﺳﻄﻮ،ﻫﺬاﻫﻮ اﻟﴩط اﻷول
ﻟﻠﻤﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔ، املﻌﺮوفﺑﺎﺳﻢ اﻟﴩط اﻟﺘﺤﻜﱡﻤﻲ:ﰲ اﻷﺧﻼﻗﻴﺎت اﻟﻨﻴﻘﻮﻣﺎﺧﻴﺔ،ﻳﻘﻮل
أرﺳﻄﻮ إن اﻟﻔﻌﻞﻳﺠﺐ أنﻳﻨﺸﺄﻣﻦ اﻟﻔﺎﻋﻞ. وﻟﻬﺬا اﻟﺮأي أﻳﻀًﺎﺟﺎﻧﺐﺗﻘﻴﻴﻤﻲ: إذاﻛﺎن
ﻟﺪﻳﻚ وﻛﺎﻟﺔ وإذاﻛﻨﺖَﻗﺎدرًاﻋﲆ اﺗﺨﺎذﻗﺮارات،ﻓﻴﻨﺒﻐﻲ أنﺗﺘﺤﻤﱠﻞ املﺴﺌﻮﻟﻴﺔﻋﻦ أﻓﻌﺎﻟﻚ.
وﻣﺎﻧﺮﻳﺪﺗﺠﻨﱡﺒﻪﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔﻫﻮ أنﻳُﻮﺟَﺪﺷﺨﺺﻳﺘﻤﺘﻊﺑﺎﻟﻮﻛﺎﻟﺔ واﻟﻘﺪرة وﻟﻜﻨﻪ
ﻻﻳﺘﺤﻤﻞ املﺴﺌﻮﻟﻴﺔ. أﺿﺎف أرﺳﻄﻮ أﻳﻀًﺎﴍﻃًﺎ آﺧَﺮﻓﻴﻤﺎﻳﺨﺺ املﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔ: أﻧﺖ
ﻣﺴﺌﻮل إذاﻛﻨﺖﺗﻌﻠﻢﻣﺎﺗﻔﻌﻠﻪ. وﻫﺬاﴍط إدراﻛﻲ:ﻳﺠﺐ أنﺗﻜﻮن واﻋﻴًﺎﺑﻤﺎﺗﻔﻌﻞ وﻋﲆ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
دراﻳﺔﺑﻌﻮاﻗﺒﻪ املﺤﺘﻤﻠﺔ. وﻣﺎﻧﺤﺘﺎج إﱃﺗﺠﻨﱡﺒﻪﻫﻨﺎﻫﻮﺷﺨﺺﺗﺼﺪُرﻋﻨﻪ أﻓﻌﺎلﻻﻳﺪري
ﻣﺎﻫﻴﺘﻬﺎ، وﻫﻮﻣﺎﻗﺪﻳﺆديﰲ اﻟﻨﻬﺎﻳﺔ إﱃﻋﻮاﻗﺐ وﺧﻴﻤﺔ.
إذاﻣُﻨِﺢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻛﺎﻟﺔً أﻛﱪ وأﺧﺬﻋﲆﻋﺎﺗِﻘِﻪﻣﺎﻛﺎنﻳﺘﻮﻻﱠه اﻟﺒﴩﰲ املﺎﴈ،ﻓﻜﻴﻒﻧُﺴﻨﺪ
املﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔﻋﻦ أﻓﻌﺎﻟﻪ؟
اﻵن دﻋﻮﻧﺎﻧﺮىﻫﻞﺗﺘﺤﻘﱠﻖﻫﺬه اﻟﴩوطﻋﻨﺪﺗﻔﻮﻳﺾ اﻟﻘﺮارات واﻷﻋﻤﺎل إﱃ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ. املﺸﻜﻠﺔ اﻷوﱃﻫﻲ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻤﻜﻦ أنﻳﺘﱠﺨﺬﻗﺮاراتٍ وﻳﺆدي أﻓﻌﺎﻻً
ﻟﻬﺎﻋﻮاﻗﺐ أﺧﻼﻗﻴﺔ، وﻟﻜﻨﻪﻻﻳُﺪركﻣﺎﻳﻔﻌﻠﻪ وﻏريﻗﺎدرﻋﲆ اﻟﺘﻔﻜري اﻷﺧﻼﻗﻲ وﺑﺎﻟﺘﺎﱄﻻ
ﻳُﻤﻜﻦ اﻋﺘﺒﺎرهﻣﺴﺌﻮﻻًﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔﻋﻤﺎﻳﻔﻌﻠﻪ.ﻳﻤﻜﻦ أنﺗﺘﻤﺘﱠﻊ اﻵﻻتﺑﺎﻟﻮﻛﺎﻟﺔ
وﻟﻜﻦﻟﻴﺲﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ؛ﻷﻧﻬﺎﺗﻔﺘﻘِﺮ إﱃ اﻟﻮﻋﻲ واﻹرادة اﻟﺤﺮة واﻟﻌﻮاﻃﻒ واﻟﻘُﺪرة
ﻋﲆﺗﻜﻮﻳﻦ اﻟﻨﻮاﻳﺎ وﻣﺎﺷﺎﺑَﻪَ ذﻟﻚ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، وﻓﻘًﺎﻟﺮؤﻳﺔ أرﺳﻄﻮ،ﻳﻤﻜﻦﻟﻠﺒﴩ
ﻓﻘﻂ أداء اﻷﻓﻌﺎل اﻟﺘﻄﻮﱡﻋﻴﺔ واﻟﺘﻔﻜريﰲ أﻓﻌﺎﻟﻬﻢ. إذاﻛﺎنﻫﺬاﺻﺤﻴﺤًﺎ،ﻓﺈن اﻟﺤﻞﱠ اﻟﻮﺣﻴﺪ
ﻫﻮﺟﻌْﻞ اﻟﺒﴩﻣﺴﺌﻮﻟنيﻋﻤﺎﺗﻔﻌﻠﻪ اﻵﻟﺔ. وﻣﻦﺛَﻢﻓﺈن اﻟﺒﴩﻳُﻔﻮﱢﺿﻮن اﻟﻮﻛﺎﻟﺔ إﱃ اﻵﻟﺔ،
وﻟﻜﻨﻬﻢﻳﺤﺘﻔِﻈﻮنﺑﺎملﺴﺌﻮﻟﻴﺔ. وﻧﺤﻦﻧﻔﻌﻞ ذﻟﻚﺑﺎﻟﻔﻌﻞﰲ أﻧﻈﻤﺘﻨﺎ اﻟﻘﺎﻧﻮﻧﻴﺔ؛ إذ إﻧﻨﺎﻻ
ﻧَﻌﺘﱪِ اﻟﻜﻼب أو اﻷﻃﻔﺎل اﻟﺼﻐﺎرﻣﺴﺌﻮﻟنيﻋﻦ أﻓﻌﺎﻟﻬﻢ، وﻟﻜﻨﻨﺎﻧﻀﻊ املﺴﺌﻮﻟﻴﺔ اﻟﻘﺎﻧﻮﻧﻴﺔ
ﻣﺎ
ﻋﲆﻋﺎﺗﻖﻣَﻦﻳﺘﻮﻟﱠﻮن رﻋﺎﻳﺘﻬﻢ. وﰲﻣﺆﺳﺴﺔٍﻣﺎ،ﻗﺪﻧُﻔﻮﱢضﻣﻬﻤﺔًﻣﻌﻴﻨﺔ إﱃﺷﺨﺺٍ
وﻟﻜﻨﻨﺎﻧُﺤﻤﱢﻞ املﺴﺌﻮﻟﻴﺔﻟﻠﻤﺪﻳﺮ املﺴﺌﻮلﻋﻦ املﴩوع اﻟﻌﺎم،ﻋﲆ اﻟﺮﻏﻢﻣﻦ أن اﻟﺸﺨﺺ
إذَن ملﺎذاﻻﻧﺴﻤﺢﻟﻶﻟﺔﺑﺄداء اﻷﻋﻤﺎل2.املُﻔﻮضﰲﻫﺬه اﻟﺤﺎﻟﺔﻳﺘﺤﻤﱠﻞﺟﺰءًاﻣﻦ املﺴﺌﻮﻟﻴﺔ
وﻧﺤﺘﻔﻆﺑﺎملﺴﺌﻮﻟﻴﺔﻋﲆ اﻟﺠﺎﻧﺐ اﻟﺒﴩي؟ﻳﺒﺪو أنﻫﺬهﻫﻲ أﻓﻀﻞ وﺳﻴﻠﺔﻧﻤﴤﺑﻬﺎﻗﺪﻣًﺎ،
ﺣﻴﺚ إن اﻟﺨﻮارزﻣﻴﺎت واﻵﻻتﺑﻼﻣﺴﺌﻮﻟﻴﺔ.
وﻣﻊ ذﻟﻚ،ﻳﻮاﺟِﻪﻫﺬا اﻟﺤﻞﱡﻋﺪةﻣﺸﻜﻼتﰲﺣﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. أوﻻً ،ﻳﻤﻜﻦ
ﻟﻠﻨﻈﺎم املﺰوﱠدﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنﻳﺘﱠﺨﺬﻗﺮاراﺗﻪ وﻳﺆدي أﻓﻌﺎﻟﻪﺑﴪﻋﺔﻛﺒريةﻟﻠﻐﺎﻳﺔ،
ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ اﻟﺘﺪاول اﻟﻌﺎﱄ اﻟﱰدﱡد أوﰲ اﻟﺴﻴﺎرات اﻟﺬاﺗﻴﺔ اﻟﻘﻴﺎدة،ﻣﻤﺎﻳﺤﺮم
اﻹﻧﺴﺎنﻣﻦ اﻟﻮﻗﺖ اﻟﻜﺎﰲﻻﺗﺨﺎذ اﻟﻘﺮار اﻟﻨﻬﺎﺋﻲ أو اﻟﺘﺪﺧﱡﻞﰲ اﻟﻔﻌﻞ.ﻓﻜﻴﻒﻳُﻤﻜﻦﻟﻠﺒﴩ
أنﻳﺘﺤﻤﱠﻠﻮا املﺴﺌﻮﻟﻴﺔﻋﻦﻣﺜﻞﻫﺬه اﻷﻓﻌﺎل واﻟﻘﺮارات؟ﺛﺎﻧﻴًﺎ،ﻷﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺗﻮارﻳﺦ.ﻋﻨﺪﻣﺎﻳﻘﻮم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺄﺷﻴﺎءﰲﺳﻴﺎقﺗﻄﺒﻴﻖٍﻣُﻌني،ﻓﺮﺑﻤﺎﻳُﺼﺒﺢﻣﻦ
80</p>
<p>ﻻﻣﺴﺌﻮﻟﻴﺔُ اﻵﻻت واﻟﻘﺮاراتﻏري املُﱪرة
ﻏري اﻟﻮاﺿﺢﻣَﻦ أﻧﺸﺄه، وﻣَﻦ اﺳﺘﺨﺪﻣﻪ أوﻻً ، واﻟﻜﻴﻔﻴﺔ اﻟﺘﻲﻳﺠﺐﺑﻬﺎﺗﻮزﻳﻊ املﺴﺌﻮﻟﻴﺔﺑني
ﻫﺬه اﻷﻃﺮاف املﺨﺘﻠﻔﺔ املﻌﻨﻴﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﺣﺎﻟﺔ إﻧﺸﺎءﺧﻮارزﻣﻴﺔ ذﻛﺎء اﺻﻄﻨﺎﻋﻲ
ﰲﺳﻴﺎقﻣﴩوعٍﻋﻠﻤﻲﰲ اﻟﺠﺎﻣﻌﺔ،ﺛﻢﺗﻄﺒﻴﻖﻫﺬه اﻟﺨﻮارزﻣﻴﺔﻟﻠﻤﺮة اﻷوﱃﰲ املُﺨﺘﱪﰲ
اﻟﺠﺎﻣﻌﺔ،ﺛﻢﰲﻗﻄﺎع اﻟﺮﻋﺎﻳﺔ اﻟﺼﺤﻴﺔ، وﰲ وﻗﺖٍﻻﺣﻖﰲﺳﻴﺎقٍﻋﺴﻜﺮي.ﻓﻤَﻦﻳﺘﺤﻤﱠﻞ
املﺴﺌﻮﻟﻴﺔ؟ﻗﺪﻳﻜﻮنﻣﻦ اﻟﺼﻌﺐﺗﺘﺒﱡﻊﺟﻤﻴﻊ اﻟﺒﴩ املﺘﻮرﱢﻃنيﰲﺗﺎرﻳﺦﻫﺬه اﻟﺨﻮارزﻣﻴﺔ
ﺑﺎﻟﺬات،ﺑﻞﰲ اﻟﺘﺎرﻳﺦ اﻟﺴﺒﺒﻲ اﻟﺬي أدﱠى إﱃﻧﺘﻴﺠﺔٍﻣﻌﻴﱠﻨﺔﺗَﺤﻤِﻞ إﺷﻜﺎﻟﻴﺔ أﺧﻼﻗﻴﺔ.ﻓﻨﺤﻦﻻ
ﻧﻌﺮف داﺋﻤًﺎﺟﻤﻴﻊ اﻷﺷﺨﺎص املَﻌﻨﻴﱢنيﰲ اﻟﻠﺤﻈﺔ اﻟﺘﻲﺗُﺜﺎرﻓﻴﻬﺎﻣﺸﻜﻠﺔﺗﺘﻌﻠﻖﺑﺎملﺴﺌﻮﻟﻴﺔ.
ﻓﺨﻮارزﻣﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻏﺎﻟﺒًﺎﻣﺎﻳﻜﻮنﻟﻬﺎﺗﺎرﻳﺦﻃﻮﻳﻞﻳﺸﺎركﻓﻴﻪ اﻟﻌﺪﻳﺪﻣﻦ
اﻷﺷﺨﺎص. وﻫﺬاﻳُﻔﴤﺑﻨﺎ إﱃﻣﺸﻜﻠﺔﻧﻤﻄﻴﺔﰲ إﺳﻨﺎد املﺴﺌﻮﻟﻴﺔﻋﻦ اﻷﻓﻌﺎل اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ؛
إذﻏﺎﻟﺒًﺎﻣﺎﻳﻜﻮنﻫﻨﺎك اﻟﻜﺜريﻣﻦ اﻷﻃﺮاف وﻳُﻤﻜﻨﻨﻲ أن أﺿﻴﻒ، اﻷﺷﻴﺎء.
ﻫﻨﺎك اﻟﻜﺜريﻣﻦ اﻷﻃﺮافﺑﻤﻌﻨﻰ أن اﻟﻜﺜريﻣﻦ اﻷﺷﺨﺎصﻳﺸﺎرﻛﻮنﰲ اﻟﻔﻌﻞ
اﻟﺘﻜﻨﻮﻟﻮﺟﻲ.ﰲﺣﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻳﺒﺪأ اﻷﻣﺮﺑﺎملﱪﻣﺞ، وﻟﻜﻦﻟﺪﻳﻨﺎ أﻳﻀًﺎ املﺴﺘﺨﺪم
اﻟﻨﻬﺎﺋﻲ وآﺧﺮون. دﻋﻮﻧﺎﻧﻔﻜﺮﻣﺜﻼًﰲ اﻟﺴﻴﺎرة اﻟﺬاﺗﻴﺔ اﻟﻘﻴﺎدة:ﻫﻨﺎك املﱪﻣﺞ، وﻣُﺴﺘﺨﺪِمُ
اﻟﺴﻴﺎرة، وأﺻﺤﺎبُﴍﻛﺔ اﻟﺴﻴﺎرات، واملﺴﺘﺨﺪِﻣﻮن اﻵﺧﺮونﻟﻠﻄﺮﻳﻖ، وﻫﻜﺬا.ﰲﻣﺎرس
٨١٠٢،ﺗﺴﺒﱠﺒَﺖﺳﻴﺎرة ذاﺗﻴﺔ اﻟﻘﻴﺎدةﻟﴩﻛﺔ أوﺑﺮﰲﺣﺎدثٍﰲ أرﻳﺰوﻧﺎ أدﱠى إﱃ وﻓﺎة أﺣﺪ
املُﺸﺎة.ﻓﻤَﻦ املﺴﺌﻮلﻋﻦﻫﺬه اﻟﻨﺘﻴﺠﺔ املﺄﺳﺎوﻳﺔ؟ﻳﻤﻜﻦ أنﻳﻜﻮن املﺴﺌﻮﻟﻮنﻫﻢﻣَﻦ
ﺑﺮﻣﺠﻮا اﻟﺴﻴﺎرة، واﻷﺷﺨﺎص املﺴﺌﻮﻟنيﻋﻦﺗﻄﻮﻳﺮ املﻨﺘﺞﰲ اﻟﴩﻛﺔ، وﴍﻛﺔ أوﺑﺮﻧﻔﺴﻬﺎ،
وﻣﺴﺘﺨﺪم اﻟﺴﻴﺎرة، واﻟﺸﺨﺺ اﻟﺴﺎﺋﺮ، واملﴩع )ﻋﲆﺳﺒﻴﻞ املﺜﺎل، وﻻﻳﺔ أرﻳﺰوﻧﺎ(، وﻫﻜﺬا.
إذَنﻓﻠﻴﺲﻣﻦ اﻟﻮاﺿﺢﻋﲆﻣَﻦﺗﻘﻊ املﺴﺌﻮﻟﻴﺔ.ﻗﺪﻳﻜﻮن اﻷﻣﺮﻫﻮ أن املﺴﺌﻮﻟﻴﺔﻻﻳﻤﻜﻦ
واﺣﺪ؛ ورﺑﻤﺎﺗﻘﻊﻋﲆ أﻛﺜﺮﻣﻦﺷﺨﺺ. وﻟﻜﻦﻫﺬاﻳﻌﻨﻲ
وﻻﻳﺠﺐ إﺳﻨﺎدﻫﺎ إﱃﺷﺨﺺٍ
أﻧﻪﻟﻴﺲﻣﻦ اﻟﻮاﺿﺢﻛﻴﻔﻴﺔﺗﻮزﻳﻊ املﺴﺌﻮﻟﻴﺔ.ﻓﻘﺪﺗﻘﻊ املﺴﺌﻮﻟﻴﺔﻋﲆﺑﻌﻀﻬﻢ أﻛﺜﺮﻣﻦ
اﻵﺧﺮﻳﻦ.
ﻫﻨﺎك أﻳﻀًﺎ اﻟﻜﺜريﻣﻦ اﻷﺷﻴﺎء،ﺑﻤﻌﻨﻰ أن اﻟﻨﻈﺎم اﻟﺘﻜﻨﻮﻟﻮﺟﻲﻳﺘﺄﻟﻒﻣﻦ اﻟﻌﺪﻳﺪ
ﻣﻦ اﻟﻌﻨﺎﴏ املﺘﺼﻠﺔ؛ وﻋﺎدةًﻣﺎﻳﻜﻮنﻫﻨﺎك اﻟﻌﺪﻳﺪﻣﻦ املﻜﻮﻧﺎت اﻟﺘﻲﺗﺪﺧﻞﰲ اﻟﻨﻈﺎم.
ﻫﻨﺎكﺧﻮارزﻣﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻦﻫﺬه اﻟﺨﻮارزﻣﻴﺔﺗﺘﻔﺎﻋﻞﻣﻊ أﺟﻬﺰة اﺳﺘﺸﻌﺎر،
وﺗﺴﺘﺨﺪمﺟﻤﻴﻊ أﻧﻮاع اﻟﺒﻴﺎﻧﺎت، وﺗﺘﻔﺎﻋﻞﻣﻊﺟﻤﻴﻊ أﻧﻮاع املﻜﻮﻧﺎت املﺎدﻳﺔ واﻟﱪﻣﺠﻴﺔ.
ﻛﻞﻫﺬه اﻷﺷﻴﺎءﻟﻬﺎﺗﺎرﻳﺨﻬﺎ وﻣﺘﺼﻠﺔﺑﺎﻷﺷﺨﺎص اﻟﺬﻳﻦﺑﺮﻣﺠﻮﻫﺎ أو أﻧﺘﺠﻮﻫﺎ. وﻋﻨﺪﻣﺎ
ﻳﺤﺪُثﺧﻄﺄ،ﻻﻳﻜﻮن واﺿﺤًﺎﻟﻨﺎﺑﺎﻟﴬورةﻣﺎ إذاﻛﺎن »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ«ﻫﻮ اﻟﺬي
81</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺳﺒﱠﺐ املﺸﻜﻠﺔ أمﻣُﻜﻮﱢن آﺧَﺮﻣﻦﻣﻜﻮﻧﺎت اﻟﻨﻈﺎم؛ﺑﻞ إﻧﻨﺎﻻﻧﻌﺮفﺑﺎﻟﴬورة أﻳﻦﺗﻨﺘﻬﻲ
ﻣﺴﺌﻮﻟﻴﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺗﺒﺪأﻣﺴﺌﻮﻟﻴﺔﺑﻘﻴﺔ املﻜﻮﻧﺎت اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ. وﻫﺬاﻳﺠﻌﻞﻣﻦ
اﻟﺼﻌﺐ إﺳﻨﺎد املﺴﺌﻮﻟﻴﺔ وﺗﻮزﻳﻌﻬﺎ. دﻋﻮﻧﺎﻧﻔﻜﺮ أﻳﻀًﺎﰲﺗﻌﻠﻢ اﻵﻟﺔ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت:ﻛﻤﺎ
رأﻳﻨﺎ،ﻟﻴﺲﻫﻨﺎكﻓﻘﻂﺧﻮارزﻣﻴﺔ، وﻟﻜﻦ أﻳﻀًﺎﻋﻤﻠﻴﺔﺗﺸﻤﻞﻣﺮاﺣﻞﻣﺨﺘﻠﻔﺔﻣﺜﻞﺟﻤﻊ
اﻟﺒﻴﺎﻧﺎت وﻣﻌﺎﻟﺠﺘﻬﺎ، وﺗﺪرﻳﺐ اﻟﺨﻮارزﻣﻴﺔ، وﻫﻜﺬا؛ وﺟﻤﻴﻊﻫﺬه املﺮاﺣﻞﻳﺪﺧﻞﻓﻴﻬﺎﻋﻨﺎﴏ
ﺗﻘﻨﻴﺔﻣﺨﺘﻠﻔﺔ وﺗﺘﻄﻠﱠﺐﻗﺮاراتﺑﴩﻳﺔ.ﻣﺮة أﺧﺮى،ﻫﻨﺎكﺗﺎرﻳﺦﺳﺒﺒﻲﻳﺸﱰكﻓﻴﻪ اﻟﻜﺜري
ﻣﻦ اﻟﺒﴩ واﻷﺟﺰاء، وﻫﺬاﻳﺠﻌﻞ إﺳﻨﺎد املﺴﺌﻮﻟﻴﺔ أﻣﺮًاﺻﻌﺒًﺎ.
ﻟﻜﻲﻧُﺤﺎول اﻟﺘﻌﺎﻣﻞﻣﻊﻫﺬه اﻟﻘﻀﺎﻳﺎ،ﻳﻤﻜﻨﻨﺎ أنﻧﺘﻌﻠﻢﻣﻦ اﻷﻧﻈﻤﺔ اﻟﻘﺎﻧﻮﻧﻴﺔ أو
ﻧﻠﻘﻲﻧﻈﺮةﻋﲆﻛﻴﻔﻴﺔﻋﻤﻞ اﻟﺘﺄﻣني؛ وﺳﻮف أﺗﺤﺪﱠثﻋﻦﺑﻌﺾ املﻔﺎﻫﻴﻢ اﻟﻘﺎﻧﻮﻧﻴﺔﰲ
اﻟﻔﺼﻮل املﺘﻌﻠﻘﺔﺑﺎﻟﺴﻴﺎﺳﺔ. وﻟﻜﻦﺛﻤﱠﺔ أﺳﺌﻠﺔ أﻛﺜﺮﻋﻤﻮﻣﻴﺔﺗﻠﻮحﻟﻨﺎﻣﻦ وراءﻫﺬه اﻷﻧﻈﻤﺔ
اﻟﻘﺎﻧﻮﻧﻴﺔ وأﻧﻈﻤﺔ اﻟﺘﺄﻣنيﺣﻮل وﻛﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واملﺴﺌﻮﻟﻴﺔﻋﻨﻪ: إﱃ أيﻣﺪى
ﻧﺮﻳﺪ أنﻧﻌﺘﻤﺪﻋﲆﺗﻘﻨﻴﺔ اﻷﺗﻤﺘﺔ، وﻫﻞﻳُﻤﻜﻨﻨﺎ أنﻧﺘﺤﻤﻞ املﺴﺌﻮﻟﻴﺔﻋﻤﺎﻳﻘﻮمﺑﻪ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ، وﻛﻴﻒﻳُﻤﻜﻨﻨﺎ إﺳﻨﺎد املﺴﺌﻮﻟﻴﺎت وﺗﻮزﻳﻌﻬﺎ؟ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﻔﻬﻮم اﻹﻫﻤﺎل
ﰲ اﻟﻘﺎﻧﻮنﻳﺘﻌﻠﱠﻖﺑﻤﺎ إذاﻛﺎن اﻟﺸﺨﺺﻗﺪ أدﱠىﻣﺎﻋﻠﻴﻪﻣﻦ واﺟﺐ اﻟﻌﻨﺎﻳﺔ. وﻟﻜﻦﻣﺎذاﻳﻌﻨﻲ
ﻫﺬا اﻟﻮاﺟﺐﰲﺣﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺧﺎﺻﺔً أﻧﻪﻣﻦ اﻟﺼﻌﺐ اﻟﺘﻨﺒﱡﺆﺑﺠﻤﻴﻊ اﻟﻌﻮاﻗﺐ
اﻷﺧﻼﻗﻴﺔ املُﺤﺘﻤﻠﺔ؟
وﻫﺬاﻳﻘﻮدﻧﺎ إﱃ اﻟﻘﻀﻴﺔ اﻟﺘﺎﻟﻴﺔ.ﺣﺘﻰ إذاﺗﻢﱠﺣﻞﱡﻣﺸﻜﻠﺔ اﻟﺘﺤﻜﻢ،ﻓﻬﻨﺎك اﻟﴩط
اﻟﺜﺎﻧﻲﻟﻠﻤﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔ، واﻟﺬيﻳﺘﻌﻠﱠﻖﺑﻤﺸﻜﻠﺔ املﻌﺮﻓﺔ.ﻟﻜﻲﺗﺘﺤﻤﱠﻞ املﺴﺌﻮﻟﻴﺔ،ﻳﺠﺐ
أنﺗﻌﺮفﻣﺎﺗﻔﻌﻠﻪ واﻟﻨﺘﺎﺋﺞ املُﱰﺗﱢﺒﺔﻋﲆﻓﻌﻠﻚ، وﻓﻴﻤﺎﺑﻌﺪ،ﺗﻌﺮفﻣﺎﻗﻤﺖَﺑﻪ. وﺑﺎﻹﺿﺎﻓﺔ
إﱃ ذﻟﻚ،ﻫﺬه املﺴﺄﻟﺔﻟﻬﺎﺟﺎﻧﺐﴎدي:ﰲﺣﺎﻟﺔ اﻟﺒﴩ،ﻧﺘﻮﻗﱠﻊ أنﻳﺘﻤﻜﻦ اﻟﺸﺨﺺﻣﻦ
ﴍحﻣﺎﻗﺎمﺑﻪ أوﻗﺮﱠرَه. املﺴﺌﻮﻟﻴﺔ إذَنﺗﻌﻨﻲ اﻟﻘﺪرةﻋﲆ اﻟﺮد واﻟﺘﻔﺴري.ﻓﺈذاﺣﺪثﺧﻄﺄ
ﻗﺮاره، أو
ﻣﺎ،ﻓﻨﺤﻦﻧﺮﻳﺪ ردٍّا وﺗﻔﺴريًا.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻧﻄﻠﺐﻣﻦ اﻟﻘﺎﴈ أنﻳُﻔﴪﱢ
ﻧﺴﺄل اﻟﺠﺎﻧﻲ ملﺎذاﻓﻌﻞﻣﺎﻓﻌﻠَﻪ. وﻫﺬه اﻟﴩوطﺗُﺼﺒﺢ إﺷﻜﺎﻟﻴﺔًﻟﻠﻐﺎﻳﺔﰲﺣﺎﻟﺔ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ. أوﻻً ،ﻣﻦﺣﻴﺚ املﺒﺪأ،ﻻ »ﻳﻌﺮف« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ اﻟﻮﻗﺖ اﻟﺤﺎﴐﻣﺎ
ﻳﻔﻌﻠﻪ،ﺑﻤﻌﻨﻰ أﻧﻪﻟﻴﺲ واﻋﻴًﺎ وﺑﺎﻟﺘﺎﱄﻻﻳﺪركﻣﺎﻳﻘﻮمﺑﻪ وﻻﻳﺪركﻧﺘﺎﺋﺞ أﻓﻌﺎﻟﻪ.ﻳﻤﻜﻨﻪ
ﺗﺨﺰﻳﻦﻣﺎﻳﻔﻌﻠﻪ وﺗﺴﺠﻴﻠﻪ، وﻟﻜﻨﻪﻻ »ﻳﻌﺮفﻣﺎﻳﻘﻮمﺑﻪ«ﻛﻤﺎﻳﻔﻌﻞ اﻟﺒﴩ، اﻟﺬﻳﻦﻳُﺪرﻛﻮن،
ﺑﻮﺻﻔﻬﻢﻛﺎﺋﻨﺎت واﻋﻴﺔ،ﻣﺎﻳﻔﻌﻠﻮن وﻳﻤﻜﻨﻬﻢ — وﻓﻘًﺎﻷرﺳﻄﻮﻣﺮة أﺧﺮى — اﻟﺘﻔﻜري
واﻟﺘﺄﻣﻞﰲ أﻓﻌﺎﻟﻬﻢ وﻋﻮاﻗﺐﺗﻠﻚ اﻷﻓﻌﺎل. وﻋﻨﺪﻣﺎﻻﺗُﻠﺒﱠﻰﻫﺬه اﻟﴩوطﰲﺣﺎﻟﺔ اﻟﺒﴩ،ﻋﲆ
82</p>
<p>ﻻﻣﺴﺌﻮﻟﻴﺔُ اﻵﻻت واﻟﻘﺮاراتﻏري املُﱪرة
ﺳﺒﻴﻞ املﺜﺎل،ﰲﺣﺎﻟﺔ اﻷﻃﻔﺎل اﻟﺼﻐﺎرﺟﺪٍّا،ﻓﺈﻧﻨﺎﻻﻧﺤﻤﱢﻠﻬﻢ املﺴﺌﻮﻟﻴﺔ. وﻛﺬﻟﻚﻋﺎدةًﻣﺎﻻ
وإذاﻟﻢﻳُﻠﺐﱢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﺬه اﻟﴩوط،ﻓﺈﻧﻨﺎﻻ3.ﻧُﺤﻤﱢﻞ اﻟﺤﻴﻮاﻧﺎت املﺴﺌﻮﻟﻴﺔ أﻳﻀًﺎ
ﻧﺴﺘﻄﻴﻊ أنﻧُﺤﻤﱢﻠﻪ املﺴﺌﻮﻟﻴﺔ. واﻟﺤﻞﻣﺮة أﺧﺮىﻫﻮﺗﺤﻤﻴﻞ املﺴﺌﻮﻟﻴﺔﻟﻠﺒﴩﻋﻦ أﻋﻤﺎل
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻋﲆ اﻓﱰاض أﻧﻬﻢﻳﻌﺮﻓﻮنﻣﺎﻳﻘﻮمﺑﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣﺎﻳﻔﻌﻠﻮﻧﻪ
ﺑﺎﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ — وﺑﻤﺮاﻋﺎة اﻟﺠﺎﻧﺐ اﻟﴪدي — وأﻧﻬﻢﻗﺎدرونﻋﲆ اﻟﺮدﱢﻋﻦ
أﻓﻌﺎﻟﻪ وﻳُﻤﻜﻨﻬﻢﺗﻔﺴريﻣﺎﻗﺎمﺑﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
وﻣﻊ ذﻟﻚ،ﻓﺈنﻣﺪىﺻﺤﺔﻫﺬا اﻻﻓﱰاضﻟﻴﺲ أﻣﺮًاﻣﻦ اﻟﺴﻬﻞﺗﻘﺮﻳﺮهﻛﻤﺎﻗﺪﻳﺒﺪو
ﻟﻠﻮﻫﻠﺔ اﻷوﱃ.ﻋﺎدةًﻣﺎﻳﻌﺮف املﱪﻣﺠﻮن واملﺴﺘﺨﺪﻣﻮنﻣﺎ اﻟﺬيﻳﺮﻏﺒﻮنﰲ اﻟﻘﻴﺎمﺑﻪ
ﺑﺎﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، أوﺑﺪﻗﱠﺔ أﻛﱪ:ﻳﻌﺮﻓﻮنﻣﺎﻳﺮﻳﺪونﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
أنﻳﻔﻌﻠﻪﻟﻬﻢ. إﻧﻬﻢﻳﻌﺮﻓﻮن اﻟﻬﺪف اﻟﻨﻬﺎﺋﻲ؛ وﻟﻬﺬا اﻟﺴﺒﺐﻳﻔﻮﱢﺿﻮن املﻬﻤﺔ إﱃ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ. وﻗﺪﻳﻜﻮﻧﻮن أﻳﻀًﺎﻋﲆ دراﻳﺔﺑﻜﻴﻔﻴﺔﻋﻤﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺑﺸﻜﻞٍﻋﺎم. وﻟﻜﻦ،
ﻛﻤﺎﺳﻨﺮى،ﻫﻢﻻﻳﻌﺮﻓﻮنﺑﺪﻗﱠﺔٍ داﺋﻤًﺎﻣﺎﻳﻔﻌﻠﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ )ﰲ أيﻟﺤﻈﺔ( وﻻ
ﻳُﻤﻜﻨﻬﻢ داﺋﻤًﺎﺗﻔﺴريﻣﺎﻓﻌﻠﻪ أوﻛﻴﻒ وﺻﻞ إﱃﻗﺮاره.
اﻟﺸﻔﺎﻓﻴﺔ واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري
،ﻧﺤﻦﻧﻮاﺟﻪﻫﻨﺎﻣﺸﻜﻠﺔ اﻟﺸﻔﺎﻓﻴﺔ واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري.ﰲﺑﻌﺾ أﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺗﻜﻮن اﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳﺴﺘﺨﺪﻣﻬﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻻﺗﺨﺎذﻗﺮاره واﺿﺤﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
إذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺴﺘﺨﺪمﺷﺠﺮة اﺗﺨﺎذ اﻟﻘﺮارات،ﻓﺈن اﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳﺼﻞﺑﻬﺎ
إﱃﻗﺮارهﺗﻜﻮن واﺿﺤﺔ.ﻓﻘﺪﺗﻤﱠﺖﺑﺮﻣﺠﺘُﻪﺑﻄﺮﻳﻘﺔﺗُﺤﺪﱢد اﻟﻘﺮار،ﺑﻨﺎءًﻋﲆﻣﺪﺧﻼت
ﻣُﻌﻴﱠﻨﺔ. وﺑﺎﻟﺘﺎﱄﻳﻤﻜﻦﻟﻠﺒﴩﺗﻔﺴريﻛﻴﻒ وﺻﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﻗﺮاره، وﻳﻤﻜﻦ أن
»ﻧﻄﻠُﺐ«ﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أن »ﻳُﻔﴪ«ﻗﺮاره.ﺑﻌﺪ ذﻟﻚ،ﻳﻤﻜﻦﻟﻠﺒﴩﺗﺤﻤﱡﻞﻣﺴﺌﻮﻟﻴﺔ
اﻟﻘﺮار أو،ﻋﲆ اﻷﺣﺮى، اﺗﺨﺎذﻗﺮارﺑﻨﺎءًﻋﲆ اﻟﺘﻮﺻﻴﺔ اﻟﺘﻲﻗﺪﱠﻣَﻬﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
وﻣﻊ ذﻟﻚ،ﻣﻊﺑﻌﺾ أﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻷﺧﺮى، وﻻﺳﻴﻤﺎﺗﻠﻚ اﻟﺘﻲﺗﺴﺘﺨﺪمﺗﻌﻠﱡﻢ
اﻵﻟﺔ وﺧﺎﺻﺔ اﻟﺘﻌﻠﱡﻢ اﻟﻌﻤﻴﻖ اﻟﺬيﻳﺴﺘﺨﺪم اﻟﺸﺒﻜﺎت اﻟﻌﺼﺒﻴﺔ،ﻟﻢﻳﻌُﺪﻣﻦ املﻤﻜﻦﻟﻺﻧﺴﺎن
ﺗﻘﺪﻳﻢﻫﺬا اﻟﺘﻔﺴري أو اﺗﺨﺎذﻗﺮاراتٍﻣﻦﻫﺬا اﻟﻨﻮع.ﺣﻴﺚﻟﻢﻳﻌُﺪ واﺿﺤًﺎﻛﻴﻒﻳﺼﻞ
ﺗﻔﺴري اﻟﻘﺮارﺑﺸﻜﻞٍﻛﺎﻣﻞ. إﻧﻬﻢ
اﻟﺬﻛﺎءُ اﻻﺻﻄﻨﺎﻋﻲ إﱃﻗﺮاره، وﺑﺎﻟﺘﺎﱄﻻﻳُﻤﻜﻦﻟﻠﺒﴩَ
ﻳﻌﺮﻓﻮنﻛﻴﻒﻳﻌﻤﻞ اﻟﻨﻈﺎم اﻟﺨﺎصﺑﻬﻢ،ﺑﺸﻜﻞٍﻋﺎم، وﻟﻜﻦﻻﻳُﻤﻜﻨﻬﻢﺗﻔﺴريﻗﺮارٍﻣﻌنيﱠ .
وﻟﻨﴬبﻣﺜﻼًﺑﻠﻌﺒﺔ اﻟﺸﻄﺮﻧﺞ املﺰودةﺑﺎﻟﺘﻌﻠﱡﻢ اﻟﻌﻤﻴﻖ:ﻳﻌﺮف املﱪﻣﺠﻮنﻛﻴﻒﻳﻌﻤﻞ اﻟﺬﻛﺎء
83</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻻﺻﻄﻨﺎﻋﻲ، وﻟﻜﻦ اﻟﻄﺮﻳﻘﺔ اﻟﺪﻗﻴﻘﺔ اﻟﺘﻲﻳﺼﻞﻣﻦﺧﻼﻟﻬﺎ اﻟﺠﻬﺎز إﱃﺣﺮﻛﺔٍﻣﻌﻴﱠﻨﺔ )أي
ﻣﺎﻳﺤﺪثﰲﻃﺒﻘﺎت اﻟﺸﺒﻜﺔ اﻟﻌﺼﺒﻴﺔ(ﻟﻴﺴﺖ واﺿﺤﺔ وﻻﻳﻤﻜﻦﺗﻔﺴريﻫﺎ. وﻫﺬهﻣﺸﻜﻠﺔ
ﻓﻴﻤﺎﻳﺨﺺﱡﺗﺤﻤﱡﻞ املﺴﺌﻮﻟﻴﺔ،ﺣﻴﺚﻻﻳﺴﺘﻄﻴﻊ اﻟﺒﴩ اﻟﺬﻳﻦﻳُﻨﺸﺌﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أو
ﻳﺴﺘﺨﺪﻣﻮﻧﻪﺗﻔﺴريﻗﺮارﻣﻌني، وﺑﺎﻟﺘﺎﱄﻳﻔﺸﻠﻮنﰲﻣﻌﺮﻓﺔﻣﺎﻳﻘﻮمﺑﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻻﻳُﻤﻜﻨﻬﻢﺗﱪﻳﺮ أﻓﻌﺎﻟﻪ.ﻓﻤِﻦﻧﺎﺣﻴﺔ،ﻳﻌﺮف اﻟﺒﴩﻣﺎ اﻟﺬيﻳﻘﻮمﺑﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
)ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻌﺮﻓﻮن اﻟﺮﻣﻮز اﻟﱪﻣﺠﻴﺔ اﻟﺨﺎﺻﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻳﻌﺮﻓﻮنﻛﻴﻒ
ﻳﻌﻤﻞﺑﺸﻜﻞٍﻋﺎم(، وﻟﻜﻦﻣﻦﻧﺎﺣﻴﺔ أﺧﺮى،ﻫﻢﻻﻳﻌﺮﻓﻮن )ﻻﻳُﻤﻜﻨﻬﻢﺗﻔﺴريﻗﺮار
ﻣﻌنيﱠ (، وﺗﻜﻮنﻧﺘﻴﺠﺔ ذﻟﻚ أن اﻟﺒﴩ اﻟﺬﻳﻦﻳﺘﺄﺛﺮونﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻻﻳﻤﻜﻦ إﻋﻄﺎؤﻫﻢ
ﻣﻌﻠﻮﻣﺎتٍ دﻗﻴﻘﺔﺣﻮلﻣﺎ اﻟﺬي دﻓﻊ اﻵﻟﺔ إﱃ اﻟﻮﺻﻮل إﱃﻫﺬا اﻟﺘﻮﻗﱡﻊ. وﺑﺎﻟﺘﺎﱄ،ﻋﲆ اﻟﺮﻏﻢ
ﻣﻦ أنﻛﻞﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻷﺗﻤﺘﺔﺗُﺜريﻣﺸﻜﻼتﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺎملﺴﺌﻮﻟﻴﺔ،ﻓﺈﻧﻨﺎﻫﻨﺎﻧﻮاﺟﻪﻣﺸﻜﻠﺔً
ﺗﺨﺺﱡﺑﻌﺾ أﻧﻮاع اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؛ وﻫﻲﻣﺎﻳﻄﻠَﻖﻋﻠﻴﻬﺎﻣﺸﻜﻠﺔ اﻟﺼﻨﺪوق اﻷﺳﻮد.
ﻋﻼوةًﻋﲆ ذﻟﻚ،ﺣﺘﻰ اﻻﻓﱰاضﺑﺄن اﻟﺒﴩﰲﻣﺜﻞﻫﺬه اﻟﺤﺎﻻتﻳﺘﻤﺘﻌﻮنﺑﻤﻌﺮﻓﺔٍﺣﻮل
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞٍﻋﺎم وﺣﻮل رﻣﻮزه اﻟﱪﻣﺠﻴﺔﻟﻴﺲ داﺋﻤًﺎﺻﺤﻴﺤًﺎ.ﻓﻌﲆ اﻷرﺟﺢ
ﻳﻌﺮف املﱪﻣﺠﻮن اﻷﺻﻠﻴﻮن اﻟﺮﻣﻮز اﻟﱪﻣﺠﻴﺔ وﻛﻴﻔﻴﺔﻋﻤﻞﻛﻞﳾءٍ )أوﻋﲆ اﻷﻗﻞﻳﻌﺮﻓﻮن
اﻟﺠﺰء اﻟﺬيﺑﺮﻣﺠﻮه(، وﻟﻜﻦ ذﻟﻚﻻﻳﻌﻨﻲ أن املﱪﻣِﺠني واملُﺴﺘﺨﺪﻣني اﻟﻼﺣﻘِ ني اﻟﺬﻳﻦ
ﻳُﻐريون اﻟﺨﻮارزﻣﻴﺔ أوﻳﺴﺘﺨﺪﻣﻮﻧﻬﺎﻟﺘﻄﺒﻴﻘﺎتٍﻣﺤﺪﱠدةﻳﻌﺮﻓﻮنﺗﻤﺎﻣًﺎﻣﺎﻳﻔﻌﻠﻪ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﻻﻳﻔﻬﻢ اﻟﺸﺨﺺ اﻟﺬيﻳﺴﺘﺨﺪمﺧﻮارزﻣﻴﺔ اﻟﺘﺪاول اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﺗﻤﺎم املﻌﺮﻓﺔ، أوﻗﺪﻻﻳﻌﺮفﻣُﺴﺘﺨﺪﻣﻮ وﺳﺎﺋﻞ اﻟﺘﻮاﺻﻞ اﻻﺟﺘﻤﺎﻋﻲﺣﺘﻰ
أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳُﺴﺘﺨﺪَم،ﻓﻤﺎﺑﺎﻟﻚﺑﺄنﻳﻔﻬﻤﻮه. وﻣﻦﺟﻬﺔ املﱪﻣِﺠني )اﻷﺻﻠﻴني(،
ﻓﻬﻢﻗﺪﻻﻳﻌﺮﻓﻮنﻋﲆﻧﺤﻮٍ دﻗﻴﻖ اﻻﺳﺘﺨﺪام »املُﺴﺘﻘﺒﲇ«ﻟﻠﺨﻮارزﻣﻴﺔ اﻟﺘﻲﻳُﻄﻮروﻧﻬﺎ
أوﻣﺨﺘﻠﻒﻣﺠﺎﻻت اﻟﺘﻄﺒﻴﻖ اﻟﺘﻲﻳُﻤﻜﻦ اﺳﺘﺨﺪاﻣﻬﺎﻓﻴﻬﺎ،ﻓﻤﺎﺑﺎﻟﻚﺑﻜﻞﱢ اﻟﺘﺒِﻌﺎتﻏري
اﻟﻨﻈﺮﻋﻦ املﺸﻜﻠﺔ
املﻘﺼﻮدةﻟﻼﺳﺘﺨﺪام املُﺴﺘﻘﺒﲇﻟﻬﺬه اﻟﺨﻮارزﻣﻴﺔ.ﻟﺬﻟﻚ،ﺣﺘﻰﺑﻐﺾﱢ
اﻟﺨﺎﺻﺔﺑﺘﻌﻠﱡﻢ اﻵﻟﺔ )اﻟﺘﻌﻠﻢ اﻟﻌﻤﻴﻖ(،ﻫﻨﺎكﻣﺸﻜﻠﺔﺗﺘﻌﻠﱠﻖﺑﺎملﻌﺮﻓﺔﻟﺪرﺟﺔ أنﱠ اﻟﻜﺜريﻳﻦﻣﻤﱠﻦ
ﻳﺴﺘﺨﺪﻣﻮﻧﻪﻻﻳﻌﺮﻓﻮنﻣﺎﻳﻔﻌﻠﻮن؛ﻷﻧﻬﻢﻻﻳﻌﺮﻓﻮنﻣﺎ اﻟﺬيﻳﻔﻌﻠﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،
وﻣﺎﻫﻲﺗﺄﺛرياﺗﻪ، أوﺣﺘﻰ أﻧﻪﻣُﺴﺘﺨﺪَمﻣﻦ اﻷﺳﺎس. وﻫﺬه أﻳﻀًﺎﻣﺸﻜﻠﺔﻓﻴﻤﺎﻳﺨﺺﱡﺟﺎﻧﺐ
املﺴﺌﻮﻟﻴﺔ، وﺑﺎﻟﺘﺎﱄﻓﻬﻲﻣﺸﻜﻠﺔ أﺧﻼﻗﻴﺔﺧﻄرية.
ﰲﺑﻌﺾ اﻷﺣﻴﺎن،ﻳﺘﻢﺗﺴﻠﻴﻂ اﻟﻀﻮءﻋﲆﻫﺬه املﺸﻜﻼتﰲﺳﻴﺎق اﻟﺜﻘﺔ:ﻓﻐﻴﺎب
اﻟﺸﻔﺎﻓﻴﺔﻳﺆدي إﱃﻏﻴﺎب اﻟﺜﻘﺔﰲ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﰲ اﻷﺷﺨﺎص اﻟﺬﻳﻦﻳﺴﺘﺨﺪﻣﻮنﻫﺬه
84</p>
<p>ﻻﻣﺴﺌﻮﻟﻴﺔُ اﻵﻻت واﻟﻘﺮاراتﻏري املُﱪرة
،اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ.ﻟﺬﻟﻚﻳﺴﺄلﺑﻌﺾ اﻟﺒﺎﺣﺜنيﻛﻴﻒﻳُﻤﻜﻨﻨﺎ زﻳﺎدة اﻟﺜﻘﺔﰲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻳُﺤﺪﱢدون اﻟﺸﻔﺎﻓﻴﺔ واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴريﻛﻌﺎﻣﻞٍﻣﻦ اﻟﻌﻮاﻣﻞ اﻟﺘﻲﻳﻤﻜﻦ أنﺗﺰﻳﺪﻣﻦ
( أوﺻﻮر اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺮﻋﺒﺔWinikoff 2018)اﻟﺜﻘﺔ،ﻓﻀﻼًﻋﻦﺗﺠﻨﱡﺐ اﻟﺘﺤﻴﱡﺰ
(. وﻛﻤﺎﺳﻨﺮىﰲ اﻟﻔﺼﻞ اﻟﻘﺎدم،ﻏﺎﻟﺒًﺎﻣﺎﺗﻬﺪفSiau and Wang 2018) («)»ﺗﺮﻣﻴﻨﻴﺘﻮر
ﺳﻴﺎﺳﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎ إﱃﺑﻨﺎء اﻟﺜﻘﺔ. وﻣﻊ ذﻟﻚ،ﻓﺈنﻣﺼﻄﻠﺤﺎتﻣﺜﻞ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ »اﻟﺠﺪﻳﺮﺑﺎﻟﺜﻘﺔ«ﻣُﺜريةﻟﻠﺠﺪل؛ إذﺗﺠﻌﻠﻨﺎﻧﺘﺴﺎءلﻫﻞﻳﺠِﺐ أنﻧﺤﺘﻔﻆ
ﺑﻤﺼﻄﻠﺢ »اﻟﺜﻘﺔ«ﻟﻠﺤﺪﻳﺚﻋﻦ اﻟﻌﻼﻗﺎت اﻹﻧﺴﺎﻧﻴﺔ، أمﻳﻤﻜﻦ اﺳﺘﺨﺪاﻣﻪﻟﻠﺤﺪﻳﺚﻋﻦ اﻵﻻت
أﻳﻀًﺎ؟ﺗﻘﻮلﺟﻮاﻧﺎﺑﺮاﻳﺴﻮن )٨١٠٢(، اﻟﺒﺎﺣﺜﺔﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، إن اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺲﺷﻴﺌًﺎﻳﻤﻜﻦ اﻟﻮﺛﻮقﺑﻪ وﻟﻜﻨﻪﻣﺠﻤﻮﻋﺔﻣﻦﺗﻘﻨﻴﺎتﺗﻄﻮﻳﺮ اﻟﱪاﻣﺞ؛ وﻣﻦ
ﺛَﻢﻓﻬﻲﺗﻌﺘﻘﺪ أنﻣﺼﻄﻠﺢ »اﻟﺜﻘﺔ«ﻳﺠﺐ أنﻳُﺤﺘﻔَﻆﺑﻪﻟﻠﺤﺪﻳﺚﻋﻦ اﻟﺒﴩ وﻣﺆﺳﺴﺎﺗﻬﻢ
اﻻﺟﺘﻤﺎﻋﻴﺔ. وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻳُﺜريﻣﻮﺿﻮع اﻟﺸﻔﺎﻓﻴﺔ واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴريﺗﺴﺎؤﻻتٍﺣﻮلﻧﻮع
املﺠﺘﻤﻊ اﻟﺬيﻧﺮﻏﺐﰲ اﻟﻌﻴﺶﻓﻴﻪ.ﻓﻬﻨﺎﻻﻳﻜﻤُﻦ اﻟﺨﻄﺮﰲﻣﺠﺮدﺗﻼﻋُﺐ اﻟﺮأﺳﻤﺎﻟﻴني أو
اﻟﻨﺨﺐ اﻟﺘﻜﻨﻮﻗﺮاﻃﻴﺔ وﻫﻴﻤﻨﺘﻬﻢ،ﻣﻤﺎﻳﺨﻠﻖﻣﺠﺘﻤﻌًﺎﻳُﻌﺎﻧﻲﻣﻦ اﻻﻧﻘﺴﺎم إﱃﺣﺪﱟﻛﺒري. وإﻧﻤﺎ
ﻳﺘﻤﺜﻞ اﻟﺨﻄﺮ اﻷﻛﱪ ورﺑﻤﺎ اﻷﻋﻤﻖ اﻟﺬيﻳَﺤﻴﻖﺑﻨﺎﰲ أنﻧﻌﻴﺶﰲﻣﺠﺘﻤﻊٍﻋﺎﱄ اﻟﺘﻘﻨﻴﺔ،
ﻣﺠﺘﻤﻊﻻﺗﻌﻮدﻓﻴﻪﺣﺘﻰﻫﺬه اﻟﻨﺨﺐﻗﺎدرةًﻋﲆﻣﻌﺮﻓﺔﻣﺎﺗﻔﻌﻠﻪ،ﻣﺠﺘﻤﻊﻻﻳﺴﺘﻄﻴﻊﻓﻴﻪ
ﻣﺎﻳﺤﺪث.
أﺣﺪٌ أنﻳُﻔﴪﱢ
ﻛﻤﺎﺳﻨﺮى،ﻳﻘﱰحﺻﺎﻧﻌﻮ اﻟﺴﻴﺎﺳﺎتﰲﺑﻌﺾ اﻷﺣﻴﺎن »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺑﻞ
ﻟﻠﺘﻔﺴري« و»ﺣﻖ اﻟﺘﻔﺴري«. إﻻ إﻧﻨﺎﻻﻧﺪري إنﻛﺎنﻣﻦ املُﻤﻜﻦ أنﻳﻜﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺷﻔﺎﻓًﺎﻃﻮال اﻟﻮﻗﺖ.ﻳﺒﺪوﻫﺬاﺳﻬﻞَ اﻟﺘﺤﻘﻴﻖﰲ اﻷﻧﻈﻤﺔ اﻟﻜﻼﺳﻴﻜﻴﺔ. وﻟﻜﻦ إذاﺑﺪاﻣُﺴﺘﺤﻴﻼً
ﻣﻦﺣﻴﺚ املﺒﺪأﴍحﻛﻞﱢﺧﻄﻮةﰲﻋﻤﻠﻴﺔ اﺗﺨﺎذ اﻟﻘﺮار وﴍح اﻟﻘﺮارات املُﺘﻌﻠﻘﺔﺑﺄﻓﺮاد
ﻣُﺤﺪﱠدﻳﻦﻣﻊﺗﻄﺒﻴﻘﺎتﺗﻌﻠﻢ اﻵﻟﺔ املُﻌﺎﴏة،ﻓﻠﺪَﻳﻨﺎﻣﺸﻜﻠﺔ إذَن.ﻫﻞﻣﻦ املﻤﻜﻦ »ﻓﺘﺢ
اﻟﺼﻨﺪوق اﻷﺳﻮد«؟ﻗﺪﻳﻜﻮنﻫﺬاﺷﻴﺌًﺎﺟﻴﺪًا،ﻟﻴﺲﻓﻘﻂﻟﻸﺧﻼق وﻟﻜﻦ أﻳﻀًﺎﻟﺘﺤﺴني
اﻟﻨﻈﺎم )أي، اﻟﻨﻤﻮذج( واﻟﺘﻌﻠﱡﻢﻣﻨﻪ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إذاﻛﺎن اﻟﻨﻈﺎم أﻛﺜﺮﻗﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري،
وإذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳَﺴﺘﺨﺪِمﻣﺎﻧﻌﺘﱪهﺳﻤﺎتٍﻏريﻣﻼﺋﻤﺔ،ﻋﻨﺪﺋﺬٍﻳﻤﻜﻦﻟﻠﺒﴩ
اﻛﺘﺸﺎفﻫﺬه املﺸﻜﻼت واملﺴﺎﻋﺪةﰲ اﻟﻘﻀﺎءﻋﲆ اﻻرﺗﺒﺎﻃﺎت اﻟﺰاﺋﻔﺔ. وإذاﻛﺎن اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻳُﺤﺪد اﺳﱰاﺗﻴﺠﻴﺎتﺟﺪﻳﺪة ملُﻤﺎرﺳﺔﻟﻌﺒﺔٍ وﻳﺠﻌﻞﻫﺬه اﻻﺳﱰاﺗﻴﺠﻴﺎت أﻛﺜﺮ
ﺷﻔﺎﻓﻴﺔﻟﻠﺒﴩ،ﻋﻨﺪﺋﺬٍﻳﻤﻜﻦﻟﻠﺒﴩﺗﻌﻠﱡﻤﻬﺎﻣﻦ اﻵﻟﺔﻟﺘﺤﺴني أداﺋﻬﻢﰲ اﻟﻠﻌﺒﺔ. وﻫﺬاﻣُﻔﻴﺪ
ﻟﻴﺲﻓﻘﻂﰲﻣﺠﺎل اﻷﻟﻌﺎب، وﻟﻜﻦ أﻳﻀًﺎﰲﻣﺠﺎﻻتﻣِﺜﻞ اﻟﺮﻋﺎﻳﺔ اﻟﺼﺤﻴﺔ واﻟﻌﺪاﻟﺔ اﻟﺠﻨﺎﺋﻴﺔ
85</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Samek,)واﻟﻌﻠﻮم.ﻟﺬﻟﻚ،ﻳُﺤﺎولﺑﻌﺾ اﻟﺒﺎﺣﺜنيﺗﻄﻮﻳﺮﺗﻘﻨﻴﺎتﻟﻔﺘﺢ اﻟﺼﻨﺪوق اﻷﺳﻮد
(. وﻟﻜﻦ إذاﻟﻢﻳﻜﻦ ذﻟﻚﻣُﻤﻜﻨًﺎﺑﻌﺪُ أوﻛﺎنﻣُﻤﻜﻨًﺎﺑﺪرﺟﺔWiegand, and Müller 2017
ﻣﺤﺪودة،ﻓﻜﻴﻒﻟﻨﺎ أنﻧﻤﴤﻗﺪﻣًﺎ؟ﻫﻞﺗﺘﻌﻠﱠﻖ املﺸﻜﻠﺔ اﻷﺧﻼﻗﻴﺔﻫﻨﺎﺑﺎﻻﺧﺘﻴﺎرﺑني اﻷداء
(؟ وإذاﻛﺎﻧﺖﺗﻜﻠﻔﺔ إﻧﺸﺎءﻧﻈﺎم ذي أداءٍﺟﻴﺪﻫﻲﻧﻘﺺSeseri 2018)وإﻣﻜﺎﻧﻴﺔ اﻟﺘﻔﺴري
ﰲ اﻟﺸﻔﺎﻓﻴﺔ،ﻓﻬﻞﻳﺠِﺐﻋﻠﻴﻨﺎ اﺳﺘﺨﺪامﻣﺜﻞﻫﺬا اﻟﻨﻈﺎم، أمﻻ؟ أمﻳﺠﺐ أنﻧُﺤﺎولﺗﺠﻨﱡﺐ
ﻫﺬه املﺸﻜﻠﺔ واﻟﺒﺤﺚﻋﻦﺣﻠﻮلﺗﻘﻨﻴﺔ أﺧﺮى،ﺑﺤﻴﺚﺗﻜﻮنﺣﺘﻰ أﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻷﻛﺜﺮﺗﻘﺪﻣًﺎﻗﺎدرةًﻋﲆﺗﱪﻳﺮ أﻓﻌﺎﻟﻬﺎﻟﻠﺒﴩ؟ﻫﻞﻳُﻤﻜﻨﻨﺎﺗﺪرﻳﺐ اﻵﻻتﻋﲆ اﻟﻘﻴﺎمﺑﺬﻟﻚ؟
ﻋﻼوةًﻋﲆ ذﻟﻚ،ﺣﺘﻰ إذاﻛﺎﻧﺖ اﻟﺸﻔﺎﻓﻴﺔﻣﺮﻏﻮﺑﺔ وﻣُﻤﻜﻨﺔ،ﻓﻘﺪﻳﻜﻮنﻣﻦ اﻟﺼﻌﺐ
ﺗﺤﻘﻴﻘﻬﺎﻋﻤﻠﻴٍّﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، رﺑﻤﺎﻻﺗﻜﻮن اﻟﴩﻛﺎت اﻟﺨﺎﺻﺔﻋﲆ اﺳﺘﻌﺪادٍﻟﻠﻜﺸﻒ
ﻋﻦﺧﻮارزﻣﻴﺎﺗﻬﺎ؛ﻷﻧﻬﺎﺗﺮﻏﺐﰲﺣﻤﺎﻳﺔﻣﺼﺎﻟﺤﻬﺎ اﻟﺘﺠﺎرﻳﺔ.ﻛﺬﻟﻚﻗﺪﺗﺤُﻮلﻗﻮاﻧني املﻠﻜﻴﺔ
اﻟﻔﻜﺮﻳﺔ اﻟﺘﻲﺗﺤﻤﻲﺗﻠﻚ املﺼﺎﻟﺢ دون ذﻟﻚ. وﻛﻤﺎﺳﻨﺮىﰲﻓﺼﻮلﻻﺣﻘﺔ، إذاﻛﺎن اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﰲ أﻳﺪي اﻟﴩﻛﺎت اﻟﻘﻮﻳﺔ،ﻓﺈنﻫﺬاﻳُﺜري اﻟﺴﺆالﺣﻮلﻣَﻦﻳﺼﻨﻊﻗﻮاﻧني اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ وﻣَﻦﻳﺠﺐ أنﻳﺼﻨﻌﻬﺎ.
وﻣﻊ ذﻟﻚ،ﻳﺠﺐﻣﺮاﻋﺎة أن اﻟﺸﻔﺎﻓﻴﺔ واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴريﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔﻻﺗﺘﻌﻠﱠﻖ
ﺑﺎﻟﴬورةﺑﺎﻟﻜﺸﻒﻋﻦ اﻟﺮﻣﻮز اﻟﱪﻣﺠﻴﺔ، وﻫﻲﺑﺎﻟﺘﺄﻛﻴﺪﻻﺗﻘﺘﴫﻋﲆ ذﻟﻚﻓﺤﺴﺐ.
املﺴﺄﻟﺔﺗﺘﻌﻠﱠﻖ أﺳﺎﺳًﺎﺑﺘﻔﺴري اﻟﻘﺮاراتﻟﻠﺒﴩ. إﻧﻬﺎﻻﺗﺘﻌﻠﱠﻖﰲ املﻘﺎم اﻷولﺑﺘﻔﺴري »ﻛﻴﻒ
ﻳﻌﻤﻞ« وإﻧﻤﺎﺗﺘﻌﻠﱠﻖﺑﻜﻴﻒﻳُﻤﻜﻨﻨﻲ أﻧﺎ،ﺑﻮﺻﻔﻲ إﻧﺴﺎﻧًﺎﻣﻦ املﺘﻮﻗﱠﻊﻣﻨﻪ أنﻳﻜﻮنﻣﺴﺌﻮﻻً
وﻳﺘﴫﱠفﺑﻤﺴﺌﻮﻟﻴﺔ،ﺗﻔﺴريﻗﺮاري. وﻳُﻤﻜﻦ أنﺗﻜﻮنﻛﻴﻔﻴﺔﻋﻤﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،
وﻛﻴﻔﻴﺔ وﺻﻮﻟﻪ إﱃﻫﺬه اﻟﺘﻮﺻﻴﺔ،ﺟﺰءًاﻣﻦ ذﻟﻚ اﻟﺘﻔﺴري.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻓﺈن اﻟﻜﺸﻒﻋﻦ
اﻟﺮﻣﻮز اﻟﱪﻣﺠﻴﺔﺑﻤُﻔﺮدﻫﺎﻻﻳﻌﻄﻲﺑﺎﻟﴬورةﻣﻌﺮﻓﺔًﺣﻮلﻛﻴﻔﻴﺔﻋﻤﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
ﻓﻬﺬه املﻌﺮﻓﺔﺗﻌﺘﻤِﺪﻋﲆ اﻟﺨﻠﻔﻴﺔ اﻟﺘﻌﻠﻴﻤﻴﺔﻟﻺﻧﺴﺎن وﻣﻬﺎراﺗﻪ.ﻓﺈذاﻛﺎنﻳﻔﺘﻘﺮ إﱃ اﻟﺨﱪة
اﻟﺘﻘﻨﻴﺔ ذات اﻟﺼﻠﺔ،ﻓﺈﻧﻨﺎﻧﺤﺘﺎج إﱃﻧﻮعٍ آﺧَﺮﻣﻦ اﻟﺘﻔﺴري. وﻫﺬاﻻﻳُﺬﻛﱢﺮﻧﺎﻓﺤﺴﺐﺑﻤﺸﻜﻠﺔ
اﻟﺘﻌﻠﻴﻢ وﻟﻜﻨﻪﻳﺆدﱢيﺑﻨﺎ إﱃﺳﺆالٍﺣﻮلﻧﻮع اﻟﺘﻔﺴري اﻟﺬيﻧﺤﺘﺎﺟُﻪ،ﺛﻢﻣﺎﻫﻴﺔ اﻟﺘﻔﺴريﰲ
ﺣﺪﱢ ذاﺗﻪ.
وﻫﻜﺬاﺗَﻄﺮَحﻗﻀﻴﺔ اﻟﺸﻔﺎﻓﻴﺔ واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري أﻳﻀًﺎ أﺳﺌﻠﺔﻓﻠﺴﻔﻴﺔ وﻋﻠﻤﻴﺔﻣُﺜرية
(. وﻣﻤﺎﻳﺘﺄﻟﻒWeld and Bansal 2018)ﻟﻼﻫﺘﻤﺎم،ﻣﺜﻞ اﻷﺳﺌﻠﺔ املﺘﻌﻠﻘﺔﺑﻄﺒﻴﻌﺔ اﻟﺘﻔﺴري
اﻟﺘﻔﺴري اﻟﺠﻴﺪ؟ وﻣﺎ اﻟﻔﺮقﺑني اﻟﺘﻔﺴريات واﻷﺳﺒﺎب، وﻫﻞﻳﻤﻜﻦﻟﻶﻻتﺗﻘﺪﻳﻢ أيﻣﻨﻬﺎ؟
وﻛﻴﻒﻳﺘﱠﺨﺬ اﻟﺒﴩ اﻟﻘﺮاراتﰲ اﻟﻮاﻗﻊ؟ وﻛﻴﻒﻳُﱪﱢرونﻗﺮاراﺗﻬﻢ؟ﻫﻨﺎك أﺑﺤﺎثﺣﻮلﻫﺬا
86</p>
<p>ﻻﻣﺴﺌﻮﻟﻴﺔُ اﻵﻻت واﻟﻘﺮاراتﻏري املُﱪرة
املﻮﺿﻮعﰲﻋﻠﻢ اﻟﻨﻔﺲ املﻌﺮﰲ واﻟﻌﻠﻮم املﻌﺮﻓﻴﺔ، واﻟﺘﻲﻳُﻤﻜﻦ اﺳﺘﺨﺪاﻣﻬﺎﻟﻠﺘﻔﻜريﰲ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺑﻞﻟﻠﺘﻔﺴري.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻻﻳُﻘﺪم اﻟﻨﺎسﻋﻤﻮﻣًﺎﺳﻼﺳﻞﺳﺒﺒﻴﺔًﻛﺎﻣﻠﺔ؛
ﻟﻬﻢ:
وإﻧﻤﺎﻳﺨﺘﺎرونﺗﻔﺴرياتٍ وﻳﺠﻴﺒﻮنﻋﻤﺎﻳﻌﺘﻘﺪون أﻧﻬﺎﻣُﻌﺘﻘﺪات اﻟﺸﺨﺺ اﻟﺬيﻳُﻔﴪﱢ
(. ورﺑﻤﺎﻧﺘﻮﻗﻊ أﻳﻀًﺎ أنﺗﻜﻮنﺗﻔﺴريات اﻵﻻتﻣﺨﺘﻠﻔﺔMiller 2018)اﻟﺘﻔﺴريات اﺟﺘﻤﺎﻋﻴﺔ
ﻋﻦﺗﻔﺴريات اﻟﺒﴩ، اﻟﺬﻳﻦﻳُﱪرون أﻓﻌﺎﻟﻬﻢﰲﻛﺜريٍﻣﻦ اﻷﺣﻴﺎنﺑﺄﻧﻬﺎﻧﺘﻴﺠﺔﻟﻠﻌﻮاﻃﻒ.
وﻟﻜﻦ إذاﻓﻌﻠﻨﺎ ذﻟﻚ،ﻓﻬﻞﻳﻌﻨﻲﻫﺬا أﻧﻨﺎﻧﻌﺘﱪﻃﺮﻳﻘﺔ اﺗﺨﺎذ اﻵﻻتﻟﻠﻘﺮارات أﻓﻀﻞﻣﻦ
(، وإذاﻛﺎن اﻷﻣﺮﻛﺬﻟﻚ،ﻓﻬﻞﻳﺠﺐ أنDignum et al. 2018)ﻃﺮﻳﻘﺔ اﺗﺨﺎذ اﻟﺒﴩﻟﻬﺎ
ﻧﻔﻌﻞ؟ﻳﺘﺤﺪثﺑﻌﺾ اﻟﺒﺎﺣﺜنيﻋﻦ اﻻﺳﺘﺪﻻلﺑﺪﻻًﻣﻦ اﻟﺘﻔﺴري.ﺑﻞ إن وﻳﻨﻴﻜﻮف )٨١٠٢(
ﻳﻄﻠﺐ »اﻻﺳﺘﺪﻻلﺑﻨﺎءًﻋﲆ اﻟﻘِﻴَﻢ«ﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻏريهﻣﻦ اﻷﻧﻈﻤﺔ املُﺴﺘﻘﻠﺔ، اﻟﺘﻲ
ﻳﺠﺐ أنﺗﻜﻮنﻗﺎدرةًﻋﲆﺗﻤﺜﻴﻞ اﻟﻘﻴﻢ اﻟﺒﴩﻳﺔ واﻻﺳﺘﺪﻻلﺑﺎﺳﺘﺨﺪامﺗﻠﻚ اﻟﻘِﻴَﻢ. وﻟﻜﻦﻫﻞ
ﻳﻤﻜﻦﻟﻶﻟﺔ أنﺗﻘﻮمﺑﺎﻻﺳﺘﺪﻻل، وﻛﻴﻒﻳﻤﻜﻦﻟﻠﻨﻈﺎم اﻟﺘﻜﻨﻮﻟﻮﺟﻲ »اﺳﺘﺨﺪام« اﻟﻘِﻴَﻢ أو
»ﺗﻤﺜﻴﻠﻬﺎ«ﻣﻦ اﻷﺳﺎس؟ أيﻧﻮعﻣﻦ املﻌﺮﻓﺔﻳﻤﺘﻠﻜﻬﺎﻫﺬا اﻟﻨﻈﺎم؟ وﻫﻞﻳﻤﺘﻠﻚﻣﻌﺮﻓﺔﻣﻦ
اﻷﺳﺎس؟ وﻫﻞﻳﺴﺘﻄﻴﻊ اﻟﻔﻬﻢﻣﻦ اﻷﺳﺎس؟ وﻛﻤﺎﻳﺴﺄلﺑﻮدﻳﻨﺠﺘﻮن )٧١٠٢(،ﻫﻞﻳﻤﻜﻦ
ﻟﻠﺒﴩ أنﻳُﻌﱪﱢ واﺑﺸﻜﻞٍﻛﺎﻣﻞﻋﻦﻗﻴَﻤِﻬﻢ اﻟﺠﻮﻫﺮﻳﺔ؟
ﻣﺜﻞﻫﺬه املﺸﻜﻼتﻣُﺜريةﻟﻼﻫﺘﻤﺎمﻣﻦﻣﻨﻈﻮر اﻟﻔﻼﺳﻔﺔ، وﻟﻜﻨﻬﺎ أﻳﻀًﺎ ذاتﺻﻠﺔٍ
ﻣﺒﺎﴍةﺑﺎﻷﺧﻼﻗﻴﺎت،ﻛﻤﺎ أﻧﻬﺎ واﻗﻌﻴﺔ وﻋﻤﻠﻴﺔﻟﻠﻐﺎﻳﺔ. وﻛﻤﺎﻳﻘﻮلﻛﺎﺳﺘﻴﻠﻔﻴﺘﴚ )٦١٠٢(:
إنﻓﺘﺢ »اﻟﺼﻨﺪوق اﻷﺳﻮد«ﻣﺸﻜﻠﺔﰲ اﻟﻌﺎﻟَﻢ اﻟﺤﻘﻴﻘﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﺠﺐﻋﲆ اﻟﺒﻨﻮك
ﻣﺎ؛ وﻳﺠﺐﻋﲆ اﻟﻘﻀﺎةﺗﻔﺴريﺳﺒﺐ إﺻﺪار اﻷواﻣﺮﺑﺤﺒﺲ
ﺳﺒﺐ رﻓﺾﻗﺮضٍ
أنﺗُﻔﴪﱢ
ﻣﺎ )ﻣﺮةً أﺧﺮى(. إنﺗﻔﺴري اﻟﻘﺮاراتﻟﻴﺲﻓﻘﻂﺟﺰءًاﻣﻦﻃﺒﻴﻌﺔ اﻟﺒﴩﻋﻨﺪﻣﺎ
ﺷﺨﺺٍ
(،ﺑﻞﻫﻮ أﻳﻀًﺎﻣﻄﻠﺐ أﺧﻼﻗﻲ. إن اﻟﻘﺪرةﻋﲆ اﻟﺘﻔﺴريGoebel et al. 2018)ﻳﺘﻮاﺻﻠﻮن
ﴍطﴐوريﻟﻠﺴﻠﻮك واﺗﺨﺎذ اﻟﻘﺮاراتﺑﺸﻜﻞﻣﺴﺌﻮل وﻗﺎﺑﻞﻟﻠﻤﺴﺎءﻟﺔ. وﻳﺒﺪو أﻧﻪ
ﴐوريﻷيﻣﺠﺘﻤﻊﻳﺮﻏﺐﰲ اﺣﱰام اﻟﺒﴩﺑﻮﺻﻔﻬﻢ أﻓﺮادًاﻣُﺴﺘﻘﻠني اﺟﺘﻤﺎﻋﻴﱢنيﻳُﺤﺎوﻟﻮن
اﻟﺘﴫف واﺗﺨﺎذ اﻟﻘﺮاراتﺑﺸﻜﻞٍﻣﺴﺌﻮل وﰲ اﻟﻮﻗﺖﻧﻔﺴﻪﻳُﻄﺎﻟﺒﻮن،ﻋﻦ اﺳﺘﺤﻘﺎق،
ﺑﺎﻟﺤﺼﻮلﻋﲆ أﺳﺒﺎبٍﻟﻠﻘﺮارات اﻟﺘﻲﺗﺆﺛﺮﻋﻠﻴﻬﻢ وﺗﻔﺴرياتﻟﻬﺎ. وﺳﻮاءٌ أﻛﺎنﺑﺈﻣﻜﺎن
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﻮﻓريﺗﻠﻚ اﻷﺳﺒﺎب واﻟﺘﻔﺴريات »ﻣﺒﺎﴍةً« أمﻻ،ﻓﺈن اﻟﺒﴩﻻﺑﺪ أن
ﻳﻜﻮﻧﻮاﻗﺎدرﻳﻦﻋﲆ اﻹﺟﺎﺑﺔﻋﻨﺪﺳﺆاﻟﻬﻢﻋﻦ اﻷﺳﺒﺎب. إن اﻟﺘﺤﺪي اﻟﺬيﻳﻮاﺟِﻪ اﻟﺒﺎﺣﺜني
ﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻮﺿﻤﺎن أﻧﻪﰲﺣﺎل اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻷﻏﺮاض
اﺗﺨﺎذ اﻟﻘﺮاراتﻣﻦ اﻷﺳﺎس،ﻓﻴﺠﺐﺗﺼﻤﻴﻢ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺑﺤﻴﺚﻳﺘﻤﻜﻦ اﻟﺒﴩﻗﺪْر اﻹﻣﻜﺎن
ﻣﻦ اﻹﺟﺎﺑﺔﻋﻨﺪﺳﺆاﻟﻬﻢﻋﻦ أﺳﺒﺎب اﺗﺨﺎذﺗﻠﻚ اﻟﻘﺮارات.
87</p>
</section>
<section id="section-10">
    <h2>التحيز ومعنى الحياة</h2>
    <div class="page-range">Pages 89-100</div>
    <p>اﻟﻔﺼﻞ اﻟﺘﺎﺳﻊ
اﻟﺘﺤﻴﺰ وﻣﻌﻨﻰ اﳊﻴﺎة
اﻟﺘﺤﻴﺰ
ﻳُﻌﺪ اﻟﺘﺤﻴﱡﺰﻣﺸﻜﻠﺔً أﺧﺮىﻣﻦ املﺸﻜﻼت ذات اﻟﺠﻮاﻧﺐ اﻷﺧﻼﻗﻴﺔ واﻻﺟﺘﻤﺎﻋﻴﺔﰲ اﻟﻮﻗﺖ
ﻧﻔﺴﻪ، وﻫﻲ أﻳﻀًﺎﺗﺘﻌﻠﱠﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺋﻢﻋﲆﻋِﻠﻢ اﻟﺒﻴﺎﻧﺎتﺑﻌﻴﺪًاﻋﻦﻏريهﻣﻦ
ﺗﻘﻨﻴﺎت اﻷﺗﻤﺘﺔ اﻷﺧﺮى.ﻋﻨﺪﻣﺎﻳﺘﱠﺨﺬ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ — أوﻋﲆ اﻷﺣﺮى،ﻋﻨﺪﻣﺎﻳُﻮﴆ
ﺑﺎﺗﺨﺎذ —ﻗﺮارات،ﻗﺪﻳُﻈﻬﺮ اﻟﺘﺤﻴﱡﺰ؛ إذﻗﺪﺗﻜﻮن اﻟﻘﺮاراتﻏريﻣﻨﺼﻔﺔٍ أوﻏريﻋﺎدﻟﺔﺗﺠﺎه
أﻓﺮادٍ أوﻣﺠﻤﻮﻋﺎتﺑﻌﻴﻨﻬﺎ. وﻋﲆ اﻟﺮﻏﻢﻣﻦ أن اﻟﺘﺤﻴﱡﺰﻗﺪﻳﻈﻬﺮ أﻳﻀًﺎﻋﻨﺪ اﺳﺘﺨﺪام اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻟﺘﻘﻠﻴﺪي —ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻧﻈﺎمﺧﺒريﻳَﺴﺘﺨﺪمﺷﺠﺮة اﺗﺨﺎذﻗﺮارات أو
ﻗﺎﻋﺪةﺑﻴﺎﻧﺎتﺗﺘﺴﻢﺑﺎﻟﺘﺤﻴﺰ —ﻓﺈنﻗﻀﻴﺔ اﻟﺘﺤﻴﺰﻏﺎﻟﺒًﺎﻣﺎﺗﻜﻮنﻣﺮﺗﺒﻄﺔًﺑﺘﻄﺒﻴﻘﺎتﺗﻌﻠﱡﻢ
اﻵﻟﺔ. وﺑﻴﻨﻤﺎﻛﺎﻧﺖﻣﺸﻜﻼت اﻟﺘﺤﻴﺰ واﻟﺘﻤﻴﻴﺰﻣﻮﺟﻮدة داﺋﻤًﺎﰲ املﺠﺘﻤﻊ، إﻻ أن اﻟﻘﻠﻖﻳﻜﻤُﻦ
ﰲ أنﻳﺆدي اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃ اﺳﺘﻤﺮارﻫﺬه املﺸﻜﻼت وﺗﻔﺎﻗُﻢ آﺛﺎرﻫﺎ.
ﺑﻴﻨﻤﺎﻛﺎﻧﺖﻣﺸﻜﻼت اﻟﺘﺤﻴﱡﺰ واﻟﺘﻤﻴﻴﺰﻣﻮﺟﻮدةً داﺋﻤًﺎﰲ املﺠﺘﻤﻊ، إﻻ أن اﻟﻘﻠﻖﻳﻜﻤُﻦﰲ أنﻳﺆدي
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃ اﺳﺘﻤﺮارﻫﺬه املﺸﻜﻼت وﺗﻔﺎﻗُﻢ آﺛﺎرﻫﺎ.
ﻏﺎﻟﺒًﺎﻣﺎﻳﻜﻮن اﻟﺘﺤﻴﱡﺰﻏريﻣﻘﺼﻮد؛ﻓﺎملُﻄﻮﱢرون واملﺴﺘﺨﺪِﻣﻮن، وﻏريﻫﻢﻣﻦ أﻃﺮاف
ﻣُﻌﻨﻴﺔﻣﺜﻞ إدارة اﻟﴩﻛﺔ،ﻻﻳﺘﻮﻗﻌﻮن،ﰲﻛﺜريٍﻣﻦ اﻷﺣﻴﺎن، آﺛﺎر اﻟﺘﻤﻴﻴﺰﺿﺪﱠﻣﺠﻤﻮﻋﺎت أو
أﻓﺮادٍﻣُﻌﻴﻨني. وﻳﻤﻜﻦ أنﻳﻜﻮن اﻟﺴﺒﺐﰲ ذﻟﻚﻫﻮﻋﺪمﻓﻬﻤﻬﻢﻧﻈﺎم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻛﻤﺎﻳﻨﺒﻐﻲ، أوﻋﺪم وﻋﻴِﻬﻢﺑﺸﻜﻞٍﻛﺎفٍﺑﻤﺸﻜﻠﺔ اﻟﺘﺤﻴﱡﺰ أوﺣﺘﻰﺑﺘﺤﻴﱡﺰاﺗﻬﻢ اﻟﺸﺨﺼﻴﺔ،</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
أوﺑﺸﻜﻞٍﻋﺎمﻋﺪمﺗﺼﻮﱡرﻫﻢ وﻋﺪمﺗﻔﻜريﻫﻢﺑﻤﺎﻓﻴﻪ اﻟﻜﻔﺎﻳﺔﰲ اﻟﻌﻮاﻗﺐ املُﺤﺘﻤَﻠﺔﻏري
املﻘﺼﻮدةﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻋﺪمﺗﻮاﺻُﻠﻬﻢﻣﻊﺑﻌﺾ اﻷﻃﺮاف ذات اﻟﺼﻠﺔ.ﻳُﻌَﺪﻫﺬا أﻣﺮًا
إﺷﻜﺎﻟﻴٍّﺎﻧﻈﺮًا إﱃ أن اﻟﻘﺮارات املُﺘﺤﻴﱢﺰةﻳﻤﻜﻦ أنﺗﻜﻮنﻟﻬﺎﻋﻮاﻗﺐ وﺧﻴﻤﺔ،ﻋﲆﺳﺒﻴﻞ
(؛ إذﻗﺪﻻﻳﺤﺼﻞCDT 2018)املﺜﺎل،ﻣﻦﺣﻴﺚ اﻟﻮﺻﻮل إﱃ املﻮارد واﻟﺘﻤﺘﱡﻊﺑﺎﻟﺤﺮﻳﺎت
اﻷﻓﺮادﻋﲆ وﻇﻴﻔﺔ، أوﻻﻳﺘﻤﻜﱠﻨﻮنﻣﻦ اﻟﺤﺼﻮلﻋﲆ اﺋﺘﻤﺎن، أوﻗﺪﻳﻨﺘﻬﻲﺑﻬﻢ اﻟﺤﺎلﰲ
ﻋﲆ اﻷﻓﺮادﻓﺤﺴﺐ؛ إذﻗﺪﺗﺘﺄﺛﺮ
اﻟﺴﺠﻦ، أوﺣﺘﻰﻳﺘﻌﺮﱠﺿﻮنﻟﻠﻌﻨﻒ. واملُﻌﺎﻧﺎةﻻﺗﻘﺘﴫِ
ﻣﺠﺘﻤﻌﺎتﺑﺄﴎِﻫﺎﺑﺎﻟﻘﺮارات املُﺘﺤﻴﺰة،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪﻣﺎﺗُﺼﻨﱠﻒﻣﻨﻄﻘﺔﻛﺎﻣﻠﺔﰲ
املﺪﻳﻨﺔ أوﺟﻤﻴﻊ اﻷﺷﺨﺎصﻣﻤﱠﻦﻟﻬﻢﺧﻠﻔﻴﺔﻋﺮﻗﻴﺔﻣُﻌﻴﱠﻨﺔﺑﻮاﺳﻄﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆ
أﻧﻬﻢﻳﺸﻜﻠﻮنﺧﻄﻮرةً أﻣﻨﻴﺔﻋﺎﻟﻴﺔ.
وﻟﻨﻌُﺪﻣﺮﱠة أﺧﺮى إﱃﻣﺜﺎلﺧﻮارزﻣﻴﺔﻛﻮﻣﺒﺎس اﻟﺬيﺗﺤﺪﱠﺛﻨﺎﻋﻨﻪﰲ اﻟﻔﺼﻞ اﻷول،
ﺗﻠﻚ اﻟﺨﻮارزﻣﻴﺔ اﻟﺘﻲﺗﺘﻨﺒﱠﺄﺑﻤﺪى اﺣﺘﻤﺎﻟﻴﺔ أنﻳﻘﻮم املُﺪﱠﻋﻰﻋﻠﻴﻪﺑﺈﻋﺎدة ارﺗﻜﺎب اﻟﺠﺮﻳﻤﺔ
وﻛﺎن اﻟﻘﻀﺎةﰲﻓﻠﻮرﻳﺪاﻳﺴﺘﺨﺪﻣﻮﻧﻬﺎﰲ اﺗﺨﺎذﻗﺮاراﺗﻬﻢﺑﺸﺄن إﻣﻜﺎﻧﻴﺔﻣﻨﺢ اﻟﺴﺠني
إﻓﺮاﺟًﺎﻣﴩوﻃًﺎ. وﻓﻘًﺎﻟﺪراﺳﺔٍ أﺟﺮَﺗْﻬﺎ »ﺑﺮوﺑﺎﺑﻠﻴﻜﺎ«، وﻫﻲﻏﺮﻓﺔ إﺧﺒﺎرﻳﺔﻋﱪ اﻹﻧﱰﻧﺖ،
ﻛﺎﻧﺖ اﻟﻨﺘﺎﺋﺞ اﻹﻳﺠﺎﺑﻴﺔ اﻟﻜﺎذﺑﺔﻟﻠﺨﻮارزﻣﻴﺔ )املُﺪﱠﻋﻰﻋﻠﻴﻬﻢ اﻟﺬﻳﻦﺗﻮﻗﻌﺖ اﻟﺨﻮارزﻣﻴﺔ أن
ﻳُﻌﻴﺪوا ارﺗﻜﺎب اﻟﺠﺮاﺋﻢ وﻟﻜﻨﻬﻢﰲ اﻟﻮاﻗﻊﻟﻢﻳﻔﻌﻠﻮا(ﺗﻤﻴﻞﺑﺸﻜﻞٍﻣُﻔﺮِط إﱃ اﻷﺷﺨﺎص
ﻣﻦ ذوي اﻟﺒﴩة اﻟﺴﻤﺮاء، وﻛﺎﻧﺖ اﻟﻨﺘﺎﺋﺞ اﻟﺴﻠﺒﻴﺔ اﻟﻜﺎذﺑﺔ )املُﺪﱠﻋﻰﻋﻠﻴﻬﻢ اﻟﺬﻳﻦﺗﻮﻗﻌﺖ
اﻟﺨﻮارزﻣﻴﺔ أﻻﻳُﻌﻴﺪوا ارﺗﻜﺎب اﻟﺠﺮاﺋﻢ وﻟﻜﻨﻬﻢﰲ اﻟﻮاﻗﻊﻓﻌﻠﻮا(ﺗﻤﻴﻞﺑﺸﻜﻞٍﻣُﻔﺮط إﱃ
(. وﻣِﻦﺛَﻢ رأى اﻟﻨﻘﱠﺎد أنﻫﻨﺎكﺗﺤﻴﱡﺰًاﺿﺪFry 2018)اﻷﺷﺨﺎص ذوي اﻟﺒﴩة اﻟﺒﻴﻀﺎء
املُﺪﱠﻋﻰﻋﻠﻴﻬﻢﻣﻦ ذوي اﻟﺒﴩة اﻟﺴﻤﺮاء.ﻣﺜﺎل آﺧَﺮﻋﲆ ذﻟﻚﻫﻮ أداة »ﺑﺮﻳﺪﺑﻮل«، وﻫﻲ
أداةﻟﻠﺘﻨﺒﱡﺆﺑﺎﻟﺠﺮاﺋﻢ وﻗﺪ اﺳﺘُﺨﺪِﻣَﺖﰲ اﻟﻮﻻﻳﺎت املﺘﺤﺪةﻟﺘﻮﻗﱡﻊ اﺣﺘﻤﺎﻟﻴﺔﺣﺪوثﺟﺮﻳﻤﺔٍ
ﰲﻣﻨﺎﻃﻖﻣُﻌﻴﱠﻨﺔﻣﻦ املﺪن وﻟﻠﺘﻮﺻﻴﺔﺑﺘﺨﺼﻴﺺﻣﻮارد اﻟﴩﻃﺔ )ﻋﲆﺳﺒﻴﻞ املﺜﺎل، أﻳﻦ
ﻳﺠﺐ أنﻳُﺠﺮيﺿﺒﺎط اﻟﴩﻃﺔﻋﻤﻠﻴﺎت اﻟﺘﻔﺘﻴﺶ واﻟﺘﺠﻮال( اﺳﺘﻨﺎدًا إﱃﻫﺬه اﻟﺘﻮﻗﱡﻌﺎت.
وﺗﺮﻛﺰت املﺨﺎوفﰲﻫﺬا اﻟﺼﺪدﰲ أنﻳﻜﻮن اﻟﻨﻈﺎمﻣُﺘﺤﻴﺰًاﺿﺪ اﻷﺣﻴﺎء اﻟﻔﻘرية وأﺣﻴﺎء
املُﻠﻮﱠﻧني أو أنﺗﺆدي املﺮاﻗﺒﺔ اﻷﻣﻨﻴﺔ املُﻔﺮﻃﺔ إﱃﻛﴪ اﻟﺜﻘﺔﺑني اﻟﻨﺎسﰲﺗﻠﻚ املﻨﺎﻃﻖ،ﻣﻤﺎ
(.Kelleher and Tierney 2018)ﻳُﺤَﻮﱢلﺗﻮﻗﻊﺣﺪوث اﻟﺠﺮﻳﻤﺔ إﱃﻧﺒﻮءةٍﺗﺘﺤﻘﱠﻖ ذاﺗﻴٍّﺎ
ﻋﲆ اﻟﻌﺪاﻟﺔ اﻟﺠﻨﺎﺋﻴﺔ أو املُﺮاﻗﺒﺔ اﻷﻣﻨﻴﺔ؛ﺑﻞﻳُﻤﻜﻦ أنﻳﻌﻨﻲ أﻳﻀًﺎ،
وﻟﻜﻦ اﻟﺘﺤﻴﱡﺰﻻﻳﻘﺘﴫِ
ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗﻌﺮﱡضﻣُﺴﺘﺨﺪﻣﻲﺧﺪﻣﺎت اﻹﻧﱰﻧﺖﻟﺘﺤﻴﺰاتٍﺿﺪﱠﻫﻢ إذاﺻﻨﱠﻔﻬﻢ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﺗﺼﻨﻴﻔًﺎﺳﻴﺌًﺎ.
90</p>
<p>اﻟﺘﺤﻴﺰ وﻣﻌﻨﻰ اﻟﺤﻴﺎة
ﻗﺪﻳﻨﺸﺄ اﻟﺘﺤﻴﱡﺰﺑﻌﺪﱠةﻃﺮُقٍﰲﺟﻤﻴﻊﻣﺮاﺣﻞ اﻟﺘﺼﻤﻴﻢ واﻻﺧﺘﺒﺎر واﻟﺘﻄﺒﻴﻖ. وإذاﻣﺎ
رﻛﱠﺰﻧﺎﻋﲆﻣﺮﺣﻠﺔ اﻟﺘﺼﻤﻴﻢ،ﻓﺴﻨﺠﺪ أن اﻟﺘﱠﺤﻴﱡﺰﻗﺪﻳﻈﻬﺮﰲ اﺧﺘﻴﺎرﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت
اﻟﺘﻲﺳﻴﺘﻢ اﻟﺘﺪرﻳﺐﻋﻠﻴﻬﺎ؛ وﰲﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﺳﻴﺘﻢ اﻟﺘﺪرﻳﺐﻋﻠﻴﻬﺎﻧﻔﺴﻬﺎ،
واﻟﺘﻲﻗﺪﺗﻜﻮنﻏريﻣُﻤﺜﻠﺔ أوﻏريﻛﺎﻣﻠﺔ، وﰲ اﻟﺨﻮارزﻣﻴﺔ، وﰲﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲ
ﻳﺘﻢ إدﺧﺎﻟﻬﺎ إﱃ اﻟﺨﻮارزﻣﻴﺔﺑﻌﺪﺗﺪرﻳﺒﻬﺎ، وﰲ اﻟﻘﺮارات اﻟﻘﺎﺋﻤﺔﻋﲆ اﻻرﺗﺒﺎﻃﺎت اﻟﺰاﺋﻔﺔ
)اﻧﻈﺮ اﻟﻔﺼﻞ اﻟﺴﺎﺑﻖ(، وﰲ املﺠﻤﻮﻋﺔ اﻟﺘﻲﺗُﻨﺸﺊ اﻟﺨﻮارزﻣﻴﺔ، وﰲ املﺠﺘﻤﻊ اﻷوﺳَﻊ.ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﻻﺗﻜﻮنﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎتﻣُﻤﺜﱢﻠﺔﻟﻠﺴﻜﺎن )ﻛﺄنﺗﻜﻮنﻣَﺒﻨﻴﺔﻋﲆ رﺟﺎلٍ
أﻣﺮﻳﻜﻴنيﺑﻴﺾ( وﻟﻜﻨﻬﺎﺗُﺴﺘﺨﺪَمﻟﻠﺘﻨﺒﺆﻣﻊ اﻟﺴﻜﺎنﻛﻜﻞﱟ )اﻟﺮﺟﺎل واﻟﻨﺴﺎءﻣﻦﺧﻠﻔﻴﺎت
ﻋﺮﻗﻴﺔﻣُﺘﻨﻮﱢﻋﺔ(.ﻳﻤﻜﻦ أﻳﻀًﺎ أنﻳﻜﻮن اﻟﺘﺤﻴﱡﺰﻣُﺘﻌﻠﱢﻘًﺎﺑﺎﻻﺧﺘﻼﻓﺎتﺑني اﻟﺒﻠﺪان.ﻓﻜﺜريﻣﻦ
اﻟﺸﺒﻜﺎت اﻟﻌﺼﺒﻴﺔ اﻟﻌﻤﻴﻘﺔ املُﺴﺘﺨﺪﻣﺔﰲ اﻟﺘﻌﺮﱡفﻋﲆ اﻟﺼﻮرﺗُﺪرﱠبﻋﲆﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت
، اﻟﺘﻲﺗﺤﺘﻮيﻋﲆﻛﻤﻴﺔٍﻏريﻣﺘﻜﺎﻓﺌﺔﻣﻦ اﻟﺒﻴﺎﻧﺎتﻣﻦImageNet «املُﺤَﺪﱠدة »إﻳﻤﺪﺟﻨﺖ
اﻟﻮﻻﻳﺎت املﺘﺤﺪة،ﰲﺣني أنﺑﻠﺪانﻣﺜﻞ اﻟﺼني واﻟﻬﻨﺪ، اﻟﻠﱠﺘنيﺗُﻤﺜﻼنﺟﺰءًا أﻛﱪﺑﻜﺜريٍﻣﻦ
(. وﻫﺬاﻗﺪZou and Schiebinger 2018)ﺳﻜﺎن اﻟﻌﺎﻟﻢ،ﺗُﺴﻬﻤﺎنﺑﻨﺴﺒﺔﺻﻐريةﻓﻘﻂ
ﻳﺆدي إﱃﺗﺤﻴﱡﺰﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎتﺛﻘﺎﻓﻴٍّﺎ. وﺑﺸﻜﻞٍﻋﺎم،ﻳﻤﻜﻦ أنﺗﻜﻮنﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت
ﻏريَﻛﺎﻣﻠﺔٍ أو ذاتﺟﻮدة ردﻳﺌﺔ،ﻣﻤﺎﻗﺪﻳﺆدي إﱃ وﺟﻮدﺗﺤﻴﱡﺰ.ﻛﺬﻟﻚﻗﺪﻳﻜﻮن اﻟﺘﻨﺒﱡﺆﻣَﺒﻨﻴٍّﺎ
ﻋﲆﻗﺪْرٍﺿﺌﻴﻞﻣﻦ اﻟﺒﻴﺎﻧﺎت،ﻋﲆﺳﺒﻴﻞ املﺜﺎلﰲﺣﺎﻟﺔ اﻟﺘﻨﺒﱡﺆﺑﺠﺮاﺋﻢ اﻟﻘﺘﻞ:ﺣﻴﺚﻻﻳُﻮﺟَﺪ
ﻫﺬا اﻟﻜﻢ اﻟﻜﺒريﻣﻦﺟﺮاﺋﻢ اﻟﻘﺘﻞ،ﻣﻤﺎﻳﺠﻌﻞ اﻟﺘﻌﻤﻴﻢ أﻣﺮًا إﺷﻜﺎﻟﻴٍّﺎ.ﻛﻤﺜﺎلٍ آﺧﺮ،ﻳﺸﻌﺮ
ﺑﻌﺾ اﻟﺒﺎﺣِﺜنيﺑﺎﻟﻘﻠﻖ إزاءﻧﻘﺺ اﻟﺘﻨﻮﱡعﰲﻓِﺮقﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت؛
ﺣﻴﺚﻳﻜﻮنﻣﻌﻈﻢﻋﻠﻤﺎء اﻟﻜﻤﺒﻴﻮﺗﺮ وﻣﻬﻨﺪﳼ اﻟﻜﻤﺒﻴﻮﺗﺮ رﺟﺎﻻًﺑِﻴﻀًﺎﻣﻦ اﻟﺒﻠﺪان اﻟﻐﺮﺑﻴﺔ
ﺗﱰاوَح أﻋﻤﺎرﻫﻢﻣﺎﺑني ٠٢ﻋﺎﻣًﺎ و٠٤ﻋﺎﻣًﺎ، وﻗﺪﺗﻨﻌﻜﺲﺗﺠﺎرﺑﻬﻢ اﻟﺸﺨﺼﻴﺔ وآراؤﻫﻢ،
وﺑﺎﻟﺘﺄﻛﻴﺪﺗﺤﻴﱡﺰاﺗﻬﻢﰲ اﻟﻌﻤﻠﻴﺔ، وﻫﻮﻣﺎﻗﺪﻳﺆﺛﺮﺳﻠﺒًﺎﻋﲆ اﻷﺷﺨﺎص اﻟﺬﻳﻦﻻﺗﻨﻄﺒﻖ
ﻋﻠﻴﻬﻢﻫﺬه اﻷوﺻﺎف،ﻣﺜﻞ اﻟﻨﺴﺎء، واﻷﺷﺨﺎص ذوي اﻹﻋﺎﻗﺔ، وﻛﺒﺎر اﻟﺴﻦ، واﻷﺷﺨﺎص
املُﻠﻮﻧني، واﻷﺷﺨﺎصﻣﻦ اﻟﺒﻠﺪان اﻟﻨﺎﻣﻴﺔ.
ﻗﺪﺗﻜﻮن اﻟﺒﻴﺎﻧﺎتﻣُﺘﺤﻴﺰة أﻳﻀًﺎﺿﺪﻣﺠﻤﻮﻋﺎتٍﻣُﻌﻴﻨﺔ؛ﻷنﻫﻨﺎكﺗَﺤﻴﱡﺰًاﰲﻣُﻤﺎرﺳﺔٍ
ﻣﻌﻴﻨﺔﺑﺸﻜﻞٍﺧﺎص أوﰲ املﺠﺘﻤﻊﺑﺸﻜﻞٍﻋﺎم.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺛﻤﺔ ادﻋﺎءاتﺑﺄنﻣﺠﺎل
اﻟﻄﺐﻳَﺴﺘﺨﺪِمﺑﺸﻜﻞٍ رﺋﻴﴘﺑﻴﺎﻧﺎتٍﻣﻦ املﺮﴇ اﻟﺬﻛﻮر، وﺑﺎﻟﺘﺎﱄﻓﺈﻧﻪﻣُﺘﺤﻴﱢﺰ،ﻛﺬﻟﻚ
ﻫﻨﺎك اﻟﺘﺤﻴﱡﺰﺿﺪ اﻷﺷﺨﺎص املُﻠﻮﱠﻧني وﻫﻮﻳُﻌﺘﱪﺳﺎﺋﺪًاﰲ املﺠﺘﻤﻊﺑﺸﻜﻞٍ أوﺳﻊ. إذاﻛﺎﻧﺖ
اﻟﺨﻮارزﻣﻴﺔﺗﺴﺘﺨﺪِمﻣﺜﻞﻫﺬه اﻟﺒﻴﺎﻧﺎت،ﻓﺈن اﻟﻨﺘﺎﺋﺞﺳﺘﻜﻮن أﻳﻀًﺎﻣُﺘﺤﻴﺰة. وﻛﻤﺎ ورد
91</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﰲﻣﻘﺎلﻣﺠﻠﺔ »ﻧﻴﺘﴩ« اﻻﻓﺘﺘﺎﺣﻲﻋﺎم ٦١٠٢: اﻟﺘﺤﻴﱡﺰﰲ املﺪﺧﻼتﻳﺆدي إﱃﺗﺤﻴﱡﺰﰲ
املُﺨﺮﺟﺎت. وﻗﺪﺗﺒني أﻳﻀًﺎ أنﺗﻌﻠﱡﻢ اﻵﻟﺔﻳﻤﻜﻦ أنﻳﻜﺘﺴِﺐﺳﻤﺎتِ اﻟﺘﺤﻴﱡﺰﻣﻦﺧﻼل
اﺳﺘﺨﺪام اﻟﺒﻴﺎﻧﺎت اﻟﻨﺼﻴﱠﺔﻣﻦﺷﺒﻜﺔ اﻟﻮﻳﺐ اﻟﻌﺎملﻴﺔ،ﺣﻴﺚﺗﻌﻜﺲﻫﺬه اﻟﺒﻴﺎﻧﺎت اﻟﻠﻐﻮﻳﺔ
Caliskan, Bryson, and Narayanan)اﻟﺜﻘﺎﻓﺔ اﻹﻧﺴﺎﻧﻴﺔ اﻟﻴﻮﻣﻴﺔ،ﺑﻤﺎﻓﻴﻬﺎﻣﻦﺗﺤﻴﺰات
(.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﺗﺤﺘﻮيﻣﺘﻮن اﻟﻠﻐﺎتﻧﻔﺴﻬﺎﻋﲆﺗﺤﻴﺰاتﺟﻨﺴﻴﺔ. واملُﺜري2017
ﻟﻠﻘﻠﻖﰲﻫﺬه اﻟﺤﺎﻟﺔ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ رﺑﻤﺎﻳﺴﺎﻋﺪﰲ اﺳﺘﻤﺮارﻫﺬه اﻟﺘﺤﻴﱡﺰات،ﻣﻤﺎ
ﻳﴬﱡﺑﺸﻜﻞٍ أﻛﱪ اﻟﺠﻤﺎﻋﺎت اﻟﺘﻲﻛﺎﻧﺖﺗُﻌﺎﻧﻲﻣﻦ اﻟﺘﻬﻤﻴﺶ داﺋﻤًﺎ.ﻳﻤﻜﻦ أﻳﻀًﺎ أنﻳﻈﻬﺮ
اﻟﺘﺤﻴﺰ إذاﻛﺎنﻫﻨﺎك ارﺗﺒﺎط وﻟﻜﻦﻻﻳﻮﺟﺪﺳﺒﺐ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﻣﺠﺎل اﻟﻌﺪاﻟﺔ
اﻟﺠﻨﺎﺋﻴﺔﻣﺮة أﺧﺮى:ﻗﺪﺗﺴﺘﻨﺘﺞ اﻟﺨﻮارزﻣﻴﺔ أﻧﻪ إذاﻛﺎن أﺣﺪ واﻟﺪَي املُﺪﱠﻋﻰﻋﻠﻴﻪﻗﺪ أُودِع
اﻟﺴﺠﻦ،ﻓﺈنﻫﺬا املُﺪﱠﻋﻰﻋﻠﻴﻪﻣﻦ املُﺮﺟﱠﺢ أنﻳُﻮدَع اﻟﺴﺠﻦ أﻳﻀًﺎ.ﺣﺘﻰﻟﻮﻛﺎنﻫﺬا اﻻرﺗﺒﺎط
ﻗﺎﺋﻤًﺎ وﺣﺘﻰﻟﻮﻛﺎن اﻻﺳﺘﻨﺘﺎجﺗﻨﺒﺆﻳٍّﺎ،ﻳﺒﺪو أﻧﻪﻣﻦﻏري اﻟﻌﺪل أنﻳﺤﺼﻞﻫﺬا املُﺪﱠﻋﻰ
(.House of Commons 2018)ﻋﻠﻴﻪﻋﲆﻋﻘﻮﺑﺔ أﺷﺪ؛ﻧﻈﺮًا إﱃﻋﺪم وﺟﻮدﻋﻼﻗﺔﺳﺒﺒﻴﺔ
وأﺧريًا،ﻳﻤﻜﻦ أﻳﻀًﺎ أنﻳﻨﺸﺄ اﻟﺘﺤﻴﱡﺰﺑﺴﺒﺐ أنﺻﺎﻧﻌﻲ اﻟﻘﺮاراتﻣﻦ اﻟﺒﴩﻳﺜﻘﻮنﰲ دﻗﺔ
( وﻳﺘﺠﺎﻫﻠﻮن املﻌﻠﻮﻣﺎت اﻷﺧﺮى أوCDT 2018)ﺗﻮﺻﻴﺎت اﻟﺨﻮارزﻣﻴﺎت أﻛﺜﺮﻣﻤﺎﻳﻨﺒﻐﻲ
ﻻﻳﻌﺘﻤِﺪونﻋﲆﺣُﻜﻤﻬﻢ اﻟﺸﺨﴢﺑﻤﺎﻓﻴﻪ اﻟﻜﻔﺎﻳﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﻳﻌﺘﻤﺪ اﻟﻘﺎﴈ
اﻋﺘﻤﺎدًاﻛﻠﻴٍّﺎﻋﲆ اﻟﺨﻮارزﻣﻴﺔ وﻻﻳﺄﺧﺬﰲ اﻋﺘﺒﺎره اﻟﻌﻨﺎﴏ اﻷﺧﺮى. وﻛﻤﺎﻫﻮ اﻟﺤﺎل داﺋﻤًﺎ
ﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻏريهﻣﻦﺗﻘﻨﻴﺎت اﻷﺗﻤﺘﺔ،ﺗﻠﻌﺐ اﻟﻘﺮارات واﻟﺘﻔﺴريات اﻟﺒﴩﻳﺔ
دورًاﻣﻬﻤٍّﺎ، وﻫﻨﺎك داﺋﻤًﺎﺧﻄﺮ اﻻﻋﺘﻤﺎد اﻟﺰاﺋﺪﻋﲆ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ.
وﻣﻊ ذﻟﻚ،ﻟﻴﺲﻣِﻦ اﻟﻮاﺿﺢﻣﺎ إذاﻛﺎنﻣﻦ املُﻤﻜﻦﺗﺠﻨﱡﺐ اﻟﺘﺤﻴﱡﺰﻣﻦ اﻷﺳﺎس، أو
ﺣﺘﻰﻣﺎ إذاﻛﺎنﻳﺠﺐﺗﺠﻨﱡﺒﻪ،ﻓﺈذاﻛﺎنﻣﻦ اﻟﻮاﺟﺐﺗﺠﻨﱡﺒﻪ،ﻓﻤﺎ اﻟﺘﻜﻠﻔﺔ اﻟﺘﻲﻳﻤﻜﻦﺗﺤﻤﱡﻠﻬﺎ
ﰲﺳﺒﻴﻞ ذﻟﻚ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إذاﻛﺎنﺗﻐﻴريﺧﻮارزﻣﻴﺔﺗﻌﻠﻢ اﻵﻟﺔﻟﺘﻘﻠﻴﻞ اﺣﺘﻤﺎﻻت
اﻟﺘﺤﻴﱡﺰﺳﻴﻜﻮنﻋﲆﺣﺴﺎبﺟﻌﻞﺗﻮﻗﻌﺎﺗﻬﺎ أﻗﻞ دﻗﱠﺔ،ﻓﻬﻞﻳﺠﺐﻋﻠﻴﻨﺎﺗﻐﻴريﻫﺎ؟ﻗﺪﻧُﻀﻄﺮ
إﱃ اﻻﺧﺘﻴﺎرﻣﺎﺑنيﻓﻌﺎﻟﻴﺔ اﻟﺨﻮارزﻣﻴﺔﻣﻦﻧﺎﺣﻴﺔ وﻣﻜﺎﻓﺤﺔ اﻟﺘﺤﻴﱡﺰﻣﻦﻧﺎﺣﻴﺔٍ أﺧﺮى.ﻫﻨﺎك
أﻳﻀًﺎﻣﺸﻜﻠﺔﰲ أﻧﻪ إذاﺗﻢﱠﺗﺠﺎﻫﻞﺳﻤﺎتﻣُﻌﻴﻨﺔ أوﺗﺠﺎﻫﻠﻬﺎﻣﺜﻞ اﻟﻌﺮق،ﻓﺈن أﻧﻈﻤﺔﺗﻌﻠﱡﻢ
اﻵﻟﺔﻗﺪﺗُﺤﺪدﻣﺎﻳﻌﺮفﺑﻤﺆﴍاتﻫﺬه اﻟﺴﻤﺎت،ﻣﻤﺎﻳﺆدي أﻳﻀًﺎ إﱃ اﻟﺘﺤﻴﱡﺰ.ﻋﲆﺳﺒﻴﻞ
املﺜﺎل،ﰲﺣﺎﻟﺔ اﻟﻌِﺮق،ﻗﺪﻳﻜﻮنﻣﻦ املُﻤﻜﻦ أنﺗﺨﺘﺎر اﻟﺨﻮارزﻣﻴﺔﻣُﺘﻐريات أﺧﺮىﻣﺮﺗﺒﻄﺔ
ﺑﺎﻟﻌِﺮقﻣﺜﻞ اﻟﺮﻣﺰ اﻟﱪﻳﺪي. وﻫﻞﻣﻦ املﻤﻜﻦ وﺟﻮدﺧﻮارزﻣﻴﺔﺧﺎﻟﻴﺔﺗﻤﺎﻣًﺎﻣﻦ اﻟﺘﺤﻴﺰ؟ﻻ
ﻳُﻮﺟَﺪﺗﻮاﻓﻖﺑني اﻟﻔﻼﺳﻔﺔ أوﺣﺘﻰﰲ املﺠﺘﻤﻊﺑﺸﺄن اﻟﻌﺪاﻟﺔ اﻟﻜﺎﻣﻠﺔ أو اﻹﻧﺼﺎف اﻟﻜﺎﻣﻞ.
92</p>
<p>اﻟﺘﺤﻴﺰ وﻣﻌﻨﻰ اﻟﺤﻴﺎة
ﻋﻼوةًﻋﲆ ذﻟﻚ، وﻛﻤﺎ أﴍْﻧﺎﰲ اﻟﻔﺼﻞ اﻟﺴﺎﺑﻖ،ﻓﺈنﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت املُﺴﺘﺨﺪﻣﺔﻣﻦﻗِﺒﻞ
اﻟﺨﻮارزﻣﻴﺎتﻫﻲﺗﺠﺮﻳﺪاتﻋﻦ اﻟﻮاﻗﻊ وﻫﻲﻧﺘﺎج اﺧﺘﻴﺎراتﺑﴩﻳﺔ، وﻣﻦﺛَﻢﱠﻓﻬﻲﻻﺗﻜﻮن
(.ﻳﺘﻮﻏﱠﻞ اﻟﺘﺤﻴﺰﰲﻋﺎﻟَﻤﻨﺎ وﻣُﺠﺘﻤﻌﺎﺗﻨﺎ؛Kelleher and Tierney 2018)ﻣُﺤﺎﻳﺪة أﺑﺪًا
وﺑﺎﻟﺘﺎﱄ،ﻋﲆ اﻟﺮﻏﻢﻣﻦ أﻧﻪﻳﻤﻜﻦ اﻟﻘﻴﺎمﺑﺎﻟﻜﺜري وﻳﺠﺐ اﻟﻘﻴﺎمﺑﺎﻟﻜﺜريﻟﺘﻘﻠﻴﻞ اﻟﺘﺤﻴﺰ،ﻓﺈن
(.Digital Europe 2018)ﻧﻤﺎذج اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻦﺗﺨﻠﻮَﺗﻤﺎﻣًﺎﻣﻦ اﻟﺘﺤﻴﺰ
ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻳﺒﺪوﺑﺎﻟﺘﺄﻛﻴﺪ أن اﻟﺨﻮارزﻣﻴﺎت املُﺴﺘﺨﺪﻣﺔﰲ اﺗﺨﺎذ اﻟﻘﺮار داﺋﻤًﺎﻣﺎ
ﺗﻜﻮنﻣُﺘﺤﻴﺰةﻣﻦﻣﻨﻄﻠﻖﻛﻮﻧﻬﺎﺗﻤﻴﻴﺰﻳﺔ؛ إذ إﻧﻬﺎﻣُﺼﻤﻤﺔﻟﻠﺘﻤﻴﻴﺰﺑنيﻣُﺨﺘﻠﻒ اﻻﺣﺘﻤﺎﻻت.
ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﻋﻤﻠﻴﺔ اﻟﺘﻮﻇﻴﻒ،ﻳُﻔﱰَض أنﻳﻜﻮنﻓﺤﺺ اﻟﺴﱢ ريَ اﻟﺬاﺗﻴﺔ ذاﻃﺎﺑﻊ
ﻣُﺘﺤﻴﺰ وﺗﻤﻴﻴﺰيﺗﺠﺎهﺳِﻤﺎت املﺮﺷﺤني اﻟﺘﻲﺗُﻨﺎﺳﺐ اﻟﻮﻇﻴﻔﺔ. وﻳﻜﻤُﻦ اﻟﺴﺆال اﻷﺧﻼﻗﻲ
واﻟﺴﻴﺎﳼﻓﻴﻤﺎ إذاﻛﺎنﻫﻨﺎكﺗﻤﻴﻴﺰﻣُﻌنيﻏريﻣﻨﺼﻒ وﻏريﻋﺎدل. وﻟﻜﻦﻣﺮة أﺧﺮى،
ﺗﺨﺘﻠﻒ وﺟﻬﺎت اﻟﻨﻈﺮﺑﺸﺄنﻣﺎﻫﻮﻣﻨﺼﻒ وﻣﺎﻫﻮﻋﺎدل. وﻫﺬاﻳﺠﻌﻞﻗﻀﻴﺔ اﻟﺘﺤﻴﱡﺰ
ﻟﻴﺴﺖﻓﻘﻂﺗﻘﻨﻴﺔً وﻟﻜﻨﻬﺎ أﻳﻀًﺎﻣﺮﺗﺒﻄﺔﺑﺎملﻨﺎﻗﺸﺎت اﻟﺴﻴﺎﺳﻴﺔﺣﻮل اﻹﻧﺼﺎف واﻟﻌﺪاﻟﺔ.ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل،ﻫﻞﻣﻦ اﻟﻌﺪلﻣُﻤﺎرﺳﺔ اﻟﺘﻤﻴﻴﺰ اﻹﻳﺠﺎﺑﻲ أو اﻟﺘﺪاﺑري اﻹﻳﺠﺎﺑﻴﺔ، اﻟﺘﻲﺗُﺤﺎول
ﻣﺤﻮ أﺛﺮ اﻟﺘﺤﻴﱡﺰﻋﻦﻃﺮﻳﻖ اﻟﺘﺤﻴﺰ اﻹﻳﺠﺎﺑﻲﻣﻊ اﻷﻓﺮاد أو اﻟﺠﻤﺎﻋﺎت املﺤﺮوﻣﺔ؟ﻫﻞﻳﺠِﺐ
أنﺗﻜﻮن اﻟﻌﺪاﻟﺔﻋﻤﻴﺎء وﻣﺤﺎﻳﺪة — وﺑﺎﻟﺘﺎﱄﻫﻞﻳﺠﺐ أنﺗﻜﻮن اﻟﺨﻮارزﻣﻴﺎتﻋﻤﻴﺎء إزاء
اﻟﻌِﺮق،ﻋﲆﺳﺒﻴﻞ املﺜﺎل — أم أن اﻟﻌﺪاﻟﺔﺗﻌﻨﻲﺗﻤﻴﻴﺰ أوﻟﺌﻚ املَﺤﺮوﻣنيﺑﺎﻟﻔﻌﻞﻣﻦ أي
ﻣﻴﺰات،ﻣﻤﺎﻳﺼِﻞﺑﻨﺎﰲ اﻟﻨﻬﺎﻳﺔ إﱃﻧﻮعﻣﻦ اﻟﺘﺤﻴﱡﺰ واﻟﺘﻤﻴﻴﺰ )اﻟﺘﺼﺤﻴﺤﻲ(؟ وﻫﻞﻳﺠﺐ
ﻋﲆ اﻟﺴﻴﺎﺳﺔﰲ اﻟﺴﻴﺎق اﻟﺪﻳﻤﻘﺮاﻃﻲ أنﺗُﻌﻄﻲ اﻷوﻟﻮﻳﺔﻟﺤﻤﺎﻳﺔﻣﺼﺎﻟﺢ اﻷﻏﻠﺒﻴﺔ أمﺗﺮﻛﺰ
ﻋﲆﺗﻌﺰﻳﺰﻣﺼﺎﻟﺢ اﻷﻗﻠﻴﺔ،ﺣﺘﻰ وإنﻛﺎﻧﺖ أﻗﻠﻴﺔﻣﺤﺮوﻣﺔﻗﺪﻳﻤًﺎ أوﺣﺎﻟﻴٍّﺎ؟
ﻫﻞﻳﺠِﺐ أنﺗﻜﻮن اﻟﻌﺪاﻟﺔﻋﻤﻴﺎء وﻣُﺤﺎﻳﺪة أم أن اﻟﻌﺪاﻟﺔﺗﻌﻨﻲﺗﻤﻴﻴﺰ أوﻟﺌﻚ املﺤﺮوﻣنيﺑﺎﻟﻔﻌﻞﻣﻦ
أيﻣﻴﺰات؟
وﻫﺬاﻳﻘﻮدﻧﺎ إﱃ اﻟﺴﺆالﺣﻮل اﻹﺟﺮاءات.ﺣﺘﻰ إذا اﺗﻔﻘﻨﺎﻋﲆ وﺟﻮدﺗﺤﻴﱡﺰ،ﻓﻬﻨﺎك
ﻃﺮقﻣﺨﺘﻠﻔﺔﻟﻠﺘﻌﺎﻣُﻞﻣﻊ املﺸﻜﻠﺔ. وﺗﺸﻤﻞﻫﺬه اﻟﻄﺮق اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ وﻛﺬﻟﻚ اﻹﺟﺮاءات
املُﺠﺘﻤﻌﻴﺔ واﻟﺴﻴﺎﺳﻴﺔ واﻟﺘﻌﻠﻴﻢ. وﺛﻤﺔﺧﻼفﺣﻮل اﻹﺟﺮاءات اﻟﺘﻲﻳﺠِﺐﻋﻠﻴﻨﺎ اﺗﺨﺎذﻫﺎ؛
إذ إﻧﻬﺎﺗﻌﺘﻤﺪﻣﺮة أﺧﺮىﻋﲆﻣﻔﻬﻮﻣﻨﺎﻟﻠﻌﺪاﻟﺔ واﻹﻧﺼﺎف.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗُﺜريﻗﻀﻴﺔ
اﻟﺘﺪاﺑري اﻹﻳﺠﺎﺑﻴﺔﻗﻀﻴﺔً أﻛﺜﺮﻋﻤﻮﻣﻴﺔﺣﻮلﻣﺎ إذاﻛﻨﱠﺎﻳﺠِﺐ أنﻧﻘﺒﻞ اﻟﻌﺎﻟﻢﻛﻤﺎﻫﻮ أم
93</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
أﻧﻨﺎﻳﺠﺐ أنﻧُﺸﻜﱢﻞﻋﺎملﻨﺎ املُﺴﺘﻘﺒﲇﻋﲆﻧﺤﻮٍﻓﻌﱠﺎلﺑﻄﺮﻳﻘﺔٍﻣﻦﺷﺄﻧﻬﺎﺗﺠﻨﱡﺐ اﺳﺘﻤﺮار
اﻟﻈﻠﻢ اﻟﺬيﻛﺎنﻣُﺴﺘﴩﻳًﺎﰲ املﺎﴈ.ﺑﻌﺾ اﻟﻨﺎسﻳﺮَون أﻧﻨﺎﻳﺠِﺐ أنﻧﺴﺘﺨﺪِمﻣﺠﻤﻮﻋﺔ
ﺑﻴﺎﻧﺎتٍﺗﻌﻜﺲ اﻟﻌﺎﻟﻢ اﻟﻮاﻗﻌﻲ. وﻗﺪﺗُﻤﺜﻞ اﻟﺒﻴﺎﻧﺎت اﻟﺘﺤﻴﺰات املﻮﺟﻮدةﰲ املﺠﺘﻤﻊ وﻗﺪ
ﺗُﻨﺸﺊ اﻟﺨﻮارزﻣﻴﺔﻧﻤﻮذﺟًﺎﻣﻦ اﻟﺘﺤﻴﱡﺰات املﻮﺟﻮدةﻟﺪى اﻟﻨﺎس اﻵن، وﻟﻜﻦﻫﺬهﻟﻴﺴﺖ
ﻣﺸﻜﻠﺔًﻳﺠﺐ أنﻳﻘﻠﻖﺑﺸﺄﻧﻬﺎ املُﻄﻮرون.ﺑﻴﻨﻤﺎﻳﺮى آﺧﺮون أنﻣﺜﻞﻫﺬه املﺠﻤﻮﻋﺔﻣﻦ
اﻟﺒﻴﺎﻧﺎتﻣﻮﺟﻮدةﻓﻘﻂﺑﺴﺒﺐﻗﺮونٍﻣﻦ اﻟﺘﺤﻴﺰ، وأنﻫﺬا اﻟﺘﺤﻴﱡﺰ واﻟﺘﻤﻴﻴﺰﻏريﻋﺎدل
وﻇﺎﻟِﻢ، وﻋﻠﻴﻪﻓﺈﻧﻪﻳﺠِﺐﺗﻐﻴريﺗﻠﻚ املﺠﻤﻮﻋﺔﻣﻦ اﻟﺒﻴﺎﻧﺎت أو اﻟﺨﻮارزﻣﻴﺔﻣﻦ أﺟﻞﺗﻌﺰﻳﺰ
اﻟﺘﺪاﺑري اﻹﻳﺠﺎﺑﻴﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ اﺳﺘﺠﺎﺑﺔٍ إﱃﻧﺘﺎﺋﺞﺧﻮارزﻣﻴﺔ اﻟﺒﺤﺚﰲﺟﻮﺟﻞ اﻟﺘﻲ
ﺗﺒﺪوﻣُﺘﺤﻴﺰةًﺿﺪ أﺳﺎﺗﺬة اﻟﺮﻳﺎﺿﻴﺎت اﻹﻧﺎث،ﻳﻤﻜﻦﻟﻠﻤﺮء أنﻳﻘﻮل إنﻫﺬاﻳﻌﻜﺲﺑﺒﺴﺎﻃﺔٍ
ﺣﻘﻴﻘﺔ اﻟﻌﺎﻟﻢ )وأنﻫﺬاﻫﻮﺑﺎﻟﻀﺒﻂﻣﺎﻳﺠﺐ أنﺗﻔﻌﻠﻪﺧﻮارزﻣﻴﺔ اﻟﺒﺤﺚ(؛ أوﻳﻤﻜﻦ أن
ﻧﺠﻌﻞ اﻟﺨﻮارزﻣﻴﺔﺗُﻌﻄﻲ أوﻟﻮﻳﺔًﻟﺼﻮر أﺳﺎﺗﺬة اﻟﺮﻳﺎﺿﻴﺎت اﻹﻧﺎثﻣﻦ أﺟﻞﺗﻐﻴري اﻟﺘﺼﻮر
(. وﻳﻤﻜﻦ أﻳﻀًﺎ أنﻧُﺤﺎول إﻧﺸﺎءﻓِﺮَقﺗﻄﻮﻳﺮﺗﻜﻮن أﻛﺜﺮFry 2018)ورﺑﻤﺎﺗﻐﻴري اﻟﻌﺎﻟَﻢ
ﺗﻨﻮﻋًﺎﻣﻦﺣﻴﺚ اﻟﺨﻠﻔﻴﺔ واﻟﺮأي واﻟﺘﺠﺮﺑﺔ، وﺗُﻤﺜﻞﺑﺸﻜﻞٍ أﻓﻀﻞ اﻟﻔﺌﺎت اﻟﺘﻲﻣِﻦ املﺤﺘﻤَﻞ
(.House of Commons 2018)أنﺗﺘﺄﺛﺮﺑﺎﻟﺨﻮارزﻣﻴﺔ
ﻟﻦﻳﺼﺢ اﻟﺮأي اﻟﻘﺎﺋﻞﺑﺄﻧﻬﺎﺗﻌﻜﺲ اﻟﻮاﻗﻊ إذاﻛﺎﻧﺖﻣﺠﻤﻮﻋﺔ اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﺳﻴﺘﻢ
اﻟﺘﺪرﻳﺐﻋﻠﻴﻬﺎﻻﺗﻌﻜﺲ اﻟﻌﺎﻟﻢ اﻟﻮاﻗﻌﻲ وﺗﺤﺘﻮيﻋﲆﺑﻴﺎﻧﺎتٍﻗﺪﻳﻤﺔﻻﺗﻌﻜﺲ اﻟﻮﺿﻊ
اﻟﺤﺎﱄ.ﻛﻤﺎ أن اﻟﻘﺮارات املﺒﻨﻴﺔﻋﲆﻫﺬه اﻟﺒﻴﺎﻧﺎتﺗﺴﺎﻋﺪﺑﺎﻟﻔﻌﻞﰲ اﺳﺘﻤﺮار اﻟﺘﻤﻴﻴﺰ
اﻟﺬيﻛﺎنﻣﻮﺟﻮدًاﰲ املﺎﴈﺑﺪﻻًﻣﻦ اﻻﺳﺘﻌﺪادﻟﻠﻤﺴﺘﻘﺒﻞ. وﻋﻼوةًﻋﲆ ذﻟﻚ،ﺛﻤﱠﺔ اﻋﱰاض
آﺧَﺮﻋﲆ اﻟﺮأي اﻟﻘﺎﺋﻞﺑﺄﻧﻬﺎﺗﻌﻜﺲ اﻟﻮاﻗﻊ وﻫﻮ أﻧﻪﺣﺘﻰ إذاﻛﺎن اﻟﻨﻤﻮذجﻳﻌﻜﺲ اﻟﻌﺎﻟﻢ
اﻟﻮاﻗﻌﻲ،ﻓﺈنﻫﺬاﻳﻤﻜﻦ أنﻳﺆدي إﱃﺗﺪاﺑريﺗﻤﻴﻴﺰﻳﺔ وأﴐارٍ أﺧﺮىﻗﺪﺗﻘﻊﻋﲆ أﻓﺮادٍ أو
إﱃ املُﺘﻘﺪﻣني
ﻣﺠﻤﻮﻋﺎتﺑﻌﻴﻨﻬﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﺗﺮﻓﺾﴍﻛﺎت اﻻﺋﺘﻤﺎنﻣﻨﺢَﻗﺮوضٍ
ﻋﲆ أﺳﺎسﻣﺤﻞﱢ اﻹﻗﺎﻣﺔ، أوﻗﺪﺗﻔﺮض املﻮاﻗﻊ اﻹﻟﻜﱰوﻧﻴﺔ رﺳﻮﻣًﺎ أﻛﱪﻋﲆﺑﻌﺾ اﻟﻌﻤﻼء
ﻣﻘﺎرﻧﺔًﺑﻐريﻫﻢ اﺳﺘﻨﺎدًا إﱃﻣﻠﻔﺎت اﻟﻌﻤﻼء اﻟﺘﻌﺮﻳﻔﻴﺔ اﻟﺘﻲ أﻧﺸﺄﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
Kelleher and)ﻛﺬﻟﻚﻳﻤﻜﻦ أنﺗﺘﺒﻊ املﻠﻔﺎت اﻟﺘﻌﺮﻳﻔﻴﺔ اﻷﻓﺮادﻋﱪ اﻟﻨﻄﺎﻗﺎت املﺨﺘﻠﻔﺔ
(. وﻳﻤﻜﻦ أنﺗﺮﺑﻂ وﻇﻴﻔﺔ اﻹﻛﻤﺎل اﻟﺘﻠﻘﺎﺋﻲ اﻟﺒﺴﻴﻄﺔﰲﻇﺎﻫﺮﻫﺎﺑِﺸﻜﻞٍTierney 2018
ﺧﻄﺄٍ اﺳﻤَﻚﺑﺠﺮﻳﻤﺔٍﻣﺎ )اﻷﻣﺮ اﻟﺬيﻗﺪﻳﺆدﱢي إﱃﻋﻮاﻗﺐ وﺧﻴﻤﺔ(،ﺣﺘﻰ إذاﻛﺎﻧﺖﺧﻮارزﻣﻴﺔ
اﻟﺒﺤﺚ اﻟﻜﺎﻣﻨﺔ وراءﻫﺎﺗﻌﻜﺲ اﻟﻌﺎﻟَﻢﺑﺸﻜﻞٍﺻﺤﻴﺢ؛ﺑﻤﻌﻨﻰ أنﻣﻌﻈﻢ اﻟﻨﺎسﻳُﺮﻳﺪون
اﻟﺒﺤﺚﻋﻦ اﺳﻢ املﺠﺮم وﻟﻴﺲﻋﻦ اﺳﻤﻚ. وﺛﻤﱠﺔﻣﺜﺎل آﺧﺮﻋﲆ اﻟﺘﺤﻴﱡﺰ، وﻟﻜﻨﻪ رﺑﻤﺎﻟﻴﺲ
94</p>
<p>اﻟﺘﺤﻴﺰ وﻣﻌﻨﻰ اﻟﺤﻴﺎة
،«واﺿﺤًﺎﺑﺎﻟﻘﺪْرﻧﻔﺴﻪ:ﻓﻨﻈﺎم اﺳﱰﺟﺎع املﻮﺳﻴﻘﻰ املُﺴﺘﺨﺪَمﰲﺧﺪﻣﺎتﻣﺜﻞ »ﺳﺒﻮﺗﻴﻔﺎي
اﻟﺬيﻳﻘﺪﱢمﺗﻮﺻﻴﺎتٍﺑﻨﺎءًﻋﲆ اﻟﺴﻠﻮك اﻟﺤﺎﱄ )املﺴﺎرات املﻮﺳﻴﻘﻴﺔ اﻟﺘﻲﻳﻨﻘﺮﻋﻠﻴﻬﺎﻣﻌﻈﻢ
اﻟﻨﺎس(،ﻗﺪﻳﺘﺤﻴﱠﺰﺿﺪ املﻮﺳﻴﻘﻰ واملﻮﺳﻴﻘﻴني اﻟﺬﻳﻦﻫﻢ أﻗﻞﱡﺷﻴﻮﻋًﺎ. وﺣﺘﻰ إذاﻛﺎن اﻟﻨﻈﺎم
ﻳﻌﻜﺲ اﻟﻌﺎﻟَﻢَ اﻟﻮاﻗﻌﻲ،ﻓﺈنﻫﺬاﻳﺆدي إﱃ وﺿﻊٍﻻﻳﺴﺘﻄﻴﻊﻓﻴﻪﺑﻌﺾ املﻮﺳﻴﻘﻴني اﻟﻌﻴﺶَ
ﻣﻦﻣﻮﺳﻴﻘﺎﻫﻢ وﻳﺠﻌﻞﺑﻌﺾ املﺠﺘﻤﻌﺎتﺗﺸﻌُﺮﺑﻌﺪم اﻟﺘﻘﺪﻳﺮ وﻋﺪم اﻻﺣﱰام.
ﻣﺮة أﺧﺮى،ﰲﺣنيِ أنﻫﺬهﺣﺎﻻت واﺿﺤﺔﻣﻦ اﻟﺘﻤﻴﻴﺰ اﻟﺬيﻳﻨﻄﻮيﻋﲆﻣﺸﻜﻼت، إﻻ
أﻧﻨﺎﻳﺠِﺐ أنﻧﺴﺄل داﺋﻤًﺎ:ﻫﻞﻳﻤﻜﻦ أنﻳﻜﻮن اﻟﺘﻤﻴﻴﺰﰲﺣﺎﻟﺔٍﻣُﻌﻴﻨﺔﻋﺎدﻻً أمﻻ؟ وإذاﻛﺎن
ﻏريﻋﺎدل،ﻓﻤﺎ اﻹﺟﺮاء اﻟﺬيﺳﻴُﺘﱠﺨَﺬﺣﻴﺎﻟﻪ وﻣَﻦ اﻟﺬيﺳﻴﺘﺨِﺬُه؟ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﺎ اﻟﺬي
ﻳُﻤﻜﻦ أنﻳﻔﻌﻠﻪﻋﻠﻤﺎء اﻟﻜﻤﺒﻴﻮﺗﺮﺣﻴﺎﻟﻪ؟ﻫﻞﻳﺠﺐ أنﻳﺠﻌﻠﻮاﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت اﻟﺘﻲﻳﺘﻢ
اﻟﺘﺪرﻳﺐﻋﻠﻴﻬﺎ أﻛﺜﺮﺗﻨﻮﻋًﺎ، ورﺑﻤﺎﻳُﻨﺸﺌﻮنﺑﻴﺎﻧﺎتٍ وﻣﺠﻤﻮﻋﺎتﺑﻴﺎﻧﺎت »ﻣﺜﺎﻟﻴﺔ«ﻛﻤﺎ اﻗﱰح
(؟ أمﻳﺠﺐ أنﺗﻌﻜﺲﻣﺠﻤﻮﻋﺎتSurur 2017)إرﻳﻚﻫﻮرﻓﻴﺘﺰﻣﻦﴍﻛﺔﻣﺎﻳﻜﺮوﺳﻮﻓﺖ
اﻟﺒﻴﺎﻧﺎت اﻟﻌﺎﻟَﻢ؟ﻫﻞﻳﺠﺐﻋﲆ املﻄﻮﱢرﻳﻦﺗﻀﻤني اﻟﺘﻤﻴﻴﺰ اﻹﻳﺠﺎﺑﻲﰲﺧﻮارزﻣﻴﺎﺗﻬﻢ، أمﻳﺠﺐ
ﻋﻠﻴﻬﻢ إﻧﺸﺎءﺧﻮارزﻣﻴﺎت »ﻋﻤﻴﺎء«؟ إنﻛﻴﻔﻴﺔ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﺘﺤﻴﺰﰲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻟﻴﺴﺖﻣﺴﺄﻟﺔﺗﻘﻨﻴﺔﻓﺤﺴﺐ؛ﺑﻞﻫﻲﻣﺴﺄﻟﺔﺳﻴﺎﺳﻴﺔ وﻓﻠﺴﻔﻴﺔ. إن املﺴﺄﻟﺔﺗﺘﻌﻠﱠﻖﺑﻨﻮع
املﺠﺘﻤﻊ واﻟﻌﺎﻟَﻢ اﻟﺬيﻧﺮﻳﺪه، وإذاﻛﺎنﻣﻦ اﻟﻮاﺟِﺐﻋﻠﻴﻨﺎ أنﻧُﺤﺎولﺗﻐﻴريه، وإذاﻛﺎن اﻷﻣﺮ
ﻛﺬﻟﻚ،ﻓﻤﺎﻫﻲ اﻟﻄﺮق املﻘﺒﻮﻟﺔ واﻟﻌﺎدﻟﺔﻟﺘﻐﻴريه. إﻧﻬﺎ أﻳﻀًﺎﻣﺴﺄﻟﺔﺗﺘﻌﻠﱠﻖﺑﺎﻟﺒﴩﺑﻘﺪْرﻣﺎ
ﺗﺘﻌﻠﻖﺑﺎﻵﻻت:ﻫﻞﻧﻌﺘﻘﺪ أن اﺗﺨﺎذ اﻟﻘﺮارات اﻟﺒﴩﻳﺔﻋﺎدل وﻣﻨﺼﻒ، وإذاﻟﻢﻳﻜﻦ اﻷﻣﺮ
ﻛﺬﻟﻚ،ﻓﻤﺎ دور اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ رﺑﻤﺎﻳُﻤﻜﻦ أنﻳُﻌﻠﱢﻤﻨﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺷﻴﺌًﺎﻋﻦ
اﻟﺒﴩ وﻣﺠﺘﻤﻌﺎﺗﻬﻢﻣﻦﺧﻼل اﻟﻜﺸﻒﻋﻦﺗَﺤﻴﱡﺰاﺗﻨﺎ. وﻗﺪﺗﻜﺸﻒﻣﻨﺎﻗﺸﺔ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻻﺧﺘﻼل اﻟﻜﺒريﰲﻣﻮازﻳﻦ اﻟﻘﻮى اﻻﺟﺘﻤﺎﻋﻴﺔ واملﺆﺳﺴﻴﺔ.
وﻫﻜﺬاﺗﺼِﻞ املﻨﺎﻗﺸﺎتﺣﻮل أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﻋُﻤﻖﻗﻀﺎﻳﺎﻣﺠﺘﻤﻌﻴﺔ
وﺳﻴﺎﺳﻴﺔﺣﺴﱠﺎﺳﺔﺗﺮﺗﺒﻂﺑﺄﺳﺌﻠﺔٍﻓﻠﺴﻔﻴﺔﺣﻮل اﻟﻌﺪاﻟﺔ واﻹﻧﺼﺎف، وأﺳﺌﻠﺔﻓﻠﺴﻔﻴﺔ وﻋِﻠﻤﻴﺔ
ﺣﻮل اﻟﺒﴩ وﻣﺠﺘﻤﻌﺎﺗﻬﻢ. واﺣﺪةﻣﻦﻫﺬه اﻟﻘﻀﺎﻳﺎﻫﻲﻣُﺴﺘﻘﺒﻞ اﻟﻌﻤﻞ.
ﻣﺴﺘﻘﺒﻞ اﻟﻌﻤﻞ وﻣﻌﻨﻰ اﻟﺤﻴﺎة
ﻣِﻦ املﺘﻮﻗﱠﻊ أنﺗُﺤﻮﱢل اﻷﺗﻤﺘﺔ اﻟﺘﻲﺗﻌﺘﻤﺪﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻗﺘﺼﺎداﺗﻨﺎ وﻣﺠﺘﻤﻌﺎﺗﻨﺎ
ﺑﺸﻜﻞٍﺟﺬري،ﻣﻤﺎﻳُﺜريﺗﺴﺎؤﻻتٍﺣﻮلﻣُﺴﺘﻘﺒﻞ اﻟﻌﻤﻞ وﻣﻌﻨﺎه،ﻓﻀﻼًﻋﻦﻣﺴﺘﻘﺒﻞ اﻟﺤﻴﺎة
اﻟﺒﴩﻳﺔ وﻣﻌﻨﺎﻫﺎ.
95</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
أوﻻً ،ﻫﻨﺎكﻣَﺨﺎوفﻣﻦ أنﻳﺆدي اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﺗﺪﻣري اﻟﻮﻇﺎﺋﻒ، اﻷﻣﺮ اﻟﺬي
ﻗﺪﻳﺆدي إﱃ اﻟﺒﻄﺎﻟﺔ اﻟﺸﺎﻣﻠﺔ. وﻫﻨﺎك أﻳﻀًﺎﺳﺆالﺣﻮلﻧﻮع اﻟﻮﻇﺎﺋﻒ اﻟﺘﻲﻳﺴﺘﻄﻴﻊ اﻟﺬﻛﺎء
ﻋﲆ وﻇﺎﺋﻒ ذوي اﻟﻴﺎﻗﺎت اﻟﺰرﻗﺎء )اﻟﻌﻤﺎﻟﺔ اﻟﻴﺪوﻳﺔ(،
اﻻﺻﻄﻨﺎﻋﻲﺗﻮﻟﱢﻴﻬﺎ: وﻫﻞﺳﺘﻘﺘﴫِ
ﻛﻤﺎﻳُﻄﻠَﻖﻋﻠﻴﻬﺎ، أم أنﻫﻨﺎك وﻇﺎﺋﻒ أﺧﺮىﻳﻤﻜﻦ أنﻳﺘﻮﻻﱠﻫﺎ؟ﻳﺘﻨﺒﱠﺄﺗﻘﺮﻳﺮﺷﻬريﻟﻜﻞﱟﻣﻦ
ﺑﻨﻴﺪﻳﻜﺖﻓﺮي وﻣﺎﻳﻜﻞ أوزﺑﻮرن )٣١٠٢(ﺑﺄن ٧٤ﰲ املﺎﺋﺔﻣﻦﺟﻤﻴﻊ اﻟﻮﻇﺎﺋﻒﰲ اﻟﻮﻻﻳﺎت
املﺘﺤﺪةﻳُﻤﻜﻦ أﺗﻤﺘَﺘُﻬﺎ. وﺗﺤﻤﻞﺗﻘﺎرﻳﺮ أﺧﺮى أرﻗﺎﻣًﺎ أﻗﻞﱠ إﺛﺎرةًﻟﻠﺠﺪل، وﻟﻜﻦﻣﻌﻈﻤﻬﺎﻳﺘﻨﺒﺄ
ﺑﺄنﻓﻘﺪان اﻟﻮﻇﺎﺋﻒﺳﻴﻜﻮنﻛﺒريًا. وﻳﺘﻔﻖ اﻟﻌﺪﻳﺪﻣﻦ اﻟﻜﺘﱠﺎبﻋﲆ أن اﻻﻗﺘﺼﺎدﻗﺪﺗﺄﺛﺮ
(،ﺑﻤﺎﰲ ذﻟﻚ اﻟﺘﻐرياتBrynjolfsson and McAffee 2014)وﺳﻴﻈﻞﱡﻳﺘﺄﺛﺮﺑﺸﻜﻞٍﻛﺒري
املﻠﺤﻮﻇﺔ اﻟﺘﻲﺣﺪﺛﺖﰲ اﻟﺘﻮﻇﻴﻒ اﻵن واﻟﺘﻲﺳﺘﺤﺪثﰲ املﺴﺘﻘﺒﻞ. وﻣﻦ املُﺘﻮﻗﱠﻊ أنﻳﺆدي
ﻓﻘﺪان اﻟﻮﻇﺎﺋﻒﺑﺴﺒﺐ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃ اﻟﺘﺄﺛريﻋﲆﺟﻤﻴﻊ أﻧﻮاع اﻟﻌﺎﻣِﻠني،ﻟﻴﺲ
ﻓﻘﻂ ذوي اﻟﻴﺎﻗﺎت اﻟﺰرﻗﺎء،ﺣﻴﺚ أﺻﺒﺢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺎدرًاﺑﺸﻜﻞٍﻣﺘﺰاﻳﺪﻋﲆ أداء
املﻬﺎم املَﻌﺮﻓﻴﺔ املُﻌﻘﺪة. إذاﻛﺎنﻫﺬاﺻﺤﻴﺤًﺎ،ﻓﻜﻴﻒﻳُﻤﻜﻨﻨﺎ أنﻧُﻌِﺪﱠ اﻷﺟﻴﺎل اﻟﺠﺪﻳﺪةﻟﻬﺬا
املﺴﺘﻘﺒﻞ؟ﻣﺎذاﻳﺠﺐ أنﻳﺘﻌﻠﱠﻤﻮا؟ وﻣﺎذاﻳﺠﺐ أنﻳﻔﻌﻠﻮا؟ وﻣﺎذاﻟﻮﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳُﻔﻴﺪﺑﻌﺾ اﻷﺷﺨﺎص أﻛﺜﺮﻣﻦﻏريﻫﻢ؟
ﺑﻬﺬا اﻟﺴﺆال اﻷﺧري،ﻧﻌﻮدﻣﺮةً أﺧﺮى إﱃﻗﻀﺎﻳﺎ اﻟﻌﺪاﻟﺔ واﻹﻧﺼﺎف، اﻟﺘﻲﺷﻐﻠﺖ
ﺗﻔﻜري اﻟﻔﻼﺳﻔﺔ اﻟﺴﻴﺎﺳﻴنيﻟﻌﺼﻮر.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺳﻴﻮﺳﱢﻊ
اﻟﻔﺠﻮةﺑني اﻷﺛﺮﻳﺎء واﻟﻔﻘﺮاء،ﻓﻬﻞﻫﺬا أﻣﺮﻋﺎدل؟ وإذاﻟﻢﻳﻜﻦﻋﺎدﻻً ،ﻓﻤﺎ اﻟﺬيﻳﻤﻜﻦ
اﻟﻘﻴﺎمﺑﻪﺣﻴﺎل ذﻟﻚ؟ﻳﻤﻜﻦ أﻳﻀًﺎﺻﻴﺎﻏﺔ املﺸﻜﻠﺔﻣﻦﺣﻴﺚﻋﺪم املﺴﺎواة )ﻫﻞﺳﻴﺰﻳﺪ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦﻋﺪم املﺴﺎواةﰲ املﺠﺘﻤﻌﺎت وﰲ اﻟﻌﺎﻟﻢ؟( أوﻣﻦﺣﻴﺚ اﻟﺘﻌﺮﱡض إﱃ
اﻟﺘﺄﺛريات اﻟﺴﻠﺒﻴﺔ:ﻫﻞﺳﻴﺤﻈﻰ أﺻﺤﺎب اﻟﻮﻇﺎﺋﻒ واﻷﺛﺮﻳﺎء واملُﺘﻌﻠﱠﻤﻮنﰲ اﻟﺪول املﺘﻘﺪﻣﺔ
ﺗﻜﻨﻮﻟﻮﺟﻴٍّﺎﺑﻔﻮاﺋﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻴﻨﻤﺎﺳﻴﻜﻮنُ اﻟﻌﺎﻃﻠﻮنﻋﻦ اﻟﻌﻤﻞ واﻟﻔﻘﺮاء واﻷﻗﻞ
(؟ وﻟﻠﺘﻌﺎﻣُﻞJansen et al. 2018)ﺗﻌﻠﻴﻤًﺎﰲ اﻟﺪول اﻟﻨﺎﻣﻴﺔ أﻛﺜﺮﻋﺮﺿﺔًﻟﺘﺄﺛرياﺗﻪ اﻟﺴﻠﺒﻴﺔ
ﻣﻊﻗﻀﻴﺔ أﺧﻼﻗﻴﺔ وﺳﻴﺎﺳﻴﺔ أﺧﺮى أﻛﺜﺮﺣﺪاﺛﺔ:ﻣﺎذاﻋﻦ اﻟﻌﺪاﻟﺔ اﻟﺒﻴﺌﻴﺔ؟ﻣﺎﻫﻮﺗﺄﺛري
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆ اﻟﺒﻴﺌﺔ وﻋﻼﻗﺘﻨﺎﺑﺎﻟﺒﻴﺌﺔ؟ﻣﺎذاﻳﻌﻨﻲ »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺴﺘﺪام«؟
ﻫﻨﺎك أﻳﻀًﺎﺳﺆالﺣﻮلﻣﺎ إذاﻛﺎﻧﺖ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺳﻴﺎﺳﺎﺗﻪﻣُﺮﺗﺒﻄﺔﺑﻘِﻴَﻢ
اﻟﺒﴩ وﻣﺼﺎﻟﺤﻬﻢﻓﻘﻂ أمﻻ. )اﻧﻈﺮ اﻟﻔﺼﻞ اﻟﺜﺎﻧﻲﻋﴩ.(
96</p>
<p>اﻟﺘﺤﻴﺰ وﻣﻌﻨﻰ اﻟﺤﻴﺎة
ٍﻣﻦ املﺘﻮﻗﱠﻊ أنﺗُﺤﻮﱢل اﻷﺗﻤﺘﺔ اﻟﺘﻲﺗﻌﺘﻤﺪﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻗﺘﺼﺎداﺗﻨﺎ وﻣُﺠﺘﻤﻌﺎﺗﻨﺎﺑﺸﻜﻞ
ﺟﺬري،ﻣﻤﺎﻳُﺜري أﺳﺌﻠﺔﺣﻮلﻣُﺴﺘﻘﺒﻞ اﻟﻌﻤﻞ وﻣﻌﻨﺎه،ﻓﻀﻼًﻋﻦﻣُﺴﺘﻘﺒﻞ اﻟﺤﻴﺎة اﻟﺒﴩﻳﺔ وﻣﻌﻨﺎﻫﺎ.
ﺛﻤﺔﺳﺆال آﺧَﺮ ذوﻃﺎﺑﻊ وﺟﻮديﻳﺘﻌﻠﱠﻖﺑﻤﻌﻨﻰ اﻟﻌﻤﻞ واﻟﺤﻴﺎة اﻟﺒﴩﻳﺔ.ﺗﻔﱰِض
املﺨﺎوفﻣﻦﻓﻘﺪان اﻟﻮﻇﺎﺋﻒ أن اﻟﻌﻤﻞﻫﻮ اﻟﻘﻴﻤﺔ اﻟﻮﺣﻴﺪة واملﺼﺪر اﻟﻮﺣﻴﺪﻟﻠﺪﺧﻞ واملﻌﻨﻰ.
وﻟﻜﻦ إذاﻛﺎﻧﺖ اﻟﻮﻇﺎﺋﻒﻫﻲ اﻟﴚء اﻟﻮﺣﻴﺪ ذو اﻟﻘﻴﻤﺔ،ﻓﺮﺑﻤﺎﻋﻠﻴﻨﺎﻋﻨﺪﺋﺬٍﺧﻠﻖ املﺰﻳﺪﻣﻦ
اﻷﻣﺮاض اﻟﻌﻘﻠﻴﺔ، ورﻓﻊﻣُﻌﺪل اﻟﺘﺪﺧني، وزﻳﺎدةﻣﻌﺪﻻت اﻟﺴﻤﻨﺔ؛ﻷنﻫﺬه املﺸﻜﻼتﻫﻲ
وﻧﺤﻦﻻﻧُﺮﻳﺪ ذﻟﻚ. إذَنﻓﻤﻦ اﻟﻮاﺿﺢ أﻧﻨﺎﻧﺆﻣﻦﺑﺄنﻫﻨﺎك1.اﻟﺘﻲﺗﺆدي إﱃﺧﻠﻖ وﻇﺎﺋﻒ
ﻗﻴﻤًﺎ أﺧﺮى أﻫﻢﻣﻦﺧﻠﻖ اﻟﻮﻇﺎﺋﻒﰲﺣﺪﱢ ذاﺗﻪ. وملﺎذاﻧﻌﺘﻤﺪﻋﲆ اﻟﻮﻇﺎﺋﻒﻟﺘﺤﻘﻴﻖ اﻟﺪﺧﻞ
واملﻌﻨﻰ؟ﻳُﻤﻜﻨﻨﺎﺗﻨﻈﻴﻢﻣﺠﺘﻤﻌﺎﺗﻨﺎ واﻗﺘﺼﺎداﺗﻨﺎﺑﻄﺮﻳﻘﺔٍﻣﺨﺘﻠﻔﺔ.ﻳُﻤﻜﻨﻨﺎ أنﻧﻔﺼﻞﺑني
اﻟﻌﻤﻞ واﻟﺪﺧﻞ، أوﺑﺎﻷﺣﺮىﻣﺎﻧﻌﺘﱪه »ﻋﻤﻼً « ودﺧﻼً .ﻓﻬﻨﺎك اﻟﻜﺜريونﻳﻘﻮﻣﻮنﺑﺎﻟﻌﻤﻞ
ﻣﺠﱠﺎﻧًﺎ،ﻋﲆﺳﺒﻴﻞ املﺜﺎلﰲ املﻨﺰل ورﻋﺎﻳﺔ اﻷﻃﻔﺎل واملُﺴﻨﱢني.ﻓﻠﻤﺎذاﻻﻳُﻌﺘﱪﻫﺬا »ﻋﻤﻼً «؟
وملﺎذاﻳﻜﻮن اﻟﻘﻴﺎمﺑﺬﻟﻚ اﻟﻨﻮعﻣﻦ اﻟﻌﻤﻞ أﻗﻞﱠﻗﻴﻤﺔً وأﻫﻤﻴﺔﻣﻦﻏريهﻣﻦ اﻷﻋﻤﺎل؟ وملﺎذا
ﻻﻧﺠﻌﻠﻪﻣﺼﺪرًاﻟﻠﺪﺧﻞ؟ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻳﻌﺘﻘﺪﺑﻌﺾ اﻷﺷﺨﺎص أن اﻷﺗﻤﺘﺔﻳُﻤﻜﻦ أن
ﺗُﺘﻴﺢﻟﻨﺎ املﺰﻳﺪﻣﻦ اﻟﺮﻓﺎﻫﻴﺔ واﻟﺮاﺣﺔ. رﺑﻤﺎﻳُﻤﻜﻨﻨﺎ اﻟﻘﻴﺎمﺑﺄﺷﻴﺎء أﻛﺜﺮﻣﺘﻌﺔً وإﺑﺪاﻋًﺎ،ﻟﻴﺲ
ﺑﺎﻟﴬورةﰲﺷﻜﻞ وﻇﻴﻔﺔ.ﻳُﻤﻜﻨﻨﺎ،ﺑﻌﺒﺎرةٍ أﺧﺮى، اﻻﻋﱰاضﻋﲆﻓﻜﺮة أن اﻟﺤﻴﺎة ذات
ﰲ أداءﻋﻤﻞٍﻣﺪﻓﻮع اﻷﺟﺮ وﻣُﻨﻈﻢﻣُﺴﺒﻘًﺎﻣﻦﻗِﺒﻞ اﻵﺧﺮﻳﻦ أو
املﻌﻨﻰﻫﻲﻓﻘﻂﺣﻴﺎةﺗُﻘﴣَ
ﻋﻤﻞﻳﺘﻢﰲ إﻃﺎرﻣﺎﻳُﻄﻠَﻖﻋﻠﻴﻪ »اﻟﺘﻮﻇﻴﻒ اﻟﺬاﺗﻲ«. رﺑﻤﺎﻳُﻤﻜﻨﻨﺎﻓﺮضﺗﺪاﺑريﻣُﻌﻴﱠﻨﺔﻣﺜﻞ
ﺗﺤﺪﻳﺪ »دﺧﻞ أﺳﺎﳼ«ﻟﻨﺴﻤﺢﻟﻠﺠﻤﻴﻊﺑﻔﻌﻞﻣﺎﻳﺮَوﻧﻪ ذاﻣﻌﻨًﻰ وﻗﻴﻤﺔ. وﺑﺎﻟﺘﺎﱄ، ردٍّاﻋﲆ
ﻣﺸﻜﻠﺔﻣُﺴﺘﻘﺒﻞ اﻟﻌﻤﻞ،ﻳُﻤﻜﻨﻨﺎ أنﻧُﻔﻜﺮﻓﻴﻤﺎﻳﺠﻌﻞ اﻟﻌﻤﻞ ذاﻣﻌﻨًﻰ، وﰲﻧﻮع اﻟﻌﻤﻞ اﻟﺬي
ﻳﻨﺒﻐﻲﻟﻠﺒﴩﻋﻤﻠُﻪ )أوﺑﺎﻷﺣﺮىﻳُﺴﻤَﺢﻟﻬﻢﺑﻌﻤﻠﻪ(، وﰲﻛﻴﻔﻴﺔ إﻋﺎدةﺗﻨﻈﻴﻢﻣﺠﺘﻤﻌﺎﺗﻨﺎ
واﻗﺘﺼﺎداﺗﻨﺎﺑﺤﻴﺚﻻﻳﺮﺗﺒﻂ اﻟﺪﺧﻞﺑﺎﻟﻮﻇﺎﺋﻒ واﻟﺘﻮﻇﻴﻒ.
ﻋﲆ اﻟﺮﻏﻢﻣﻦﻛﻞﱢﻣﺎﻗﻴﻞ،ﻓﺈن اﻷﻓﻜﺎر اﻟﻴﻮﺗﻮﺑﻴﺔﺣﻮل املﺠﺘﻤﻌﺎت املُﺮﻓﱠﻬﺔ وﻏريﻫﺎ
ﻣﻦ اﻟﺠﻨﺎنﻣﺎﺑﻌﺪ اﻟﺼﻨﺎﻋﻴﺔﻟﻢﺗﺘﺤﻘﱠﻖﺣﺘﻰ اﻵن.ﻟﻘﺪﺷﻬﺪﻧﺎﺑﺎﻟﻔﻌﻞﻋﺪةﻣﻮﺟﺎتٍﻣﻦ
اﻷﺗﻤﺘﺔﺑﺪءًاﻣﻦ اﻟﻘﺮن اﻟﺘﺎﺳﻊﻋﴩﺣﺘﻰ اﻵن، وﻟﻜﻦ إﱃ أيﻣﺪًىﺣﺮﱠرَﺗﻨﺎ اﻵﻻت وأﻋﺘﻘﺖ
رﻗﺎﺑﻨﺎ؟ رﺑﻤﺎﺗﻮﻟﱠﺖﻧﻴﺎﺑﺔًﻋﻨﺎﺑﻌﺾَ اﻷﻋﻤﺎل املُﻀﺠﺮة واﻟﺨﻄرية، وﻟﻜﻨﻬﺎ اﺳﺘُﺨﺪِﻣﺖ أﻳﻀًﺎ
ﻟﻼﺳﺘﻐﻼل وﻟﻢﺗُﻐريﱢﺑﺸﻜﻞٍﺟﺬري اﻟﻬﻴﻜﻞ اﻟﻬﺮَﻣﻲﻟﻠﻤﺠﺘﻤﻊ. وﻗﺪ اﺳﺘﻔﺎدﺑﻌﺾ اﻟﻨﺎس
97</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﺳﺘﻔﺎدةًﻫﺎﺋﻠﺔﻣﻦ اﻷﺗﻤﺘﺔ،ﺑﻴﻨﻤﺎﻟﻢﻳﻔﻌﻞ آﺧﺮون. ورﺑﻤﺎﺗﻜﻮن اﻷوﻫﺎمﺣﻮلﻋﺪم وﺟﻮد
وﻇﺎﺋﻒﻫﻲ رﻓﺎﻫﻴﺔﻣﺤﻔﻮﻇﺔﻓﻘﻂﻷوﻟﺌﻚ اﻟﺬﻳﻦﻛﺎﻧﻮاﰲﺟﺎﻧﺐ املُﺴﺘﻔﻴﺪﻳﻦ.ﻓﻀﻼًﻋﻦ
ذﻟﻚ،ﻫﻞﺣﺮﱠرَﺗﻨﺎ اﻵﻻتﻟﻨﻌﻴﺶﺣﻴﺎةً ذاتﻣﻌﻨًﻰ أﻛﺜﺮﻣﻦ ذيﻗﺒﻞ؟ أم أﻧﻬﺎﺗُﻬﺪﱢد إﻣﻜﺎﻧﻴﺔ
ﻫﺬه اﻟﺤﻴﺎةﻧﻔﺴﻬﺎ؟ﻫﺬاﻧﻘﺎشﻃﻮﻳﻞ وﻻﺗُﻮﺟَﺪ إﺟﺎﺑﺎتﺳﻬﻠﺔﻋﻦﻫﺬه اﻷﺳﺌﻠﺔ، وﻟﻜﻦ
املﺨﺎوف اﻟﺘﻲﻟﺪﻳﻨﺎﺗُﻌﺪ أﺳﺒﺎﺑًﺎ وﺟﻴﻬﺔﻷنﻧﺘﺸﻜﱠﻚﻋﲆ اﻷﻗﻞﰲ اﻟﻌﺎﻟﻢ اﻟﺠﺪﻳﺪ اﻟﺠﻤﻴﻞ
اﻟﺬي رﺳﻤَﺘْﻪﻟﻨﺎﻧﺒﻮءاتُ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻗﺪﻻﻳﻜﻮن اﻟﻌﻤﻞﺑﺎﻟﴬورةﺷﻘﺎءًﻳﺠﺐﺗﺠﻨﱡﺒُﻪ أو اﺳﺘﻐﻼﻻًﻳﺠﺐ
ﻣﻘﺎوﻣﺘﻪ؛ﻓﺜﻤﺔ وﺟﻬﺔﻧﻈﺮ أﺧﺮىﺗُﺸري إﱃ أن اﻟﻌﻤﻞﻟﻪﻗﻴﻤﺔﰲﺣﺪﱢ ذاﺗﻪ، وأﻧﻪﻳﻤﻨﺢ
اﻟﻌﺎﻣﻞﻫﺪﻓًﺎ وﻣﻌﻨًﻰ، وأنﻟﻪﻓﻮاﺋﺪﻣُﺘﻨﻮﻋﺔﻣﺜﻞ اﻟﺘﻮاﺻُﻞ اﻻﺟﺘﻤﺎﻋﻲﻣﻊ اﻵﺧﺮﻳﻦ، واﻻﻧﺘﻤﺎء
Boddington)إﱃﳾءٍ أﻛﱪ، واﻟﺘﻤﺘﱡﻊﺑﺎﻟﺼﺤﺔ، واﻟﺤﺼﻮلﻋﲆﻓُﺮَص ملﻤﺎرﺳﺔ املﺴﺌﻮﻟﻴﺔ
(.ﻓﺈذاﻛﺎنﻫﺬاﻫﻮ اﻟﺤﺎل،ﻓﻠﺮﺑﻤﺎﻛﺎنﻋﻠﻴﻨﺎ أنﻧﺤﺘﻔِﻆﺑﺎﻟﻌﻤﻞﻟﻠﺒﴩ؛ أوﻋﲆ2016
اﻷﻗﻞﺑﺒﻌﺾ أﻧﻮاع اﻟﻌﻤﻞ،ﻛﺎﻟﻌﻤﻞ ذي املَﻐﺰى اﻟﺬيﻳُﻮﻓﱢﺮﻓﺮﺻًﺎﻟﺘﺤﻘﻴﻖﻫﺬه اﻟﻔﻮاﺋﺪ. أو
رﺑﻤﺎﻋﻠﻴﻨﺎ أنﻧﺤﺘﻔِﻆﻋﲆ اﻷﻗﻞﺑﺒﻌﺾ املﻬﺎم. وﻟﻴﺲﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أنﻳﺄﺧُﺬ
ﻋﲆﻋﺎﺗﻘﻪ وﻇﺎﺋﻒﺑﺄﻛﻤﻠﻬﺎ، وﻟﻜﻦﻳُﻤﻜﻦ أنﻳﺘﻮﱃﱠﺑﻌﺾ املﻬﺎم ذات اﻟﻘﻴﻤﺔ اﻷﻗﻞ. وﻳُﻤﻜﻨﻨﺎ
أنﻧﺘﻌﺎونﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳُﻤﻜﻨﻨﺎ اﺧﺘﻴﺎرﻋﺪمﺗﻔﻮﻳﺾ اﻟﻌﻤﻞ
اﻹﺑﺪاﻋﻲ إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ )وﻫﻮﻣﺎﻳﻘﱰِﺣﻪﺑﻮﺳﱰوم( أوﻳُﻤﻜﻨﻨﺎ اﺧﺘﻴﺎر اﻟﺘﻌﺎون
ﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻠﻘﻴﺎمﺑﺄﺷﻴﺎء إﺑﺪاﻋﻴﺔ.ﻣﺎﻳُﺜري اﻟﻘﻠﻖﰲﻫﺬا اﻟﺼﺪدﻫﻮ أﻧﻪ إذا
ﻛﺎﻧﺖ اﻵﻻتﺳﺘﺘﻮﱃﱠ اﻟﻘﻴﺎمﺑﻜﻞﱢﻣﺎﻧﻘﻮمﺑﻪﰲﺣﻴﺎﺗﻨﺎ اﻵن،ﻓﻠﻦﻳﺘﺒﻘﱠﻰﻟﻨﺎﳾءﻧﻘﻮم
ﺑﻪ، وﺳﻨﺠﺪﺣﻴﺎﺗﻨﺎﺑﻼﻣﻌﻨًﻰ. وﻣﻊ ذﻟﻚ،ﻓﻨﺤﻦﻧﻘﻮل »إذا«؛ وﻳﺠﺐ أنﻧﻀﻊﰲ اﻋﺘﺒﺎرﻧﺎ
اﻟﺸﻚﱠﻓﻴﻤﺎﻳﻤﻜﻦ أنﻳﻘﻮمﺑﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ )اﻧﻈﺮ اﻟﻔﺼﻞ اﻟﺜﺎﻟﺚ( وﺣﻘﻴﻘﺔ أن اﻟﻌﺪﻳﺪ
ﻣﻦ أﻧﺸﻄﺘﻨﺎﻟﻴﺴﺖ »ﻋﻤﻼً « وﻟﻜﻨﻬﺎ ذاتﻣﻐﺰًىﻛﺒري، وﺑﺎﻟﺘﺎﱄﻓﺈﻧﻨﺎﺳﻨﺤﺘﻔﻆﻋﲆ اﻷرﺟﺢ
ﺑﺎﻟﻜﺜريﻟﻨﻘﻮمﺑﻪ.ﻋﲆﻫﺬا،ﻳُﻤﻜﻨﻨﺎ أنﻧﻘﻮل إن اﻟﺴﺆال اﻵنﻟﻴﺲﻣﺎذاﺳﻴﻔﻌﻞ اﻟﺒﴩ
ﻋﻨﺪﻣﺎﺗﺘﻮﱃﱠ اﻵﻻت اﻟﻘﻴﺎمﺑﺠﻤﻴﻊ أﻋﻤﺎﻟﻬﻢ وأﻧﺸﻄﺘﻬﻢ، وﻟﻜﻦ أي املﻬﺎمﻧﺮﻳﺪ أوﻧﺤﺘﺎج إﱃ
اﻻﺣﺘﻔﺎظﺑﻬﺎﻟﻠﺒﴩ، وﻣﺎﻫﻲ اﻷدوار اﻟﺘﻲﻳﻤﻜﻦ أنﻳﺘﻮﻻﱠﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، إنﻛﺎن
ﺳﻴﺘﻮﱃ أي أدوار،ﻟﺪﻋﻤﻨﺎﰲﻫﺬه املﻬﺎمﱢﺑﻄﺮق أﺧﻼﻗﻴﺔ وﻣﻘﺒﻮﻟﺔ اﺟﺘﻤﺎﻋﻴٍّﺎ.
ﺧﺘﺎﻣًﺎ،ﺗﺪﻋﻮﻧﺎ أﺧﻼﻗﻴﱠﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃ اﻟﺘﻔﻜريﰲﻣﺎﻫﻴﺔ املﺠﺘﻤﻊ اﻟﺨَريﱢ
واﻟﻌﺎدل، وﻣﺎﻫﻴﺔ اﻟﺤﻴﺎة اﻟﺒﴩﻳﺔ ذات املﻌﻨﻰ، وﻣﺎﻫﻴﺔ اﻟﺪور اﻟﺬيﺗﻀﻄﻠِﻊﺑﻪ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
واﻟﺬيﻳﻤﻜﻦ أنﺗﻀﻄﻠﻊﺑﻪﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖﺑﻜﻞﱢ ذﻟﻚ. وﻳﻤﻜﻦ أنﺗﻜﻮن اﻟﻔﻠﺴﻔﺔ،ﺑﻤﺎﻓﻴﻬﺎ
98</p>
<p>اﻟﺘﺤﻴﺰ وﻣﻌﻨﻰ اﻟﺤﻴﺎة
اﻟﻔﻠﺴﻔﺔ اﻟﻘﺪﻳﻤﺔ،ﻣﺼﺪر إﻟﻬﺎمٍﻟﻠﺘﻔﻜريﰲﺗﻘﻨﻴﺎت اﻟﻴﻮم واملﺸﻜﻼت اﻟﺘﻲﺗﺠﻠِﺒﻬﺎﺑﺎﻟﻔﻌﻞ
واﻟﺘﻲﻳُﺤﺘﻤَﻞ أنﺗﺠﻠﺒﻬﺎﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔ واملُﺠﺘﻤﻌﻴﺔ.ﻓﺈذاﻛﺎن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳُﺜريﻫﺬه اﻷﺳﺌﻠﺔ اﻟﻘﺪﻳﻤﺔﺣﻮل اﻟﺤﻴﺎة اﻟﺠﻴﺪة ذات املﻌﻨﻰ،ﻓﻠﺪَﻳﻨﺎﻣﺼﺎدرﰲﻣﺨﺘﻠﻒ
اﻟﺘﻘﺎﻟﻴﺪ اﻟﻔﻠﺴﻔﻴﺔ واﻟﺪﻳﻨﻴﺔﻳﻤﻜﻦ أنﺗُﺴﺎﻋﺪﻧﺎﰲ اﻟﺘﻌﺎﻣُﻞﻣﻊﻫﺬه اﻷﺳﺌﻠﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
ﻛﻤﺎ اﻗﱰﺣﺖﺷﺎﻧﻮنﻓﺎﻟﻮر )٦١٠٢(،ﻓﺈنﺗﻘﻠﻴﺪ أﺧﻼﻗﻴﺎت اﻟﻔﻀﻴﻠﺔ اﻟﺬي وﺿﻌﻪ أرﺳﻄﻮ
وﻛﻮﻧﻔﻮﺷﻴﻮس وﻓﻼﺳﻔﺔﻗﺪﻣﺎء آﺧﺮون رﺑﻤﺎﻣﺎ زالﻳﺴﺘﻄﻴﻊ أنﻳُﺴﺎﻋﺪﻧﺎ اﻟﻴﻮمﻟﻠﺘﻔﻜريﰲ
ﻣﻌﻨﻰ ازدﻫﺎر اﻹﻧﺴﺎن وﻛﻴﻒﻳﻨﺒﻐﻲ أنﻳﻜﻮنﰲﻋﴫ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ. وﺑﻌﺒﺎرةٍ أﺧﺮى،ﻗﺪ
ﺗُﻮﺟَﺪﻟﺪﻳﻨﺎﺑﺎﻟﻔﻌﻞ إﺟﺎﺑﺎتﻋﻦﻫﺬه اﻷﺳﺌﻠﺔ، وﻟﻜﻦﻋﻠﻴﻨﺎ اﻟﻘﻴﺎمﺑﺒﻌﺾ اﻟﻌﻤﻞﻟﻠﺘﻔﻜريﰲ
ﻣﻌﻨﻰ اﻟﺤﻴﺎة اﻟﺠﻴﺪةﰲﺳﻴﺎق اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺤﺪﻳﺜﺔ،ﺑﻤﺎﰲ ذﻟﻚ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
وﻣﻊ ذﻟﻚ،ﺗُﻮاﺟِﻪﻓﻜﺮةﺗﻄﻮﻳﺮ »أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻠﺤﻴﺎة اﻟﺠﻴﺪة«
وأﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻠﻌﺎﻟَﻢ اﻟﻮاﻗﻌﻲﺑﺸﻜﻞٍﻋﺎمﱟﻋﺪةﻣﺸﻜﻼت.ﺗﺘﻤﺜﱠﻞ املﺸﻜﻠﺔ
اﻷوﱃﰲ اﻟﴪﻋﺔ.ﻳﻔﱰضﻧﻤﻮذج أﺧﻼﻗﻴﺎت اﻟﻔﻀﻴﻠﺔ اﻟﺬي ورﺛﺘﻪ اﻟﻔﻠﺴﻔﺔ اﻟﻐﺮﺑﻴﺔﻣﻦ
أرﺳﻄﻮﻣﺠﺘﻤﻌًﺎﻳﺘﻐريﱠﺑﺒﻂءٍ وﻻﺗﺘﻐريﱠﻓﻴﻪ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺑﴪﻋﺔٍﻛﺒرية، وﻳﻤﺘﻠﻚﻓﻴﻪ اﻟﻨﺎس
وﻗﺘًﺎﻟﺘﻌﻠﱡﻢ اﻟﺤﻜﻤﺔ اﻟﻌﻤﻠﻴﺔ؛ وﻟﺬا،ﻓﺈﻧﻪﻣﻦﻏري اﻟﻮاﺿﺢﻛﻴﻒﻳﻤﻜﻦ اﺳﺘﺨﺪاﻣﻪﻟﻠﺘﻌﺎﻣُﻞ
( وﻣﻊ اﻟﺘﻄﻮﱡر اﻟﴪﻳﻊﻟﻠﺘﻘﻨﻴﺎتﻣﺜﻞ اﻟﺬﻛﺎءBoddington 2016)ﻣﻊﻣﺠﺘﻤﻊٍﴎﻳﻊ اﻟﺘﻐريﱡ
اﻻﺻﻄﻨﺎﻋﻲ.ﻫﻞﻣﺎ زالﻟﺪَﻳﻨﺎ اﻟﻮﻗﺖ اﻟﻜﺎﰲﻟﻼﺳﺘﺠﺎﺑﺔ وﻟﺘﻄﻮﻳﺮ اﻟﺤﻜﻤﺔ اﻟﻌﻤﻠﻴﺔ وﻧﻘﻠﻬﺎ
ﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖﺑﺎﺳﺘﺨﺪامﺗﻘﻨﻴﺎتﻣﺜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ﻫﻞﺗﺄﺗﻲ اﻷﺧﻼﻗﻴﺎتﺑﻌﺪﻓﻮات
ﺑﻮﻣﺔﻣِﻴﻨريﻓﺎﺟﻨﺎﺣَﻴﻬﺎ )اﻟﺘﻲﺗﺮﻣﺰﻟﻠﺤﻜﻤﺔﻋﻨﺪ اﻟﻴﻮﻧﺎن(، رﺑﻤﺎﻳﻜﻮن
اﻷوان؟ﻋﻨﺪﻣﺎﺗﻨﴩُ
ﺷﻜﻞ اﻟﻌﺎﻟﻢﻗﺪﺗﻐريﱠﺗﻤﺎﻣًﺎ وﻟﻢﻳﻌُﺪﺑﺎﻹﻣﻜﺎن اﻟﺘﻌﺮفﻋﻠﻴﻪ.ﻓﻤﺎﻫﻮ دورﻣﺜﻞﻫﺬه
اﻷﺧﻼﻗﻴﺎت، وﻣﺎذاﻳﻨﺒﻐﻲ أنﻳﻜﻮن دورﻫﺎﰲﺳﻴﺎق اﻟﺘﻄﻮﱡرات اﻟﺘﻲﺗﺤﺪثﰲ اﻟﻌﺎﻟﻢ
اﻟﻮاﻗﻌﻲ؟
أﻣﺎ املﺸﻜﻠﺔ اﻟﺜﺎﻧﻴﺔ،ﻓﻨﻈﺮًا إﱃﺗﻨﻮع وﺗﻌﺪد وﺟﻬﺎت اﻟﻨﻈﺮﰲﻫﺬا اﻷﻣﺮ داﺧﻞ
املﺠﺘﻤﻌﺎت، واﻻﺧﺘﻼﻓﺎت اﻟﺜﻘﺎﻓﻴﺔﺑني املﺠﺘﻤﻌﺎت،ﻓﺈن اﻷﺳﺌﻠﺔ اﻟﺨﺎﺻﺔﺑﻤﺎﻫﻴﺔ اﻟﺤﻴﺎة
اﻟﺠﻴﺪة ذات املﻌﻨﻰﰲﻇﻞ وﺟﻮد اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻳﻤﻜﻦ اﻹﺟﺎﺑﺔﻋﻨﻬﺎﻋﲆﻧﺤﻮٍﻣﺨﺘﻠﻒﰲ
اﻷﻣﺎﻛﻦ واﻟﺴﻴﺎﻗﺎت املُﺨﺘﻠﻔﺔ، وﻫﻲﺗﺨﻀﻊ،ﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻟﻌﻤﻠﻴﺔ إﱃﻛﻞ أﻧﻮاع اﻟﻌﻤﻠﻴﺎت
اﻟﺴﻴﺎﺳﻴﺔ اﻟﺘﻲﻗﺪﺗﻨﺘﻬﻲ أوﻻﺗﻨﺘﻬﻲﺑﺎﻟﺘﻮاﻓﻖ. واﻻﻋﱰافﺑﻬﺬا اﻟﺘﻨﻮﱡع واﻟﺘﻌﺪﱡدﻗﺪﻳﺆدي
إﱃﻧﻬﺞﻳﻤﻴﻞ إﱃ اﻟﺘﻌﺪﱡدﻳﺔ.ﻛﻤﺎﻳﻤﻜﻦ أنﻳﺄﺧﺬﺷﻜﻞ اﻟﻨﺴﺒﻴﺔ. وﻗﺪ أﺛﺎرت اﻟﻔﻠﺴﻔﺔ
وﻧﻈﺮﻳﺔ املﺠﺘﻤﻊﰲ اﻟﻘﺮن اﻟﻌﴩﻳﻦ،ﺧﺎﺻﺔًﻣﺎﻳُﻌﺮَفﺑﻤﺪرﺳﺔﻣﺎﺑﻌﺪ اﻟﺤﺪاﺛﺔ، اﻟﻜﺜري
99</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻣﻦ اﻟﺸﻜﻮكﺣﻮل اﻹﺟﺎﺑﺎت اﻟﺘﻲﻳُﺰﻋَﻢﻛﻮﻧﻬﺎﻋﺎملﻴﺔﰲﺣني أﻧﻬﺎﻧﺸﺄتﻣﻦﺳﻴﺎقٍﺟﻐﺮاﰲ
وﺗﺎرﻳﺨﻲ وﺛﻘﺎﰲﻣُﻌني )ﻣﻦ »اﻟﻐﺮب«،ﻋﲆﺳﺒﻴﻞ املﺜﺎل( وأﻧﻬﺎﻣﺮﺗﺒﻄﺔﺑﻤﺼﺎﻟﺢ وﻋﻼﻗﺎت
ﻗﻮةﻣُﻌﻴﻨﺔ.ﻛﻤﺎ أﺛريتﺷﻜﻮكﺣﻮلﻣﺎ إذاﻛﺎﻧﺖ اﻟﺴﻴﺎﺳﺔﻳﺠﺐ أنﺗﻬﺪُف إﱃ اﻟﺘﻮاﻓُﻖﻣﻦ
اﻷﺳﺎس )اﻧﻈﺮ أﻋﻤﺎلﺷﺎﻧﺘﺎلﻣﻮف،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﻮف ٣١٠٢(؛ وﻣﺎ إذاﻛﺎن اﻟﺘﻮاﻓُﻖ
ﻣﺮﻏﻮﺑًﺎﻓﻴﻪ داﺋﻤًﺎ، أم أن اﻟﴫاع اﻟﴩسﺣﻮلﻣﺴﺘﻘﺒﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻤﻜﻦ أن
ﻳﻜﻮنﻟﻪﺑﻌﺾ اﻟﻔﻮاﺋﺪ؟ وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻫﻨﺎكﻣﺸﻜﻠﺔ أﺧﺮىﺗﺘﻌﻠﻖﺑﺎﻟﻬﻴﻤﻨﺔ:ﻓﺎﻟﺘﻔﻜري
ﰲ اﻷﺧﻼﻗﻴﺎتﰲ اﻟﻌﺎﻟﻢ اﻟﺤﻘﻴﻘﻲﻳﻌﻨﻲ اﻟﺘﻔﻜريﻟﻴﺲﻓﻘﻂﻓﻴﻤﺎﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪﻓﻴﻤﺎ
ﻳﺘﻌﻠﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻟﻜﻦ أﻳﻀًﺎﻓﻴﻤَﻦﺳﻴﻘﺮر، وﻣَﻦﻳﺠﺐﻋﻠﻴﻪ أنﻳﻘﺮر،ﻣﺴﺘﻘﺒﻞ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺑﺎﻟﺘﺎﱄﻣﺴﺘﻘﺒﻞﻣﺠﺘﻤﻌﻨﺎ. ودﻋﻮﻧﺎﻧﻔﻜﺮﻣﻌًﺎﻣﺮة أﺧﺮىﰲﻗﻀﺎﻳﺎ
اﻟﺤﻜﻢ اﻟﺸﻤﻮﱄ وﻫﻴﻤﻨﺔ اﻟﴩﻛﺎت اﻟﻜﺒرية. وإذا رﻓﻀﻨﺎ اﻟﺤﻜﻢ اﻟﺸﻤﻮﱄ واﻟﺒﻠﻮﺗﻮﻗﺮاﻃﻴﺔ
)ﺣﻜﻢ اﻷﺛﺮﻳﺎء(،ﻓﻤﺎذاﻳﻌﻨﻲ اﺗﺨﺎذﻗﺮار دﻳﻤﻮﻗﺮاﻃﻲﺑﺸﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ﻣﺎﻫﻮ
ﻧﻮع املﻌﺮﻓﺔ املﺘﻌﻠﻖﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳﺤﺘﺎﺟﻪ اﻟﺴﻴﺎﺳﻴﻮن واملﻮاﻃﻨﻮن؟ إذاﻛﺎن
ﻫﻨﺎكﻓَﻬﻢﺿﻌﻴﻒﻟﻠﻐﺎﻳﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣﺸﻜﻼﺗﻪ املﺤﺘﻤَﻠﺔ،ﻓﺈﻧﻨﺎﻧﻮاﺟﻪﺧﻄﺮ
اﻟﺘﻜﻨﻮﻗﺮاﻃﻴﺔ أوﺑﺒﺴﺎﻃﺔﻋﺪم وﺟﻮدﺳﻴﺎﺳﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆ اﻹﻃﻼق.
وﻣﻊ ذﻟﻚ،ﻛﻤﺎﻳُﻮﺿﺢ اﻟﻔﺼﻞ اﻟﺘﺎﱄ،ﻳﺒﺪو أن واﺣﺪةﻋﲆ اﻷﻗﻞﻣﻦ اﻟﻌﻤﻠﻴﺎت اﻟﺴﻴﺎﺳﻴﺔ
املﺘﻌﻠﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺘﻲﻇﻬﺮتﻣﺆﺧﺮًاﺟﺎءتﰲ اﻟﻮﻗﺖ املﻨﺎﺳﺐ. وﺗﻠﻚﻫﻲﺻﻨﻊ
ﺳﻴﺎﺳﺎتﺧﺎﺻﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻫﻲﻋﻤﻠﻴﺔ اﺳﺘﺒﺎﻗﻴﺔ، وﺗﻬﺪف إﱃ اﻟﺘﻮاﻓﻖ، وﺗُﻈﻬِﺮ
درﺟﺔًﻣﺘﺰاﻳﺪةﻣﻦ اﻟﺘﻘﺎرب، وﻳﺒﺪو أﻧﻬﺎﺗﻠﺘﺰمﺑﻨﻮعﻣﻦ اﻟﻌﺎملﻴﺔﺑﻼﺧﺠﻞ، وﺗﻌﺘﻤﺪﻋﲆ
املﻌﺮﻓﺔ اﻟﺨﺒرية، وﺗﺰﻋﻢ — وﻟﻮﻋﲆ اﻷﻗﻞﺷﻔﻬﻴٍّﺎ — اﺣﱰامﻣﺒﺎدئ اﻟﺪﻳﻤﻘﺮاﻃﻴﺔ، وﺧﺪﻣﺔ
اﻟﺼﺎﻟﺢ اﻟﻌﺎم واملﺼﻠﺤﺔ اﻟﻌﺎﻣﺔ، وﻣﺸﺎرﻛﺔﺟﻤﻴﻊ اﻷﻃﺮاف املَﻌﻨﻴﺔ.
100</p>
</section>
<section id="section-11">
    <h2>السياسات المقترحة</h2>
    <div class="page-range">Pages 101-112</div>
    <p>اﻟﻔﺼﻞ اﻟﻌﺎﴍ
اﻟﺴﻴﺎﺳﺎت اﳌﻘﱰﺣﺔ
ﻣﺎﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪ وأﺳﺌﻠﺔ أﺧﺮىﻳﺘﻌنيﱠﻋﲆﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت اﻹﺟﺎﺑﺔﻋﻨﻬﺎ
ﻧﻈﺮًا إﱃ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ املُﺮﺗﺒﻄﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﺈﻧﻪﻣﻦ اﻟﻮاﺿﺢ أنﺷﻴﺌًﺎﻣﺎ
ﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪ. وﻟﺬا،ﺗﺘﻀﻤﱠﻦﻣﻌﻈﻢﻣﺒﺎدرات اﻟﺴﻴﺎﺳﺎت املُﺘﻌﻠﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﺟﺪﻳﺮﺑﺎﻟﺬﻛﺮ أنﻫﻨﺎك اﻟﻜﺜريﻣﻦ املﺒﺎدراتﰲﻫﺬا املﺠﺎل
ﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄ. وﻣﻊ ذﻟﻚ،ﻟﻴﺲﻣﻦ اﻟﻮاﺿﺢﺑﺎﻟﻀﺒﻂﻣﺎﻳﺠِﺐ اﻟﻘﻴﺎمﺑﻪ، وﻣﺎ املﺴﺎر اﻟﺬي
ﻳﺠﺐ اﺗﱢﺨﺎذه.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻟﻴﺲ واﺿﺤًﺎﻛﻴﻔﻴﺔ اﻟﺘﻌﺎﻣُﻞﻣﻊﻣﺸﻜﻠﺔ اﻟﺸﻔﺎﻓﻴﺔ أو اﻟﺘﺤﻴﱡﺰ،
ﻧﻈﺮًا إﱃ اﻟﺘﻘﻨﻴﺎتﻧﻔﺴﻬﺎ، واﻟﺘﺤﻴﱡﺰ اﻟﺬيﻳُﻌﺎﻧﻲﻣﻨﻪ املﺠﺘﻤﻊﺑﺎﻟﻔﻌﻞ، واﻵراء املُﺘﺒﺎﻳﻨﺔﺣﻮل
اﻟﻌﺪاﻟﺔ واﻹﻧﺼﺎف. وﻫﻨﺎك أﻳﻀًﺎ اﻟﻌﺪﻳﺪﻣﻦ اﻟﺘﺪاﺑري املُﻤﻜﻦ اﺗﺨﺎذﻫﺎ: إذﻳﻤﻜﻦ أنﺗﻌﻨﻲ
اﻟﺴﻴﺎﺳﺔ اﻟﺘﻨﻈﻴﻢَﻣﻦﺧﻼل إﺻﺪار اﻟﻘﻮاﻧني واﻟﻠﻮاﺋﺢ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﻷﻧﻈﻤﺔ اﻟﻘﺎﻧﻮﻧﻴﺔ،
وﻟﻜﻦﻫﻨﺎك أﻳﻀًﺎ اﺳﱰاﺗﻴﺠﻴﺎت أﺧﺮىﻗﺪﺗﻜﻮنﻣُﺘﺼﻠﺔ أوﻏريﻣﺘﺼﻠﺔﺑﺎﻷﻧﻈﻤﺔ اﻟﻘﺎﻧﻮﻧﻴﺔ،
ﻣﺜﻞ اﻟﺘﺪاﺑري اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ، وﻗﻮاﻋﺪ اﻷﺧﻼق، واﻟﺘﻌﻠﻴﻢ. وﻻﻳﻘﺘﴫ اﻟﺘﻨﻈﻴﻢﻋﲆ اﻟﻘﻮاﻧني وﻟﻜﻨﻪ
ﻳﺘﻀﻤﻦ أﻳﻀًﺎﻣﻌﺎﻳريﻣﺜﻞﻣﻌﺎﻳري اﻵﻳﺰو. وﻋﻼوةﻋﲆ ذﻟﻚ،ﻫﻨﺎك أﻳﻀًﺎ أﻧﻮاع أﺧﺮىﻣﻦ
اﻷﺳﺌﻠﺔ اﻟﺘﻲﻳﺘﻌنيﱠ اﻹﺟﺎﺑﺔﻋﻨﻬﺎﰲ اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ؛ﻓﺎﻷﻣﺮﻟﻴﺲﻓﻘﻂﻣﺎﻳﺠِﺐ اﻟﻘﻴﺎم
ﺑﻪ، وﻟﻜﻦ أﻳﻀًﺎ ملﺎذاﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪ، وﻣﺘﻰﻳﺠِﺐ اﻟﻘﻴﺎمﺑﻪ، وﻣﺎﻣِﻘﺪارﻣﺎﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪ،
وﻣَﻦﻳﺠﺐﻋﻠﻴﻪ أنﻳﻘﻮمﺑﻪ، وﻣﺎﻫﻲﻃﺒﻴﻌﺔ املﺸﻜﻠﺔ وﻣَﺪاﻫﺎ ودرﺟﺔﺧﻄﻮرﺗﻬﺎ وإﻟﺤﺎﺣﻬﺎ.
أوﻻً :ﻣﻦ املُﻬﻢﺗﱪﻳﺮ اﻟﺘﺪاﺑري املﻘﱰﺣﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﺗﺴﺘﻨِﺪ اﻟﺴﻴﺎﺳﺔ املُﻘﱰﺣﺔ
إﱃﻣﺒﺎدئﺣﻘﻮق اﻹﻧﺴﺎنﻟﺘﱪﻳﺮ اﻗﱰاحٍﺑﺎﻟﺘﻘﻠﻴﻞﻣﻦ اﺗﺨﺎذ اﻟﻘﺮارات اﻟﺘﻲﺗﻌﺘﻤِﺪﻋﲆ
ﺧﻮارزﻣﻴﺎتﻣُﺘﺤﻴﺰة.ﺛﺎﻧﻴًﺎ: اﺳﺘﺠﺎﺑﺔ إﱃ اﻟﺘﻄﻮﱡر اﻟﺘﻜﻨﻮﻟﻮﺟﻲ،ﻏﺎﻟﺒًﺎﻣﺎﺗﺄﺗﻲ اﻟﺴﻴﺎﺳﺔ
ﺑﻌﺪﻓﻮات اﻷوان،ﻋﻨﺪﻣﺎﺗﻜﻮن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻗﺪﺗﻮﻏﱠﻠﺖﺑﺎﻟﻔﻌﻞﰲ املﺠﺘﻤﻊ ودﺧﻠﺖﰲﻛﻞﱢ</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﳾء.ﺑﺪﻻًﻣﻦ ذﻟﻚ،ﻳﻤﻜﻦ أنﻧُﺤﺎول وﺿﻊﺳﻴﺎﺳﺔﻗﺒﻞ أنﻳﻜﺘﻤِﻞﺗﻄﻮﻳﺮ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
وﻳﺒﺪأ اﺳﺘﺨﺪاﻣﻬﺎ. وﻓﻴﻤﺎﻳﺨﺺﱡ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻳﻤﻜﻦ اﻟﻘﻮل إنﻫﺬاﻣﺎ زالﻣُﻤﻜﻨًﺎ،
إﱃﺣﺪﱟﻣﺎ،ﻋﲆ اﻟﺮﻏﻢﻣﻦ أن اﻟﻜﺜريﻣﻦ اﻷﻧﻈﻤﺔ املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻮﺟﻮدة
ﺑﺎﻟﻔﻌﻞﺣﻮﻟﻨﺎ. واﻟﺒُﻌﺪ اﻟﺰﻣﻨﻲﻣُﻬﻢ أﻳﻀًﺎﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖﺑﺎﻟﻨﻄﺎق اﻟﺰﻣﻨﻲﻟﻠﺴﻴﺎﺳﺔ:ﻫﻞﻫﻲ
ﻣُﺨﺼﱠﺼﺔﻓﻘﻂﻟﻠﺴﻨﻮات اﻟﺨﻤﺲ أو اﻟﻌﴩ املﻘﺒﻠﺔ، أمﺗﻬﺪف إﱃ أنﺗُﻜﻮﱢن إﻃﺎرﻋﻤﻞ
ﻋﲆ املﺪى اﻟﺒﻌﻴﺪ؟ﻫﻨﺎﻋﻠﻴﻨﺎ أنﻧﺨﺘﺎر.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦﺗﺠﺎﻫﻞ اﻟﺘﻨﺒﺆاتﻋﲆ
املﺪى اﻟﺒﻌﻴﺪ واﻟﱰﻛﻴﺰﻋﲆ املﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ،ﻛﻤﺎﺗﻔﻌﻞﻣﻌﻈﻢ اﻟﺴﻴﺎﺳﺎت املُﻘﱰﺣﺔ، أو
ﻳﻤﻜﻦﻃﺮح رؤﻳﺔ ملﺴﺘﻘﺒﻞ اﻹﻧﺴﺎﻧﻴﺔ.ﺛﺎﻟﺜًﺎ:ﻻﻳﺘﻔﻖ اﻟﺠﻤﻴﻊﻋﲆ أنﺣﻞﱠ املﺸﻜﻼتﻳﺘﻄﻠﱠﺐ
اﻟﻜﺜريﻣﻦ اﻟﺘﺪاﺑري اﻟﺠﺪﻳﺪة.ﻳﺰﻋﻢﺑﻌﺾ اﻷﺷﺨﺎص واملﺆﺳﺴﺎت أن اﻟﺘﴩﻳﻌﺎت اﻟﺤﺎﻟﻴﺔ
ﻛﺎﻓﻴﺔﻟﻠﺘﻌﺎﻣُﻞﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻓﺈذاﻛﺎنﻫﺬاﻫﻮ اﻟﺤﺎل،ﻓﺈﻧﻪﻳﺒﺪو أن املُﴩﱢﻋني
ﻟﻴﺴﻮاﰲﺣﺎﺟﺔ إﱃ اﻟﻘﻴﺎمﺑﺎﻟﻜﺜري،ﰲﺣني أن اﻟﺬﻳﻦﻳُﻔﴪون اﻟﻘﺎﻧﻮن واﻟﺬﻳﻦﻳُﻄﻮﱢرون
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻢﻣَﻦﻳﺤﺘﺎﺟﻮن إﱃ اﻟﻌﻤﻞ اﻟﺪءوب. وﻳﻌﺘﻘﺪ آﺧَﺮون أﻧﻪﻳﺠﺐ أنﻧُﻌﻴﺪ
اﻟﺘﻔﻜريﰲﺟﻮﻫﺮ املﺠﺘﻤﻊ وﻣﺆﺳﺴﺎﺗﻪ،ﺑﻤﺎﰲ ذﻟﻚ أﻧﻈﻤﺘﻨﺎ اﻟﻘﺎﻧﻮﻧﻴﺔ،ﻣﻦ أﺟﻞ اﻟﺘﻌﺎﻣُﻞﻣﻊ
املﺸﻜﻼت اﻷﺳﺎﺳﻴﺔ وإﻋﺪاد أﺟﻴﺎل املُﺴﺘﻘﺒﻞ. راﺑﻌًﺎ:ﻳﺠﺐ أنﺗﻮﺿﱢﺢ اﻟﺴﻴﺎﺳﺔ املﻘﱰﺣﺔﻣَﻦ
ﻫﺬاﻋﲆﺟﻬﺔٍ واﺣﺪة وإﻧﻤﺎ أﻛﺜﺮﻣﻦﺟﻬﺔ.
اﻟﺬيﻳﺠﺐ أنﻳﺘﺨﺬ اﻹﺟﺮاءات. وﻗﺪﻻﻳﻘﺘﴫِ
ﻓﻜﻤﺎ رأﻳﻨﺎ،ﻳﺸﱰك اﻟﻜﺜريونﰲ أيﻋﻤﻞٍﺗﻜﻨﻮﻟﻮﺟﻲ. وﻳُﺜريﻫﺬاﺳﺆاﻻًﺣﻮلﻛﻴﻔﻴﺔﺗﻮزﻳﻊ
املﺴﺌﻮﻟﻴﺔﻋﻦ اﻟﺴﻴﺎﺳﺔ واﻟﺘﻐﻴري:ﻫﻞ اﻟﺤﻜﻮﻣﺎت أﺳﺎﺳًﺎﻫﻲ املﺴﺌﻮﻟﺔﻋﻦ اﺗﺨﺎذ إﺟﺮاءات،
أمﻳﺠﺐ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﲆ اﻟﴩﻛﺎت واﻟﺼﻨﺎﻋﺔ اﺗﺨﺎذ إﺟﺮاءاتٍﺧﺎﺻﺔﺑﻬﺎﻟﻀﻤﺎن
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻷﺧﻼﻗﻲ؟ وﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖﺑﺎﻟﴩﻛﺎت،ﻫﻞﻳﺠﺐﻣﺨﺎﻃﺒﺔ اﻟﴩﻛﺎت اﻟﻜﺒرية
ﻓﻘﻂ أم أﻳﻀًﺎ اﻟﴩﻛﺎت اﻟﺼﻐرية واملﺘﻮﺳﱢﻄﺔ اﻟﺤﺠﻢ؟ وﻣﺎﻫﻮ دور اﻟﻌﻠﻤﺎء )املُﺨﺘﺼﱢ ني
ﺑﺎﻟﻜﻤﺒﻴﻮﺗﺮ( واملﻬﻨﺪﺳني اﻷﻓﺮاد؟ وﻣﺎﻫﻮ دور املﻮاﻃﻨني؟
ﺧﺎﻣﺴًﺎ:ﺗﻌﺘﻤﺪ اﻹﺟﺎﺑﺔﻋﻤﺎﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪ وﻣﻘﺪارﻣﺎﻳﺠﺐ اﻟﻘﻴﺎمﺑﻪ، وﻋﻦ أﺳﺌﻠﺔ
أﺧﺮى،ﻋﲆﻛﻴﻔﻴﺔﺗﻌﺮﻳﻒﻃﺒﻴﻌﺔ املﺸﻜﻠﺔﻧﻔﺴﻬﺎ وﻣَﺪاﻫﺎ ودرﺟﺔﺧﻄﻮرﺗﻬﺎ وإﻟﺤﺎﺣﻬﺎ.
ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻫﻨﺎك اﺗﺠﺎهﰲﺳﻴﺎﺳﺎت اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ )وﰲ اﻟﻮاﻗﻊ،ﰲ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ(ﻟﺮؤﻳﺔﻣﺸﻜﻼتٍﺟﺪﻳﺪةﰲﻛﻞﱢﻣﻜﺎن. وﻣﻊ ذﻟﻚ،ﻛﻤﺎ رأﻳﻨﺎﰲ اﻟﻔﺼﻞ اﻟﺴﺎﺑﻖ،
ﻓﺎﻟﻌﺪﻳﺪﻣﻦ املﺸﻜﻼتﻗﺪﻻﺗﻜﻮنﺣﻜﺮًاﻋﲆ اﻟﺘﻘﻨﻴﺎت اﻟﺠﺪﻳﺪة، وﻟﻜﻨﻬﺎ رﺑﻤﺎﺗﻜﻮنﻣﻮﺟﻮدةً
ﻣﻨﺬ وﻗﺖٍﻃﻮﻳﻞ.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻛﻤﺎ أﻇﻬﺮ اﻟﻨﻘﺎشﺣﻮل اﻟﺘﺤﻴﱡﺰ،ﻳﻌﺘﻤِﺪﻣﺎﻧﻘﱰح اﻟﻘﻴﺎم
ﺑﻪﻋﲆﻛﻴﻔﻴﺔﺗﻌﺮﻳﻒ املﺸﻜﻠﺔ:ﻫﻞﻫﻲﻣﺸﻜﻠﺔﺧﺎﺻﺔﺑﺎﻟﻌﺪاﻟﺔ، وإذاﻛﺎﻧﺖﻛﺬﻟﻚ،ﻓﻤﺎﻫﻮ
102</p>
<p>اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ
ﻧﻮع اﻟﻌﺪاﻟﺔ املُﻬﺪﱠدة؟ﺳﻴﺸﻜﻞﺗﻌﺮﻳﻒ املﺸﻜﻠﺔ اﻟﺘﺪاﺑري اﻟﺘﻲﻧﻘﱰﺣﻬﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إذا
ﻗﺪﱠﻣﻨﺎﺗﺪاﺑريﻟﻠﻌﻤﻞ اﻹﻳﺠﺎﺑﻲ،ﻓﺈنﻫﺬاﻳﺴﺘﻨﺪ إﱃﺗﻌﺮﻳﻒٍﻣُﻌنيﻟﻠﻤﺸﻜﻠﺔ. وأﺧريًا،ﻳﻠﻌﺐ
أﻳﻀًﺎﺗﻌﺮﻳﻒ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ دورًاﰲﺗﺤﺪﻳﺪ اﻟﺴﻴﺎﺳﺔ املﻘﱰﺣﺔ وﻧﻄﺎﻗﻬﺎ، وﻗﺪﻛﺎنﻫﺬا
اﻟﺘﻌﺮﻳﻒ داﺋﻤًﺎﻣُﺜريًاﻟﻠﺠﺪل واﻟﻨﻘﺎﺷﺎت.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻫﻞﻣِﻦ املُﻤﻜﻦ وﻣﻦ املُﺴﺘﺤﺴَﻦ
أنﻧُﻤﻴﺰﺑﻮﺿﻮحﺑني اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺨﻮارزﻣﻴﺎت اﻟﺬﻛﻴﺔ املُﺴﺘﻘﻠﺔ، أوﺑني اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ وﺗﻘﻨﻴﺎت اﻷﺗﻤﺘﺔ؟ﺟﻤﻴﻊﻫﺬه اﻷﺳﺌﻠﺔﺗﺠﻌﻞﻣﻦﺻﻨﻊ اﻟﺴﻴﺎﺳﺎت املُﺘﻌﻠﻘﺔ
ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻣﺮًاﻗﺪﻳُﺜري اﻟﺠﺪلﺑﺸﻜﻞٍﻛﺒري. وﺑﺎﻟﻔﻌﻞ،ﻧﺠﺪ اﻟﻌﺪﻳﺪﻣﻦ اﻻﺧﺘﻼﻓﺎت
واﻟﺠﺪاﻻت،ﻋﲆﺳﺒﻴﻞ املﺜﺎلﺣﻮلﻣﺪى اﻟﺤﺎﺟﺔ إﱃﺗﴩﻳﻌﺎتﺟﺪﻳﺪة، وﺣﻮل املﺒﺎدئ اﻟﺘﻲ
ﻳﺠﺐ اﻻﺳﺘﻨﺎد إﻟﻴﻬﺎﺑﺎﻟﻀﺒﻂﻟﺘﱪﻳﺮ اﻟﺘﺪاﺑري، وﺣﻮلﻣﺴﺄﻟﺔﻣﺎ إذاﻛﺎنﻳﻨﺒﻐﻲﺗﺤﻘﻴﻖﺗﻮازن
ﺑني أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻻﻋﺘﺒﺎرات اﻷﺧﺮى )ﻣﺜﻞﺗﻨﺎﻓﺴﻴﺔ اﻟﴩﻛﺎت واﻻﻗﺘﺼﺎد(.
وﻣﻊ ذﻟﻚ، إذاﻓﻜﱠﺮﻧﺎﰲ وﺛﺎﺋﻖ اﻟﺴﻴﺎﺳﺔ اﻟﻔﻌﻠﻴﺔ،ﻓﺴﻨﺠﺪ درﺟﺔًﻣﻠﺤﻮﻇﺔﻣﻦ اﻟﺘﻘﺎرُب.
املﺒﺎدئ اﻷﺧﻼﻗﻴﺔ واﻟﺘﱪﻳﺮات
ﻟﻘﺪ أدﱠى اﻹﺣﺴﺎس اﻟﻮاﺳﻊ اﻻﻧﺘﺸﺎرﺑﴬورة وأﻫﻤﻴﺔ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﺘﺤﺪﻳﺎت اﻷﺧﻼﻗﻴﺔ
واملُﺠﺘﻤﻌﻴﺔ اﻟﺘﻲ أﺛﺎرﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﺳَﻴﻞﻣﻦ املﺒﺎدرات ووﺛﺎﺋﻖ اﻟﺴﻴﺎﺳﺎت اﻟﺘﻲ
ﻻﺗُﻌﺮﱢفﻓﻘﻂﺑﻌﺾ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ املُﺮﺗﺒﻄﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻟﻜﻨﻬﺎﺗﻬﺪف
أﻳﻀًﺎ إﱃﺗﻮﻓريﺗﻮﺟﻴﻬﺎتﻣِﻌﻴﺎرﻳﺔﻟﻠﺴﻴﺎﺳﺎت. وﻗﺪ اﻗﱰُﺣﺖﺳﻴﺎﺳﺎتﺧﺎﺻﺔﺑﺎﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﺗﺸﺘﻤﻞﻋﲆﻋﻨﴫٍ أﺧﻼﻗﻲﻣﻦﻗِﺒﻞﻣﺠﻤﻮﻋﺔﻣﺘﻨﻮﻋﺔﻣﻦ اﻟﺠﻬﺎت،ﺑﻤﺎﰲ ذﻟﻚ
اﻟﺤﻜﻮﻣﺎت واﻟﻬﻴﺌﺎت اﻟﺤﻜﻮﻣﻴﺔﻣﺜﻞ اﻟﻠﺠﺎن اﻟﻮﻃﻨﻴﺔﻟﻸﺧﻼﻗﻴﺎت، وﴍﻛﺎت اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
ﻣﺜﻞﺟﻮﺟﻞ، واملﻬﻨﺪﺳني وﻣﻨﻈﻤﺎﺗﻬﻢ املﻬﻨﻴﺔﻣﺜﻞﻣﻌﻬﺪﻣﻬﻨﺪﳼ اﻟﻜﻬﺮﺑﺎء واﻹﻟﻜﱰوﻧﻴﺎت،
واﻟﻬﻴﺌﺎت اﻟﺤﻜﻮﻣﻴﺔ اﻟﺪوﻟﻴﺔﻣﺜﻞ اﻻﺗﺤﺎد اﻷوروﺑﻲ، واﻟﺠﻬﺎتﻏري اﻟﺤﻜﻮﻣﻴﺔ وﻏري اﻟﻬﺎدﻓﺔ
ﻟﻠﺮﺑﺢ، واﻟﺒﺎﺣﺜني.
ﻟﻘﺪ أدﱠى اﻹﺣﺴﺎس اﻟﻮاﺳﻊ اﻻﻧﺘﺸﺎرﺑﴬورة وأﻫﻤﻴﺔ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﺘﺤﺪﻳﺎت اﻷﺧﻼﻗﻴﺔ واملُﺠﺘﻤﻌﻴﺔ
اﻟﺘﻲ أﺛﺎرﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﱃﺳَﻴﻞﻣﻦ املﺒﺎدرات ووﺛﺎﺋﻖ اﻟﺴﻴﺎﺳﺎت.
إذا راﺟﻌﻨﺎﺑﻌﺾ املﺒﺎدرات واملﻘﱰﺣﺎت اﻟﺤﺪﻳﺜﺔ،ﻳﺘﺒنيﱠ أنﻣﻌﻈﻢ اﻟﻮﺛﺎﺋﻖﺗﺒﺪأﺑﺘﱪﻳﺮ
اﻟﺴﻴﺎﺳﺔﻣﻦﺧﻼلﺗﻮﺿﻴﺢ املﺒﺎدئ،ﺛﻢﺗُﻘﺪمﺑﻌﺾ اﻟﺘﻮﺻﻴﺎتﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺎملﺸﻜﻼت
103</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻷﺧﻼﻗﻴﺔ املُﺤﺪدة. وﻛﻤﺎﺳﻨﺮى،ﻫﺬه املﺸﻜﻼت واملﺒﺎدئﺷﺪﻳﺪة اﻟﺘﺸﺎﺑُﻪ. وﰲﻛﺜريﻣﻦ
اﻟﺤﺎﻻت،ﺗﻌﺘﻤِﺪ املﺒﺎدراتﻋﲆﻣﺒﺎدئ أﺧﻼﻗﻴﺔﻋﺎﻣﺔ وﻣﺒﺎدئﻣﻦﻗﺎﻧﻮن أﺧﻼﻗﻴﺎت املﻬﻨﺔ.
ﻓﺪﻋﻮﻧﻲ أُراﺟِﻊﻣﻌﻜﻢﺑﻌﺾ املﻘﱰﺣﺎت.
ﺗﺮﻓﺾﻣﻌﻈﻢ املﻘﱰﺣﺎتﺳﻴﻨﺎرﻳﻮ اﻟﺨﻴﺎل اﻟﻌﻠﻤﻲ اﻟﺬيﺗﺴﺘﻮﱄﻓﻴﻪ اﻵﻻت اﻟﻔﺎﺋﻘﺔ
اﻟﺬﱠﻛﺎءﻋﲆ زﻣﺎم اﻷﻣﻮر وﺗﺘﻮﱃﱠﻓﻴﻪ اﻟﺴﻴﻄﺮة.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﻓﱰة رﺋﺎﺳﺔ أوﺑﺎﻣﺎ،
ﻧﴩتﺣﻜﻮﻣﺔ اﻟﻮﻻﻳﺎت املﺘﺤﺪةﺗﻘﺮﻳﺮًاﺑﻌﻨﻮان »اﻻﺳﺘﻌﺪاد ملُﺴﺘﻘﺒﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ«،
ﺗﺆﻛﱢﺪﻓﻴﻪﴏاﺣﺔًﻋﲆ أن املﺨﺎوف اﻟﻄﻮﻳﻠﺔ اﻷﻣﺪﺑﺸﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻔﺎﺋﻖ اﻟﻌﺎم
»ﻳﺠﺐ أﻻﻳﻜﻮنﻟﻬﺎﺗﺄﺛريﻛﺒريﻋﲆ اﻟﺴﻴﺎﺳﺔ اﻟﺤﺎﻟﻴﺔ« )املﻜﺘﺐ اﻟﺘﻨﻔﻴﺬيﻟﻠﺮﺋﻴﺲ ٦١٠٢،
٨(. وﺑﺪﻻًﻣﻦ ذﻟﻚ،ﻳﺘﻨﺎول اﻟﺘﻘﺮﻳﺮ املُﺸﻜﻼت اﻟﺤﺎﻟﻴﺔ واملُﺘﻮﻗﱠﻌﺔﰲ املﺴﺘﻘﺒﻞ اﻟﻘﺮﻳﺐ اﻟﺘﻲ
ﻳُﺜريﻫﺎﺗﻌﻠﱡﻢ اﻵﻟﺔ،ﻣﺜﻞ اﻟﺘﺤﻴﱡﺰ وﻣﺸﻜﻠﺔ أﻧﻪﺣﺘﻰ املُﻄﻮرونﻗﺪﻻﻳﻔﻬﻤﻮنﻧﻈﺎﻣﻬﻢﺑﻤﺎﻓﻴﻪ
اﻟﻜﻔﺎﻳﺔﻟﺘﺠﻨﱡﺐﻣﺜﻞﻫﺬه اﻟﻌﻮاﻗﺐ. وﻳﺆﻛﱢﺪ اﻟﺘﻘﺮﻳﺮ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣُﻔﻴﺪﻟﻼﺑﺘﻜﺎر
واﻟﻨﻤﻮ اﻻﻗﺘﺼﺎدي وﻳُﺸﺪﱢدﻋﲆ اﻟﺮﻗﺎﺑﺔ اﻟﺬاﺗﻴﺔ، وﻟﻜﻨﻪﻳﻘﻮل إنﺣﻜﻮﻣﺔ اﻟﻮﻻﻳﺎت املﺘﺤﺪة
ﻳُﻤﻜﻨﻬﺎﻣﺮاﻗﺒﺔﺳﻼﻣﺔ اﻟﺘﻄﺒﻴﻘﺎت وﻋﺪاﻟﺘﻬﺎ، وﺗﻌﺪﻳﻞ اﻷﻃﺮ اﻟﻘﺎﻧﻮﻧﻴﺔ إذاﻟﺰِم اﻷﻣﺮ.
ﻋﻼوةًﻋﲆ ذﻟﻚ،ﺗﻤﻠﻚ اﻟﻌﺪﻳﺪﻣﻦ اﻟﺪول اﻷوروﺑﻴﺔﺣﺎﻟﻴٍّﺎ اﺳﱰاﺗﻴﺠﻴﺎتﻟﻠﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﺗﺘﻀﻤﱠﻦﻋﻨﴫًا أﺧﻼﻗﻴٍّﺎ. وﻳُﻌﺪ »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺑﻞﻟﻠﺘﻔﺴري«ﻫﺪﻓًﺎ
ﻣﺸﱰﻛًﺎﺑني اﻟﻌﺪﻳﺪﻣﻦﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت.ﻳﻘﻮلﻣﺠﻠﺲﻋﻤﻮم املﻤﻠﻜﺔ املﺘﺤﺪة )٨١٠٢(
إن اﻟﺸﻔﺎﻓﻴﺔ وﺣﻖ اﻟﺘﻔﺴري أﻣﻮر أﺳﺎﺳﻴﺔﻟﻨﺘﻤﻜﱠﻦﻣﻦﻣﺴﺎءﻟﺔ اﻟﺨﻮارزﻣﻴﺎت، وﻳﺠﺐ
ﻋﲆ اﻟﺼﻨﺎﻋﺎت واﻟﺠﻬﺎت اﻟﺘﴩﻳﻌﻴﺔ اﻟﺘﻌﺎﻣُﻞﻣﻊﻣﺴﺄﻟﺔ اﺗﺨﺎذ اﻟﻘﺮارات املُﺘﺤﻴﺰةﻣﻦ
ﻗِﺒﻞ اﻟﺨﻮارزﻣﻴﺎت.ﻛﺬﻟﻚﺗﻔﺤﺺﻟﺠﻨﺔﻣﺠﻠﺲﻟﻮردات املﻤﻠﻜﺔ املﺘﺤﺪة املﺨﺘﺎرة املَﻌﻨﻴﺔ
ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺘﺪاﻋِﻴﺎت اﻷﺧﻼﻗﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﰲﻓﺮﻧﺴﺎ،ﻳﻘﱰحﺗﻘﺮﻳﺮ
ﻓﻴﻼﻧﻲ اﻟﻌﻤﻞﻧﺤﻮﺗﻄﻮﻳﺮ »ذﻛﺎء اﺻﻄﻨﺎﻋﻲ ذيﻣﻌﻨًﻰ«ﻻﻳﺆدي إﱃﺗﻔﺎﻗُﻢﻣﺸﻜﻼت
اﻹﻗﺼﺎء، أوﻳﺰﻳﺪﻣﻦ اﻟﺘﻔﺎوت اﻻﺟﺘﻤﺎﻋﻲ، أوﻳﺆدي إﱃﻣﺠﺘﻤﻊﺗﺤﻜُﻤﻨﺎﻓﻴﻪﺧﻮارزﻣﻴﺎت
»ﺻﻨﺎدﻳﻖﺳﻮداء«؛ إذﻳﺠﺐ أنﻳﻜﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺎﺑﻼًﻟﻠﺘﻔﺴري وﺻﺪﻳﻘًﺎﻟﻠﺒﻴﺌﺔ
(.ﻛﻤﺎ أﻧﺸﺄت اﻟﻨﻤﺴﺎﻣﺆﺧﺮًاﻣﺠﻠﺴًﺎ اﺳﺘﺸﺎرﻳٍّﺎ وﻃﻨﻴٍّﺎﻣﻌﻨﻴٍّﺎﺑﺎﻟﺮوﺑﻮﺗﺎتVillani 2018)
واﻟﺬيﻗﺪﱠمﺗﻮﺻﻴﺎتٍﻟﺴﻴﺎﺳﺔٍﺗﺴﺘﻨِﺪ إﱃﺣﻘﻮق اﻹﻧﺴﺎن، واﻟﻌﺪاﻟﺔ1،واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
واﻹﻧﺼﺎف، واﻹﴍاك واﻟﺘﻀﺎﻣُﻦ، واﻟﺪﻳﻤﻘﺮاﻃﻴﺔ واملﺸﺎرﻛﺔ، وﻋﺪم اﻟﺘﻤﻴﻴﺰ، واملﺴﺌﻮﻟﻴﺔ،
وﻗِﻴَﻢ أﺧﺮىﺷﺒﻴﻬﺔ.ﻛﻤﺎﺗُﻮﴆ ورﻗﺘﻬﺎ اﻟﺒﻴﻀﺎءﺑﺘﻄﻮﻳﺮ ذﻛﺎء اﺻﻄﻨﺎﻋﻲﻗﺎﺑﻞٍﻟﻠﺘﻔﺴري
وﺗﻘﻮلﴏاﺣﺔً إن املﺴﺌﻮﻟﻴﺔﺗﻈﻞﱡﻋﲆﻋﺎﺗﻖ اﻟﺒﴩ؛ وﻻﻳﻤﻜﻦ أنﻳﻜﻮن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
104</p>
<p>اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ
.(.ﻛﺬﻟﻚ،ﻓﺈن اﻟﻬﻴﺌﺎت واملﺆﺗﻤﺮات اﻟﺪوﻟﻴﺔﻧﺸﻄﺔﻟﻠﻐﺎﻳﺔACRAI 2018)ﻣﺴﺌﻮﻻً أﺧﻼﻗﻴٍّﺎ
ﻓﻘﺪﻧﴩ املﺆﺗﻤﺮ اﻟﺪوﱄ ملُﻔﻮﴈﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت واﻟﺨﺼﻮﺻﻴﺔ إﻋﻼﻧًﺎﺑﺸﺄن اﻷﺧﻼﻗﻴﺎت
وﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎتﰲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻳﺘﻀﻤﱠﻦﻣﺒﺎدئ اﻟﻌﺪاﻟﺔ، واملﺴﺎءﻟﺔ، واﻟﺸﻔﺎﻓﻴﺔ
واﻟﻔﻬﻢ، واﻟﺘﺼﻤﻴﻢ املﺴﺌﻮل، واﻟﺨﺼﻮﺻﻴﺔ املُﺘﻀﻤﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ )ﻣﻔﻬﻮمﻳُﻄﺎﻟﺐﺑﻤﺮاﻋﺎة
اﻟﺨﺼﻮﺻﻴﺔﰲﺟﻤﻴﻊﻣﺮاﺣﻞﻋﻤﻠﻴﺔ اﻟﻬﻨﺪﺳﺔ(، وﺗﻤﻜني اﻷﻓﺮاد، واﻟﺤﺪﱢﻣﻦ اﻟﺘﺤﻴﺰ أو
(.ICDPPC 2018)اﻟﺘﻤﻴﻴﺰ وﺗﺨﻔﻴﻒ آﺛﺎرﻫﻤﺎ
ﻳﻀﻊﺑﻌﺾﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎتﻫﺪﻓﻬﻢﰲ إﻃﺎر »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺠﺪﻳﺮﺑﺎﻟﺜﻘﺔ«.
ﻓﻌﲆﺳﺒﻴﻞ املﺜﺎل،ﺗﺆﻛﱢﺪ املُﻔﻮﺿﻴﺔ اﻷوروﺑﻴﺔ، اﻟﺘﻲﺗُﻌَﺪﺑﻼﺷﻚﱟ واﺣﺪةﻣﻦ أﺑﺮز اﻟﻬﻴﺌﺎت
اﻟﻌﺎملﻴﺔﰲﻣﺠﺎلﺻُﻨﻊﺳﻴﺎﺳﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻋﲆ أﻫﻤﻴﺔﻫﺬا املﺼﻄﻠﺢ. وﰲ أﺑﺮﻳﻞ
٨١٠٢، أﻧﺸﺄتﻓﺮﻳﻖَﺧﱪاء رﻓﻴﻊ املﺴﺘﻮىﻣﻌﻨِﻴٍّﺎﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻮﺿﻊﻣﺠﻤﻮﻋﺔٍ
ﺟﺪﻳﺪةﻣﻦ إرﺷﺎدات اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؛ وﰲ دﻳﺴﻤﱪ ٨١٠٢، أﺻﺪر اﻟﻔﺮﻳﻖﻣُﺴﻮدة
وﺛﻴﻘﺔﻋﻤﻞﺗﺘﻀﻤﱠﻦ إرﺷﺎدات أﺧﻼﻗﻴﺔﺗﺪﻋﻮ إﱃﻧﻬﺞٍﰲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺘﻤﺤﻮرﺣﻮل
اﻹﻧﺴﺎن، وإﱃﺗﻄﻮﻳﺮ ذﻛﺎءٍ اﺻﻄﻨﺎﻋﻲﺟﺪﻳﺮﺑﺎﻟﺜﻘﺔ،ﻳﺤﱰم اﻟﺤﻘﻮق اﻷﺳﺎﺳﻴﺔ واملﺒﺎدئ
اﻷﺧﻼﻗﻴﺔ. وﻛﺎﻧﺖ اﻟﺤﻘﻮق املﺬﻛﻮرةﻫﻲﻛﺮاﻣﺔ اﻹﻧﺴﺎن، وﺣﺮﻳﺔ اﻟﻔﺮد، واﺣﱰام اﻟﺪﻳﻤﻘﺮاﻃﻴﺔ،
واﻟﻌﺪاﻟﺔ، وﺳﻴﺎدة اﻟﻘﺎﻧﻮن، وﺣﻘﻮق املﻮاﻃﻦ. أﻣﺎ املﺒﺎدئ اﻷﺧﻼﻗﻴﺔ،ﻓﻬﻲ اﻹﺣﺴﺎن )ﻓﻌﻞ
اﻟﺨري( وﻋﺪم إﻟﺤﺎق اﻷذى، واﻻﺳﺘﻘﻼل )اﻟﺤﻔﺎظﻋﲆ وﻛﺎﻟﺔ اﻹﻧﺴﺎن(، واﻟﻌﺪاﻟﺔ )أنﺗﻜﻮن
ﻋﺎدﻻً (، واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري )ﺷﻔﺎﻓﻴﺔ اﻟﺘﻨﻔﻴﺬ(.ﻫﺬه املﺒﺎدئﻣﺄﻟﻮﻓﺔﻣﻦﻣﺠﺎل أﺧﻼﻗﻴﺎتﻋﻠﻢ
اﻷﺣﻴﺎء، وﻟﻜﻦ اﻟﻮﺛﻴﻘﺔﺗُﻀﻴﻒ إﻟﻴﻬﺎ اﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري، وﺗﺘﻀﻤﱠﻦﺗﻔﺴرياتٍﺗﺴﻠﻂ اﻟﻀﻮءﻋﲆ
ﻣﺒﺪأ
املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ اﻟﺨﺎﺻﺔ اﻟﺘﻲﻳُﺜريﻫﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳُﻔﴪﱢ
ﻋﺪم إﻟﺤﺎق اﻷذىﻋﲆ املﻄﺎﻟﺒﺔﺑﺄنﺧﻮارزﻣﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺠﺐ أنﺗﺘﺠﻨﱠﺐ اﻟﺘﻤﻴﻴﺰ،
واﻟﺘﻼﻋُﺐ، واﻟﺘﻮﺟﻴﻪ اﻟﺴﻠﺒﻲ، وﻳﺠِﺐ أنﺗﺤﻤﻲ اﻟﻔﺌﺎت اﻟﻀﻌﻴﻔﺔﻣﺜﻞ اﻷﻃﻔﺎل واملﻬﺎﺟﺮﻳﻦ.
ﻋﲆ أﻧﻪﻳﺘﻀﻤﻦﻣﻄﺎﻟﺒﺔﻣﻄﻮري اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻣﻨﻔﱢﺬﻳﻪ
أﻣﺎﻣﺒﺪأ اﻟﻌﺪاﻟﺔ،ﻓﻴُﻔﴪﱠ
ﺑﻀﻤﺎن اﺣﺘﻔﺎظ اﻷﻓﺮاد واملﺠﻤﻮﻋﺎت اﻷﻗﻠﻴﺔﺑﺎﻟﺘﺤﺮﱡرﻣﻦ اﻟﺘﺤﻴﱡﺰ. وﻳﻔﴪﻣﺒﺪأ اﻟﻘﺎﺑﻠﻴﺔ
ﻟﻠﺘﻔﺴريﻋﲆ أﻧﻪﻳُﻄﺎﻟﺐﺑﺄنﺗﻜﻮن أﻧﻈﻤﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺎﺑﻠﺔﻟﻠﺘﺪﻗﻴﻖ و»ﻣﻔﻬﻮﻣﺔ
European Commission AI) «ﻣﻦﻗِﺒﻞ اﻟﺒﴩﻋﲆ اﺧﺘﻼفﻣﺴﺘﻮﻳﺎتﻓﻬﻤﻬﻢ وﺧﱪﺗﻬﻢ
(. وﺗُﺤﺪﱢد اﻟﻨﺴﺨﺔ اﻟﻨﻬﺎﺋﻴﺔ، اﻟﺘﻲﺻﺪرتﰲ أﺑﺮﻳﻞ ٩١٠٢،ﺑﺸﻜﻞٍﺧﺎصﱟHLEG 2018, 10
أنﻗﺎﺑﻠﻴﺔ اﻟﺘﻔﺴريﻻﺗﺘﻌﻠﱠﻖﻓﻘﻂﺑﺘﻔﺴري اﻟﻌﻤﻠﻴﺔ اﻟﺘﻘﻨﻴﺔ وﻟﻜﻦ أﻳﻀًﺎﺑﺎﻟﻘﺮارات اﻟﺒﴩﻳﺔ
(.European Commission AI HLEG 2019, 18)ذات اﻟﺼﱢﻠﺔﺑﻬﺎ
105</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﰲ وﻗﺖٍﺳﺎﺑﻖ، أﺻﺪرتﻫﻴﺌﺔ اﺳﺘﺸﺎرﻳﺔ أﺧﺮىﺗﺎﺑﻌﺔ إﱃ اﻻﺗﺤﺎد اﻷوروﺑﻲ، وﻫﻲ
املﺠﻤﻮﻋﺔ اﻷوروﺑﻴﺔ املَﻌﻨﻴﺔﺑﺎﻷﺧﻼﻗﻴﺎتﰲ اﻟﻌﻠﻮم واﻟﺘﻘﻨﻴﺎت اﻟﺠﺪﻳﺪةﺑﻴﺎﻧًﺎﺣﻮل اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ واﻟﺮوﺑﻮﺗﺎت واﻷﻧﻈﻤﺔ املُﺴﺘﻘﻠﺔ،ﻣﻘﱰﺣﺔًﻣﺒﺎدئ اﻟﻜﺮاﻣﺔ اﻹﻧﺴﺎﻧﻴﺔ، واﻻﺳﺘﻘﻼل،
واملﺴﺌﻮﻟﻴﺔ، واﻟﻌﺪاﻟﺔ، واملﺴﺎواة، واﻟﺘﻀﺎﻣُﻦ، واﻟﺪﻳﻤﻘﺮاﻃﻴﺔ، وﺳﻴﺎدة اﻟﻘﺎﻧﻮن واملﺴﺎءﻟﺔ،
واﻷﻣﺎن واﻟﺴﻼﻣﺔ، وﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت واﻟﺨﺼﻮﺻﻴﺔ، واﻻﺳﺘﺪاﻣﺔ. وﻳُﻘﺎل إنﻣﺒﺪأ اﻟﻜﺮاﻣﺔ
EGE)اﻹﻧﺴﺎﻧﻴﺔﻳﻘﺘﴤ إﻋﻼم اﻷﻓﺮادﺑﻤﺎ إذاﻛﺎﻧﻮاﻳﺘﻔﺎﻋﻠﻮنﻣَﻊ آﻟﺔ أمﻣﻊَ إﻧﺴﺎن آﺧﺮ
(.ﻛﺬﻟﻚﻋﻠﻴﻚﻣﻼﺣﻈﺔ أن اﻻﺗﺤﺎد اﻷوروﺑﻲﻟﺪَﻳﻪﺑﺎﻟﻔﻌﻞﺗﴩﻳﻌﺎتﻗﺎﺋﻤﺔﺗﺘﻌﻠﻖ2018
ﺑﺘﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﺳﺘﺨﺪاﻣﻪ. وﺗﻬﺪفﻻﺋﺤﺔﺣِﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت اﻟﻌﺎﻣﺔ، اﻟﺘﻲ
اﻋﺘُﻤِﺪتﰲﻣﺎﻳﻮ ٨١٠٢، إﱃﺣﻤﺎﻳﺔﺟﻤﻴﻊﻣﻮاﻃﻨﻲ اﻻﺗﺤﺎد اﻷوروﺑﻲ وﺗﻤﻜﻴﻨﻬﻢﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖ
ﺑﺨﺼﻮﺻﻴﺔ اﻟﺒﻴﺎﻧﺎت. وﺗﺘﻀﻤﱠﻦﻣﺒﺎدئﻣﺜﻞﺣﻖ اﻟﻔﺮدﰲﻧﺴﻴﺎنﺑﻴﺎﻧﺎﺗﻪ )ﻳﻤﻜﻦﻟﻠﻔﺮد أن
ﻳﻄﻠﺐﻣﺴﺢﺑﻴﺎﻧﺎﺗﻪ اﻟﺸﺨﺼﻴﺔ ووﻗﻒﻣﻌﺎﻟﺠﺔﺗﻠﻚ اﻟﺒﻴﺎﻧﺎتﰲ املﺴﺘﻘﺒﻞ( واﻟْﺨﺼﻮﺻﻴﺔ
املُﺘﻀﻤﱠﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ.ﻛﻤﺎﺗﻤﻨﺢ اﻷﻓﺮاد املﻌﻨﻴنيﺣﻖ اﻟﻮﺻﻮل إﱃ »ﻣﻌﻠﻮﻣﺎت ذاتﻣﻌﻨﻰ
ﺣﻮل املﻨﻄﻖ املُﻀﻤﱠﻦ«ﰲ اﺗﺨﺎذ اﻟﻘﺮارات املﺆﺗﻤﺘﺔ وﻣﻌﻠﻮﻣﺎتﺣﻮل »اﻟﻌﻮاﻗﺐ املُﺘﻮﻗﱠﻌﺔ«
ﻟِﻤﺜﻞﻫﺬه املﻌﺎﻟﺠﺔ )اﻟﱪملﺎن اﻷوروﺑﻲ وﻣﺠﻠﺲ اﻻﺗﺤﺎد اﻷوروﺑﻲ ٦١٠٢(. اﻻﺧﺘﻼفﻋﻦ
وﺛﺎﺋﻖ اﻟﺴﻴﺎﺳﺔﻫﻮ أنﻫﺬه املﺒﺎدئ املﺬﻛﻮرةﻫﻨﺎﺗُﻌﺪﻣُﺘﻄﻠﺒﺎتﻗﺎﻧﻮﻧﻴﺔ. إﻧﻬﺎﺑﻤﺜﺎﺑﺔﺗﴩﻳﻊ
ﻣﻔﺮوض؛ﺑﻤﻌﻨﻰ أن املﺆﺳﱠﺴﺎت اﻟﺘﻲﺗﻨﺘﻬﻚﻻﺋﺤﺔﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت اﻟﻌﺎﻣﺔﻳُﻤﻜﻦﺗﻐﺮﻳﻤﻬﺎ.
وﻣﻊ ذﻟﻚ،ﺛﻤﺔﺗﺴﺎؤلﻣﻄﺮوحﻋﻤﺎ إذاﻛﺎﻧﺖ أﺣﻜﺎمﻻﺋﺤﺔﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت اﻟﻌﺎﻣﱠﺔﺗﻜﺎﻓﺊ
(، وﺑﺸﻜﻞﻋﺎم، إذاﻛﺎﻧﺖﺗﻮﻓﱢﺮDigital Europe 2018)اﻟﺤﻖ اﻟﻜﺎﻣﻞﰲﺗﻔﺴري اﻟﻘﺮار
Wachter, Mittelstadt, and Floridi)ﺣﻤﺎﻳﺔﻛﺎﻓﻴﺔﺿﺪﻣﺨﺎﻃﺮ اﺗﺨﺎذ اﻟﻘﺮار املﺆﺗﻤﺖ
(.ﺗﻮﻓﺮﻻﺋﺤﺔﺣﻤﺎﻳﺔ اﻟﺒﻴﺎﻧﺎت اﻟﻌﺎﻣﱠﺔ اﻟﺤﻖﰲ اﻹﻋﻼمﺑﺎﺗﺨﺎذ اﻟﻘﺮار املﺆﺗﻤﺖ وﻟﻜﻦ2017
ﻳﺒﺪو أﻧﻬﺎﻻﺗُﻄﺎﻟِﺐﺑﺘﻔﺴري اﻷﺳﺎس املﻨﻄﻘﻲﻷيﻗﺮارٍﺑﻌَﻴﻨﻪ. وﻫﺬه أﻳﻀًﺎﻣﺸﻜﻠﺔﻓﻴﻤﺎ
ﻳﺘﻌﻠﱠﻖﺑﺎﺗﺨﺎذ اﻟﻘﺮارﰲ املﺠﺎل اﻟﻘﺎﻧﻮﻧﻲ. وﻗﺪﻃﺎﻟﺒﺖ دراﺳﺔٌ أﺟﺮاﻫﺎﻣﺠﻠﺲ أوروﺑﺎ،
اﺳﺘﻨﺎدًا إﱃﻋﻤﻞﻟﺠﻨﺔٍﻣﻦﺧﱪاءﺣﻘﻮق اﻹﻧﺴﺎن،ﺑﺄنﻳﻜﻮنﻟﻸﻓﺮاد اﻟﺤﻖﰲﻣﺤﺎﻛﻤﺔٍﻋﺎدﻟﺔ
(.Yeung 2018)وإﺟﺮاءاتﻗﺎﻧﻮﻧﻴﺔﺳﻠﻴﻤﺔﺑﴩوطﻳُﻤﻜﻨﻬﻢﻓﻬﻤﻬﺎ
ﺗُﻌَﺪ املﻨﺎﻗﺸﺎت اﻟﻘﺎﻧﻮﻧﻴﺔ ذات أﻫﻤﻴﺔٍﺑﺎﻟﻄﺒﻊﰲ املﻨﺎﻗﺸﺎت املُﺘﻌﻠﻘﺔﺑﺄﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ وﺳﻴﺎﺳﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻗﺪﻧﺎﻗﺶﺗريﻧﺮ )٩١٠٢( املﻘﺎرﻧﺎتﺑﺎﻟﺤﻴﻮاﻧﺎت
)ﻛﻴﻒﻋﻮﻣِﻠﺖ وﺗُﻌﺎﻣﻞﰲ اﻟﻘﺎﻧﻮن وﻣﺎ إذاﻛﺎﻧﺖﺗﺘﻤﺘﱠﻊﺑﺤﻘﻮق( وراﺟﻊﻋﺪدًاﻣﻦ اﻟﺼﻜﻮك
اﻟﻘﺎﻧﻮﻧﻴﺔﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﻤﺎﻳﻤﻜﻦ أنﺗﻌﻨﻲﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪ وﻗﻮع
106</p>
<p>اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ
اﻟﴬر،ﻓﺈنﻣﺴﺄﻟﺔ اﻹﻫﻤﺎلﺗﺘﻌﻠﻖﺑﻤﺎ إذاﻛﺎنﺷﺨﺺٌﻣﺎﻣُﻠﺘﺰﻣًﺎﺑﻮاﺟﺐ اﻟﺮﻋﺎﻳﺔﻟﺘﺠﻨﱡﺐ
وﻗﻮعﴐر،ﺣﺘﻰ إذاﻟﻢﻳﻜﻦ اﻟﴬَر اﻟﻮاﻗﻊﻣﻘﺼﻮدًا.ﻳﻤﻜﻦ أنﻳﻨﻄﺒﻖ ذﻟﻚﻋﲆﻣُﺼﻤﻢ أو
ﻣُﺪرب اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻟﻜﻦﻣﺎﻣﺪىﺳﻬﻮﻟﺔ اﻟﺘﻨﺒﺆﺑﻌﻮاﻗﺐ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ أﻣﺎ
اﻟﻘﺎﻧﻮن اﻟﺠﻨﺎﺋﻲ،ﻓﻌﲆ اﻟﻌﻜﺲﻣﻦ ذﻟﻚ،ﻓﻬﻮﻳﺘﻄﻠﱠﺐﻧِﻴﱠﺔ إﻳﻘﺎع اﻟﴬر. وﻟﻜﻦﻫﺬاﻏﺎﻟﺒًﺎ
ﻟﻴﺲ اﻟﺤﺎلﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻣﻦﻧﺎﺣﻴﺔٍ أﺧﺮى،ﻻﺗﺘﻌﻠﻖ املﺴﺌﻮﻟﻴﺔﻋﻦ املﻨﺘَﺞﺑﺨﻄﺄ
اﻷﻓﺮاد وﻟﻜﻨﻬﺎﺗﻔﺮِضﻋﲆ اﻟﴩﻛﺔ اﻟﺘﻲ أﻧﺘﺠﺖ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ دﻓﻊﺗﻌﻮﻳﻀﺎتٍﻋﻦ اﻷﴐار،
ﺑﻐﺾﱢ اﻟﻨﻈﺮﻋﻦ اﻟﺨﻄﺄ. وﻳﻤﻜﻦ أنﻳﻜﻮنﻫﺬا أﺣﺪ اﻟﺤﻠﻮل املُﻤﻜﻨﺔﻟﻠﻤﺴﺌﻮﻟﻴﺔ اﻟﻘﺎﻧﻮﻧﻴﺔﻋﻦ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻛﺬﻟﻚﺗﺘﱠﺼﻞﻗﻮاﻧني املﻠﻜﻴﺔ اﻟﻔﻜﺮﻳﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻣﺜﻞﺣﻘﻮق
اﻟﻄﺒﻊ واﻟﻨﴩ وﺑﺮاءات اﻻﺧﱰاع، وﻗﺪﺑﺪأتﻣﻨﺎﻗﺸﺎتﺣﻮل »اﻟﺸﺨﺼﻴﺔ اﻻﻋﺘﺒﺎرﻳﺔ«ﻟﻠﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ، وﻫﻮﻣﺎﻳُﻌﺪ اﻓﱰاﺿًﺎﻗﺎﻧﻮﻧﻴٍّﺎ وﻟﻜﻨﻪ ذرﻳﻌﺔﺗُﻄﺒﱠﻖﺣﺎﻟﻴٍّﺎﻋﲆ اﻟﴩﻛﺎت وﻣﺨﺘﻠﻒ
املُﻨﻈﻤﺎت.ﻓﻬﻞﻳﺠﺐ أنﻳُﻄﺒﱠﻖ أﻳﻀًﺎﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ﰲﻗﺮارٍﻣُﺜريﻟﻠﺠﺪلﰲﻋﺎم
٧١٠٢، اﻗﱰح اﻟﱪملﺎن اﻷوروﺑﻲ أنﻣﻨﺢ اﻟﺮوﺑﻮﺗﺎت اﻟﺬاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞ اﻷﻛﺜﺮﺗﻄﻮرًاﻣﻨﺰﻟﺔ
اﻷﺷﺨﺎص اﻹﻟﻜﱰوﻧﻴنيﻫﻮﺣﻞﱞﻗﺎﻧﻮﻧﻲﻣُﻤﻜﻦﻟﻘﻀﻴﺔ املﺴﺌﻮﻟﻴﺔ اﻟﻘﺎﻧﻮﻧﻴﺔ؛ وﻫﺬه اﻟﻔﻜﺮةﻟﻢ
ﰲﻋﺎم2ﻳﺘﻢ اﻻﻋﱰافﺑﻬﺎﻣﻦﻗِﺒﻞ املﻔﻮﺿﻴﺔ اﻷوروﺑﻴﺔﰲ اﺳﱰاﺗﻴﺠﻴﺘﻬﺎﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
٨١٠٢.ﻛﺬﻟﻚ اﻋﱰض آﺧﺮون اﻋﱰاﺿًﺎﺣﺎزﻣًﺎﻋﲆﻓﻜﺮة إﻋﻄﺎءﺣﻘﻮقٍ وﺷﺨﺼﻴﺔﻟﻶﻻت،
ﻣُﺠﺎدِﻟني،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺑﺄﻧﻪﺳﻴُﺼﺒﺢﻣﻦ اﻟﺼﻌﺐ، إنﻟﻢﻳﻜُﻦﻣﻦ املُﺴﺘﺤﻴﻞ،ﻣﺤﺎﺳﺒﺔ
Bryson,)ذاﺗﻴﺔ
ﻷن اﻟﻨﺎسﺳﻴﺴﻌَﻮن إﱃ اﺳﺘﻐﻼلﻫﺬه اﻟﻔﻜﺮةﻷﻏﺮاضٍ
أيﺷﺨﺺٍ
(.ﻛﺎنﻫﻨﺎك أﻳﻀًﺎ اﻟﺤﺎﻟﺔ اﻟﺸﻬريةﻟﺼﻮﻓﻴﺎ، اﻟﺮوﺑﻮتDiamantis, and Grant 2017
اﻟﺬيﻣﻨﺤﺘﻪ اﻟﺴﻌﻮدﻳﺔ »اﻟﺠﻨﺴﻴﺔ«ﰲﻋﺎم ٧١٠٢.ﺗُﺜريﻣﺜﻞﻫﺬه اﻟﺤﺎﻟﺔﻣﺠﺪدًاﻣﺴﺄﻟﺔ
املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔﻟﻠﺮوﺑﻮﺗﺎت واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ )اﻧﻈﺮ اﻟﻔﺼﻞ اﻟﺮاﺑﻊ(.
اﻗﱰُ ِﺣَﺖ أﻳﻀًﺎﺳﻴﺎﺳﺎت ذﻛﺎء اﺻﻄﻨﺎﻋﻲﺧﺎرجﻧﻄﺎق أﻣﺮﻳﻜﺎ اﻟﺸﻤﺎﻟﻴﺔ وأوروﺑﺎ.
ﻓﺎﻟﺼني،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻟﺪَﻳﻬﺎ اﺳﱰاﺗﻴﺠﻴﺔ وﻃﻨﻴﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﺗُﻘﺮﺧُﻄﺘﻬﺎ
اﻟﺘﻨﻤﻮﻳﺔﺑﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻮﺗﻜﻨﻮﻟﻮﺟﻴﺎﻫﺪﱠاﻣﺔﻳﻤﻜﻦ أنﺗﴬﱠﺑﺎﻻﺳﺘﻘﺮار اﻻﺟﺘﻤﺎﻋﻲ،
وﺗﺆﺛﺮﻋﲆ اﻟﻘﺎﻧﻮن واﻷﺧﻼﻗﻴﺎت اﻻﺟﺘﻤﺎﻋﻴﺔ، وﺗﻨﺘﻬِﻚ اﻟﺨﺼﻮﺻﻴﺔ اﻟﺸﺨﺼﻴﺔ، وﺗﺨﻠﻖ
ﻣﺨﺎﻃﺮ أﻣﻨﻴﺔ؛ وﻣِﻦﺛَﻢﺗُﻮﴆ اﻟﺨﻄﺔﺑﺘﻌﺰﻳﺰ اﻟﻮﻗﺎﻳﺔ املُﺴﺘﻘﺒﻠﻴﺔ وﺗﻘﻠﻴﻞ املﺨﺎﻃﺮ املﺤﺘﻤَﻠﺔ
)ﻣﺠﻠﺲ اﻟﺪوﻟﺔ اﻟﺼﻴﻨﻲ ٧١٠٢(. وﺗﺮويﺑﻌﺾ اﻟﺠﻬﺎت اﻟﻔﺎﻋﻠﺔﰲ اﻟﻐﺮبﴎدﻳﺔﻣﻨﺎﻓﺴﺔ:
إﻧﻬﻢﻳﺨﺸَﻮن أنﺗﺘﺠﺎوزﻫﻢ اﻟﺼني أوﺣﺘﻰﻓﻜﺮة أﻧﻨﺎﻧﻘﱰِبﻣﻦ اﻧﺪﻻعﺣﺮبٍﻋﺎملﻴﺔ
ﺟﺪﻳﺪة.ﺑﻴﻨﻤﺎﻳُﺤﺎول آﺧﺮون اﻟﺘﻌﻠﱡﻢﻣﻦ اﺳﱰاﺗﻴﺠﻴﺔ اﻟﺼني. وﻗﺪﻳﺘﺴﺎءل اﻟﺒﺎﺣﺜﻮن أﻳﻀًﺎ
107</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻋﻦﻛﻴﻔﻴﺔﺗﻌﺎﻣُﻞ اﻟﺜﻘﺎﻓﺎت املﺨﺘﻠﻔﺔﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻄﺮُقﻣﺨﺘﻠﻔﺔ. وﻳﻤﻜﻦ أن
ﻳُﺴﻬﻢ اﻟﺒﺤﺚﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻧﻔﺴﻪﰲﺑﻨﺎء وﺟﻬﺔﻧﻈﺮﻣﻘﺎرﻧﺔﻋﺎﺑﺮةﻟﻠﺜﻘﺎﻓﺎت
ﺑﺸﺄن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻋﻨﺪﻣﺎﻳُﺬﻛﺮﻧﺎﺑﺎﻟﻔﺮوقﺑني اﻟﺜﻘﺎﻓﺎت
(. وﻳﻤﻜﻦ أنﻳُﺜريAwad et al. 2018)اﻟﻔﺮدﻳﺔ واﻟﺠﻤﺎﻋﻴﺔﻓﻴﻤﺎﻳﺘﻌﻠﱠﻖﺑﺎملُﻌﻀﻼت اﻷﺧﻼﻗﻴﺔ
ﻫﺬاﻣﺸﻜﻼتٍﻷﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إذاﻛﺎﻧﺖﺗﻬﺪف إﱃ أنﺗﻜﻮنﻋﺎملﻴﺔ. وﻳﻤﻜﻦ
أﻳﻀًﺎ اﺳﺘﻜﺸﺎفﻛﻴﻒﺗﺨﺘﻠﻒ اﻟﴪدﻳﺎتﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ اﻟﺼني أو اﻟﻴﺎﺑﺎن،ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل،ﻋﻦ اﻟﴪدﻳﺎت اﻟﻐﺮﺑﻴﺔ. وﻣﻊ ذﻟﻚ،ﻋﲆ اﻟﺮﻏﻢﻣﻦ اﻻﺧﺘﻼﻓﺎت اﻟﺜﻘﺎﻓﻴﺔ،ﻳﺘﺒنيﱠ أن
ﺳﻴﺎﺳﺎت أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣُﺘﺸﺎﺑﻬﺔﺑﺪرﺟﺔٍﻛﺒرية وﻣﻠﺤﻮﻇﺔ.ﻓﺒﻴﻨﻤﺎﺗﺆﻛﺪﺧﻄﺔ
اﻟﺼني أﻛﺜﺮﻋﲆ اﻻﺳﺘﻘﺮار اﻻﺟﺘﻤﺎﻋﻲ واﻟﺼﺎﻟﺢ اﻟﻌﺎم اﻟﺠﻤﺎﻋﻲ، إﻻ أن املﺨﺎﻃﺮ اﻷﺧﻼﻗﻴﺔ
املُﺤﺪدة واملﺒﺎدئ املﺬﻛﻮرةﻟﻴﺴﺖﻣﺨﺘﻠﻔﺔﻛﺜريًاﻋﻦﺗﻠﻚ املُﻘﱰﺣﺔﻣﻦﻗِﺒﻞ اﻟﺪول اﻟﻐﺮﺑﻴﺔ.
ﻋﲆ اﻟﺮﻏﻢﻣﻦ اﻻﺧﺘﻼﻓﺎت اﻟﺜﻘﺎﻓﻴﺔ،ﻳﺘﺒنيﱠ أنﺳﻴﺎﺳﺎت أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺘﺸﺎﺑﻬﺔﺑﺪرﺟﺔ
ﻛﺒرية وﻣﻠﺤﻮﻇﺔ.
ًوﻟﻜﻦ،ﻛﻤﺎ ذﻛﺮﻧﺎﺳﺎﺑﻘًﺎ،ﺳﻴﺎﺳﺔ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺴﺖﻣﻘﺼﻮرة
ﻋﲆ اﻟﺤﻜﻮﻣﺎت وﻟﺠﺎﻧﻬﺎ وﻫﻴﺌﺎﺗﻬﺎﻓﻘﻂ.ﻓﻘﺪ أﺧﺬ اﻷﻛﺎدﻳﻤﻴﻮن أﻳﻀًﺎ زﻣﺎم املﺒﺎدرة.ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل، اﻗﱰُ ِحَ إﻋﻼنﻣﻮﻧﱰﻳﺎلﺑﺸﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﺴﺌﻮلﻣﻦﻗِﺒﻞﺟﺎﻣﻌﺔ
ﻣﻮﻧﱰﻳﺎل وﺷﻤﻞ اﺳﺘﺸﺎرة املﻮاﻃﻨني واﻟﺨﱪاء وﻏريﻫﻢﻣﻦ أﺻﺤﺎب اﻟﺸﺄن. وﻳﻘﻮل اﻹﻋﻼن
إنﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺠﺐ أنﻳُﻌﺰﱢز رﻓﺎهﺟﻤﻴﻊ املﺨﻠﻮﻗﺎت اﻟﺤﻴﺔ وﻳُﻌﺰﱢز اﺳﺘﻘﻼل
اﻟﺒﴩ، وﻳﻘﴤﻋﲆﺟﻤﻴﻊ أﻧﻮاع اﻟﺘﻤﻴﻴﺰ، وﻳﺤﱰم اﻟﺨﺼﻮﺻﻴﺔ اﻟﺸﺨﺼﻴﺔ، وﻳَﺤﻤﻴﻨﺎ
ﻣﻦ اﻟﺪﻋﺎﻳﺔ واﻟﺘﻼﻋُﺐ، وﻳُﻌﺰﱢز اﻟﻨﻘﺎش اﻟﺪﻳﻤﻘﺮاﻃﻲ، وﻳﺠﻌﻞﻣﺨﺘﻠﻒ اﻟﺠﻬﺎت اﻟﻔﺎﻋﻠﺔ
(.Université de Montréal 2017)ﻣَﺴﺌﻮﻟنيﻋﻦﻣﻜﺎﻓﺤﺔﻣﺨﺎﻃﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻗﺪ اﻗﱰحﺑﺎﺣﺜﻮن آﺧﺮونﻣﺒﺎدئ اﻹﺣﺴﺎن، وﻋﺪم اﻟﺘﺴﺒﱡﺐﰲ اﻷذى، واﻻﺳﺘﻘﻼل، واﻟﻌﺪاﻟﺔ،
(. وﺗﻌﻤﻞ اﻟﺠﺎﻣﻌﺎتﻣﺜﻞﻛﺎﻣﱪﻳﺪج وﺳﺘﺎﻧﻔﻮردFloridi et al. 2018)وﻗﺎﺑﻠﻴﺔ اﻟﺘﻔﺴري
ﻋﲆ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻏﺎﻟﺒًﺎﻣﻦ وﺟﻬﺔﻧﻈﺮ اﻷﺧﻼق اﻟﺘﻄﺒﻴﻘﻴﺔ. وﻛﺬﻟﻚﻳﺆدي
اﻷﺷﺨﺎص اﻟﻌﺎﻣِﻠﻮنﰲﻣﺠﺎل اﻷﺧﻼق املﻬﻨﻴﺔ أﻳﻀًﺎﻋﻤﻼًﻣُﻔﻴﺪًا.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪمﻣﺮﻛﺰ
ﻣﺎرﻛﻮﻻﻟﻸﺧﻼق اﻟﺘﻄﺒﻴﻘﻴﺔﰲﺟﺎﻣﻌﺔﺳﺎﻧﺘﺎﻛﻼراﻣﺠﻤﻮﻋﺔًﻣﻦ اﻟﻨﻈﺮﻳﺎت اﻷﺧﻼﻗﻴﺔﻛﺄداةٍ
108</p>
<p>اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ
ملُﻤﺎرﺳﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ واﻟﻬﻨﺪﺳﺔ، واﻟﺘﻲﻗﺪﺗُﻔﻴﺪ أﻳﻀًﺎﰲ إﺛﺮاء أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻛﻤﺎ أﺑﺪىﻓﻼﺳﻔﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻫﺘﻤﺎﻣًﺎﻛﺒريًاﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺆﺧﺮًا.3.ﺑﺎملﻌﻠﻮﻣﺎت
ﻧﺠﺪ أﻳﻀًﺎﻣُﺒﺎدراتﺑﺸﺄن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﻋﺎﻟﻢ اﻟﴩﻛﺎت.ﻋﲆﺳﺒﻴﻞ
املﺜﺎل،ﻳﺪﺧﻞﰲ اﻟﴩاﻛﺔﺑﺸﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﴍﻛﺎتﻣﺜﻞ دﻳﺐﻣﺎﻳﻨﺪ، وآيﺑﻲ إم،
وﺗﺪرك اﻟﻌﺪﻳﺪﻣﻦ اﻟﴩﻛﺎت اﻟﺤﺎﺟﺔ إﱃ اﻟﺬﻛﺎء4.وإﻧﺘﻞ، وأﻣﺎزون، وأﺑﻞ، وﺳﻮﻧﻲ، وﻓﻴﺴﺒﻮك
اﻻﺻﻄﻨﺎﻋﻲ اﻷﺧﻼﻗﻲ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻧﴩتﺟﻮﺟﻞﻣﺒﺎدئ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ:
ﺗﻘﺪﻳﻢﻓﺎﺋﺪة اﺟﺘﻤﺎﻋﻴﺔ، وﺗﺠﻨﱡﺐ اﻟﺘﺴﺒﱡﺐﰲ اﻟﺘﺤﻴﱡﺰﻏري اﻟﻌﺎدل أوﺗﻌﺰﻳﺰه، وﻓﺮض اﻟﺴﻼﻣﺔ،
واﻟﺤﻔﺎظﻋﲆﺗﺤﻤﱡﻞ املﺴﺌﻮﻟﻴﺔ، واﻟﺤﻔﺎظﻋﲆﺗﺼﻤﻴﻢ اﻟﺨﺼﻮﺻﻴﺔ، وﺗﻌﺰﻳﺰ اﻟﺘﻤﻴﱡﺰ اﻟﻌﻠﻤﻲ،
وﺗﻘﻴﻴﺪ اﻟﺘﻄﺒﻴﻘﺎت اﻟﺘﻲﻳُﺤﺘَﻤﻞﻛﻮﻧﻬﺎﺿﺎرة أوﻣُﺴﻴﺌﺔﻣﺜﻞ اﻷﺳﻠﺤﺔ أو اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
وﺗﺘﺤﺪﱠثﴍﻛﺔﻣﺎﻳﻜﺮوﺳﻮﻓﺖﻋﻦ5.اﻟﺘﻲﺗﻨﺘﻬِﻚﻣﺒﺎدئ اﻟﻘﺎﻧﻮن اﻟﺪوﱄ وﺣﻘﻮق اﻹﻧﺴﺎن
ﻓﻜﺮة »اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦ أﺟﻞ اﻟﺨري« وﺗﻘﱰحﻣﺒﺎدئ اﻟﻌﺪاﻟﺔ، واملﻮﺛﻮﻗﻴﺔ واﻟﺴﻼﻣﺔ،
ﻛﻤﺎ اﻗﱰﺣﺖﴍﻛﺔ أﻛﺴﻨﺘﴩ6.واﻟﺨﺼﻮﺻﻴﺔ واﻷﻣﺎن، واﻟﺘﻀﻤني، واﻟﺸﻔﺎﻓﻴﺔ، واملﺴﺎءﻟﺔ
ﻣﺒﺎدئﻋﺎملﻴﺔﻷﺧﻼﻗﻴﺎت اﻟﺒﻴﺎﻧﺎت،ﺑﻤﺎﰲ ذﻟﻚ اﺣﱰام اﻷﺷﺨﺎص اﻟﻜﺎﻣﻨﺔ وراء اﻟﺒﻴﺎﻧﺎت،
وﻋﲆ اﻟﺮﻏﻢﻣﻦ أن وﺛﺎﺋﻖ اﻟﴩﻛﺎتﺗَﻤﻴﻞ إﱃ اﻟﱰﻛﻴﺰ7.واﻟﺨﺼﻮﺻﻴﺔ، واﻟﺘﻀﻤني، واﻟﺸﻔﺎﻓﻴﺔ
ﻋﲆ اﻟﺮﻗﺎﺑﺔ اﻟﺬاﺗﻴﺔ،ﻓﺈنﺑﻌﺾ اﻟﴩﻛﺎتﺗﻌﱰفﺑﴬورة اﻟﻠﻮاﺋﺢ اﻟﺘﻨﻈﻴﻤﻴﺔ اﻟﺨﺎرﺟﻴﺔ.
وﻗﺪﻗﺎلﺗﻴﻢﻛﻮك اﻟﺮﺋﻴﺲ اﻟﺘﻨﻔﻴﺬيﻟﴩﻛﺔ أﺑﻞ إن اﻟﻠﻮاﺋﺢ اﻟﺘﻨﻈﻴﻤﻴﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ،ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل،ﻟﻀﻤﺎن اﻟﺨﺼﻮﺻﻴﺔ أﻣﺮﻻﻏِﻨﻰﻋﻨﻪﻷن اﻟﺴﻮق اﻟﺤﺮة اﻟﺘﻲﻻﺗﺨﻀﻊﻟﺮﻗﺎﺑﺔ
وﻣﻊ ذﻟﻚ،ﻫﻨﺎكﺟﺪلﺣﻮلﻣﺎ إذاﻛﺎنﻫﺬاﻳﺘﻄﻠﺐﻟﻮاﺋﺢ8.ﺣﻜﻮﻣﻴﺔﻻﺗُﻔﻴﺪﰲﻫﺬه اﻟﺤﺎﻟﺔ
ﺗﻨﻈﻴﻤﻴﺔﺟﺪﻳﺪة. وﻳﺪﻋﻢ اﻟﺒﻌﺾﻣﺴﺎر اﻟﻠﻮاﺋﺢ اﻟﺘﻨﻈﻴﻤﻴﺔ،ﺑﻤﺎﰲ ذﻟﻚ اﻟﻘﻮاﻧني اﻟﺠﺪﻳﺪة.
ﻓﻘﺪﻗﺪﻣﺖ وﻻﻳﺔﻛﺎﻟﻴﻔﻮرﻧﻴﺎﺑﺎﻟﻔﻌﻞﻣﴩوعﻗﺎﻧﻮنﻳﻄﺎﻟﺐﺑﺎﻟﻜﺸﻒﻋﻦ اﻟﺮوﺑﻮﺗﺎت:
ﻓﺈن اﺳﺘﺨﺪام اﻟﺮوﺑﻮتﺑﻄﺮﻳﻘﺔٍﺗُﻀﻠﱢﻞ اﻟﺸﱠﺨﺺ اﻵﺧﺮﺣﻮلﻫﻮﻳﺘﻪ اﻻﺻﻄﻨﺎﻋﻴﺔ أﻣﺮﻏري
وﺗﺘﺨﺬﴍﻛﺎت أﺧﺮىﻣﻮﻗﻔًﺎ أﻛﺜﺮﺗﺤﻔﻈًﺎ.ﻓﻘﺪﺟﺎدﻟﺖﴍﻛﺔ دﻳﺠﻴﺘﺎلﻳﻮروب9.ﻗﺎﻧﻮﻧﻲ
)٨١٠٢(، اﻟﺘﻲﺗﻤﺜﻞ اﻟﺼﻨﺎﻋﺔ اﻟﺮﻗﻤﻴﺔﰲ أوروﺑﺎ،ﺑﺄن اﻹﻃﺎر اﻟﻘﺎﻧﻮﻧﻲ اﻟﺤﺎﱄﻣُﺠﻬﱠﺰ ملﻌﺎﻟﺠﺔ
املﺸﻜﻼت املﺘﻌﻠﻘﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺑﻤﺎﻓﻴﻬﺎ اﻟﺘﺤﻴﱡﺰ واﻟﺘﻤﻴﻴﺰ، وﻟﻜﻦﻟﺒﻨﺎء اﻟﺜﻘﺔ،ﻓﺈن
اﻟﺸﻔﺎﻓﻴﺔ واﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري أﻣﺮانﻏﺎﻳﺔﰲ اﻷﻫﻤﻴﺔ:ﻳﺠﺐ أنﻳﻔﻬﻢ اﻷﻓﺮاد واﻟﴩﻛﺎتﻣﺘﻰ
وﻛﻴﻒﺗُﺴﺘﺨﺪَم اﻟﺨﻮارزﻣﻴﺎتﰲ اﺗﺨﺎذ اﻟﻘﺮارات، وﻧﺤﻦﺑﺤﺎﺟﺔٍ إﱃﺗﻮﻓريﻣﻌﻠﻮﻣﺎتٍ ذات
ﻣﻌﻨﻰ وﺗﻴﺴريﻋﻤﻠﻴﺔﺗﻔﺴري اﻟﻘﺮارات اﻟﺨﻮارزﻣﻴﺔ.
ﺗﻠﻌﺐ اﻟﺠﻬﺎتﻏري اﻟﻬﺎدﻓﺔ إﱃ اﻟﺮﺑﺢ دورًا أﻳﻀًﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗﻄﺮح اﻟﺤﻤﻠﺔ
اﻟﺪوﻟﻴﺔﻟﻮﻗﻒ اﻟﺮوﺑﻮﺗﺎت اﻟﻘﺎﺗﻠﺔ اﻟﻌﺪﻳﺪﻣﻦ اﻷﺳﺌﻠﺔ اﻷﺧﻼﻗﻴﺔﺑﺸﺄن اﻟﺘﻄﺒﻴﻘﺎت اﻟﻌﺴﻜﺮﻳﺔ
109</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻣﻦﺟﺎﻧﺐ دُﻋﺎةﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ،ﺗُﻮﺟَﺪﻣﺒﺎدئ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ10ﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺘﻲ اﺗﱠﻔﻖﻋﻠﻴﻬﺎ املﺸﺎرﻛﻮن اﻷﻛﺎدﻳﻤﻴﻮن واﻟﺼﻨﺎﻋﻴﻮنﰲﻣﺆﺗﻤﺮ أﺳﻴﻠﻮﻣﺎر، وﻫﻮﻣﺆﺗﻤﺮ
ﻋﻘﺪه »ﻣﻌﻬﺪﻣﺴﺘﻘﺒﻞ اﻟﺤﻴﺎة« )ﻣﺎﻛﺲﺗﻴﺠﻤﺎرك وآﺧﺮون(. وﻛﺎن اﻟﻬﺪف اﻟﻌﺎمﻫﻮ
اﻟﺤﺮصﻋﲆ أنﻳﻈﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻔﻴﺪًا، واﺣﱰام املﺒﺎدئ واﻟﻘﻴﻢ اﻷﺧﻼﻗﻴﺔﻣﺜﻞ
ﻫﻨﺎك11.اﻟﺴﻼﻣﺔ واﻟﺸﻔﺎﻓﻴﺔ واملﺴﺌﻮﻟﻴﺔ، وﺗﻮﺟﻴﻪ اﻟﻘﻴﻢ، واﻟﺨﺼﻮﺻﻴﺔ، واﻟﺘﺤﻜﻢ اﻟﺒﴩي
أﻳﻀًﺎﻣﻨﻈﻤﺎتﻣﻬﻨﻴﺔﺗﻌﻤﻞﰲﻣﺠﺎلﺳﻴﺎﺳﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻓﻘﺪﻃﺮحﻣﻌﻬﺪﻣﻬﻨﺪﳼ
اﻟﻜﻬﺮﺑﺎء واﻹﻟﻜﱰوﻧﻴﺎت، اﻟﺬيﻳﺰﻋﻢ أﻧﻪ أﻛﱪﻣﻨﻈﻤﺔﻣﻬﻨﻴﺔﻓﻨﻴﺔﰲ اﻟﻌﺎﻟﻢ،ﻣﺒﺎدرةًﻋﺎملﻴﺔ
ﺣﻮل أﺧﻼﻗﻴﺎت اﻷﻧﻈﻤﺔ اﻟﺬﻛﻴﺔ واملُﺴﺘﻘﻠﺔ. وﺑﻌﺪﻣﻨﺎﻗﺸﺎتٍﺑني اﻟﺨﱪاء، أﺛﻤﺮت املﺒﺎدرةﻋﻦ
وﺛﻴﻘﺔٍﺗﺘﻀﻤﱠﻦ رؤﻳﺔﻟ »ﺗﺼﻤﻴﻢٍﻣﻮﺟﱠﻪ أﺧﻼﻗﻴٍّﺎ«،ﺗﻘﱰح أنﻳﻜﻮنﺗﺼﻤﻴﻢﻫﺬه اﻟﺘﻘﻨﻴﺎت
وﺗﻄﻮﻳﺮﻫﺎ وﺗﻨﻔﻴﺬﻫﺎﻣﻮﺟﻬًﺎﺑﻮاﺳﻄﺔ املﺒﺎدئ اﻟﻌﺎﻣﺔﻟﺤﻘﻮق اﻹﻧﺴﺎن واﻟﺮﻓﺎه واملﺴﺎءﻟﺔ
واﻟﺸﻔﺎﻓﻴﺔ واﻟﺘﻮﻋﻴﺔﺑﺸﺄنﺳﻮء اﻻﺳْﺘِﺨﺪام. وﻳﻤﻜﻦ أنﻳﻜﻮنﺗﻀﻤني اﻷﺧﻼقﰲ املﻌﺎﻳري
اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ اﻟﻌﺎملﻴﺔ وﺳﻴﻠﺔﻓﻌﱠﺎﻟﺔﻟﻠﻤﺴﺎﻫﻤﺔﰲﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻷﺧﻼﻗﻲ.
اﻟﺤﻠﻮل اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ وﻣﺴﺄﻟﺔ اﻷﺳﺎﻟﻴﺐ واﻟﺘﻨﻔﻴﺬ
ﺗﺒني املﺒﺎدرة اﻟﻌﺎملﻴﺔ اﻟﺘﻲﻃﺮﺣﻬﺎﻣﻌﻬﺪﻣﻬﻨﺪﳼ اﻟﻜﻬﺮﺑﺎء واﻹﻟﻜﱰوﻧﻴﺎت أﻧﻪﻓﻴﻤﺎﻳﺘﻌﻠﻖ
ﺑﺎﻟﺘﺪاﺑري،ﺗُﺮﻛﺰﺑﻌﺾ وﺛﺎﺋﻖ اﻟﺴﻴﺎﺳﺎتﻋﲆ اﻟﺤﻠﻮل اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻛﻤﺎ
ذﻛﺮﻧﺎﰲ اﻟﻔﺼﻞ اﻟﺴﺎﺑﻖ، دﻋﺎﺑﻌﺾ اﻟﺒﺎﺣِﺜني إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺑﻞﻟﻠﺘﻔﺴري، إﱃ
ﻓﺘﺢ اﻟﺼﻨﺪوق اﻷﺳﻮد. وﻫﻨﺎك أﺳﺒﺎب وﺟﻴﻬﺔﻟﻠﺮﻏﺒﺔﰲﻓِﻌﻞ ذﻟﻚ؛ إذ إنﺗﻔﺴري املﻨﻄﻖ وراء
اﻟﻘﺮار اﻟﺬيﻳُﺘﱠﺨَﺬﻟﻴﺲﻣﻄﻠﺒًﺎ أﺧﻼﻗﻴٍّﺎﻓﻘﻂ وﻟﻜﻨﻪ أﻳﻀًﺎﺟﺎﻧﺐﻣُﻬﻢﻣﻦ اﻟﺬﻛﺎء اﻟﺒﴩي
(. إذَنﻓﺎﻟﻔﻜﺮة وراء اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺑﻞSamek, Wiegand, and Müller 2017)
.ﻟﻠﺘﻔﺴري أو اﻟﺸﻔﱠﺎفﻫﻲ أنﻳﻜﻮنﻣﻦ اﻟﺴﻬﻞﻓﻬﻢ أﻓﻌﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻗﺮاراﺗﻪ
وﻛﻤﺎ رأﻳﻨﺎ،ﻓﺈنﻫﺬه اﻟﻔﻜﺮةﻣﻦ اﻟﺼﻌﺐﺗﻨﻔﻴﺬﻫﺎﰲﺣﺎﻟﺔﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﺬيﻳﺴﺘﺨﺪم
(. وﻟﻜﻦﻳﻤﻜﻦﻟﻠﺴﻴﺎﺳﺎتﺑﺎﻟﻄﺒﻊ دﻋﻢ اﻟﺒﺤﺚGoebel et al. 2018)اﻟﺸﺒﻜﺎت اﻟﻌﺼﺒﻴﺔ
ﰲﻫﺬا اﻻﺗﺠﺎه.
ﺑﺸﻜﻞﻋﺎم،ﻓﺈنﻓﻜﺮةﺗﻀﻤني اﻷﺧﻼقﰲﺗﺼﻤﻴﻢ اﻟﺘﻘﻨﻴﺎت اﻟﺠﺪﻳﺪةﻫﻲﻓﻜﺮة راﺋﻌﺔ.
وﻳﻤﻜﻦ أنﺗُﺴﺎﻋﺪﻧﺎ اﻷﻓﻜﺎرﻣﺜﻞ اﻷﺧﻼﻗﻴﺎت املُﺘﻀﻤﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ أو اﻟﺘﺼﻤﻴﻢ اﻟﺤﺴﱠﺎس
ﰲﺗﺼﻤﻴﻢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻄﺮﻳﻘﺔٍﺗﺆدي إﱃﻣﺰﻳﺪٍ12،ﻟﻠﻘﻴﻢ، اﻟﺘﻲﻟﻬﺎﺗﺎرﻳﺨﻬﺎ اﻟﺨﺎص
ﻣﻦ املﺴﺎءﻟﺔ واملﺴﺌﻮﻟﻴﺔ واﻟﺸﻔﺎﻓﻴﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦ أنﺗﻨﻄﻮي اﻷﺧﻼﻗﻴﺎت املُﺘﻀﻤﱠﻨﺔ
110</p>
<p>اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ
(،ﻣﻤﺎﻳُﺴﻬﻢﰲDignum et al. 2018)ﰲ اﻟﺘﺼﻤﻴﻢﻋﲆﺿﻤﺎن اﻟﺘﺘﺒﱡﻊﰲﺟﻤﻴﻊ املﺮاﺣﻞ
إﻣﻜﺎﻧﻴﺔﻣﺴﺎءﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻳﻤﻜﻦﺗﺤﻘﻴﻖﻓﻜﺮة اﻟﺘﺘﺒﻊﺣﺮﻓﻴٍّﺎ،ﺑﻤﻌﻨﻰﺗﺴﺠﻴﻞ
ﺑﻴﺎﻧﺎتﺣﻮلﺳﻠﻮك اﻟﻨﻈﺎم. وﻗﺪﻃﺎﻟﺐ وﻳﻨﻔﻴﻠﺪ وﺟريوﺗﻜﺎ )٧١٠٢(ﺑﺘﻨﻔﻴﺬ »ﺻﻨﺪوق
أﺳﻮد أﺧﻼﻗﻲ«ﰲ اﻟﺮوﺑﻮﺗﺎت واﻷﻧﻈﻤﺔ املُﺴﺘﻘﻠﱠﺔ،ﻟﻴُﺴﺠﻞﻣﺎﻳﻔﻌﻠﻪ اﻟﺮوﺑﻮت )اﻟﺒﻴﺎﻧﺎتﻣﻦ
اﻷﺟﻬﺰة اﻻﺳﺘﺸﻌﺎرﻳﺔ وﻣِﻦ اﻟﻮﺿﻊ »اﻟﺪاﺧﲇ«ﻟﻠﻨﻈﺎم(ﺑﻄﺮﻳﻘﺔٍﺗُﺸﺒﻪ اﻟﺼﻨﺪوق اﻷﺳﻮد
املُﺜﺒﱠﺖﰲ اﻟﻄﺎﺋﺮات. وﻳﻤﻜﻦﺗﻄﺒﻴﻖﻫﺬه اﻟﻔﻜﺮة أﻳﻀًﺎﰲ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺴﺘﻘﻞ:
ﻓﻌﻨﺪﻣﺎﻳﺤﺪثﺧﻄﺄﻣﺎ،ﻗﺪﺗُﺴﺎﻋﺪﻧﺎﻣﺜﻞﻫﺬه اﻟﺒﻴﺎﻧﺎتﰲﺗﻔﺴريﻣﺎﺣﺪثﺑﺎﻟﻀﺒﻂ.
وﻫﺬاﺑﺪَورهﻗﺪﻳُﺴﺎﻋﺪﰲ اﻟﺘﺤﻠﻴﻞ اﻷﺧﻼﻗﻲ واﻟﻘﺎﻧﻮﻧﻲﻟﻠﺤﺎﻟﺔ. وﻋﻼوةًﻋﲆ ذﻟﻚ،ﻛﻤﺎ
ﻳﻘﻮل اﻟﺒﺎﺣﺜﻮن، وﻫﻢﻣُﺤﻘﱡﻮنﰲﻗﻮﻟﻬﻢ،ﻳُﻤﻜﻨﻨﺎ أنﻧﺘﻌﻠﱠﻢﺷﻴﺌًﺎﻣﻦﺻﻨﺎﻋﺔ اﻟﻄﺎﺋﺮات،
اﻟﺘﻲﺗﺨﻀﻊ إﱃﺗﻨﻈﻴﻢٍﺻﺎرم وﻟﺪَﻳﻬﺎﻋﻤﻠﻴﺎت دﻗﻴﻘﺔﻟﻠﺘﺤﻘﱡﻖﻣﻦ اﻟﺴﻼﻣﺔ وﻋﻤﻠﻴﺎتﻣﺮﺋﻴﺔ
ﻟﻠﺘﺤﻘﻴﻖﰲ اﻟﺤﻮادث.ﻓﻬﻞﻳُﻤﻜﻦﺗﺜﺒﻴﺖﺑِﻨﻴﺔ أﺳﺎﺳﻴﺔﻣُﻤﺎﺛﻠﺔﺗﻀﻤﻦ اﻟﺘﻨﻈﻴﻢ واﻟﺴﻼﻣﺔﰲ
ﺣﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟ وﻟﻠﻤُﻘﺎرﻧﺔﺑﻤﺠﺎل آﺧَﺮﻣﻦﻣﺠﺎﻻت وﺳﺎﺋﻞ اﻟﻨﻘﻞ،ﻗﺪ اﻗﱰﺣﺖ
ﺻﻨﺎﻋﺔ اﻟﺴﻴﺎرات أﻳﻀًﺎﺷﻬﺎدةً أوﻧﻮﻋًﺎﻣﻦ »رﺧﺼﺔ اﻟﻘﻴﺎدة«ﻟﻠﻤﺮﻛﺒﺎت اﻟﺬاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞ
ﻳﺬﻫﺐﺑﻌﺾ اﻟﺒﺎﺣﺜني إﱃ أﺑﻌَﺪَﻣﻦ ذﻟﻚ وﻳﻬﺪﻓﻮن إﱃ13.املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
إﻧﺸﺎء آﻻتٍ أﺧﻼﻗﻴﺔ،ﰲﻣُﺤﺎوﻟﺔٍﻟﺘﺤﻘﻴﻖ »أﺧﻼﻗﻴﺎت اﻵﻟﺔ«ﺑﻤﻌﻨﻰ أنﺗﺴﺘﻄﻴﻊ اﻵﻻتﻧﻔﺴﻬﺎ
اﺗﺨﺎذﻗﺮاراتٍ أﺧﻼﻗﻴﺔ. وﻳُﺠﺎدل آﺧﺮونﺑﺄنﻫﺬهﻓﻜﺮةﺧﻄرية وأﻧﻪﻳﺠِﺐ اﻻﺣﺘﻔﺎظﺑﻬﺬه
اﻟﻘﺪرةﻟﻠﺒﴩَ ، وأﻧﻪﻣﻦ املُﺴﺘﺤﻴﻞﺧﻠﻖ آﻻتﺗﺘﻤﺘﱠﻊﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﻜﺎﻣﻠﺔ، وﻻﺣﺎﺟﺔ
إﱃ أنﺗﺘﻤﺘﱠﻊ اﻵﻻتﺑﺎﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﻜﺎﻣﻠﺔ، وﻳﻜﻔﻲ أنﺗﻜﻮن اﻵﻻت آﻣﻨﺔً وﻣﻠﺘﺰﻣﺔ
Wallach) «(، أوﻗﺪﺗُﻨﺸَﺄ أﺷﻜﺎلﻣﻦ »اﻷﺧﻼق اﻟﻮﻇﻴﻔﻴﺔYampolskiy 2013)ﺑﺎﻟﻘﺎﻧﻮن
( اﻟﺘﻲﻻﺗﻜﺎﻓﺊ اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﻜﺎﻣﻠﺔ، وﻟﻜﻨﻬﺎﻣﻊ ذﻟﻚﺗﺠﻌﻞ اﻵﻟﺔand Allen 2009
ﻣُﺮاﻋﻴﺔًﻧﺴﺒﻴٍّﺎﻟﻘﻮاﻋﺪ اﻷﺧﻼق.ﺗُﻌﺪﻫﺬه املﻨﺎﻗﺸﺔ، اﻟﺘﻲﺗﺘﻌﻠﱠﻖﻣﺠﺪدًاﺑﻤﻮﺿﻮع املﻜﺎﻧﺔ
اﻷﺧﻼﻗﻴﺔ، ذاتﺻِﻠﺔ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﺣﺎﻟﺔ اﻟﺴﻴﺎرات اﻟﺬاﺗﻴﺔ اﻟﻘﻴﺎدة: وإﱃ أيﻣﺪًى
ﻳﺘﻌني وﻳﻤﻜﻦ وﻳُﺴﺘﺤﺴَﻦﺗﻀﻤني اﻟﻘﻮاﻋﺪ اﻷﺧﻼﻗﻴﺔﰲﻫﺬه اﻟﺴﻴﺎرات، وﻣﺎﻧﻮعﻫﺬه
اﻟﻘﻮاﻋﺪ اﻷﺧﻼﻗﻴﺔ وﻛﻴﻒﻳُﻤﻜﻦﺗﻨﻔﻴﺬﻫﺎﺗﻘﻨﻴٍّﺎ؟
ﻳﻤﻜﻦ أنﺗُﺴﺎﻋﺪﻧﺎ اﻷﻓﻜﺎرﻣﺜﻞ اﻷﺧﻼﻗﻴﺎت املُﺘﻀﻤﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ أو اﻟﺘﺼﻤﻴﻢ اﻟﺤﺴﱠﺎسﻟﻠﻘِﻴَﻢ،ﰲ
إﻧﺸﺎء اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﻄﺮﻳﻘﺔٍﺗﺆدي إﱃﻣﺰﻳﺪٍﻣﻦ املﺴﺎءﻟﺔ واملﺴﺌﻮﻟﻴﺔ واﻟﺸﻔﺎﻓﻴﺔ.
111</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﻤﻴﻞﺻﺎﻧﻌﻮ اﻟﺴﻴﺎﺳﺎت إﱃ دﻋﻢ اﻟﻌﺪﻳﺪﻣﻦﻫﺬه اﻻﺗﺠﺎﻫﺎتﰲ اﻟﺒﺤﺚ واﻻﺑﺘﻜﺎرﰲ
ﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻣﺜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺑﻞﻟﻠﺘﻔﺴري وﺑﺸﻜﻞٍﻋﺎم،ﺗﻀﻤني
اﻷﺧﻼقﰲ اﻟﺘﺼﻤﻴﻢ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إﱃﺟﺎﻧﺐ اﻷﺳﺎﻟﻴﺐﻏري اﻟﺘﻘﻨﻴﺔﻣﺜﻞ اﻟﻠﻮاﺋﺢ
اﻟﺘﻨﻈﻴﻤﻴﺔ، ووﺿﻊ املﻌﺎﻳري، واﻟﺘﻌﻠﻴﻢ، وﺣﻮار اﻷﻃﺮاف املَﻌﻨﻴﺔ وﻓِﺮق اﻟﺘﺼﻤﻴﻢ اﻟﺸﺎﻣﻠﺔ،
ذﻛﺮﺗﻘﺮﻳﺮﻓﺮﻳﻖ اﻟﺨﱪاء اﻟﺮﻓﻴﻊ املﺴﺘﻮىﻋﺪدًاﻣﻦ اﻷﺳﺎﻟﻴﺐ اﻟﺘﻘﻨﻴﺔ وﻣﻨﻬﺎﺗﻀﻤني
اﻟﻘﻮاﻋﺪ اﻷﺧﻼﻗﻴﺔ وﺳﻴﺎدة اﻟﻘﺎﻧﻮنﰲ اﻟﺘﺼﻤﻴﻢ، وﻫﻴﺎﻛﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺠﺪﻳﺮﺑﺎﻟﺜﻘﺔ،
واﻻﺧﺘﺒﺎر واﻟﺘﺤﻘﻖ، واﻟﺘﺘﺒﻊ واﻟﺘﺪﻗﻴﻖ، واﻟﺘﻔﺴري.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳُﻤﻜﻦ أنﺗﺸﺘﻤﻞ
اﻷﺧﻼﻗﻴﺎت املُﻀﻤﻨﺔﰲ اﻟﺘﺼﻤﻴﻢﻋﲆ اﻟﺨﺼﻮﺻﻴﺔ املُﻀﻤﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ. وﻳُﺸري اﻟﺘﻘﺮﻳﺮ
أﻳﻀًﺎ إﱃﺑﻌﺾ اﻟﻄﺮق اﻟﺘﻲﻳُﻤﻜﻦﺑﻬﺎﺗﻨﻔﻴﺬ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺠﺪﻳﺮﺑﺎﻟﺜﻘﺔ،ﻣﺜﻞ اﻟﺘﺘﺒﱡﻊ
ﻛﻄﺮﻳﻘﺔٍﻟﻠﻤﺴﺎﻫﻤﺔﰲ اﻟﺸﻔﺎﻓﻴﺔ: وﰲﺣﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺴﺘﻨﺪ إﱃﻗﻮاﻋﺪﻳﺠِﺐ
ﺗﻮﺿﻴﺢﻛﻴﻔﻴﺔﺑﻨﺎء اﻟﻨﻤﻮذج، وﰲﺣﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺴﺘﻨِﺪ إﱃ اﻟﺘﻌﻠﱡﻢﻳﺠﺐﺗﻮﺿﻴﺢ
وﺳﻴﻠﺔﺗﺪرﻳﺐ اﻟﺨﻮارزﻣﻴﺔ،ﺑﻤﺎﰲ ذﻟﻚﻛﻴﻔﻴﺔﺟﻤﻊ اﻟﺒﻴﺎﻧﺎت واﺧﺘﻴﺎرﻫﺎ. وﻣﻦ املُﻔﱰَض أن
ﻳﻀﻤَﻦﻫﺬا أنﻳﻜﻮنﻧﻈﺎم اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺎﺑﻼًﻟﻠﺘﺪﻗﻴﻖ، وﻻﺳﻴﱠﻤﺎﰲ املﻮاﻗﻒ اﻟﺨﻄرية
(.European Commission AI HLEG 2019)
ﺗُﻌﺪﱡﻣَﺴﺄﻟﺔ اﻷﺳﺎﻟﻴﺐ واﻟﺘﻨﻔﻴﺬﺣﺎﺳﻤﺔَ اﻷﻫﻤﻴﺔ:ﺣﻴﺚ إنﺗﺤﺪﻳﺪﻋﺪدٍﻣﻦ املﺒﺎدئ
اﻷﺧﻼﻗﻴﺔﳾء، واﻛﺘﺸﺎفﻃﺮﻳﻘﺔﺗﻨﻔﻴﺬﻫﺬه املﺒﺎدئﻋﻤﻠﻴٍّﺎﳾءٌﻣﺨﺘﻠﻒﺗﻤﺎﻣًﺎ. وﺣﺘﻰ
املﻔﺎﻫﻴﻢﻣﺜﻞ اﻟﺨﺼﻮﺻﻴﺔ املُﻀﻤﱠﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ، اﻟﺘﻲﻳُﻔﱰض أنﺗﻜﻮن أﻗﺮب إﱃﻋﻤﻠﻴﺔ
اﻟﺘﻄﻮﻳﺮ واﻟﻬﻨﺪﺳﺔ،ﻓﻐﺎﻟﺒًﺎﻣﺎﺗُﺼﺎغﺑﻄﺮﻳﻘﺔٍﻣﺠﺮدة وﻋﺎﻣﺔ؛ وﻣِﻦﺛَﻢﻓﺈﻧﻨﺎﻣﺎ زﻟﻨﺎﻻﻧﺪري
ﺑﺎﻟﺘﺤﺪﻳﺪﻣﺎﻳﻨﺒﻐﻲ أنﻧﻔﻌﻠﻪ. وﻳﻘﻮدﻧﺎﻫﺬا إﱃ اﻟﻔﺼﻞ اﻟﺘﺎﱄ ملﻨﺎﻗﺸﺔٍﻣﻮﺟﺰةﺣﻮلﺑﻌﺾ
اﻟﺘﺤﺪﻳﺎت اﻟﺘﻲﺗﻮاﺟِﻪﺳﻴﺎﺳﺎتِ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
112</p>
</section>
<section id="section-12">
    <h2>١١ - التحديات التي تُواجه صانعي السياسات</h2>
    <div class="page-range">Pages 113-122</div>
    <p>اﻟﻔﺼﻞ اﻟﺤﺎديﻋﴩ
اﻟﺘﺤﺪﻳﺎت اﻟﺘﻲﺗُﻮاﺟﻪﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت
اﻷﺧﻼﻗﻴﺎت اﻻﺳﺘﺒﺎﻗﻴﺔ: اﻻﺑﺘﻜﺎر املﺴﺌﻮل وﺗﻀﻤني اﻟﻘِﻴَﻢﰲ اﻟﺘﺼﻤﻴﻢ
رﺑﻤﺎﻻﻳُﺪﻫﺸﻨﺎ أنﻧﻌﺮف أنﺳﻴﺎﺳﺎت أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﻮاﺟِﻪ اﻟﻌﺪﻳﺪﻣﻦ
اﻟﺘﺤﺪﱢﻳﺎت. وﻗﺪ رأﻳﻨﺎ أنﺑﻌﺾ اﻟﺴﻴﺎﺳﺎت املُﻘﱰﺣﺔﺗﺆﻳﺪ رؤﻳﺔً اﺳﺘﺒﺎﻗﻴﺔﻷﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ؛ﺑﻤﻌﻨﻰ أﻧﻨﺎﺑﺤﺎﺟﺔٍ إﱃﻣﺮاﻋﺎة اﻷﺧﻼقﰲ املﺮﺣﻠﺔ املُﺒﻜﺮةﻣﻦﺗﻄﻮﻳﺮﺗﻜﻨﻮﻟﻮﺟﻴﺎ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﺗﻜﻤُﻦ اﻟﻔﻜﺮةﰲﺗﺠﻨﱡﺐ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ واملُﺠﺘﻤﻌﻴﺔ اﻟﺘﻲﻳﺨﻠﻘﻬﺎ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺘﻲﺳﻴﻜﻮنﻣﻦ اﻟﺼﻌﺐ اﻟﺘﻌﺎﻣُﻞﻣﻌﻬﺎﺑﻤﺠﺮدﺣﺪوﺛﻬﺎ. وﻳﺘﻤﺎﳽ
ﻫﺬاﻣﻊ أﻓﻜﺎر اﻻﺑﺘﻜﺎر املﺴﺌﻮل، وﺗﻀﻤني اﻟﻘِﻴَﻢﰲ اﻟﺘﺼﻤﻴﻢ، وﻏريﻫﺎﻣﻦ اﻷﻓﻜﺎر املُﺸﺎﺑﻬﺔ
اﻟﺘﻲ اﻗﱰُ ِﺣﺖﻋﲆﻣﺪار اﻟﺴﻨﻮات اﻷﺧرية. وﻫﺬاﻳُﺤﻮﱢل املﺸﻜﻠﺔﻣﻦﻣﻌﺎﻟﺠﺔ اﻵﺛﺎر اﻟﺴﻠﺒﻴﺔ
ﻟﻠﺘﻘﻨﻴﺎت املُﺴﺘﺨﺪﻣﺔﻋﲆﻧﻄﺎق واﺳﻊﺑﺎﻟﻔﻌﻞ إﱃﺗﺤﻤﻞ املﺴﺌﻮﻟﻴﺔﺗﺠﺎه اﻟﺘﻘﻨﻴﺎت اﻟﺘﻲﻳﺘﻢ
ﺗﻄﻮﻳﺮﻫﺎ اﻟﻴﻮم.
وﻣﻊ ذﻟﻚ،ﻟﻴﺲﻣﻦ اﻟﺴﻬﻞ أنﻧﺘﻮﻗﱠﻊ اﻟﻌﻮاﻗِﺐﻏري املﻘﺼﻮدةﻟﻠﺘﻘﻨﻴﺎت اﻟﺠﺪﻳﺪةﰲ
ﻣﺮﺣﻠﺔ اﻟﺘﺼﻤﻴﻢ. إﺣﺪى اﻟﻄﺮقﻟﺘﺨﻔﻴﻒﻫﺬه املﺸﻜﻠﺔﻫﻮﺑﻨﺎءﺳﻴﻨﺎرﻳﻮﻫﺎتﺣﻮل اﻟﻌﻮاﻗﺐ
اﻷﺧﻼﻗﻴﺔ املُﺴﺘﻘﺒﻠﻴﺔ. وﻫﻨﺎك أﺳﺎﻟﻴﺐﻣُﺨﺘﻠﻔﺔ ملﻤﺎرﺳﺔ اﻷﺧﻼﻗﻴﺎتﰲ اﻟﺒﺤﺚ واﻻﺑﺘﻜﺎر
(، إﺣﺪاﻫﺎﻟﻴﺴﺖﻓﻘﻂ دراﺳﺔﺗﺄﺛريﴎدﻳﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲReijers et al. 2018)
ً( وﻟﻜﻦ أﻳﻀًﺎﺧﻠﻖﴎدﻳﺎتﺟﺪﻳﺪة أﻛﺜﺮ واﻗﻌﻴﺔRoyal Society, 2018)اﻟﺤﺎﻟﻴﺔ وﺗﻘﻴﻴﻤﻬﺎ
ﺣﻮلﺗﻄﺒﻴﻘﺎتﻣُﻌﻴﻨﺔﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
اﻟﻨﻬﺞ املُﻮﺟﱠﻪﻟﻠﻤُﻤﺎرﺳﺔ واﻟﻨﻬﺞ اﻟﺘﺼﺎﻋﺪي:ﻛﻴﻒﻧﱰﺟﻤﻬﻤﺎﻋﻤﻠﻴٍّﺎ؟
اﻻﺑﺘﻜﺎر املﺴﺌﻮلﻻﻳﺘﻌﻠﻖﻓﻘﻂﺑﺘﻀﻤني اﻷﺧﻼﻗﻴﺎتﰲ اﻟﺘﺼﻤﻴﻢ، وﻟﻜﻨﻪﻳﺘﻄﻠﱠﺐ أﻳﻀًﺎ
ﻣﺮاﻋﺎة آراءﻣُﺨﺘﻠﻒ اﻷﻃﺮاف املَﻌﻨﻴﺔ وﻣﺼﺎﻟﺤﻬﻢ. وﺗﻨﻄﻮي اﻟﺤﻮﻛﻤﺔ اﻟﺸﺎﻣﻠﺔﻋﲆ إﴍاك
ﻧﻄﺎقٍ واﺳﻊﻣﻦ اﻷﻃﺮاف املَﻌﻨﻴﺔ، وإﺟﺮاءﻧﻘﺎشٍﻋﺎم، واﻟﺘﺪﺧﻞ املُﺠﺘﻤﻌﻲ املُﺒﻜﺮﰲﻣﺮﺣﻠﺔ
(. وﻫﺬاﻗﺪﻳﻌﻨﻲ،ﻣﺜﻼً ،ﺗﻨﻈﻴﻢﻣﺠﻤﻮﻋﺎتVon Schomberg 2011)اﻟﺒﺤﺚ واﻻﺑﺘﻜﺎر
ﻧﻘﺎشٍﻣﺮﻛﺰة واﺳﺘﺨﺪامﺗﻘﻨﻴﺎت أﺧﺮى ملﻌﺮﻓﺔ رأي اﻟﻨﺎسﰲ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ.
ﻳﺘﻌﺎرضﻫﺬا اﻟﻨﻬﺞ اﻟﺘﺼﺎﻋﺪيﰲ اﻻﺑﺘﻜﺎر املﺴﺌﻮلﻣﻊﻧﻬﺞ اﻷﺧﻼﻗﻴﺎت اﻟﺘﻄﺒﻴﻘﻴﺔ
اﻟﺬيﻳﺘﺒﻌﻪﻣﻌﻈﻢ وﺛﺎﺋﻖ اﻟﺴﻴﺎﺳﺎت، واﻟﺬيﻳﻤﻴﻞﰲ اﻟﻐﺎﻟﺐ إﱃ أنﻳﻜﻮنﻧﻬﺠًﺎﺗﻨﺎزﻟﻴٍّﺎ
وﻣﺠﺮدًا. أوﻻً ،ﻳﺘﻢ إﻧﺸﺎء اﻟﺴﻴﺎﺳﺎتﻏﺎﻟﺒًﺎﻣﻦﻗِﺒﻞﺧﱪاء، دون أنﻳﺸﺎركﻓﻴﻬﺎﻧﻄﺎق
واﺳﻊﻣﻦ اﻷﻃﺮاف املَﻌﻨﻴﺔ.ﺛﺎﻧﻴًﺎ،ﺣﺘﻰ إذا أﻳﱠﺪتﻫﺬه اﻟﺴﻴﺎﺳﺎتﻣﺒﺎدئﻣﺜﻞ اﻷﺧﻼﻗﻴﺎت
املُﻀﻤﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ،ﻓﺈﻧﻬﺎﺗﻈﻞﱡﺷﺪﻳﺪة اﻟﻐﻤﻮضﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﻤﺎﻳَﻌﻨﻴﻪﺗﻄﺒﻴﻖﻫﺬه
املﺒﺎدئﻋﻤﻠﻴٍّﺎ. وﻹﻧﺠﺎحﺳﻴﺎﺳﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻳﻈﻞﱡ اﻟﺘﺤﺪيﻛﺒريًاﻟﺒﻨﺎءﺟﴪٍﺑني
املﺒﺎدئ اﻷﺧﻼﻗﻴﺔ واﻟﻘﺎﻧﻮﻧﻴﺔ املُﺠﺮدة واﻟﻌﺎﻟﻴﺔ املﺴﺘﻮىﻣﻦﻧﺎﺣﻴﺔ، وﺑنيﻣُﻤﺎرﺳﺎتﺗﻄﻮﻳﺮ
اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ واﺳﺘﺨﺪاﻣﻬﺎﰲﺳﻴﺎﻗﺎتٍﻣُﻌﻴﻨﺔ، واﻟﺘﻘﻨﻴﺎت، وأﺻﻮات أوﻟﺌﻚ اﻟﺬﻳﻦﻳﺸﺎرﻛﻮن
ﰲﻫﺬه املﻤﺎرﺳﺎت وﻳﻌﻤﻠﻮنﰲﻫﺬه اﻟﺴﻴﺎﻗﺎتﻣﻦﻧﺎﺣﻴﺔ أﺧﺮى.ﻳُﱰكﺑﻨﺎءﻫﺬا اﻟﺠﴪ ملَﻦ
ﺗُﻮﺟﱠﻪ إﻟﻴﻬﻢﻫﺬه اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ.ﻓﻬﻞﻳُﻤﻜﻨﻨﺎ اﻟﻘﻴﺎمﺑﺎملﺰﻳﺪﰲ املﺮﺣﻠﺔ اﻷوﱃﻣﻦﺻﻨﻊ
اﻟﺴﻴﺎﺳﺎت، وﻫﻞﻳﺠِﺐﻋﻠﻴﻨﺎ ذﻟﻚ؟ﻧﺤﺘﺎجﻋﲆ اﻷﻗﻞ إﱃ املﺰﻳﺪﻣﻦ اﻟﻌﻤﻞﻋﲆ اﻷﺳﺎﻟﻴﺐ
واﻹﺟﺮاءات واملﺆﺳﱠﺴﺎت اﻟﺘﻲﻧﺤﺘﺎﺟﻬﺎﻟﺠﻌﻞ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﻨﺠﺢﻋﻤﻠﻴٍّﺎ.
وﻳﺠﺐﻋﻠﻴﻨﺎ أنﻧُﻮﱄ املﺰﻳﺪﻣﻦ اﻻﻫﺘﻤﺎمﻟﻠﻌﻤﻠﻴﺔ.
اﻻﺑﺘﻜﺎر املﺴﺌﻮلﻻﻳﺘﻌﻠﻖﻓﻘﻂﺑﺘﻀﻤني اﻷﺧﻼﻗﻴﺎتﰲ اﻟﺘﺼﻤﻴﻢ، وﻟﻜﻨﻪﻳﺘﻄﻠﺐ أﻳﻀًﺎﻣﺮاﻋﺎة آراء
ﻣﺨﺘﻠﻒ اﻷﻃﺮاف املَﻌﻨﻴﺔ وﻣﺼﺎﻟﺤﻬﻢ.
ﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺎﻟﺴﺆالﻋﻤﱠﻦﻳﺸﺎركﰲ وﺿﻊ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﺈﻧﻨﺎ
ﻧﺤﺘﺎج إﱃﺗﻄﺒﻴﻖﻧﻬﺞﺗﺼﺎﻋﺪي إﱃﺟﺎﻧﺐ اﻟﻨﻬﺞ اﻟﺘﻨﺎزﱄ،ﺑﻤﻌﻨﻰ اﻻﺳﺘﻤﺎع أﻛﺜﺮ إﱃ
اﻟﺒﺎﺣﺜني واملﻬﻨﻴني اﻟﺬﻳﻦﻳﺘﻌﺎﻣﻠﻮنﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﻤﻠﻴٍّﺎ،ﺑﻞ وإﱃ اﻷﺷﺨﺎص اﻟﺬﻳﻦ
ﻣﻦ املُﺤﺘﻤَﻞ أنﻳﴬﱠﻫﻢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. إذاﻛﻨﺎﻧﺆﻳﺪﻣﺒﺪأ اﻟﺪﻳﻤﻘﺮاﻃﻴﺔ وإذاﻛﺎن
114</p>
<p>اﻟﺘﺤﺪﻳﺎت اﻟﺘﻲﺗُﻮاﺟﻪﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت
ﻫﺬا املﻔﻬﻮمﻳﺸﻤﻞ اﻟﺘﻀﻤني واملﺸﺎرﻛﺔﰲﺻﻨﻊ اﻟﻘﺮارﺑﺸﺄنﻣُﺴﺘﻘﺒﻞﻣﺠﺘﻤﻌﺎﺗﻨﺎ،ﻓﺈن
ﺳﻤﺎعﺻﻮت اﻷﻃﺮاف املَﻌﻨﻴﺔﻟﻴﺲ أﻣﺮًا اﺧﺘﻴﺎرﻳٍّﺎ وﻟﻜﻨﻪ إﻟﺰاﻣﻲﻣﻦ اﻟﻨﺎﺣﻴﺘَني اﻷﺧﻼﻗﻴﺔ
واﻟﺴﻴﺎﺳﻴﺔ.ﺑﻴﻨﻤﺎﻳﺸﺎركﺑﻌﺾﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎتﰲﻧﻮعﻣﻦ اﻟﺘﺸﺎورﻣﻊ اﻷﻃﺮاف
املﻌﻨﻴﺔ )ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻟﺪى املﻔﻮﺿﻴﺔ اﻷوروﺑﻴﺔﺗﺤﺎﻟﻒ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺨﺎص
ﻻﻳﺰالﻣﻦ املﺸﻜﻮكﻓﻴﻪﻣﺎ إذاﻛﺎﻧﺖﻣﺜﻞﻫﺬه اﻟﺠﻬﻮدﺗﺼﻞﺣﻘٍّﺎ إﱃ املُﻄﻮرﻳﻦ1،(ﺑﻬﺎ
واملﺴﺘﺨﺪﻣني اﻟﻨﻬﺎﺋﻴنيﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎ، واﻷﻫﻢﻣﻦ ذﻟﻚ، إﱃ أوﻟﺌﻚ اﻟﺬﻳﻦﺳﻴﺘﻌنيﱠﻋﻠﻴﻬﻢﺗﺤﻤﱡﻞ
ﻣﻌﻈﻢ املﺨﺎﻃﺮ واﻟﺘﻌﺎﻳﺶﻣﻊ آﺛﺎرﻫﺎ اﻟﺴﻠﺒﻴﺔ.ﻓﻬﻞﺻُﻨﻊ اﻟﻘﺮار واﻟﺴﻴﺎﺳﺎت اﻟﺨﺎﺻﺔ
ﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻣﺮٌ دﻳﻤﻘﺮاﻃﻲﻳﻨﻄﻮيﻋﲆﻣﺸﺎرﻛﺔﺣﻘٍّﺎ؟
إنﱠﻣﻔﻬﻮم اﻟﺪﻳﻤﻘﺮاﻃﻴﺔﻣُﻬﺪﱠد أﻳﻀًﺎﺑﺤﻘﻴﻘﺔﺗﺮﻛﺰ اﻟﺴﻠﻄﺔﰲ أﻳﺪيﻋﺪدٍﺻﻐريﻧﺴﺒﻴٍّﺎ
ﻣﻦ اﻟﴩﻛﺎت اﻟﻜﺒرية. وﻳﺮىﺑﻮلﻧﻴﻤﻴﺘﺰ )٨١٠٢( أنﺗﺮاﻛُﻢ اﻟﺴﻠﻄﺔ اﻟﺮﻗﻤﻴﺔﰲ أﻳﺪي
ﴍﻛﺎتﻗﻠﻴﻠﺔﻳﻨﻄﻮيﻋﲆ إﺷﻜﺎﻟﻴﺔ: إذاﻣﺎرﺳﺖﺣﻔﻨﺔﻣﻦ اﻟﴩﻛﺎتﺳُﻠﻄﺘﻬﺎﻟﻴﺲﻓﻘﻂ
ﻋﲆ اﻷﻓﺮاد —ﻣﻦﺧﻼلﺗﻜﻮﻳﻦﻣﻠﻔﱠﺎتٍﺗﻌﺮﻳﻔﻴﺔﻋﻨﺎ — وﻟﻜﻦ أﻳﻀًﺎﻋﲆ اﻟﺒﻨﻴﺔ اﻷﺳﺎﺳﻴﺔ
ﻟﻠﺪﻳﻤﻘﺮاﻃﻴﺔ،ﻓﺈنﻫﺬه اﻟﴩﻛﺎت،ﻋﲆ اﻟﺮﻏﻢﻣﻦﻧﻮاﻳﺎﻫﺎ اﻟﺤﺴﻨﺔﻟﻠﻤﺴﺎﻫﻤﺔﰲ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻷﺧﻼﻗﻲ،ﺳﻮفﺗﻀﻊﻋﻘﺒﺎتٍ أﻣﺎﻣﻪ. وﻟﺬﻟﻚ،ﻓﻤِﻦ اﻟﴬوري وﺿﻊﻟﻮاﺋﺢ
ﺗﻨﻈﻴﻤﻴﺔ وﺣﺪودﻟﺤﻤﺎﻳﺔ املﺼﻠﺤﺔ اﻟﻌﺎﻣﺔ، وﻟﻀﻤﺎن أنﻫﺬه اﻟﴩﻛﺎتﻟﻦﺗُﺸﻜﻞ اﻟﻘﻮاﻋﺪ
ﺑﻤﻔﺮدﻫﺎ. وأﺷﺎرﻣﻮرايﺷﺎﻧﺎﻫﺎن إﱃ أن »املَﻴﻞ إﱃﺗﺮﻛﱡﺰ اﻟﺴﻠﻄﺔ واﻟﺜﺮوة واملﻮاردﰲ أﻳﺪي
ﻋﺪدﻗﻠﻴﻞﻳﺘﱠﺴﻢﺑﺎﻻﺳﺘﺪاﻣﺔ اﻟﺬاﺗﻴﺔ« )٥١٠٢، ٦٦١(،ﻣﻤﺎﻳﺠﻌﻞﻣﻦ اﻟﺼﻌﺐﺗﺤﻘﻴﻖ
ﻣﺠﺘﻤﻊٍ أﻛﺜﺮ إﻧﺼﺎﻓًﺎ.ﻛﻤﺎ أﻧﻪﻳﺠﻌﻞ اﻷﻓﺮادﻋُﺮﺿﺔﻟﺠﻤﻴﻊ أﻧﻮاع املﺨﺎﻃﺮ،ﺑﻤﺎﰲ ذﻟﻚ
اﻻﺳﺘﻐﻼل واﻧﺘﻬﺎﻛﺎت اﻟﺨﺼﻮﺻﻴﺔ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﺎﺗُﺴﻤﱢﻴﻪ دراﺳﺔ أﺟﺮاﻫﺎ املﺠﻠﺲ
(.Yeung 2018, 33) «اﻷوروﺑﻲ »اﻟﺘﺄﺛري املُﺮوﱢعﻹﻋﺎدة اﺳﺘﺨﺪام اﻟﺒﻴﺎﻧﺎت
إذاﻗﺎرﻧﱠﺎ اﻟﻮﺿﻊﻣﻊﺳﻴﺎﺳﺔ اﻟﺒﻴﺌﺔ،ﻳُﻤﻜﻦ أنﻧﻜﻮنﻣُﺘﺸﺎﺋﻤني أﻳﻀًﺎﺑﺸﺄن إﻣﻜﺎﻧﻴﺔ أن
ﺗﺘﱠﺨﺬ اﻟﺒﻠﺪان إﺟﺮاءًﻓﻌﱠﺎﻻً وﺗﻌﺎوﻧﻴٍّﺎﺑﺸﺄن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.ﻓﻠﻨﺄﺧُﺬ،ﻋﲆﺳﺒﻴﻞ
املﺜﺎل، اﻟﻌﻤﻠﻴﺎت اﻟﺴﻴﺎﺳﻴﺔ املُﺘﻌﻠﻘﺔﺑﺘﻐريﱡ املﻨﺎخﰲ اﻟﻮﻻﻳﺎت املﺘﺤﺪة،ﺣﻴﺚﻳﺘﻢﰲﺑﻌﺾ
اﻷﺣﻴﺎن إﻧﻜﺎرﻣﺸﻜﻠﺔ اﻻﺣﱰار اﻟﻌﺎملﻲ وﺗﻐريﱡ املﻨﺎخﻧﻔﺴﻬﺎ، وﺣﻴﺚﺗﻌﻤﻞﺑﻌﺾ اﻟﻘﻮى
اﻟﺴﻴﺎﺳﻴﺔ ذات اﻟﻨﻔﻮذﺿﺪ اﺗﺨﺎذ أي إﺟﺮاءٍﺣﻴﺎل ذﻟﻚ، أو اﻟﻨﺠﺎح املﺤﺪودﻟﻠﻐﺎﻳﺔ ملﺆﺗﻤﺮات
ﺗﻐريﱡ املﻨﺎخ اﻟﺪوﻟﻴﺔﰲ اﻻﺗﻔﺎقﻋﲆﺳﻴﺎﺳﺔﻣﻨﺎﺧﻴﺔﻣﺸﱰﻛﺔ وﻓﻌﱠﺎﻟﺔ. وﻗﺪﻳﻮاﺟِﻪ أوﻟﺌﻚ اﻟﺬﻳﻦ
ﻳﺴﻌﻮن إﱃ اﺗﺨﺎذ إﺟﺮاءٍﻋﺎﻟَﻤﻲﰲﻇﻞ املﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ واملﺠﺘﻤﻌﻴﺔ اﻟﺘﻲ أﺛﺎرﻫﺎ اﻟﺬﻛﺎءُ
115</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
،اﻻﺻﻄﻨﺎﻋﻲﺻﻌﻮﺑﺎتﻣُﻤﺎﺛﻠﺔ.ﻓﻐﺎﻟﺒًﺎﻣﺎﺗﺘﻔﻮق املﺼﺎﻟﺢ اﻷﺧﺮىﻋﲆ املﺼﻠﺤﺔ اﻟﻌﺎﻣﺔ
وﻫﻨﺎكﻧﺪرةﰲ اﻟﺴﻴﺎﺳﺎت اﻟﺤﻜﻮﻣﻴﺔ اﻟﺪوﻟﻴﺔ اﻟﺨﺎﺻﺔﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺮﻗﻤﻴﺔ اﻟﺠﺪﻳﺪة،ﺑﻤﺎ
ﻓﻴﻬﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وﻣﻊ ذﻟﻚ،ﻫﻨﺎك اﺳﺘﺜﻨﺎءٌ واﺣﺪﻟﺬﻟﻚ وﻫﻮ اﻻﻫﺘﻤﺎم اﻟﻌﺎملﻲﺑﺤﻈﺮ
اﻷﺳﻠﺤﺔ اﻟﻘﺎﺗﻠﺔ اﻟﺬاﺗﻴﺔ اﻟﺘﺸﻐﻴﻞ، اﻟﺘﻲﺗﺤﺘﻮي أﻳﻀًﺎﻋﲆﺟﺎﻧﺐ ذﻛﺎء اﺻﻄﻨﺎﻋﻲ. وﻟﻜﻦﻫﺬا
ﻻﻳﺰال اﺳﺘﺜﻨﺎءً، وﻻﻳﺤﻈﻰ أﻳﻀًﺎﺑﺪﻋﻢﺟﻤﻴﻊ اﻟﺒﻠﺪان )ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﺎ زالﻣﻮﺿﻊ
ﺟﺪلﰲ اﻟﻮﻻﻳﺎت املﺘﺤﺪة(.
ﻋﻼوةًﻋﲆ ذﻟﻚ، ورﻏﻢﺣﺴﻦ اﻟﻨﻴﺔ،ﻓﺈنﻟﻜﻞﱟﻣﻦ أﺧﻼﻗﻴﺎت اﻟﺘﺼﻤﻴﻢ واﻻﺑﺘﻜﺎر املﺴﺌﻮل
ﻗﻴﻮدﻫﻤﺎ اﻟﺨﺎﺻﺔ. أوﻻً ،ﺗﻔﱰض أﺳﺎﻟﻴﺐﻣﺜﻞ اﻟﺘﺼﻤﻴﻢ اﻟﺤﺴﺎسﻟﻠﻘِﻴَﻢ أﻧﻪﻳُﻤﻜﻨﻨﺎ اﻟﺘﻌﺒري
ﻋﻦﻗِﻴَﻤﻨﺎ، وﺗﻔﱰضﺟﻬﻮدﺑﻨﺎء اﻵﻻت اﻷﺧﻼﻗﻴﺔ أﻧﻨﺎﻳﻤﻜﻦ أنﻧُﻌﱪﱢﺑﺸﻜﻞٍﻛﺎﻣﻞﻋﻦ
أﺧﻼﻗﻴﺎﺗﻨﺎ. وﻟﻜﻦﻫﺬاﻻﻳﺤﺪثﺑﺎﻟﴬورة داﺋﻤًﺎ؛ إذ إﻧﻨﺎﻗﺪﻻﻧﺴﺘﻄﻴﻊ اﻟﺘﻔﻜريﺑﻮﺿﻮحٍ
وﻻ اﻟﺘﻌﺒريﻋﻦ أﺧﻼﻗﻴﺎﺗﻨﺎ اﻟﻴﻮﻣﻴﺔ.ﻓﻔﻲﺑﻌﺾ اﻷﺣﻴﺎن،ﻧﺴﺘﺠﻴﺐ إﱃﻣﺸﻜﻼت أﺧﻼﻗﻴﺔ
(.Boddington 2017)ﺑﻄﺮﻳﻘﺔٍﻣُﻌﻴﻨﺔ دون أنﻧﺘﻤﻜﻦﻣﻦﺗﱪﻳﺮ اﺳﺘﺠﺎﺑﺘﻨﺎﺑﺸﻜﻞﻛﺎﻣﻞ
وﻛﻤﺎﻗﺎلﻓﻴﺘﺠﻨﺸﺘﺎﻳﻦ: أﺧﻼﻗﻴﺎﺗﻨﺎﻟﻴﺴﺖﻓﻘﻂﻣﺘﺠﺴﺪة وﻟﻜﻨﻬﺎﻣُﻀﻤﱠﻨﺔﰲﺷﻜﻞٍﻣﻦ
أﺷﻜﺎل اﻟﺤﻴﺎة. إﻧﻬﺎﻣﺘﺼﻠﺔﻋﲆﻧﺤﻮٍﻋﻤﻴﻖﺑﻄﺮﻳﻘﺔﻗﻴﺎﻣﻨﺎﺑﺎﻷﻓﻌﺎلﻛﻜﺎﺋﻨﺎتﻣﺘﺠﺴﺪة
واﺟﺘﻤﺎﻋﻴﺔ، وﻛﻤﺠﺘﻤﻌﺎت وﺛﻘﺎﻓﺎت. وﻫﺬاﻳﻔﺮضﺣﺪودًاﻋﲆﻣﴩوع اﻟﺘﻌﺒري اﻟﻜﺎﻣﻞﻋﻦ
اﻷﺧﻼق واﻟﺘﻔﻜري اﻷﺧﻼﻗﻲ. وﻳﻤﺜﻞ أﻳﻀًﺎﻣﺸﻜﻠﺔ ملﴩوعﺗﻄﻮﻳﺮ اﻵﻻت اﻷﺧﻼﻗﻴﺔ، وﻳﺘﺤﺪى
اﻻﻓﱰاﺿﺎت اﻟﺘﻲﺗﻘﻮل إن اﻷﺧﻼق واﻟﺪﻳﻤﻘﺮاﻃﻴﺔﻳﻤﻜﻦﻣﻨﺎﻗﺸﺘﻬﻤﺎ واﻟﺘﻌﺒريﻋﻨﻬﻤﺎﺑﺎﻟﻜﺎﻣﻞ.
ﻛﻤﺎﻳﺨﻠﻖﻣﺸﻜﻠﺔﻟﺼﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت اﻟﺬﻳﻦﻳﻌﺘﻘﺪون أن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﻤﻜﻦ اﻟﺘﻌﺎﻣﻞﻣﻌﻬﺎﺗﻤﺎﻣًﺎﻣﻦﺧﻼلﻗﺎﺋﻤﺔﻣﻦ املﺒﺎدئ أوﻣﻦﺧﻼل أﺳﺎﻟﻴﺐﻗﺎﻧﻮﻧﻴﺔ وﺗﻘﻨﻴﺔ
ﻣُﺤﺪﱠدة.ﻧﺤﻦﺑﺎﻟﺘﺄﻛﻴﺪﺑﺤﺎﺟﺔٍ إﱃ أﺳﺎﻟﻴﺐ وإﺟﺮاءات وﻋﻤﻠﻴﺎت. وﻟﻜﻦﻛﻞﻫﺬاﻟﻴﺲﻛﺎﻓﻴًﺎ؛
ﻓﺎﻷﺧﻼﻗﻴﺎتﻻﺗﻌﻤﻞﻣﺜﻞ اﻵﻟﺔ، وﻛﺬﻟﻚ اﻟﺴﻴﺎﺳﺔ واﻻﺑﺘﻜﺎر املﺴﺌﻮل.
ﺛﺎﻧﻴًﺎ،ﻳُﻤﻜﻦ أنﻳﻜﻮنﻫﺬان اﻟﻨﻬﺠﺎنﻋﺎﺋﻘًﺎ أﻣﺎم اﻷﺧﻼﻗﻴﺎتﻋﻨﺪﻣﺎﻳﻜﻮنﻣﻦ اﻟﻮاﺟﺐ
أﺧﻼﻗﻴٍّﺎ إﻳﻘﺎفﺗﻄﻮﻳﺮ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ.ﻓﻐﺎﻟﺒًﺎﻣﺎﺗﻜﻮن وﻇﻴﻔﺘﻬﻤﺎﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻟﻌﻤﻠﻴﺔﻫﻲ
ﺗﻴﺴريﻋﻤﻠﻴﺔ اﻻﺑﺘﻜﺎر، وﺗﻌﺰﻳﺰﺗﺤﻘﻴﻖ اﻷرﺑﺎح، وﺿﻤﺎنﻗﺒﻮل اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ. وﻗﺪﻻﻳﻜﻮن
ﻫﺬاﺑﺎﻟﴬورةﺳﻴﺌًﺎ. وﻟﻜﻦﻣﺎذاﻟﻮﻛﺎﻧﺖ املﺒﺎدئ اﻷﺧﻼﻗﻴﺔﺗُﺸري إﱃ أﻧﻪﻳﺠﺐ إﻳﻘﺎف أو
ﺗﻌﻠﻴﻖ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ، أوﺗﻄﺒﻴﻖﻣُﻌنيﱠﻣﻦﺗﻄﺒﻴﻘﺎﺗﻬﺎ؟ اﻋﺘﱪﻛﺮوﻓﻮرد وﻛﺎﻟﻮ )٦١٠٢( أن
أداﺗَﻲ اﻟﺘﺼﻤﻴﻢ اﻟﺤﺴﱠﺎسﻟﻠﻘِﻴَﻢ واﻻﺑﺘﻜﺎر املﺴﺌﻮلﺗﻌﺘﻤﺪانﻋﲆ اﻓﱰاض أن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
ﺳﻴﺠﺮيﺗﻄﻮﻳﺮﻫﺎ؛ وﺗَﻘﻞﱡﻓﻌﺎﻟﻴﱠﺘﻬﻤﺎﻋﻨﺪﻣﺎﻳﺘﻌﻠﻖ اﻷﻣﺮﺑﺎﺗﺨﺎذﻗﺮارﺣﻮلﻣﺎ إذاﻛﺎنﻳﺠﺐ
116</p>
<p>اﻟﺘﺤﺪﻳﺎت اﻟﺘﻲﺗُﻮاﺟﻪﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت
إﻧﺸﺎءﻫﺬه اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻣﻦ اﻷﺳﺎس.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲﺣﺎﻟﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺘﻘﺪﱢم
ﻣﺜﻞﺗﻄﺒﻴﻘﺎتﺗﻌﻠﱡﻢ اﻵﻟﺔ اﻟﺠﺪﻳﺪة، رﺑﻤﺎﺗﻜﻮنﻫﺬه اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻻﺗﺰالﻏريﺟﺪﻳﺮةﺑﺎﻟﺜﻘﺔ
أوﻟﻬﺎﻋﻴﻮب أﺧﻼﻗﻴﺔﺧﻄرية، وأنﺑﻌﺾﺗﻄﺒﻴﻘﺎﺗﻬﺎﻋﲆ اﻷﻗﻞﻗﺪﻳﺘﻮﺟﺐﻋﺪم اﺳﺘﺨﺪاﻣﻬﺎ
)ﺑﻌﺪ(. وﺳﻮاء أﻛﺎن وﻗﻒ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻫﻮ اﻟﺤﻞ اﻷﻓﻀﻞ داﺋﻤًﺎ أمﻻ،ﻓﺈن اﻟﻘﻀﻴﺔﻫﻲ أﻧﻨﺎ
ﻳﺠِﺐﻋﲆ اﻷﻗﻞ أنﻧﺘﻤﺘﱠﻊﺑﺎﻟﺤﻖﰲﻃﺮح اﻟﺴﺆال وﺗﻘﺮﻳﺮﻣﺎﻳﻨﺒﻐﻲﻓﻌﻠﻪ.ﻓﺈذاﻛﺎنﻫﺬا
اﻟﺤﻖﻏﺎﺋﺒًﺎ،ﻓﺴﻮفﻳﻈﻞﱡ اﻻﺑﺘﻜﺎر املﺴﺌﻮلﺳﺘﺎرًاﻧُﺨﻔﻲ وراءهﻣﻮاﺻﻠﺔ اﻟﻌﻤﻞﻛﺎملﻌﺘﺎد.
ﻧﺤﻮ أﺧﻼﻗﻴﺎت إﻳﺠﺎﺑﻴﺔ
ﻋﲆ اﻟﺮﻏﻢﻣﻦﻛﻞﱢﻣﺎﻗﻴﻞ،ﻓﺈن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞٍﻋﺎمﱟﻻﺗﺘﻌﻠﱠﻖ
(.ﻫﻨﺎكﻋﺎﺋﻖٌ آﺧﺮﻳَﺤُﻮل دونﻣُﻤﺎرﺳﺔBoddington 2017)ﺑﺎﻟﴬورةﺑﻤﻨﻊ اﻷﺷﻴﺎء
أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﻤﻠﻴٍّﺎ، وﻫﺬا اﻟﻌﺎﺋﻖﻫﻮ أنﱠ اﻟﻌﺪﻳﺪﻣﻦ اﻟﺠﻬﺎت اﻟﻔﺎﻋﻠﺔﰲ
ﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺜﻞ اﻟﴩﻛﺎت واﻟﺒﺎﺣﺜني اﻟﺘﻘﻨﻴﱢنيﻻﻳﺰاﻟﻮنﻳﻌﺘﱪون اﻷﺧﻼﻗﻴﺎت
ﻗﻴﻮدًا، أو أﺷﻴﺎءًﺳﻠﺒﻴﺔ.ﻫﺬه اﻟﻔﻜﺮةﻟﻴﺴﺖﻣُﻀﻠﻠﺔﺑﺸﻜﻞٍﻛﺎﻣﻞ؛ إذﻏﺎﻟﺒًﺎﻣﺎﻳﺠﺐﻋﲆ
اﻷﺧﻼق أنﺗُﻘﻴﱢﺪ، وﺗَﺤُﺪ، وﺗﻘﻮلَ إنﺷﻴﺌًﺎﻣﺎﻏريﻣﻘﺒﻮل. وإذا أﺧﺬﻧﺎ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻋﲆﻣَﺤﻤﻞ اﻟﺠﺪ وﻧﻔﱠﺬﻧﺎﺗﻮﺻﻴﺎﺗﻬﺎ،ﻓﻘﺪﻧُﻮاﺟِﻪﺑﻌﺾ اﻟﺘﻨﺎزُﻻت، وﻻﺳﻴﱠﻤﺎﻋﲆ
املﺪى اﻟﻘﺼري.ﻓﻘﺪﻳﻜﻮنﻟﻸﺧﻼﻗﻴﺎتﺛﻤَﻦﻻﺑﺪﻣﻦ دﻓﻌﻪ؛ﺳﻮاءٌﻋﲆﻣﺴﺘﻮى املﺎل أو
اﻟﻮﻗﺖ أو اﻟﻄﺎﻗﺔ. وﻣﻊ ذﻟﻚ،ﻓﻤِﻦﺧﻼلﺗﻘﻠﻴﻞ املﺨﺎﻃﺮ،ﺗﺪﻋﻢ اﻷﺧﻼﻗﻴﺎت واﻻﺑﺘﻜﺎر املﺴﺌﻮل
اﻟﺘﻨﻤﻴﺔَ املُﺴﺘﺪاﻣﺔﻟﻸﻋﻤﺎل اﻟﺘﺠﺎرﻳﺔ واملﺠﺘﻤﻊﻋﲆ املﺪى اﻟﺒﻌﻴﺪ. وﻻﻳﺰالﻫﻨﺎكﺗَﺤﺪﱟﰲ
إﻗﻨﺎعﺟﻤﻴﻊ اﻟﺠﻬﺎت اﻟﻔﺎﻋﻠﺔﰲﻣﺠﺎل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺑﻤَﻦﻓﻴﻬﻢﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت،
ﺑﺄنﻫﺬاﻫﻮ اﻟﺤﺎلﻓﻌﻼً .ﻻﺣﻆ أﻳﻀًﺎ أن اﻟﺴﻴﺎﺳﺔ واﻟﻠﻮاﺋﺢ اﻟﺘﻨﻈﻴﻤﻴﱠﺔﻻﺗﺘﻌﻠﱠﻖﻓﻘﻂﺑﺤﻈﺮ
اﻷﺷﻴﺎء أوﺑﺠﻌﻠِﻬﺎ أﻛﺜﺮﺻﻌﻮﺑﺔً وﺗﻌﻘﻴﺪًا؛ﺑﻞﻳُﻤﻜﻦ أنﺗﻜﻮن داﻋﻤﺔ،ﻣﻦﺧﻼلﺗﻘﺪﻳﻢ
ﺣﻮاﻓﺰ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل.
ﻋﻼوةًﻋﲆ ذﻟﻚ، إﱃﺟﺎﻧﺐ اﻷﺧﻼﻗﻴﺎت اﻟﺴﻠﺒﻴﺔ اﻟﺘﻲﺗﻔﺮضﻗﻴﻮدًا،ﻧﺤﻦﰲﺣﺎﺟﺔ
إﱃﺗﻮﺿﻴﺢ اﻷﺧﻼﻗﻴﺎت اﻹﻳﺠﺎﺑﻴﺔ وﴍﺣﻬﺎ:ﻟﻮﺿﻊ رؤﻳﺔﻟﻠﺤﻴﺎة اﻟﺠﻴﺪة واملﺠﺘﻤﻊ اﻟﺠﻴﺪ.
وﺑﻴﻨﻤﺎﺗﻠﻤﺢﺑﻌﺾ املﺒﺎدئ اﻷﺧﻼﻗﻴﺔ املﻘﱰﺣﺔ أﻋﻼه إﱃﻣِﺜﻞﻫﺬه اﻟﺮؤﻳﺔ،ﻓﻼﻳﺰال
ﺗﻮﺟﻴﻪ املﻨﺎﻗﺸﺔ إﱃﻫﺬا اﻻﺗﺠﺎهﺗﺤﺪﻳٍّﺎ.ﻛﻤﺎﺳﺒﻖ وذﻛﺮﻧﺎ،ﻻﺗﺘﻌﻠﱠﻖ املﺴﺎﺋﻞ اﻷﺧﻼﻗﻴﺔ
اﻟﺨﺎﺻﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻓﺤﺴﺐ؛ﺑﻞﺗﺘﻌﻠﱠﻖﺑﺤﻴﺎة اﻹﻧﺴﺎن وازدﻫﺎره،
وﺗﺘﻌﻠﱠﻖﺑﻤُﺴﺘﻘﺒﻞ املﺠﺘﻤﻊ، ورﺑﻤﺎﺗﺘﻌﻠﻖ أﻳﻀًﺎﺑﻐري اﻟﺒﴩ، وﺑﺎﻟﺒﻴﺌﺔ، وﺑﻤُﺴﺘﻘﺒﻞ اﻟﻜﻮﻛﺐ
117</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
)اﻧﻈﺮ اﻟﻔﺼﻞ اﻟﺘﺎﱄ(. وﻫﻜﺬاﺗُﻌﻴﺪﻧﺎ املﻨﺎﻗﺸﺎتﺣﻮل أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﺳﻴﺎﺳﺎﺗﻪﻣﻦﺟﺪﻳﺪٍ إﱃ اﻷﺳﺌﻠﺔ اﻟﻜﺒرية اﻟﺘﻲﻳﺠﺐ أنﻧﻄﺮﺣﻬﺎﻋﲆ أﻧﻔﺴﻨﺎ؛ أﻓﺮادًا،
وﻣُﺠﺘﻤﻌﺎتٍ ، ورﺑﻤﺎﺑﴩًا. وﻳﻤﻜﻦﻟﻠﻔﻼﺳﻔﺔ أنﻳُﺴﺎﻋﺪوﻧﺎﰲ اﻟﺘﻔﻜريﰲﻫﺬه اﻷﺳﺌﻠﺔ.
وﺑﺎﻟﻨﺴﺒﺔ إﱃﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت،ﻳﻜﻤُﻦ اﻟﺘﺤﺪﱢيﰲﺗﻄﻮﻳﺮ رؤﻳﺔ واﺳﻌﺔﻟﻠﻤُﺴﺘﻘﺒﻞ
اﻟﺘﻜﻨﻮﻟﻮﺟﻲﺗﺘﻀﻤﱠﻦ أﻓﻜﺎرًاﺣﻮلﻣﺎﻫﻮﻣُﻬﻢ وﻣﺎﻫﻮ ذوﻣﻌﻨًﻰ وﻣﺎﻫﻮ ذوﻗﻴﻤﺔ.ﻋﲆ
اﻟﺮﻏﻢﻣﻦ أن اﻟﺪﻳﻤﻘﺮاﻃﻴﺎت اﻟﻠﻴﱪاﻟﻴﺔﺑﺸﻜﻞٍﻋﺎمﱟﺗﺘﻌﻤﱠﺪﺗﺠﺎﻫﻞﻣﺜﻞﻫﺬه اﻷﺳﺌﻠﺔ وﺗﺮﻛﻬﺎ
ﻟﻸﻓﺮاد، وﻻﺗﺘﺪﺧﱠﻞﰲﻣﺜﻞﻫﺬه املﻮﺿﻮﻋﺎت اﻟﻌﻤﻴﻘﺔﻣﺜﻞﻣﺎﻫﻴﺔ اﻟﺤﻴﺎة اﻟﺠﻴﺪة وﻣِﻦﺛَﻢ
ﻓﻬﻲ »ﺳﻄﺤﻴﺔ« )اﺑﺘﻜﺎرﺳﻴﺎﳼ أدﱠى إﱃﺗﺠﻨﱡﺐﺑﻌﺾ أﻧﻮاع اﻟﺤﺮوبﻋﲆ اﻷﻗﻞ وﺳﺎﻫﻢ
ﰲ اﻻﺳﺘﻘﺮار واﻻزدﻫﺎر(،ﻓﺈﻧﻪﰲﻇﻞﱢ اﻟﺘﺤﺪﱢﻳﺎت اﻷﺧﻼﻗﻴﺔ واﻟﺴﻴﺎﺳﻴﺔ اﻟﺘﻲﺗﻮاﺟِﻬﻨﺎ،ﻓﺈن
ﺗﺠﺎﻫﻞ اﻷﺳﺌﻠﺔ اﻷﺧﻼﻗﻴﺔ اﻷﻛﺜﺮ »ﻋﻤﻘًﺎ«ﻳُﻌﺘﱪﻣﻦﻗﺒﻴﻞ اﻧﻌﺪام املﺴﺌﻮﻟﻴﺔ. وﻳﻨﺒﻐﻲ أنﺗﺘﻌﻠﱠﻖ
اﻟﺴﻴﺎﺳﺔ أﻳﻀًﺎ،ﺑﻤﺎﻓﻴﻬﺎﺳﻴﺎﺳﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﺑﺎﻷﺧﻼﻗﻴﺎت اﻹﻳﺠﺎﺑﻴﺔ.
ﺑﺸﻜﻞٍﻋﺎم،ﻻﺗﺘﻌﻠﱠﻖ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﴬورةﺑﻤﻨﻊ اﻷﺷﻴﺎء؛ﺑﻞﻧﺤﻦﰲﺣﺎﺟﺔ إﱃ
أﺧﻼﻗﻴﺎت إﻳﺠﺎﺑﻴﺔ:ﻟﻮﺿﻊ رؤﻳﺔﻟﻠﺤﻴﺎة اﻟﺠﻴﺪة واملُﺠﺘﻤﻊ اﻟﺠﻴﺪ.
وﻣﻊ ذﻟﻚ،ﻓﺎﻟﺴﺒﻴﻞ إﱃ ذﻟﻚﻣﻦﻣﻨﻈﻮرﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت،ﻟﻴﺲﻣﻦﺧﻼل اﻟﻌﻤﻞ
ﺑﺸﻜﻞٍﻓﺮدي وﺗﻮﱄﱢ دور املﻠﻚ اﻟﻔﻴﻠﺴﻮفﻛﻤﺎﰲﻓﻠﺴﻔﺔ أﻓﻼﻃﻮن، وﻟﻜﻦﺑﺎﻟﻌﺜﻮرﻋﲆ
اﻟﺘﻮازن اﻟﺼﺤﻴﺢﺑني اﻟﺘﻜﻨﻮﻗﺮاﻃﻴﺔ واﻟﺪﻳﻤﻘﺮاﻃﻴﺔ اﻟﺘﺸﺎرﻛﻴﺔ. اﻷﺳﺌﻠﺔ اﻟﺘﻲﺗُﻮاﺟﻬﻨﺎﻫﻲ
أﺳﺌﻠﺔﺗُﻬﻤﻨﺎﺟﻤﻴﻌًﺎ؛ وﻋﻠﻴﻨﺎ أنﻧﺘﺸﺎركﺟﻤﻴﻌًﺎﰲ اﻹﺟﺎﺑﺔﻋﻨﻬﺎ.ﻟﺬﻟﻚ،ﻻﻳُﻤﻜﻨﻨﺎﺗﺮﻛﻬﺎﰲ
أﻳﺪيﻓﺌﺔٍﻗﻠﻴﻠﺔﻣﻦ اﻷﺷﺨﺎص،ﺳﻮاء أﻛﺎﻧﻮاﰲ اﻟﺤﻜﻮﻣﺔ أمﰲ اﻟﴩﻛﺎت اﻟﻜﺒرية. وﻳُﻌﻴﺪﻧﺎﻫﺬا
إﱃ اﻷﺳﺌﻠﺔﺣﻮلﻛﻴﻔﻴﺔ إﻧﺠﺎح اﻻﺑﺘﻜﺎر املﺴﺌﻮل واملﺸﺎرﻛﺔﰲﺳﻴﺎﺳﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
املﺸﻜﻠﺔﻻﺗﺘﻌﻠﱠﻖﻓﻘﻂﺑﺎﻟﺴﻠﻄﺔ؛ إﻧﻬﺎﺗﺘﻌﻠﱠﻖ أﻳﻀًﺎﺑﺎﻟﺨري: اﻟﺨريﻟﻸﻓﺮاد واﻟﺨريﻟﻠﻤﺠﺘﻤﻊ.
إن أﻓﻜﺎرﻧﺎ اﻟﺤﺎﻟﻴﺔﺣﻮل اﻟﺤﻴﺎة اﻟﺠﻴﺪة واملﺠﺘﻤﻊ اﻟﺠﻴﺪ — إذاﻛﻨﺎﻗﺎدِرﻳﻦﻋﲆ اﻟﺘﻌﺒري
ﻋﻨﻬﺎﻣﻦ اﻷﺳﺎس —ﻗﺪﺗﺤﺘﺎج إﱃﻧﻘﺎشٍﻧﻘﺪي أﻋﻤﻖﺑﻜﺜري. ودﻋﻮﻧﻲ أﻗﱰح أﻧﻪﻗﺪﻳﻜﻮن
ﻣﻦ املُﻔﻴﺪﻟﻠﻐﺮب،ﻋﲆ اﻷﻗﻞ أنﻳﺴﺘﻜﺸﻔﻮاﺧﻴﺎرﻣُﺤﺎوﻟﺔ اﻟﺘﻌﻠﱡﻢﻣﻦ أﻧﻈﻤﺔٍﺳﻴﺎﺳﻴﺔ أﺧﺮى
ﻏريﻏﺮﺑﻴﺔ وﺛﻘﺎﻓﺎتﺳﻴﺎﺳﻴﺔ أﺧﺮى.ﻻﻳﺠﻮزﻟﺴﻴﺎﺳﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻔﻌﱠﺎﻟﺔ واملُﱪرة
ﺗﺠﻨﱡﺐ املﺸﺎرﻛﺔﰲﻣﺜﻞﻫﺬه اﻟﻨﻘﺎﺷﺎت اﻷﺧﻼﻗﻴﺔ اﻟﻔﻠﺴﻔﻴﺔ واﻟﺴﻴﺎﺳﻴﺔ اﻟﻔﻠﺴﻔﻴﺔ.
118</p>
<p>اﻟﺘﺤﺪﻳﺎت اﻟﺘﻲﺗُﻮاﺟﻪﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت
ﺗﺪاﺧُﻞ اﻟﺘﺨﺼﱡﺼﺎت وﺗﺠﺎوز اﻟﺘﺨﺼﱡﺼﺎت
ﻫﻨﺎكﻋﻮاﺋﻖ أﺧﺮىﻳﺠﺐﺗﺠﺎوزﻫﺎ إذا أردْﻧﺎﺟﻌﻞ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻛﺜﺮ
ﻓﻌﺎﻟﻴﺔً وأردﻧﺎ دﻋﻢ اﻟﺘﻄﻮﻳﺮ املﺴﺌﻮلﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎ،ﺗﺠﻨﱡﺒًﺎ ملﺎﻳُﺴﻤﻴﻪ اﻟﺒﺎﺣﺜﻮن اﻟﺘﻘﻨﻴﻮن
»ﺷﺘﺎءَ« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺠﺪﻳﺪ: إﺑﻄﺎءﻋﻤﻠﻴﺔﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻻﺳﺘﺜﻤﺎر
ﻓﻴﻪ. أﺣﺪﻫﺬه اﻟﻌﻮاﺋﻖﻫﻮﻧﻘﺺﺗﺪاﺧُﻞ اﻟﺘﺨﺼﱡﺼﺎت وﺗﺠﺎوز اﻟﺘﺨﺼﱡﺼﺎت اﻟﻜﺎﰲ.ﻣﺎ
زﻟﻨﺎﻧﻮاﺟِﻪﻓﺠﻮةﺷﺎﺳﻌﺔﰲ اﻟﺨﻠﻔﻴﺔ واﻟﻔﻬﻢﺑني املُﺨﺘﺼﱢ نيﰲ اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ واﻟﻌﻠﻮم
اﻻﺟﺘﻤﺎﻋﻴﺔﻣﻦﺟﻬﺔ، واملُﺨﺘﺼﱢ نيﰲ اﻟﻌﻠﻮم اﻟﻄﺒﻴﻌﻴﺔ واﻟﻬﻨﺪﺳﻴﺔﻣﻦﺟﻬﺔٍ أﺧﺮى، داﺧﻞ
املُﺠﺘﻤﻊ اﻷﻛﺎدﻳﻤﻲ وﺧﺎرﺟﻪ.ﺣﺘﻰ اﻵن،ﻣﺎ زﻟﻨﺎﻧﻔﺘﻘﺪ اﻟﺪﻋﻢ املﺆﺳﱠﴘﻟﺴﺪﱢ اﻟﻔﺠﻮة اﻟﻮاﺳﻌﺔ
ﺑنيﻫﺬَﻳﻦ »اﻟﻌﺎملَني«،ﺳﻮاءﰲ املﺠﺘﻤﻊ اﻷﻛﺎدﻳﻤﻲ أوﰲ املﺠﺘﻤﻊ اﻷوﺳﻊ. وﻟﻜﻦ إذاﻛﻨﱠﺎﻧُﺮﻳﺪ
ﺣﻘٍّﺎ أنﻧﻤﺘﻠﻚﺗﻜﻨﻮﻟﻮﺟﻴﺎﻣﺘﻘﺪﻣﺔ أﺧﻼﻗﻴﺔﻣﺜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻷﺧﻼﻗﻲ،ﻓﻴﺠﺐﻋﻠﻴﻨﺎ
أنﻧُﻘﺮﱢبﺑنيﻫﺆﻻء اﻷﺷﺨﺎص وﺑنيﻫﺬَﻳﻦ اﻟﻌﺎملَني،ﰲ أﻗﺮب وﻗﺖٍﻣﻤﻜﻦ.
وﻳﺘﻄﻠﱠﺐﻫﺬا إﺣﺪاثﺗﻐﻴريﰲﻛﻴﻔﻴﺔ إﺟﺮاء اﻟﺒﺤﺚ واﻟﺘﻄﻮﻳﺮ —ﻓﻤﺜﻼً ،ﻳﺠﺐ أن
ﻳُﺸﺎركﻓﻴﻪﻟﻴﺲﻓﻘﻂ اﻷﺷﺨﺎص اﻟﺘﻘﻨﻴﻮن ورﺟﺎل اﻷﻋﻤﺎل وﻟﻜﻦ أﻳﻀًﺎﻣُﺨﺘﺼﱡﻮنﰲ
اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ — وﻛﺬﻟﻚﺗﻐﻴريﻛﻴﻔﻴﺔ »ﺗﻌﻠﻴﻢ« اﻷﺷﺨﺎص،ﻣﻦ اﻟﺸﺒﺎب وﻏريﻫﻢ.ﻳﺠﺐ
أنﻧﺤﺮصﻋﲆ أنﻳُﺪرك اﻷﺷﺨﺎص اﻟﺬﻳﻦﻟﺪَﻳﻬﻢﺧﻠﻔﻴﺔﰲ اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ أﻫﻤﻴﺔ اﻟﺘﻔﻜري
ﰲ اﻟﺘﻘﻨﻴﺎت اﻟﺠﺪﻳﺪةﻣﺜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻳُﺤﺎوﻟﻮا اﻛﺘﺴﺎبﺑﻌﺾ املﻌﺮﻓﺔﺣﻮلﻫﺬه
اﻟﺘﻘﻨﻴﺎت وﻣﺎﺗﻘﻮمﺑﻪ. وﻣﻦﻧﺎﺣﻴﺔٍ أﺧﺮى،ﻳﺠﺐﺟﻌﻞ اﻟﻌﻠﻤﺎء واملﻬﻨﺪﺳني أﻛﺜﺮﺣﺴﺎﺳﻴﺔً
ﺗﺠﺎه اﻟﺠﻮاﻧﺐ اﻷﺧﻼﻗﻴﺔ واملُﺠﺘﻤﻌﻴﺔﻟﺘﻄﻮﻳﺮ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ واﺳﺘﺨﺪاﻣِﻬﺎ. وﻣﻦﺛَﻢﻋﻨﺪﻣﺎ
ﻳﺘﻌﻠﱠﻤﻮن اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ، وﻳُﺴﺎﻫﻤﻮنﺑﻌﺪ ذﻟﻚﰲﺗﻄﻮﻳﺮﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ اﻟﺠﺪﻳﺪة،ﻓﺈﻧﻬﻢﻟﻦﻳﺮَوا اﻷﺧﻼﻗﻴﺎتﻣﻮﺿﻮﻋًﺎﻫﺎﻣﺸﻴٍّﺎﻻﻳﻤﺖﱡﺑﺼِﻠﺔٍ إﱃ
ﻣُﻤﺎرﺳﺎﺗﻬﻢ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ وﻟﻜﻦﻳﺮَوﻧﻬﺎ »ﺟﺰءًا أﺳﺎﺳﻴٍّﺎ«ﻣﻦﻫﺬه املﻤﺎرﺳﺎت. وﻋﻨﺪﺋﺬٍ،ﰲ
اﻟﺤﺎﻟﺔ املﺜﺎﻟﻴﺔ،ﺳﺘﻌﻨﻲ »ﻣﻤﺎرﺳﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ« أو »ﻣﻤﺎرﺳﺔﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت« أنﻳﺘﻢﱠ
ﺗﻀﻤني اﻷﺧﻼﻗﻴﺎتﺑﺒﺴﺎﻃﺔﺑﻮﺻﻔﻬﺎﺟﺰءًا أﺳﺎﺳﻴٍّﺎﻻﻏِﻨﻰﻋﻨﻪ.ﻋﲆﻧﻄﺎقٍ أوﺳﻊ،ﻳُﻤﻜﻨﻨﺎ
أنﻧﻔﻜﺮﰲﺷﻜﻞٍ أﻛﺜﺮﺗﻨﻮﱡﻋًﺎ وﺷﻤﻮﻟﻴﺔﻣﻦ اﻟﺘﻌﻠﻴﻢ أو اﻟﴪدﺗﺘﺪاﺧﻞﻓﻴﻪ اﻟﺘﺨﺼﱡﺼﺎت
ﺟﺬرﻳٍّﺎﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺎﻷﺳﺎﻟﻴﺐ واملﻨﺎﻫﺞ، وﺑﺎملﻮﺿﻮﻋﺎت، وأﻳﻀًﺎﺑﺎﻟﻮﺳﺎﺋﻂ واﻟﺘﻘﻨﻴﺎت.ﺑﻌﺒﺎرةٍ
أﺧﺮى أوﺿﺢ، إذاﺗﻌﻠﱠﻢَ املﻬﻨﺪﺳﻮنﻛﻴﻔﻴﺔ اﻟﻌﻤﻞﺑﺎﺳﺘﺨﺪام اﻟﻨﺼﻮص وﺗﻌﻠﻢ املُﺨﺘﺼﻮنﰲ
اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔﻛﻴﻔﻴﺔ اﻟﻌﻤﻞﺑﺎﺳﺘﺨﺪام أﺟﻬﺰة اﻟﻜﻤﺒﻴﻮﺗﺮ،ﻓﺴﻴﺰداد اﻷﻣﻞﰲ أﺧﻼﻗﻴﺎت
اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﰲﺳﻴﺎﺳﺔﺗﺼﻠﺢﻟﻠﺘﻨﻔﻴﺬﻋﻤﻠﻴٍّﺎ.
119</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻣﺨﺎﻃﺮ »ﺷﺘﺎء« اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺧﻄﺮ اﻻﺳﺘﺨﺪام اﻟﻼواﻋﻲ
ﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
،إذاﻟﻢﻳﺒﺪأﺗﻨﻔﻴﺬﻫﺬه اﻟﺘﻮﺟﻴﻬﺎتﰲ اﻟﺴﻴﺎﺳﺔ واﻟﺘﻌﻠﻴﻢﻋﲆ أرض اﻟﻮاﻗﻊ، وﺑﺸﻜﻞٍﻋﺎم
إذاﻓﺸﻞﻣﴩوع اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻷﺧﻼﻗﻲ،ﻓﺈﻧﻨﺎﻟﻦﻧُﻮاﺟِﻪﻓﻘﻂﻣﺨﺎﻃﺮ »ﺷﺘﺎء«
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؛ﺑﻞ إن اﻟﺨﻄﺮ اﻷدﻫﻰ واﻷﻣَﺮﱠﺳﻴﻜﻤﻦﰲ اﻟﻜﺎرﺛﺔ اﻷﺧﻼﻗﻴﺔ واﻻﺟﺘﻤﺎﻋﻴﺔ
واﻻﻗﺘﺼﺎدﻳﺔ اﻟﺘﻲﺳﺘُﻠﻢﱡﺑﻨﺎ وﺳﻴﺪﻓﻊﺛﻤﻨﻬﺎ اﻟﺒﴩ وﻏري اﻟﺒﴩ واﻟﺒﻴﺌﺔ.ﻫﺬاﻻﻳﺘﻌﻠﻖﺑﺎﻟﺘﻔﺮد
اﻟﺘﻜﻨﻮﻟﻮﺟﻲ، أوﺑﺎﻵﻻت اﻟﺘﻲﺳﺘﺪﻣﺮ اﻟﻌﺎﻟﻢ، أوﺑﺴﻴﻨﺎرﻳﻮﻫﺎتﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢ اﻷﺧﺮىﺣﻮل
املﺴﺘﻘﺒﻞ اﻟﺒﻌﻴﺪ، وﻟﻜﻨﻪﻳﺘﻌﻠﻖﺑﺎﻟﺰﻳﺎدة اﻟﺒﻄﻴﺌﺔ وﻟﻜﻦ املﺆﻛﺪةﰲﺗﺮاﻛﻢ املﺨﺎﻃﺮ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ
وﻣﺎﻳﻨﺠﻢﻋﻨﻬﺎﻣﻦﺗﻔﺎﻗﻢ اﻟﻀﻌﻒ اﻟﺒﴩي واﻻﺟﺘﻤﺎﻋﻲ واﻻﻗﺘﺼﺎدي واﻟﺒﻴﺌﻲ.ﻫﺬه اﻟﺰﻳﺎدة
ﰲ املﺨﺎﻃﺮ واﻟﻀﻌﻒﻣﺮﺗﺒﻄﺔﺑﺎملﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ املﺸﺎر إﻟﻴﻬﺎﻫﻨﺎ وﰲ اﻟﻔﺼﻮل اﻟﺴﺎﺑﻘﺔ،
ﺑﻤﺎﻓﻴﻬﺎ اﻻﺳﺘﺨﺪام اﻟﺠﺎﻫﻞ واملﺘﻬﻮرﻟﺘﻘﻨﻴﺎت اﻷﺗﻤﺘﺔ املُﺘﻘﺪﱢﻣﺔﻣﺜﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
إن اﻟﻔﺠﻮةﰲ اﻟﺘﻌﻠﻴﻢ رﺑﻤﺎﺗﺰﻳﺪﻣﻦﺗﺄﺛريﻣﺨﺎﻃﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺸﻜﻞٍﻋﺎم:ﺣﺘﻰ
ﻟﻮﻟﻢﺗﺘﺴﺒﱠﺐ داﺋﻤًﺎﰲﻣﺨﺎﻃﺮﺟﺪﻳﺪةﻣﺒﺎﴍة،ﻓﺈﻧﻬﺎﺗُﻀﺎﻋﻒ املﺨﺎﻃﺮ املﻮﺟﻮدةﺑﺎﻟﻔﻌﻞ
ﻋﲆﻧﺤﻮٍ اﺳﺘﺜﻨﺎﺋﻲ.ﺣﺘﻰ اﻵن،ﻻﻳُﻮﺟَﺪﻣﺎﻳُﺴﻤﻰ »رﺧﺼﺔﻗﻴﺎدة«ﻻﺳﺘﺨﺪام اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ، وﻻﻳُﻮﺟَﺪﺗﻌﻠﻴﻢ إﻟﺰاﻣﻲﻷﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻠﺒﺎﺣﺜني اﻟﺘﻘﻨﻴﱢني،
ورﺟﺎل اﻷﻋﻤﺎل، وﻣﺴﺌﻮﱄ اﻟﺤﻜﻮﻣﺔ وﻏريﻫﻢﻣﻦ اﻷﺷﺨﺎص املﺸﺎرﻛنيﰲ اﺑﺘﻜﺎر اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ واﺳﺘﺨﺪاﻣﻪ وﺳﻴﺎﺳﺎﺗﻪ.ﻫﻨﺎك اﻟﻜﺜريﻣﻦ آﻻت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻏري املُﺮوﱠﺿﺔ
ﻻﻳﻌﺮﻓﻮن املﺨﺎﻃﺮ واملﺸﻜﻼت اﻷﺧﻼﻗﻴﺔ املُﺮﺗﺒﻄﺔﺑﻬﺎ، أو اﻟﺬﻳﻦﻗﺪﺗﻜﻮن
ﰲ أﻳﺪي أﺷﺨﺎصٍ
ﻟﺪﻳﻬﻢﺗﻮﻗﻌﺎتﺧﻄﺄﺑﺸﺄن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ. وﻳﻜﻤﻦ اﻟﺨﻄﺮ،ﻣﺮة أﺧﺮى،ﰲﻣﻤﺎرﺳﺔ اﻟﺴﻠﻄﺔ
دونﻣﻌﺮﻓﺔ و)ﺑﺎﻟﺘﺎﱄ( دونﻣﺴﺌﻮﻟﻴﺔ؛ واﻷﺳﻮأﻣﻦ ذﻟﻚ أنﻳﺨﻀﻊ اﻵﺧﺮون إﱃﻫﺬه
اﻟﺴﻠﻄﺔ. وإذاﻛﺎنﻫﻨﺎكﴍﱞﻋﲆ اﻹﻃﻼق،ﻓﺈﻧﻪﻳُﻘﻴﻢﺣﻴﺜﻤﺎﻗﺎﻟﺖﻓﻴﻠﺴﻮﻓﺔ اﻟﻘﺮن اﻟﻌﴩﻳﻦ
ﺣﻨﺔ آرﻧﺖ:ﰲﻏﻴﺎب اﻟﻮﻋﻲﻋﻦ اﻟﻘﺮارات واﻟﻌﻤﻞ اﻟﻴﻮﻣﻲ املُﻤﻞ. وﻋﻨﺪﻣﺎﻳُﻔﱰَض أن اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻏريﻣُﺘﺤﻴﺰ وﻳُﺴﺘﺨﺪَم دونﻓَﻬﻢ ملﺎﻳﺘﻢ اﻟﻘﻴﺎمﺑﻪ،ﻓﺈنﻫﺬاﻣﻦﺷﺄﻧﻪ أنﻳُﺴﻬﻢ
ﰲﺗﻌﻤﻴﻖﻏﻴﺎب اﻟﻮﻋﻲ،ﺛﻢﰲ اﻟﻨﻬﺎﻳﺔ،ﰲ اﻟﻔﺴﺎد اﻷﺧﻼﻗﻲﻟﻠﻌﺎﻟﻢ. وﺗﺴﺘﻄﻴﻊﺳﻴﺎﺳﺎت
اﻟﺘﻌﻠﻴﻢ املﺴﺎﻋَﺪةﰲ اﻟﺘﺨﻔﻴﻒﻣﻦ ذﻟﻚ وﺑﺎﻟﺘﺎﱄ املﺴﺎﻫﻤﺔﰲﺟﻌﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺟﻴﺪًا
وذاﻣﻌﻨًﻰ.
ﻻﺗﺰالﻫﻨﺎك اﻟﻌﺪﻳﺪﻣﻦ اﻷﺳﺌﻠﺔ املُﺰﻋﺠﺔ، ورﺑﻤﺎ املﺆﻟِﻤﺔ إﱃﺣﺪﱟﻣﺎ، اﻟﺘﻲﻏﺎﻟﺒًﺎﻣﺎﻳﺘﻢ
ﺗﺠﺎﻫﻠﻬﺎﰲ املﻨﺎﻗﺸﺎت اﻟﺘﻲﺗﺪورﺣﻮل أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺳﻴﺎﺳﺎﺗﻪ، وﻟﻜﻨﻬﺎ
120</p>
<p>اﻟﺘﺤﺪﻳﺎت اﻟﺘﻲﺗُﻮاﺟﻪﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت
ﺗﺴﺘﺤﻖﱡﻣﻨﱠﺎﻋﲆ اﻷﻗﻞ أنﻧﺬﻛُﺮﻫﺎﻫﻨﺎ،ﺣﺘﻰ وإنﻟﻢﻧُﺤﻠﻠﻬﺎﺗﺤﻠﻴﻼًﻛﺎﻣﻼً .ﻫﻞ أﺧﻼﻗﻴﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺘﻌﻠﱠﻖﻓﻘﻂﺑﺨري اﻟﺒﴩ وﻗﻴﻤﺘﻬﻢ، أم إنﻋﻠﻴﻨﺎ أنﻧﺮاﻋﻲ أﻳﻀًﺎﻗِﻴَﻢﻏري
اﻟﺒﴩ وﺧريﻫﻢ وﻣﺼﺎﻟﺤﻬﻢ؟ وﺣﺘﻰ إذاﻛﺎﻧﺖ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺗﺘﻌﻠﻖﺑﺸﻜﻞ
رﺋﻴﴘﺑﺎﻟﺒﴩ،ﻓﻬﻞﻳﻤﻜﻦ أنﺗﻜﻮن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺴﺖﺑﺎملﺴﺄﻟﺔ اﻷﻫﻢ
اﻟﺘﻲﻳﺘﻌنيﱠﻋﲆ اﻟﺒﴩﻳﺔ اﻻﻫﺘﻤﺎمﺑﻬﺎ؟ﻳﻘﻮدﻧﺎﻫﺬا اﻟﺴﺆال إﱃ اﻟﻔﺼﻞ اﻷﺧريﻣﻦ اﻟﻜﺘﺎب.
121</p>
</section>
<section id="section-13">
    <h2>١٢ - تحدِّي تغيّر المناخ: حول الأولويات وحقبة التأثير البشري</h2>
    <div class="page-range">Pages 123-134</div>
    <p>اﻟﻔﺼﻞ اﻟﺜﺎﻧﻲﻋﴩ
ﲢﺪﱢ يﺗﻐﲑﱡ اﳌﻨﺎخ:ﺣﻮل اﻷوﻟﻮﻳﺎت
وﺣﻘﺒﺔ اﻟﺘﺄﺛﲑ اﻟﺒﴩي
ﻫﻞﻳﺠِﺐ أنﺗﻜﻮن أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺤﻮرﻫﺎ اﻹﻧﺴﺎن؟
ﻋﲆ اﻟﺮﻏﻢﻣﻦ أن اﻟﻌﺪﻳﺪﻣﻦ املﺆﻟﱠﻔﺎت املُﺘﻌﻠﻘﺔﺑﺄﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺴﻴﺎﺳﺎت
ﺗﺄﺗﻲﻋﲆ ذِﻛﺮ اﻟﺒﻴﺌﺔ أو اﻟﺘﻨﻤﻴﺔ املُﺴﺘﺪاﻣﺔ،ﻓﺈﻧﻬﺎﺗﺆﻛﱢﺪﻋﲆ اﻟﻘِﻴَﻢ اﻹﻧﺴﺎﻧﻴﺔ وﻏﺎﻟﺒًﺎﻣﺎ
ﺗﺘﻤﺤﻮَرﺣﻮل اﻹﻧﺴﺎنﺑﻮﺿﻮح.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﺗﻘﻮل اﻹرﺷﺎدات اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲ وﺿﻌﻬﺎ
ﻓﺮﻳﻖ اﻟﺨﱪاء اﻟﺮﻓﻴﻊ املُﺴﺘﻮى املﻌﻨﻲﱢﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إﻧﻪﻳﺠﺐﺗﺒﻨﱢﻲﻧﻬﺞٍﻣﺘﻤﺤﻮر
ﺣﻮل اﻹﻧﺴﺎنﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ »ﻳﺘﻤﺘﻊﻓﻴﻪ اﻹﻧﺴﺎنﺑﻤﻜﺎﻧﺔٍ أﺧﻼﻗﻴﺔﻓﺮﻳﺪة وراﺳﺨﺔ
European) «ﻟﻬﺎ أوﻟﻮﻳﺔﻋﲆﺟﻤﻴﻊ اﻷﺻﻌﺪة املﺪﻧﻴﺔ واﻟﺴﻴﺎﺳﻴﺔ واﻻﻗﺘﺼﺎدﻳﺔ واﻻﺟﺘﻤﺎﻋﻴﺔ
( وﻗﺪﺻﺎﻏﺖ اﻟﺠﺎﻣﻌﺎتﻣﺜﻞﺳﺘﺎﻧﻔﻮرد وﻣﻌﻬﺪCommission AI HLEG 2019, 10
ﻣﺎﺳﺎﺗﺸﻮﺳﺘﺲﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎﺳﻴﺎﺳﺎتﺑﺤﺜﻬﺎﰲﺳﻴﺎق اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺘﻤﺤﻮرﺣﻮل
1.اﻹﻧﺴﺎن
ﻏﺎﻟﺒًﺎﻣﺎﻳﺘﻢﺗﻌﺮﻳﻒﻫﺬا اﻟﺘﻤﺤﻮُرﺣﻮل اﻹﻧﺴﺎنﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﺑﺈﻋﻄﺎء
اﻷوﻟﻮﻳﺔﻟﺨري اﻹﻧﺴﺎن وﻛﺮاﻣﺘﻪﻋﲆﺣﺴﺎبﻣﺎﻗﺪﺗﺘﻄﻠﱠﺒﻪ أوﺗﻔﻌﻠﻪ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ.
ﻓﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻳﺠﺐ أنﺗﻌﻮدﺑﺎﻟﻔﺎﺋﺪةﻋﲆ اﻟﺒﴩ وأنﺗﺨﺪﻣﻬﻢ وﻟﻴﺲ اﻟﻌﻜﺲ. وﻣﻊ
ذﻟﻚ، وﻛﻤﺎ رأﻳﻨﺎﰲ اﻟﻔﺼﻮل اﻷوﱃ،ﻓﺈنﻣﺪىﻣﻨﺎﺳﺒﺔﻫﺬا اﻟﱰﻛﻴﺰﻋﲆ اﻹﻧﺴﺎنﰲ أﺧﻼﻗﻴﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺲ واﺿﺤًﺎﻛﻤﺎﻗﺪﻳﺒﺪوﻟﻠﻮﻫﻠﺔ اﻷوﱃ، وﻻﺳﻴﱠﻤﺎ إذا أﺧﺬﻧﺎﰲ اﻻﻋﺘﺒﺎر
املﻨﺎﻫﺞ املﺆﻳﺪةﻟﺘﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ أوﴎدﻳﺎت املﻨﺎﻓﺴﺔ )ﻣﺎﺑني اﻹﻧﺴﺎن واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ(.
وﺗﺒنيﻓﻠﺴﻔﺔ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ أنﻫﻨﺎك املﺰﻳﺪﻣﻦ اﻟﻄﺮق — اﻷﻛﺜﺮ دﻗﺔً وﺗﻌﻘﻴﺪًا —ﻟﺘﺤﺪﻳﺪ
اﻟﻌﻼﻗﺔﺑني اﻟﺒﴩ واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻳُﻌﺪ اﻟﻨﻬﺞ املُﺘﻤﺤﻮرﺣﻮل اﻹﻧﺴﺎنﻏري</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
واﺿﺢﻋﲆ أﻗﻞﺗﻘﺪﻳﺮ، إنﻟﻢﻳﻜُﻦﻣُﺜريًاﻟﻠﻤﺸﻜﻼت،ﰲﺿﻮء املﻨﺎﻗﺸﺎت اﻟﻔﻠﺴﻔﻴﺔﺣﻮل
اﻟﺒﻴﺌﺔ واﻟﻜﺎﺋﻨﺎت اﻟﺤﻴﺔ اﻷﺧﺮى.ﰲﻓﻠﺴﻔﺔ اﻟﺒﻴﺌﺔ وأﺧﻼﻗﻴﺎﺗﻬﺎ،ﻫﻨﺎكﻧﻘﺎشﻃﻮﻳﻞﺣﻮل
ﻗﻴﻤﺔﻏري اﻟﺒﴩ،ﺧﺎﺻﺔ اﻟﻜﺎﺋﻨﺎت اﻟﺤﻴﺔ، وﺣﻮلﻛﻴﻔﻴﺔ اﺣﱰامﺗﻠﻚ اﻟﻘﻴﻤﺔ وﻫﺬه اﻟﻜﺎﺋﻨﺎت،
وﺣﻮل املﺸﻜﻼت املُﺤﺘﻤﻠﺔ اﻟﺘﻲﻗﺪﺗﻨﺸﺄﻧﺘﻴﺠﺔ اﺣﱰامﻗﻴﻤﺔ اﻟﺒﴩ. وﻓﻴﻤﺎﻳﺨﺺﱡ أﺧﻼﻗﻴﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﺈنﻫﺬاﻳﻌﻨﻲ أنﻋﻠﻴﻨﺎﻋﲆ اﻷﻗﻞﻃﺮح اﻟﺴﺆالﺑﺸﺄنﺗﺄﺛري اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻋﲆ اﻟﻜﺎﺋﻨﺎت اﻟﺤﻴﺔ اﻷﺧﺮى واﻟﻨﻈﺮﰲ اﺣﺘﻤﺎﻟﻴﺔ وﺟﻮدﺗﻌﺎرُضﺑنيﻗِﻴَﻢ
وﻣﺼﺎﻟﺢ اﻟﺒﴩ وﻏري اﻟﺒﴩ.
ﺗﺤﺪﻳﺪ اﻷوﻟﻮﻳﺎتﻋﲆ اﻟﻨﺤﻮ اﻟﺼﺤﻴﺢ
ﻳﻤﻜﻦ أﻳﻀًﺎ اﻟﻘﻮلﺑﻮﺟﻮدﻣﺸﻜﻼت أﺧﺮى أﻛﺜﺮﺧﻄﻮرةﻣﻦﺗﻠﻚ اﻟﺘﻲﻳُﺴﺒﺒﻬﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ، وأﻧﻪﻣﻦ املُﻬﻢﺗﺤﺪﻳﺪ أوﻟﻮﻳﺎﺗﻨﺎﺑﺸﻜﻞٍﺻﺤﻴﺢ. وﻗﺪﻳﻨﺸﺄﻫﺬا اﻻﻋﱰاضﻣﻦ
اﻟﻨﻈﺮ إﱃ املﺸﻜﻼت اﻟﻌﺎملﻴﺔﻣﺜﻞﺗﻐريﱡ املﻨﺎخ، اﻟﺘﻲﺗُﻌﺪ وﻓﻘًﺎﻟﻠﺒﻌﺾ املﺸﻜﻠﺔ اﻷﻫﻢ اﻟﺘﻲ
ﺗﺤﺘﺎج اﻟﺒﴩﻳﺔ إﱃ اﻟﺘﺼﺪﱢيﻟﻬﺎ وإﻳﻼﺋﻬﺎ اﻷوﻟﻮﻳﺔﻧﻈﺮًا إﱃﺧﻄﻮرﺗﻬﺎ وﺗﺄﺛريﻫﺎ املُﺤﺘﻤَﻞﻋﲆ
اﻟﻜﻮﻛﺐﻛﻼٍّ .
ﻳُﻌَﺪ اﻟﻨﻬﺞ املُﺘﻤﺤﻮرﺣﻮل اﻹﻧﺴﺎنﻏري واﺿﺢٍﻋﲆ أﻗﻞﺗﻘﺪﻳﺮ، إنﻟﻢﻳﻜُﻦﻣُﺜريًاﻟﻠﻤﺸﻜﻼت،ﰲﺿﻮء
املﻨﺎﻗﺸﺎت اﻟﻔﻠﺴﻔﻴﺔﺣﻮل اﻟﺒﻴﺌﺔ واﻟﻜﺎﺋﻨﺎت اﻟﺤﻴﺔ اﻷﺧﺮى.
ﺑﺎﻟﻨﻈﺮ إﱃﺟﺪول أﻋﻤﺎل اﻷﻣﻢ املﺘﺤﺪةﻟﻠﺘﻨﻤﻴﺔ املُﺴﺘﺪاﻣﺔﻟﻌﺎم ٥١٠٢ )اﻟﺬيﻳﻄﻠﻖ
وﻧﻈﺮﺗﻪ اﻟﻌﺎﻣﺔ إﱃ اﻟﻘﻀﺎﻳﺎ اﻟﻌﺎملﻴﺔ املﺘﻌﻠﻘﺔﺑﻤﺎ وﺻﻔﻪ2(ﻋﻠﻴﻪ أﻫﺪاف اﻟﺘﻨﻤﻴﺔ املُﺴﺘﺪاﻣﺔ
ﻣﻮن »اﻹﻧﺴﺎن واﻟﻜﻮﻛﺐ«،ﻧﺮى اﻟﻌﺪﻳﺪﻣﻦ اﻟﻘﻀﺎﻳﺎ-اﻷﻣني اﻟﻌﺎمﻟﻸﻣﻢ املﺘﺤﺪةﺑﺎنﻛﻲ
اﻟﻌﺎملﻴﺔ اﻟﺘﻲﺗﺘﻄﻠﱠﺐﻳﻘﻈﺔ أﺧﻼﻗﻴﺔ وﺳﻴﺎﺳﻴﺔ: اﻟﺘﻔﺎوت اﻻﺟﺘﻤﺎﻋﻲ املُﺘﺰاﻳﺪ داﺧﻞ اﻟﺒﻠﺪان
وﻓﻴﻤﺎﺑﻴﻨﻬﺎ، واﻟﺤﺮوب واﻟﺘﻄﺮﱡف اﻟﻌﻨﻴﻒ، واﻟﻔﻘﺮ وﺳﻮء اﻟﺘﻐﺬﻳﺔ، وﺻﻌﻮﺑﺔ اﻟﻮﺻﻮل إﱃ
املﻴﺎه اﻟﻌﺬﺑﺔ، وﻧﻘﺺ املﺆﺳﺴﺎت اﻟﻔﻌﺎﻟﺔ واﻟﺪﻳﻤﻘﺮاﻃﻴﺔ، وزﻳﺎدةﻧِﺴﺒﺔ اﻟﺴﻜﺎن املُﺘﻘﺪﱢﻣني
ﰲ اﻟﺴﻦ، واﻷﻣﺮاض املُﻌﺪﻳﺔ واﻟﻮﺑﺎﺋﻴﺔ، وﻣﺨﺎﻃﺮ اﻟﻄﺎﻗﺔ اﻟﻨﻮوﻳﺔ، وﻧﻘﺺ اﻟﻔﺮصﻟﻸﻃﻔﺎل
واﻟﺸﺒﺎب، وﻋﺪم املﺴﺎواةﺑني اﻟﺠﻨﺴَ ني وأﺷﻜﺎل اﻟﺘﻤﻴﻴﺰ واﻹﻗﺼﺎء املُﺨﺘﻠﻔﺔ، واﻷزﻣﺎت
اﻹﻧﺴﺎﻧﻴﺔ وﺟﻤﻴﻊ أﻧﻮاع اﻧﺘﻬﺎﻛﺎتﺣﻘﻮق اﻹﻧﺴﺎن، واملُﺸﻜﻼت املﺘﻌﻠﻘﺔﺑﺎﻟﻬﺠﺮة واﻟﻼﺟﺌني،
124</p>
<p>ﺗﺤﺪﱢيﺗﻐريﱡ املﻨﺎخ:ﺣﻮل اﻷوﻟﻮﻳﺎت وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي
وﺗﻐريﱡ املﻨﺎخ واملﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ — اﻟﺘﻲﺗﺘﻌﻠﱠﻖﰲﺑﻌﺾ اﻷﺣﻴﺎنﺑﺘﻐريﱡ املﻨﺎخ —ﻣﺜﻞ
اﻟﻜﻮارث اﻟﻄﺒﻴﻌﻴﺔ املُﺘﻜﺮﱢرة واملُﺘﻔﺎﻗﻤﺔ وأﺷﻜﺎلﺗﺪﻫﻮر اﻟﺒﻴﺌﺔﻣﺜﻞ اﻟﺠﻔﺎف وﻓﻘﺪان اﻟﺘﻨﻮع
اﻟﺒﻴﻮﻟﻮﺟﻲ.ﰲﺿﻮءﻫﺬه املﺸﻜﻼت اﻟﻀﺨﻤﺔ،ﻫﻞﻳﺠﺐ أنﻧﻌﺘﱪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
أوﻟﻮﻳﺘﻨﺎ اﻷوﱃ؟ وﻫﻞﻳُﺸﺘﱢﺖ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻧﺘﺒﺎﻫﻨﺎﻋﻦﻗﻀﺎﻳﺎ أﻛﺜﺮ أﻫﻤﻴﺔ؟
ﻣﻦﺟﻬﺔ،ﻳﺒﺪو أن اﻟﱰﻛﻴﺰﻋﲆ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻏريهﻣﻦ املﺸﻜﻼت اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ
ﰲﻏريﻣﺤﻠﱢﻪﻋﻨﺪﻣﺎﻳُﻌﺎﻧﻲﻋﺪدﻫﺎﺋﻞﻣﻦ اﻟﺒﴩ وﻳُﻌﺎﻧﻲ اﻟﻌﺎﻟﻢﺑﺄﴎهﻣﻦﻣﺸﻜﻼتٍ أﺧﺮى
ﻛﺜريةﻟﻠﻐﺎﻳﺔ.ﻓﻔﻲﺣني أن اﻟﻨﺎسﰲ أﺣﺪ أﻧﺤﺎء اﻟﻌﺎﻟﻢﻳُﻜﺎﻓﺤﻮنﻣﻦ أﺟﻞ اﻟﻮﺻﻮل إﱃ املﻴﺎه
اﻟﻌﺬﺑﺔ أوﻣﻦ أﺟﻞ اﻟﺒﻘﺎءﻋﲆﻗﻴﺪ اﻟﺤﻴﺎةﰲﺑﻴﺌﺎتٍﻋﻨﻴﻔﺔ،ﻳﻘﻠﻖ آﺧﺮونﰲﺟﺰءٍ آﺧﺮﻣﻦ
اﻟﻌﺎﻟَﻢﺑﺸﺄنﺧﺼﻮﺻﻴﺘﻬﻢﻋﲆ اﻹﻧﱰﻧﺖ وﻳﺘﺨﻴﱠﻠﻮنﻣُﺴﺘﻘﺒﻼًﻳُﺤﻘﻖﻓﻴﻪ اﻟﺬﻛﺎءُ اﻻﺻﻄﻨﺎﻋﻲ
اﻟﺬﻛﺎءَ اﻟﻔﺎﺋﻖ.ﻣﻦ اﻟﻨﺎﺣﻴﺔ اﻷﺧﻼﻗﻴﺔ،ﻳﺒﺪو أنﺷﻴﺌًﺎﻣُﺮﻳﺒًﺎﻳﺤﺪث،ﺷﻴﺌًﺎﻳﺘﻌﻠﻖﺑﺎﻟﺘﻔﺎوُت
اﻷﺧﻼق واﻟﺴﻴﺎﺳﺎت اﻟﻄﺮفَﻋﻦﻣﺜﻞﻫﺬه
اﻻﺟﺘﻤﺎﻋﻲ واﻟﻈﻠﻢ اﻟﻌﺎﻟَﻤﻴﱠني.ﻳﺠﺐ أﻻﺗﻐﺾﱠ
املﺸﻜﻼت، اﻟﺘﻲﻻﺗﺘﻌﻠﱠﻖﺑﺎﻟﴬورةﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻋﲆ اﻹﻃﻼق.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﰲ
اﻟﺒﻠﺪان اﻟﻨﺎﻣﻴﺔ،ﻳُﻤﻜﻦ أﺣﻴﺎﻧًﺎﻟﻠﺘﻜﻨﻮﻟﻮﺟﻴﺎ املُﻨﺨﻔﻀﺔ اﻟﺘﻜﻠﻔﺔ — وﻟﻴﺲ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ املُﺘﻘﺪﻣﺔ
— املﺴﺎﻋﺪةﰲﺣﻞﱢﻣُﺸﻜﻼت اﻟﻨﺎس؛ﻷﻧﻬﻢﻳﺴﺘﻄﻴﻌﻮن أنﻳﺘﺤﻤﱠﻠﻮاﺗﻜﺎﻟﻴﻔﻬﺎ وﻳﺴﺘﻄﻴﻌﻮن
ﺗﺮﻛﻴﺒﻬﺎ وﺻﻴﺎﻧﺘﻬﺎ.
ﻣﻦﺟﻬﺔ أﺧﺮى،ﻳﻤﻜﻦ أنﻳُﺴﺒﺐ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺸﻜﻼتٍﺟﺪﻳﺪة وأﻳﻀًﺎﻳﻌﻤﻞ
ﻋﲆﺗﻔﺎﻗُﻢ املﺸﻜﻼت اﻟﻘﺎﺋﻤﺔﺑﺎﻟﻔﻌﻞﰲ املُﺠﺘﻤﻌﺎت وﰲ اﻟﺒﻴﺌﺔ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﺨﴙ
اﻟﺒﻌﺾ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺳﻴﻮﺳﻊ اﻟﻔﺠﻮةﺑني اﻷﻏﻨﻴﺎء واﻟﻔﻘﺮاء، وأﻧﻪ،ﻣﺜﻞ اﻟﻌﺪﻳﺪ
ﻣﻦ اﻟﺘﻘﻨﻴﺎت اﻟﺮﻗﻤﻴﺔ،ﺳﻴﺰﻳﺪﻣﻦ اﺳﺘﻬﻼك اﻟﻄﺎﻗﺔ، وﻳﺨﻠﻖﻣﺰﻳﺪًاﻣﻦ اﻟﻨﻔﺎﻳﺎت.ﻣﻦﻫﺬا
املﻨﻈﻮر،ﻓﺈنﻣﻨﺎﻗﺸﺔ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺘﻌﺎﻣُﻞﻣﻌﻬﺎﻟﻴﺲﺗﺸﺘﻴﺘًﺎﻟﻼﻧﺘﺒﺎه
وﻟﻜﻨﻪ إﺣﺪى اﻟﻄﺮق اﻟﺘﻲﻳُﻤﻜﻨﻨﺎﻣﻦﺧﻼﻟﻬﺎ املﺴﺎﻫﻤﺔﰲﻣﻌﺎﻟﺠﺔﻣﺸﻜﻼت اﻟﻌﺎﻟﻢ،ﺑﻤﺎ
ﻓﻴﻬﺎ املﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ. وﻣﻦﺛَﻢ،ﻳُﻤﻜﻨﻨﺎ أنﻧﺴﺘﺨﻠﺺ أﻧﻨﺎﺑﺤﺎﺟﺔٍ أﻳﻀًﺎ إﱃ إﻳﻼء اﻻﻫﺘﻤﺎم
ﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ:ﻧﻌﻢ، اﻟﻔﻘﺮ واﻟﺤﺮوب وﻣﺎ إﱃ ذﻟﻚﻫﻲﻣﺸﻜﻼتﺧﻄرية، وﻟﻜﻦ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻳُﻤﻜﻦ أﻳﻀًﺎ أنﻳﺆدﱢي إﱃ — أوﻳُﺴﺎﻋﺪﻋﲆ —ﺗﻔﺎﻗﻢﻣﺸﻜﻼتﺧﻄرية اﻵن وﰲ
املُﺴﺘﻘﺒﻞ، وﻳﺠﺐ أنﻳﻜﻮنﰲﻗﺎﺋﻤﺔ املﺸﻜﻼت اﻟﺘﻲﺗﺤﺘﺎجﻣﻨﺎ إﱃ إﻳﺠﺎد اﻟﺤﻠﻮل. وﻣﻊ ذﻟﻚ،
ﻓﻬﺬاﻻﻳُﺠﻴﺒﻨﺎﻋﻦ اﻟﺴﺆال املﺘﻌﻠﻖﺑﺎﻷوﻟﻮﻳﺎت؛ وﻫﻮﺳﺆالﻣُﻬﻢﻋﲆﻣﺴﺘﻮى اﻷﺧﻼﻗﻴﺎت
واﻟﺴﻴﺎﺳﺔﻋﲆﺣﺪﱟﺳﻮاء. إن اﻟﻘﻀﻴﺔﻻﺗﺘﻤﺜﻞﰲ وﺟﻮد إﺟﺎﺑﺎتﺳﻬﻠﺔﻋﻦ ذﻟﻚ اﻟﺴﺆال؛ﺑﻞ
اﻟﻘﻀﻴﺔﻫﻲ أنﻫﺬا اﻟﺴﺆالﻻﻳُﻄﺮَحﺣﺘﻰﰲﻣﻌﻈﻢ املﺆﻟﱠﻔﺎت اﻷﻛﺎدﻳﻤﻴﺔ ووﺛﺎﺋﻖ اﻟﺴﻴﺎﺳﺎت
ﺣﻮل اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
125</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻓﻔﻲﺣني أن اﻟﻨﺎسﰲ أﺣﺪ أﻧﺤﺎء اﻟﻌﺎﻟﻢﻳُﻜﺎﻓﺤﻮنﻣﻦ أﺟﻞ اﻟﻮﺻﻮل إﱃ املﻴﺎه اﻟﻌﺬﺑﺔ أوﻣﻦ أﺟﻞ
اﻟﺒﻘﺎءﻋﲆﻗﻴﺪ اﻟﺤﻴﺎةﰲﺑﻴﺌﺎتٍﻋﻨﻴﻔﺔ،ﻳﻘﻠﻖ آﺧﺮونﰲﺟﺰء آﺧَﺮﻣﻦ اﻟﻌﺎﻟﻢﺑﺸﺄنﺧﺼﻮﺻﻴﺘﻬﻢﻋﲆ
اﻹﻧﱰﻧﺖ.
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺗﻐريﱡ املﻨﺎخ وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي
إﺣﺪى أﺻﻌﺐ اﻟﻄﺮقﻟﻄﺮح اﻟﺴﺆال املُﺘﻌﻠﻖﺑﺎﻷوﻟﻮﻳﺎتﻫﻮ اﻟﺘﻌﺮﱡض ملﻨﺎﻗﺸﺔﻣﺴﺄﻟﺔﺗﻐريﱡ
املﻨﺎخ واملﻮﺿﻮﻋﺎت ذات اﻟﺼﻠﺔﻣﺜﻞﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي: »ملﺎذاﻧﻘﻠﻖﺑﺸﺄن اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ إذاﻛﺎﻧﺖ املﺸﻜﻠﺔ املﻠﺤﱠﺔﻫﻲﺗﻐريﱡ املﻨﺎخ وﻛﻮنﻣُﺴﺘﻘﺒﻞ اﻟﻜﻮﻛﺐﰲﺧﻄﺮ؟«
أو دﻋﻮﻧﺎﻧﺴﺘﻌريﻋﺒﺎرةًﻣﻦ اﻟﺜﻘﺎﻓﺔ اﻟﺴﻴﺎﺳﻴﺔ اﻷﻣﺮﻳﻜﻴﺔ: »إﻧﻪ املﻨﺎخ، أﻳﻬﺎ اﻟﻐﺒﻲ!« وﺳﻮف
أوﺿﱢﺢﻫﻨﺎﻫﺬا اﻟﺘﺤﺪﱢي وأﻧﺎﻗﺶﺗﺪاﻋِﻴﺎﺗﻪﻋﲆ اﻟﺘﻔﻜريﰲ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
ﰲﺣنيﻳﺮﻓﺾﺑﻌﺾ املﺘﻄﺮﱢﻓني اﻟﻨﺘﺎﺋﺞ اﻟﻌﻠﻤﻴﺔ،ﻳُﻘﺮ اﻟﻌﻠﻤﺎء وﺻﺎﻧﻌﻮ اﻟﺴﻴﺎﺳﺎت
ﻋﲆﻧﻄﺎقٍ واﺳﻊﺑﺄنﺗﻐريﱡ املﻨﺎخﻟﻴﺲﻓﻘﻂﻣﺸﻜﻠﺔًﻋﺎملﻴﺔﺧﻄرية وﻟﻜﻨﻪ أﻳﻀًﺎ »أﺣﺪ أﻛﱪ
أﻫﺪاف اﻟﺘﻨﻤﻴﺔ املُﺴﺘﺪاﻣﺔﻟﻸﻣﻢ املﺘﺤﺪة.
اﻟﺘﺤﺪﱢﻳﺎتﰲﻋﴫﻧﺎ«،ﻛﻤﺎﻫﻮﻣﺬﻛﻮرﰲﻧﺺﱢ
وﻫﻮﻟﻴﺲﻣﺸﻜﻠﺔًﻣُﺴﺘﻘﺒﻠﻴﺔ:ﻓﺪرﺟﺔ اﻟﺤﺮارة اﻟﻌﺎملﻴﺔ وﻣﺴﺘﻮﻳﺎت اﻟﺒﺤﺮﺗﺮﺗﻔﻊﺑﺎﻟﻔﻌﻞ،
ﻣﻤﺎﻳﺆﺛﺮﻋﲆ اﻟﺒﻠﺪان واملﻨﺎﻃﻖ اﻟﺴﺎﺣﻠﻴﺔ املُﻨﺨﻔﻀﺔ. وﻗﺮﻳﺒًﺎﺟﺪٍّاﺳﻮفﻳُﻀﻄﺮ املﺰﻳﺪﻣﻦ
اﻟﻨﺎس إﱃ اﻟﺘﻌﺎﻣُﻞﻣﻊﻋﻮاﻗﺐﺗﻐريﱡ املﻨﺎخ. وﻳﺴﺘﻨﺘﺞ اﻟﻜﺜريونﻣﻦﻫﺬا أﻧﻪﻳﺠﺐﻋﻠﻴﻨﺎ
اﻟﺘﴫﱡف اﻵنﺑﺸﻜﻞٍﻋﺎﺟﻞﻟﻠﺘﺨﻔﻴﻒﻣﻦﻣﺨﺎﻃﺮﺗﻐري املﻨﺎخ؛ وأﻧﺎ أﻗﻮل »اﻟﺘﺨﻔﻴﻒ«ﻷن
اﻟﻌﻤﻠﻴﺔ رﺑﻤﺎﻗﺪﺗﺠﺎوزتﺑﺎﻟﻔﻌﻞﻧﻘﻄﺔ اﻟﺘﻮﻗﱡﻒ. إن اﻟﻔﻜﺮةﻫﻲ أنﻫﺬاﻟﻴﺲﻓﻘﻂ اﻟﻮﻗﺖ
املﻨﺎﺳﺐﻟﻠﻘﻴﺎمﺑﴚءٍ وﻟﻜﻦ رﺑﻤﺎﻓﺎت اﻷوانﺑﺎﻟﻔﻌﻞﻟﺘﺠﻨﱡﺐﺟﻤﻴﻊ اﻟﻌﻮاﻗﺐ. وﺑﺎملﻘﺎرﻧﺔﻣﻊ
ﻣﺨﺎوفﻣﺆﻳﺪيﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﺑﺸﺄن اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ،ﻓﺈنﻫﺬه املﺨﺎوفﻣﺪﻋﻮﻣﺔﺑﺸﻜﻞٍ
أﻓﻀﻞﺑﺎﻷدﻟﺔ اﻟﻌﻠﻤﻴﺔ وﺣﺎزت دﻋﻤًﺎﻛﺒريًاﺑني اﻟﻨﱡﺨﺐ املُﺜﻘﻔﺔﰲ اﻟﻐﺮب — اﻟﺘﻲﺿﺠﺮت
ﻣﻦ اﻟﻨﺰﻋﺔ اﻟﺸﻜﻴﺔﻣﺎﺑﻌﺪ اﻟﺤﺪاﺛﻴﺔ وﺳﻴﺎﺳﺎت اﻟﻬﻮﻳﺔ اﻟﺒريوﻗﺮاﻃﻴﺔ — اﻟﺘﻲﺗﺮى اﻵنﺳﺒﺒًﺎ
ﻟﻠﱰﻛﻴﺰﻋﲆﻣﺸﻜﻠﺔﻳﺒﺪو أﻧﻬﺎﺣﻘﻴﻘﻴﺔﻟﻠﻐﺎﻳﺔ وواﻗﻌﻴﺔﻟﻠﻐﺎﻳﺔ وﻋﺎملﻴﺔﻟﻠﻐﺎﻳﺔ:ﺗﻐريﱡ املﻨﺎخ
ﻳﺤﺪثﺣﻘٍّﺎ وﻳﺆﺛﺮﻋﲆﻛﻞﱢﺷﺨﺺ وﻛﻞﳾءﰲﻫﺬا اﻟﻜﻮﻛﺐ. وﺗﺪﻋﻮﺣﻤﻠﺔﺟﺮﻳﺘﺎﺛﻮﻧﱪج
واﻻﻋﺘﺼﺎﻣﺎت املﻨﺎﺧﻴﺔ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل، إﱃﺗﻮﺟﻴﻪ اﻻﻫﺘﻤﺎم إﱃ أزﻣﺔ املﻨﺎخ.
126</p>
<p>ﺗﺤﺪﱢيﺗﻐريﱡ املﻨﺎخ:ﺣﻮل اﻷوﻟﻮﻳﺎت وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي
»ملﺎذاﻧﻘﻠﻖﺑﺸﺄن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ إذاﻛﺎﻧﺖ املﺸﻜﻠﺔ املﻠﺤﱠﺔﻫﻲﺗﻐريﱡ املﻨﺎخ وﻛﻮنﻣُﺴﺘﻘﺒﻞ اﻟﻜﻮﻛﺐ
ﰲﺧﻄﺮ؟«
ﻳُﺴﺘﺨﺪَم أﺣﻴﺎﻧًﺎﻣﻔﻬﻮمﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩيﻟﺘﺄﻃري املﺸﻜﻠﺔ. وﻫﻲﻓﻜﺮةﻃﺮﺣﻬﺎﺑﻮل
ﻛﺮوﺗﺰن اﻟﺒﺎﺣﺚﰲﺗﻐريﱡ املﻨﺎخ وﻳﻮﺟنيﺳﺘﻮرﻣﺮﻋﺎﻟِﻢ اﻷﺣﻴﺎء، وﺗﻨﺺﱡﻋﲆ أﻧﻨﺎﻧﻌﻴﺶﰲ
ﺣﻘﺒﺔﺟﻴﻮﻟﻮﺟﻴﺔ زادتﻓﻴﻬﺎﻗﻮة اﻟﺒﴩﻋﲆ اﻷرض وﻋﲆﻧﻈﻤﻬﺎ اﻟﺒﻴﺌﻴﺔ،ﻣﻤﺎﺟﻌﻞ اﻟﺒﴩ
ﻷﻋﺪاد اﻟﺒﴩ واملﺎﺷﻴﺔ، وﰲ اﻟﺘﻮﺳﻊ اﻟﻌﻤﺮاﻧﻲ املﺘﺰاﻳﺪ،
ﻗﻮةًﺟﻴﻮﻟﻮﺟﻴﺔ.ﻓﻜﱢﺮﰲ اﻟﻨﻤﻮ اﻷُﳼﱢ
واﺳﺘﻨﺰاف اﻟﻮﻗﻮد اﻷﺣﻔﻮري، واﻻﺳﺘﺨﺪام اﻟﻬﺎﺋﻞﻟﻠﻤﻴﺎه اﻟﻌﺬﺑﺔ، واﻧﻘﺮاض اﻷﻧﻮاع، وإﻃﻼق
املﻮاد اﻟﺴﺎﻣﺔ، وﻣﺎ إﱃ ذﻟﻚ.ﻳﻌﺘﻘﺪ اﻟﺒﻌﺾ أنﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩيﻗﺪﺑﺪأتﻣﻊ اﻟﺜﻮرة
(Crutzen 2006)اﻟﺰراﻋﻴﺔ؛ﺑﻴﻨﻤﺎﻳﺮى آﺧﺮون أﻧﻬﺎ اﻧﻄﻠﻘﺖﺑﺎﻧﻄﻼق اﻟﺜﻮرة اﻟﺼﻨﺎﻋﻴﺔ
أوﺑﻌﺪ اﻟﺤﺮب اﻟﻌﺎملﻴﺔ اﻟﺜﺎﻧﻴﺔ.ﻋﲆ أيﺣﺎل،ﻟﻘﺪﻧﺸﺄتﻗﺼﺔﺟﺪﻳﺪة وﺗﺎرﻳﺦﺟﺪﻳﺪ،
ورﺑﻤﺎﺣﺘﻰﴎدﻳﺔﺟﺪﻳﺪة. وﻏﺎﻟﺒًﺎﻣﺎﻳُﺴﺘﺨﺪَمﻫﺬا املﻔﻬﻮمﰲ اﻟﻮﻗﺖ اﻟﺤﺎﴐﻹﺛﺎرة اﻟﻘﻠﻖ
ﺑﺸﺄن اﻻﺣﺘﺒﺎس اﻟﺤﺮاري وﺗﻐريﱡ املﻨﺎخ، وﻟﺤﺸﺪﻣﺨﺘﻠﻒ اﻟﺘﺨﺼﱡﺼﺎت )ﺑﻤﺎﰲ ذﻟﻚ اﻟﻌﻠﻮم
اﻹﻧﺴﺎﻧﻴﺔ(ﻟﻠﺘﻔﻜريﰲﻣُﺴﺘﻘﺒﻞ اﻟﻜﻮﻛﺐ.
ﻻﻳﺘﺒﻨﱠﻰ اﻟﺠﻤﻴﻊﻫﺬا املﺼﻄﻠﺢ؛ﻓﻬﻮﻣﺼﻄﻠﺢﻣُﺜريﻟﻠﺠﺪلﺣﺘﻰﺑني اﻟﺠﻴﻮﻟﻮﺟﻴني،
وﻗﺪﺷﻜﻚ اﻟﺒﻌﺾﰲﺗﺮﻛﻴﺰهﻋﲆ أﻫﻤﻴﺔ اﻟﺒﴩ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﺟﺎدﻟﺖﻫﺎراواي
)٥١٠٢(ﻣﻦﻣﻨﻈﻮرﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔﺑﺄن اﻷﻧﻮاع اﻷﺧﺮى واﻟﻌﻮاﻣﻞ »اﻟﻼﺣﻴﻮﻳﺔ«ﺗﻠﻌﺐ
أﻳﻀًﺎ دورًاﰲ اﻟﺒﻴﺌﺔ املﺘﺤﻮﻟﺔ. وﻟﻜﻦﺣﺘﻰﻣﻦ دونﻣﻔﻬﻮمﻣُﺜريﻟﻠﺠﺪلﻣﺜﻞﺣﻘﺒﺔ اﻟﺘﺄﺛري
اﻟﺒﴩي،ﻓﺈنﺗﻐريﱡ املﻨﺎخ واملﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ )اﻷﺧﺮى(ﺳﺘﻈﻞﱡﺑﺎﻗﻴﺔ، وﻳﺠِﺐﻋﲆ اﻟﺴﻴﺎﺳﺔ
اﻟﺘﻌﺎﻣُﻞﻣﻌﻬﺎ، واﻷﻓﻀﻞ أنﻳﻜﻮن ذﻟﻚﰲ أﻗﺮب وﻗﺖٍﻣﻤﻜﻦ.ﻓﻤﺎذاﻳﻌﻨﻲﻫﺬاﺑﺎﻟﻨﺴﺒﺔ إﱃ
ﺳﻴﺎﺳﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ؟
ﻳﻌﺘﻘﺪ اﻟﻌﺪﻳﺪﻣﻦ اﻟﺒﺎﺣﺜني أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ واﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔﻳُﻤﻜﻦ أن
ﺗُﺴﺎﻋﺪﻧﺎ أﻳﻀًﺎﰲﻋﻼج اﻟﻌﺪﻳﺪﻣﻦﻣﺸﻜﻼت اﻟﻌﺎﻟﻢ،ﺑﻤﺎﰲ ذﻟﻚﺗﻐريﱡ املﻨﺎخ. وﻋﲆﻏﺮار
املﻌﻠﻮﻣﺎت اﻟﺮﻗﻤﻴﺔ وﺗﻘﻨﻴﺎت اﻻﺗﺼﺎﻻتﺑﺸﻜﻞٍﻋﺎم،ﻳﻤﻜﻦ أنﻳُﺴﻬﻢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲ
اﻟﺘﻨﻤﻴﺔ املﺴﺘﺪاﻣﺔ وﰲ اﻟﺘﻌﺎﻣُﻞﻣﻊ اﻟﻌﺪﻳﺪﻣﻦ املﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ. وﻣﻦ املُﺮﺟﱠﺢ أنﻳُﺼﺒﺢ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املُﺴﺘﺪام اﺗﺠﺎﻫًﺎﻧﺎﺟﺤًﺎﰲ اﻟﺒﺤﺚ واﻟﺘﻄﻮﻳﺮ. وﻣﻊ ذﻟﻚ،ﻳﻤﻜﻦ أنﻳﺠﻌﻞ
اﻟﺒﻴﺌﺔ؛ وﺑﺎﻟﺘﺎﱄﻓﻴﻤﺎﻳﺨﺼﱡﻨﺎﻧﺤﻦﺟﻤﻴﻌًﺎ.
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻷﻣﻮر أﺳﻮأﻓﻴﻤﺎﻳﺨﺺﱡ
127</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
وﻟﻨﺘﺬﻛﱠﺮﻣﺠﺪدًا زﻳﺎدة اﺳﺘﻬﻼك اﻟﻄﺎﻗﺔ واﻟﻨﻔﺎﻳﺎت. وﻣﻦﻣﻨﻈﻮرﻣﺸﻜﻠﺔﺣﻘﺒﺔ اﻟﺘﺄﺛري
اﻟﺒﴩي،ﻓﺈن املﺨﺎﻃﺮةﺗﻜﻤُﻦﰲ أن اﻟﺒﴩﻳﻤﻜﻦ أنﻳﺴﺘﺨﺪﻣﻮا اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻹﺣﻜﺎم
ﻗﺒﻀﺘﻬﻢﻋﲆ اﻷرض،ﻣﻤﺎﺳﻴﺰﻳﺪﻣﻦﺣﺪة املﺸﻜﻠﺔﺑﺪﻻًﻣﻦﺣﻠﱢﻬﺎ.
ﻫﺬاﻳﻌﺘﱪ أﻣﺮًا إﺷﻜﺎﻟﻴٍّﺎﺑﺸﻜﻞٍﺧﺎص إذاﻛﻨﺎﻧﻨﻈﺮ إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻴﺲ
ﻓﻘﻂﺑﻮﺻﻔﻪﺣﻼٍّ وﻟﻜﻦﺑﻮﺻﻔﻪ اﻟﺤﻞ اﻟﺮﺋﻴﴘ. وﻟﻨﻔﻜﺮﰲﺳﻴﻨﺎرﻳﻮ اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖﻟﺬﻛﺎء
اﺻﻄﻨﺎﻋﻲﻳﻌﺮف أﻓﻀﻞﻣﻨﺎﻧﺤﻦ اﻟﺒﴩﻣﺎﻫﻮﺟﻴﺪﻟﻨﺎ: ذﻛﺎء اﺻﻄﻨﺎﻋﻲ »ﺣﻤﻴﺪ«ﻳﺨﺪم
اﻟﺒﴩﻳﺔﻣﻦﺧﻼلﺟﻌﻞ اﻟﺒﴩﻳﺘﴫﱠﻓﻮنﻟﺼﺎﻟﺤﻬﻢ وﻟﺼﺎﻟﺢ اﻟﻜﻮﻛﺐ؛ﻋﲆﺳﺒﻴﻞ املﺜﺎل،
اﻵﻟﺔ اﻹﻟﻪ اﻟﺘﻲﺗُﻌﺎدلﺗﻘﻨﻴٍّﺎ املﻠﻚ اﻟﻔﻴﻠﺴﻮف املﺬﻛﻮرﰲﻓﻠﺴﻔﺔ أﻓﻼﻃﻮن.ﻳﺤﻞ اﻟﺬﻛﺎء
(، وﻳﺪﻳﺮﻧﻈﺎم دﻋﻢ اﻟﺤﻴﺎة اﻟﺨﺎصHarrari 2015)اﻻﺻﻄﻨﺎﻋﻲ اﻹﻟﻪﻣﺤﻞ اﻹﻧﺴﺎن اﻹﻟﻪ
ﺑﻨﺎ وﻳﺪﻳﺮﻧﺎ.ﻓﻠﺤﻞﻣﺸﻜﻼتﺗﻮزﻳﻊ املﻮارد،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻳﻤﻜﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أن
ﻳﻌﻤﻞﺑﻮﺻﻔﻪ »وﺣﺪةﺧﺪﻣﺔ«،ﻳُﺪﻳﺮ إﻣﻜﺎﻧﻴﺔ وﺻﻮل اﻟﺒﴩ إﱃ املﻮارد. وﺳﺘﻜﻮنﻗﺮاراﺗﻪ
ﻣُﺴﺘﻨﺪة إﱃﺗﺤﻠﻴﻠﻪﻷﻧﻤﺎط اﻟﺒﻴﺎﻧﺎت. وﻳﻤﻜﻦ دﻣﺞﻫﺬا اﻟﺴﻴﻨﺎرﻳﻮﻣﻊﺣﻠﻮلٍﺗﻜﻨﻮﻟﻮﺟﻴﺔ
ﻣﺒﺘﻜﺮةﻣﺜﻞ اﻟﻬﻨﺪﺳﺔ اﻟﺠﻴﻮﻟﻮﺟﻴﺔ. اﻟﺒﴩﻟﻴﺴﻮا اﻟﻮﺣﻴﺪﻳﻦ اﻟﺬﻳﻦﻳﺤﺘﺎﺟﻮن إﱃ اﻹدارة؛
ﻓﺎﻟﻜﻮنﻛﻠﻪﰲﺣﺎﺟﺔ إﱃ إﻋﺎدةﻫﻨﺪﺳﺘﻪ. وﻣﻦﺛَﻢ،ﻳُﻤﻜﻨﻨﺎ اﺳﺘﺨﺪام اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻟ »إﺻﻼح«
ﻣﺸﻜﻼﺗﻨﺎ وﻣﺸﻜﻼت اﻟﻜﻮﻛﺐ.
وﻣﻊ ذﻟﻚ،ﻓﺈنﻫﺬه اﻟﺴﻴﻨﺎرﻳﻮﻫﺎتﻟﻦﺗﻜﻮنﻓﻘﻂﻣﺴﺘﺒﺪة وﺗﺘﻌﺪﱠىﻋﲆ اﺳﺘﻘﻼﻟﻴﺔ
اﻟﺒﴩ،ﺑﻞﺳﺘﺴﺎﻫﻢ أﻳﻀًﺎﺑﺸﻜﻞٍ أﺳﺎﳼﰲﻣﺸﻜﻠﺔﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩيﻧﻔﺴﻬﺎ:ﻓﺎﻟﻮﻛﺎﻟﺔ
اﻟﺒﴩﻳﺔ املُﻔﺮﻃﺔ،ﻫﺬه املﺮةﻳﺘﻢﺗﻔﻮﻳﻀﻬﺎﻣﻦﻗِﺒﻞ اﻟﺒﴩ إﱃ اﻵﻻت،ﺳﺘُﺤﻮل اﻟﻜﻮﻛﺐﺑﺄﻛﻤﻠﻪ
إﱃﻣﺠﺮدﻣَﻮرِد وآﻟﺔﻟﻠﺒﴩ.ﻳﺘﻢ »ﺣﻞ«ﻣﺸﻜﻠﺔﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩيﻣﻦﺧﻼل اﻟﻮﺻﻮل
ﺑﻬﺎ إﱃ اﻟﻨﻘﻴﺾ اﻟﺘﻜﻨﻮﻗﺮاﻃﻲ،ﻣﻤﺎﻳﺆدي إﱃﻋﺎﻟَﻢٍﻣﻦ اﻵﻻتﻳُﻌﺎﻣَﻞﻓﻴﻪ اﻟﺒﴩ أوﻻًﻛﺄﻃﻔﺎل
ﻳﺠﺐ رﻋﺎﻳﺘﻬﻢ ورﺑﻤﺎﰲ وﻗﺖٍﻻﺣﻖﻳﺘﻢﺗﺠﺎﻫﻠﻬﻢﺗﻤﺎﻣًﺎ. وﰲﻫﺬا اﻟﻨﻮعﻣﻦ اﻟﺘﺄﺛري اﻟﺒﴩي
املُﺘﻌﻠﻖﺑﺎﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ واﻟﺴﻴﻨﺎرﻳﻮ املﺄﻟﻮفﺟﺪٍّا اﻟﺬيﻳﺘﻢﻓﻴﻪ إﺣﻼل اﻵﻻتﻣﺤﻞﱠ اﻟﺒﴩ،
ﻧﻌﻮدﻣﺮﱠة أﺧﺮى إﱃﺳﻴﻨﺎرﻳﻮﻫﺎت اﻷﺣﻼم واﻟﻜﻮاﺑﻴﺲ.
ﺟﻨﻮن اﻟﻔﻀﺎء اﻟﺠﺪﻳﺪ واﻹﻏﺮاء اﻷﻓﻼﻃﻮﻧﻲ
ﺛﻤﱠﺔ إﺟﺎﺑﺔ أﺧﺮىﻋﲆﺗﻐريﱡ املﻨﺎخ وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي، واﻟﺘﻲﻫﻲ أﻳﻀًﺎ رؤﻳﺔﻣُﻮﻟﻌﺔ
ﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ ورﺑﻤﺎﺗﺮﺗﺒﻂ أﺣﻴﺎﻧًﺎﺑﴪدﻳﺎتﺗﺠﺎوز اﻟﺒﴩﻳﺔ، وﻫﻲ:ﻗﺪﻧُﺪﻣﺮﻫﺬا اﻟﻜﻮﻛﺐ،
وﻟﻜﻦﻳُﻤﻜﻨﻨﺎ اﻟﻬﺮبﻣﻦ اﻷرض واﻟﺬﻫﺎب إﱃ اﻟﻔﻀﺎء.
128</p>
<p>ﺗﺤﺪﱢيﺗﻐريﱡ املﻨﺎخ:ﺣﻮل اﻷوﻟﻮﻳﺎت وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي
ﻛﺎﻧﺖ اﻟﺼﻮرة اﻷﻳﻘﻮﻧﻴﺔﻟﻌﺎم ٨١٠٢ﻫﻲﺳﻴﺎرة إﻳﻠﻮنﻣﺎﺳﻚ اﻟﺮﻳﺎﺿﻴﺔﻃﺮازﺗﺴﻼ
ﻣﺎﺳﻚ أﻳﻀًﺎﻟﺪَﻳﻪﺧُﻄﻂﻻﺳﺘﻌﻤﺎر املﺮﻳﺦ. وﻫﻮﻟﻴﺲ اﻟﺸﺨﺺ3.وﻫﻲﺗﻄﻔﻮﰲ اﻟﻔﻀﺎء
اﻟﻮﺣﻴﺪ اﻟﺬيﻳُﺮاوِدهﻫﺬا اﻟﺤﻠﻢ:ﻓﻬﻨﺎك اﻫﺘﻤﺎمﻣُﺘﺰاﻳﺪﺑﺎﻟﺬﻫﺎب إﱃ اﻟﻔﻀﺎء. وﻫﺬاﻟﻴﺲ
ﻣﺠﺮدﺣﻠﻢ. إذﺗُﺴﺘﺜﻤﺮ أﻣﻮالﻃﺎﺋﻠﺔﰲﻣﴩوﻋﺎت اﻟﻔﻀﺎء. وﻋﲆﻋﻜﺲﺳﺒﺎق اﻟﻔﻀﺎء
اﻟﺬيﺣﺪثﰲ اﻟﻘﺮن اﻟﻌﴩﻳﻦ،ﻫﺬه املﴩوﻋﺎتﻳﺘﻢ دﻋﻤُﻬﺎﻣﻦﻗِﺒﻞ اﻟﴩﻛﺎت اﻟﺨﺎﺻﺔ.
واملﻠﻴﻮﻧريات املُﻮﻟﻌﻮنﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻟﻴﺴﻮا اﻟﻮﺣﻴﺪِﻳﻦ املُﻬﺘﻤنيﺑﺎﻟﻔﻀﺎء،ﺑﻞ إن اﻟﻔﻨﺎﻧني أﻳﻀًﺎ
ﺷﻐﻮﻓﻮنﺑﻪﺑﺸﺪة.ﺗُﺨﻄﻂﴍﻛﺔﺳﺒﻴﺲ إﻛﺲ اﻟﺨﺎﺻﺔﺑﺈﻳﻠﻮنﻣﺎﺳﻚﻹرﺳﺎلﻓﻨﺎﻧني إﱃ
وﺗُﻌﺪ اﻟﺴﻴﺎﺣﺔ اﻟﻔﻀﺎﺋﻴﺔﻓﻜﺮةً أﺧﺮىﺗﺰدادﺷﻴﻮﻋًﺎ.ﻓﻤَﻦﻣﻨﱠﺎﻻﻳﺮﻏﺐﰲ4.ﻣﺪار اﻟﻘﻤﺮ
اﻟﺬﻫﺎب إﱃ اﻟﻔﻀﺎء؟ اﻟﻔﻀﺎءﻣُﻐﺮٍﻟﻠﻐﺎﻳﺔ.
ﻻﻳﻤﺜﻞ اﻟﺬﻫﺎب إﱃ اﻟﻔﻀﺎءﻣﺸﻜﻠﺔًﰲﺣﺪﱢ ذاﺗﻪ.ﺑﻞ إنﻟﻪﻓﻮاﺋﺪﻣُﺤﺘﻤﻠﺔ.ﻋﲆﺳﺒﻴﻞ
املﺜﺎل،ﻳﻤﻜﻦ أنﺗﺴﺎﻋﺪ اﻷﺑﺤﺎثﰲﻛﻴﻔﻴﺔ اﻟﺒﻘﺎءﻋﲆﻗﻴﺪ اﻟﺤﻴﺎةﰲﺑﻴﺌﺎتٍ أﻛﺜﺮﺗﻄﺮﻓًﺎﰲ
اﻟﺘﻌﺎﻣُﻞﻣﻊ املﺸﻜﻼتﻋﲆ اﻷرض، وﰲ اﺧﺘﺒﺎر اﻟﺘﻘﻨﻴﺎت املُﺴﺘﺪاﻣﺔ، واﺗﺨﺎذﻣﻨﻈﻮرﻛﻮﻛﺒﻲ.
ﺿﻊﰲ اﻋﺘﺒﺎرك أﻳﻀًﺎ أنﻣﺸﻜﻠﺔﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩيﻳُﻤﻜﻦ أنﺗﻜﻮنﻧﺎﺟﻤﺔًﻋﻦ أن
ﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﻔﻀﺎءﻣﻨﺬﺳﻨﻮاتﻃﻮﻳﻠﺔ أﺗﺎﺣﺖﻟﻨﺎ رؤﻳﺔ اﻷرضﻣﻦﺑُﻌﺪ. وﺑﺎﻟﻨﻈﺮ إﱃﺻﻮرة
ﺳﻴﺎرةﻣﺎﺳﻚﻣﺮةً أﺧﺮى:ﻳﻌﺘﻘﺪﺑﻌﺾ اﻟﻨﺎس أن اﻟﺴﻴﺎرة اﻟﻜﻬﺮﺑﺎﺋﻴﺔﺣﻞﱞﻣﻦﺣﻠﻮل
املﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ، دون اﻟﺘﺸﻜﻴﻚﰲ اﻓﱰاض أن اﻟﺴﻴﺎراتﻫﻲ أﻓﻀﻞ وﺳﻴﻠﺔﻟﻠﻨﻘﻞ ودون
اﻟﺘﻔﻜريﰲﻛﻴﻔﻴﺔ إﻧﺘﺎج اﻟﻜﻬﺮﺑﺎء.ﻋﲆ أيﺣﺎل،ﻫﻨﺎك أﻓﻜﺎرﻣﺜريةﻟﻼﻫﺘﻤﺎم.
وﻟﻜﻦ أﺣﻼم اﻟﻔﻀﺎءﺗُﻌﺪ إﺷﻜﺎﻟﻴﺔً إذاﻛﺎﻧﺖﻧﺘﻴﺠﺘﻬﺎﻫﻲ إﻫﻤﺎل املﺸﻜﻼت اﻷرﺿﻴﺔ،
وإذاﻛﺎﻧﺖﻋﺮﺿًﺎﻣﻦ أﻋﺮاض اﻟﺤﺎﻟﺔ اﻟﺘﻲﺷﺨﱠﺼﺘﻬﺎﺣﻨﺔ أرﻧﺖ )٨٥٩١(ﺑﺎﻟﻔﻌﻞﻋﻨﺪﻣﺎ
ﻛﺘﺒﺖﻋﻦ اﻟﺒﴩ: اﻟﻜﺜريﻣﻦ اﻟﺘﺠﺮﻳﺪ واﻻﻏﱰاب. أﺷﺎرتﺣﻨﺔ إﱃ أن اﻟﻌِﻠﻢﻳﺪﻋﻢ رﻏﺒﺔ دﻓﻴﻨﺔ
ﰲﻣﻐﺎدرة اﻷرض:ﺣﺮﻓﻴٍّﺎ،ﻣﻦﺧﻼلﺗﻜﻨﻮﻟﻮﺟﻴﺎ اﻟﻔﻀﺎء )ﰲﻋﴫﻫﺎ،ﺳﺒﻮﺗﻨﻴﻚ( وأﻳﻀًﺎ
ﻣﻦﺧﻼلﻃُﺮق رﻳﺎﺿﻴﺔﺗُﺠﺮدﻧﺎ وﺗَﻌﺰﻟﻨﺎﻣﻤﺎ أﺻِﻔﻪﺑﺤﻴﺎﺗﻨﺎ اﻷرﺿﻴﺔ اﻟﻔﻮﺿﻮﻳﺔ املُﺘﺠﺴﱢﺪة
واﻟﺴﻴﺎﺳﻴﺔ. وﻣﻦﻫﺬا املﻨﻈﻮر،ﻳﻤﻜﻦﺗﻔﺴري أﺣﻼمﻣﺆﻳﺪيﺗﺠﺎوز اﻟﺒﴩﻳﺔﺑﺎﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ
وﺑﻤُﻐﺎدرة اﻷرضﻋﲆ أﻧﻬﺎﺗﺪاﻋِﻴﺎتﻟﻨﻮع إﺷﻜﺎﱄﻣﻦ اﻻﻏﱰاب واﻟﻬﺮوب. إﻧﻬﺎ اﻟﻔﻜﺮ
اﻷﻓﻼﻃﻮﻧﻲ وﻓﻜﺮﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔﰲ أوﺿﺢﺻﻮره؛ إن اﻟﻔﻜﺮةﻫﻲ اﻟﺘﻐﻠﱡﺐﻟﻴﺲﻓﻘﻂ
ﻋﲆﻗﻴﻮد اﻟﺠﺴﺪ اﻟﺒﴩي، وﻟﻜﻦ أﻳﻀًﺎﻋﲆﻗﻴﻮد ذﻟﻚ »اﻟﻨﻈﺎم اﻟﺪاﻋﻢﻟﻠﺤﻴﺎة«: أي اﻷرض
ﻧﻔﺴﻬﺎ.ﻓﺎﻟﺠﺴﺪﻟﻴﺲﻫﻮ اﻟﺴﺠﻦ اﻟﻮﺣﻴﺪ،ﺑﻞ اﻷرضﻧﻔﺴﻬﺎ، وﻣﻦﺛَﻢﻋﻠﻴﻨﺎ أنﻧﻬﺮُب
ﻣﻨﻬﺎ.
129</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺑﺎﻟﺘﺎﱄ،ﻓﺈﺣﺪىﻣﺨﺎﻃﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻫﻲ أﻧﻪﻳُﻤﻜﱢﻦﻫﺬا اﻟﻨﻮعﻣﻦ اﻟﺘﻔﻜري
وﻳُﺼﺒﺢ آﻟﺔﻟﻼﻏﱰاب: أداة ملﻐﺎدرة اﻷرض وإﻧﻜﺎرﺣﺎﻟﺘﻨﺎ اﻟﻮﺟﻮدﻳﺔ اﻻﻋﺘﻤﺎدﻳﺔ اﻟﻀﻌﻴﻔﺔ
واﻟﺠﺴﺪﻳﺔ واﻷرﺿﻴﺔ.ﺑﻌﺒﺎرةٍ أﺧﺮى:ﺻﺎروخ.ﻣﺮة أﺧﺮى،ﻻﺗُﻤﺜﻞ اﻟﺼﻮارﻳﺦﻣﺸﻜﻠﺔﰲ
ﺣﺪﱢ ذاﺗﻬﺎ. إﻧﻤﺎ املﺸﻜﻠﺔﻫﻲﻣﺰجﺗﻘﻨﻴﺎتﻣُﻌﻴﻨﺔﻣﻊﴎدﻳﺎتﻣُﻌﻴﻨﺔ.ﻓﻌﲆ اﻟﺮﻏﻢﻣﻦ أن
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻤﻜﻦ أنﻳﻜﻮنﻗﻮة إﻳﺠﺎﺑﻴﺔﺑﺎﻟﻨﺴﺒﺔ إﱃﺣﻴﺎﺗﻨﺎ اﻟﺸﺨﺼﻴﺔ، واملﺠﺘﻤﻊ،
واﻟﺒﴩﻳﺔ،ﻓﺈنﻣﺰﻳﺠًﺎﻣﻦﺗﻌﺰﻳﺰ اﻻﺗﺠﺎﻫﺎت اﻟﺘﺠﺮﻳﺪﻳﺔ واﻻﻏﱰاﺑﻴﺔﰲ اﻟﻌﻠﻮم واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
ﻣﻊﺧﻴﺎﻻتﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ و»ﺗﺠﺎوز اﻷرض«ﻗﺪﻳﺆدي إﱃﻣﺴﺘﻘﺒﻞٍﺗﻜﻨﻮﻟﻮﺟﻲﻣﺆذٍ
ﻟﻠﺒﴩ وﻟﻠﻜﺎﺋﻨﺎت اﻟﺤﻴﺔ اﻷﺧﺮىﻋﲆ اﻷرض. إذاﻫﺮﺑﻨﺎﻣﻦﻣﺸﻜﻼﺗﻨﺎﺑﺪﻻًﻣﻦ اﻟﺘﻌﺎﻣُﻞﻣﻌﻬﺎ
—ﻛﻤﺎﰲﻣﺸﻜﻠﺔﺗﻐريﱡ املﻨﺎخ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل —ﻓﻘﺪﻧﻔﻮزﺑﺎملﺮﻳﺦ )ﺣﺘﻰ اﻵن( وﻟﻜﻨﻨﺎ
ﺳﻮفﻧﺨﴪ اﻷرض.
وﻛﺎﻟﻌﺎدة،ﻫﻨﺎكﺟﺎﻧﺐﺳﻴﺎﳼ آﺧَﺮﻟﻬﺬا املﻮﺿﻮع: إذﻳﻤﺘﻠﻚﺑﻌﺾ اﻟﻨﺎسﻓﺮﺻًﺎ
وﻣﺎﻻً وﻗﺪرةً أﻛﱪﻋﲆ اﻟﻬﺮوبﻣﻘﺎرﻧﺔًﺑﺎﻵﺧﺮﻳﻦ. املﺸﻜﻠﺔﻟﻴﺴﺖﻓﻘﻂﰲ أنﺗﻜﻨﻮﻟﻮﺟﻴﺎ
اﻟﻔﻀﺎء واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﻬﻤﺎﺗﻜﻠﻔﺔﺣﻘﻴﻘﻴﺔﺑﺎﻟﻨﺴﺒﺔ إﱃ اﻷرض وأنﻛﻞﱠ املﺎل املُﺴﺘﺜﻤَﺮ
ﰲﻣﴩوﻋﺎت اﻟﻔﻀﺎءﻟﻢﻳُﻨﻔَﻖﻋﲆﻣﺸﻜﻼت اﻷرض اﻟﺤﻘﻴﻘﻴﺔﻣﺜﻞ اﻟﺤﺮوب واﻟﻔﻘﺮ؛ﺑﻞ
املﺸﻜﻠﺔﻫﻲ أن اﻷﺛﺮﻳﺎءﺳﻴﻜﻮﻧﻮنﻗﺎدِرﻳﻦﻋﲆ اﻟﻬﺮوبﻣﻦ اﻷرض اﻟﺘﻲﻳُﺪﻣﱢﺮوﻧﻬﺎ،ﰲ
ﺣنيﻳﺠﺐﻋﲆﺑﻘﻴﺘﻨﺎ اﻟﺒﻘﺎءﻋﲆﻛﻮﻛﺐٍﻳﺴﺘﺤﻴﻞ اﻟﻌﻴﺶﻓﻴﻪﺑﺼﻮرةﻣﺘﺰاﻳﺪة )اﻧﻈﺮ،ﻋﲆ
ﺳﺒﻴﻞ املﺜﺎل، زﻳﻤﺮﻣﺎن ٥١٠٢(. وﻣﺜﻞ اﻟﺼﻮارﻳﺦ واﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ اﻷﺧﺮى،ﻳﻤﻜﻦ أنﻳُﺼﺒﺢ
(.Rushkoff 2018)اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أداةﻟ »ﺑﻘﺎء اﻷﻛﺜﺮﺛﺮاءً«،ﻛﻤﺎ أوﺿﺢ أﺣﺪ املﻌﻠﱢﻘني
ﰲ اﻟﻮﻗﺖ اﻟﺤﺎﴐ،ﻳﺤﺪث ذﻟﻚﺑﺎﻟﻔﻌﻞﻣﻊﺗﻘﻨﻴﺎت أﺧﺮى:ﻓﻔﻲﻣﺪنﻣﺜﻞ دﻟﻬﻲ وﺑﻜني،
ﻳُﻌﺎﻧﻲﻣﻌﻈﻢ اﻟﻨﺎسﻣﻦﺗﻠﻮﱡث اﻟﻬﻮاء،ﺑﻴﻨﻤﺎﻳﻄري اﻷﺛﺮﻳﺎء إﱃﻣﻨﺎﻃﻖ أﻗﻞﺗﻠﻮﺛًﺎ أوﻳﺸﱰون
ﻫﻮاءًﻧﻘﻴٍّﺎﺑﺎﺳﺘﺨﺪامﺗﻘﻨﻴﺎتﺗﻨﻘﻴﺔ اﻟﻬﻮاء.ﻟﻴﺲ اﻟﺠﻤﻴﻊﻳﺘﻨﻔﱠﺴﻮن اﻟﻬﻮاءﻧﻔﺴﻪ. واﻵن،ﻫﻞ
ﺳﻴُﺴﺎﻫﻢ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﰲﺗﻮﺳﻴﻊﻫﺬه اﻟﻔﺠﻮاتﺑني اﻷﺛﺮﻳﺎء واﻟﻔﻘﺮاء،ﻣﻤﺎﻳﺆدي إﱃ
ﺣﻴﺎة أﻛﺜﺮﻛﺮﺑًﺎ وﻏريﺻﺤﻴﺔﻟﻠﺒﻌﺾ وﺣﻴﺎة أﻓﻀﻞﻟﻠﺒﻌﺾ اﻵﺧﺮ؟ﻫﻞﺳﻴَﴫِﻓﻨﺎ اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲﻋﻦ املﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ؟ﻳﺒﺪو أنﻓﻜﺮة أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻨﺒﻐﻲ أنﻳﺴﻌﻰ
إﱃﺗﺤﺴني اﻟﺤﻴﺎةﻋﲆ اﻷرض،ﻟﻠﺠﻤﻴﻊ وﻟﻴﺲﻟﻔﺌﺔﻣﻌﻴﻨﺔ،ﻣﻊ اﻟﻮﺿﻊﰲ اﻻﻋﺘﺒﺎر أنﺣﻴﺎﺗﻨﺎ
ﺗﻌﺘﻤﺪﻋﲆﻛﻮﻛﺐ اﻷرض،ﺗﻌﺪﻣﺘﻄﻠﺒًﺎ أﺧﻼﻗﻴٍّﺎ. وﻗﺪﺗﻌﻴﻖﺑﻌﺾﴎدﻳﺎت اﻟﻔﻀﺎءﺗﺤﻘﻴﻖ
ﻫﺬا اﻟﻬﺪفﺑﺪﻻًﻣﻦ أنﺗﺴﺎﻋﺪﻧﺎﰲﺗﺤﻘﻴﻘﻪ.
130</p>
<p>ﺗﺤﺪﱢيﺗﻐريﱡ املﻨﺎخ:ﺣﻮل اﻷوﻟﻮﻳﺎت وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي
ﻋﻮدة إﱃ اﻷرض:ﻧﺤﻮ ذﻛﺎء اﺻﻄﻨﺎﻋﻲﻣﺴﺘﺪام
دﻋﻮﻧﻲ أﻋﻮد إﱃ املﺸﻜﻠﺔ اﻟﻌﻤﻠﻴﺔﺟﺪٍّاﻟﻸوﻟﻮﻳﺎت واملﺨﺎﻃﺮ اﻟﺤﺎﻟﻴﺔ واﻟﺤﻘﻴﻘﻴﺔ املُﺘﻌﻠﻘﺔ
ﺑﺘﻐريﱡ املﻨﺎخ.ﻣﺎذاﻳﺠﺐ أنﺗﻔﻌﻞ أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﺳﻴﺎﺳﺎﺗﻪﰲﺿﻮءﻫﺬه
اﻟﺘﺤﺪﻳﺎت؟ وﻋﻨﺪﻣﺎﺗﻜﻮنﻫﻨﺎكﺧﻼﻓﺎتﺑﺸﺄنﻗﻴﻤﺔﺣﻴﺎة اﻟﻜﺎﺋﻨﺎتﻏري اﻟﺒﴩﻳﺔ،ﻓﻜﻴﻒ
ﻳُﻤﻜﻦﺣﻠﻬﺎ؟ﺳﻴﺘﻔﻖﻣﻌﻈﻢ اﻟﻨﺎسﻋﲆ أنﺗﺴﻠﻴﻢ اﻟﺴﻴﻄﺮة إﱃ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أو
اﻟﻬﺮوبﻣﻦ اﻷرضﻟﻴﺴﺖﺣﻠﻮﻻًﺟﻴﺪة.ﻟﻜﻦﻣﺎﻫﻮ اﻟﺤﻞ اﻟﺠﻴﺪ؟ وﻫﻞﻳُﻮﺟَﺪﺣﻞ؟ إذاﻣﺎ
أﺟﺒﻨﺎ إﺟﺎﺑﺔًﻧﺎﻓﻌﺔﻋﲆﻫﺬه اﻷﺳﺌﻠﺔ،ﻓﺴﺘﻘﻮدﻧﺎﺑﺎﻟﴬورة إﱃ اﻷﺳﺌﻠﺔ اﻟﻔﻠﺴﻔﻴﺔ املﺘﻌﻠﻘﺔ
ﺑﻜﻴﻔﻴﺔﺗﻌﺎﻣُﻠﻨﺎﺑﻮﺻﻔﻨﺎﺑﴩًاﻣﻊ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻣﻊﺑﻴﺌﺘﻨﺎ.ﻛﻤﺎﺗﻘﻮدﻧﺎ أﻳﻀًﺎ إﱃ اﻟﻔﺼﻞ
املﺘﻌﻠﻖﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ:ﻣﺎذاﻳﻤﻜﻦ أنﻳﻔﻌﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻋﻠﻢ اﻟﺒﻴﺎﻧﺎتﻣﻦ أﺟﻠﻨﺎ،
وﻣﺎذاﻳُﻤﻜﻨﻨﺎ أنﻧﺘﻮﻗﱠﻊﻣﻦ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻨﻄﻘﻴٍّﺎ؟
ﻣﻦ اﻟﻮاﺿﺢ أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﻤﻜﻦ أنﻳﺴﺎﻋﺪﻧﺎﰲ اﻟﺘﺼﺪيﻟﻠﻤﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ.
ﻓﻠﻨُﻔﻜﺮﻣﺜﻼًﰲﺗﻐريﱡ املﻨﺎخ.ﻳﺒﺪو أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻳﺴﺘﻄﻴﻊﻋﲆﻧﺤﻮٍ اﺳﺘﺜﻨﺎﺋﻲ أن
ﻳﺴﺎﻋﺪﻧﺎﰲﻣﻮاﺟﻬﺔﻣﺜﻞﻫﺬه املﺸﻜﻼت املﻌﻘﱠﺪة. إذﻳﻤﻜﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺴﺎﻋﺪﺗﻨﺎ
ﰲ دراﺳﺔ املﺸﻜﻠﺔ،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﻦﺧﻼل اﻛﺘﺸﺎف اﻷﻧﻤﺎط اﻟﺘﻲﻻﻳُﻤﻜﻨﻨﺎ رؤﻳﺘﻬﺎ
ﰲ اﻟﺒﻴﺎﻧﺎت اﻟﺒﻴﺌﻴﺔ،ﻧﻈﺮًا إﱃﻛﺜﺮةﻫﺬه اﻟﺒﻴﺎﻧﺎت وﺗﻌﻘﻴﺪﻫﺎ.ﻛﻤﺎﻳﻤﻜﻦ أنﻳﺴﺎﻋﺪﻧﺎﰲ
اﻟﺤﻠﻮل،ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻣﻦﺧﻼلﻣﺴﺎﻋﺪﺗﻨﺎﰲ اﻟﺘﻌﺎﻣﻞﻣﻊﺗﻌﻘﻴﺪﻋﻤﻠﻴﺎت اﻟﺘﻨﺴﻴﻖ وﰲ
ﺗﻨﻔﻴﺬﺗﺪاﺑريﻣﺜﻞﺗﻘﻠﻴﻞ اﻧﺒﻌﺎﺛﺎت املﻮاد اﻟﻀﺎرة،ﻛﻤﺎ اﻗﱰحﻓﻠﻮرﻳﺪي وآﺧﺮون )٨١٠٢(.
وﻋﲆﻧﻄﺎق أوﺳﻊ،ﻳﻤﻜﻦ أنﻳﺴﺎﻋﺪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﻦﺧﻼلﻣﺮاﻗﺒﺔ وﻧﻤﺬﺟﺔ اﻷﻧﻈﻤﺔ
اﻟﺒﻴﺌﻴﺔ وﺗﻤﻜنيﺣﻠﻮلﻣﺜﻞ اﻟﺸﺒﻜﺎت اﻟﺬﻛﻴﺔﻟﻠﻄﺎﻗﺔ واﻟﺰراﻋﺔ اﻟﺬﻛﻴﺔ،ﻛﻤﺎ اﻗﱰﺣﺖﻣُﺪوﻧﺔ
(. وﻳﻤﻜﻦﻟﻠﺤﻜﻮﻣﺎت وﻟﻠﴩﻛﺎت أﻳﻀًﺎ أنHerweijer 2018)املﻨﺘﺪى اﻻﻗﺘﺼﺎدي اﻟﻌﺎملﻲ
ﺗﺘﻮﱃﱠ اﻷﻣﺮﻫﻨﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل، اﺳﺘﺨﺪﻣﺖﺟﻮﺟﻞﺑﺎﻟﻔﻌﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻟﺘﻘﻠﻴﻞ
اﺳﺘﺨﺪام اﻟﻄﺎﻗﺔﰲﻣﺮاﻛﺰ اﻟﺒﻴﺎﻧﺎت.
وﻣﻊ ذﻟﻚ،ﻻﻳﻌﻨﻲﻫﺬاﺑﺎﻟﴬورة »إﻧﻘﺎذ اﻟﻜﻮﻛﺐ«.ﻳﻤﻜﻦﻟﻠﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ أﻳﻀًﺎ
أنﻳُﺴﺒﺐﻣﺸﻜﻼت وﻳﺠﻌﻞ اﻷﻣﻮر أﺳﻮأ. وﻟﻨﻔﻜﺮﻣﺮةً أﺧﺮىﰲ اﻟﺘﺄﺛري اﻟﺒﻴﺌﻲ اﻟﺴﻠﺒﻲ اﻟﺬي
ﻳﻤﻜﻦ أنﻳُﺨﻠﻔﻪ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻧﻈﺮًا إﱃ اﻟﻄﺎﻗﺔ واﻟﺒِﻨﻰ اﻟﺘﺤﺘﻴﺔ واملﻮاد اﻟﺘﻲﻳﻌﺘﻤِﺪ
ﻋﻠﻴﻬﺎ. وﻟﻨﻔﻜﺮﻟﻴﺲﻓﻘﻂﰲ اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ وﻟﻜﻦ أﻳﻀًﺎﰲ إﻧﺘﺎﺟﻪ:ﻗﺪﺗﻜﻮن
اﻟﻜﻬﺮﺑﺎءﻣُﻨﺘﺠَﺔﺑﻄﺮقﻏريﻣﺴﺘﺪاﻣﺔ،ﻛﻤﺎ أن إﻧﺘﺎج اﻷﺟﻬﺰة املﺪﻋﻮﻣﺔﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳﺴﺘﻬﻠﻚ اﻟﻄﺎﻗﺔ واملﻮاد اﻟﺨﺎم وﻳﻨﺘﺞﻧﻔﺎﻳﺎت. أوﻓﻠﻨﻔﻜﺮﰲ »اﻟﺪﻓﻊ اﻟﺬاﺗﻲ« اﻟﺬي اﻗﱰﺣﻪ
131</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻓﻠﻮرﻳﺪي وآﺧﺮون؛ إذﻳﻘﱰﺣﻮن أن اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺪﻳُﺴﺎﻋﺪﻧﺎﰲ اﻟﺘﴫفﺑﻄﺮقٍﺑﻴﺌﻴﺔ
ﺟﻴﺪةﻋﻦﻃﺮﻳﻖﻣﺴﺎﻋﺪﺗﻨﺎﰲ اﻻﻟﺘﺰامﺑﺨﻴﺎرﻧﺎ املﻔﺮوض ذاﺗﻴٍّﺎ. وﻟﻜﻦﻫﺬا اﻷﻣﺮﻳﻨﻄﻮي
ﻋﲆﻣَﺨﺎﻃﺮه اﻷﺧﻼﻗﻴﺔ اﻟﺨﺎﺻﺔ:ﻓﻠﻴﺲﻣﻦ اﻟﻮاﺿﺢ أﻧﻪﻳﺤﱰم اﺳﺘﻘﻼل اﻟﺒﴩ وﻛﺮاﻣﺘﻬﻢ،
ﻛﻤﺎﻳﺪﻋﻲ اﻟﻜُﺘﱠﺎب، وﻗﺪﻳﺴريﰲ اﺗﺠﺎه اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺤﻤﻴﺪ اﻟﺬيﻳﻌﺘﻨﻲﺑﺎﻟﺒﴩﻟﻜﻨﻪ
ﻳُﺪﻣﺮﺣﺮﻳﺘﻬﻢ وﻳُﺴﺎﻫﻢﰲﻣﺸﻜﻠﺔﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي. وﻫﻨﺎكﻋﲆ اﻷﻗﻞﺧﻄﻮرةﻓﺮض
أﺷﻜﺎلٍﺟﺪﻳﺪةﻣﻦ اﻟﺴﻠﻄﺔ اﻷﺑﻮﻳﺔ واﻻﺳﺘﺒﺪاد.ﻋﻼوةًﻋﲆ ذﻟﻚ،ﻗﺪﻳﺘﻤﺎﳽ اﺳﺘﺨﺪام اﻟﺬﻛﺎء
اﻻﺻﻄﻨﺎﻋﻲ ملﻮاﺟﻬﺔﺗﻐريﱡ املﻨﺎخﻣﻊ اﻟﻨﻈﺮة اﻟﻌﺎملﻴﺔ اﻟﺘﻲﺗُﺤﻮﱢل اﻟﻌﺎﻟﻢ إﱃﻣﺠﺮدﻣُﺴﺘﻮدع
ﺑﻴﺎﻧﺎت وﻣﻊ اﻟﺮؤﻳﺔ اﻟﺘﻲﺗﺨﺘﺰل ذﻛﺎء اﻹﻧﺴﺎن إﱃﻣﻌﺎﻟﺠﺔ اﻟﺒﻴﺎﻧﺎت؛ﺑﻞ رﺑﻤﺎﻧﻮع أدﻧﻰ
ﻣﻦﻣﻌﺎﻟﺠﺔ اﻟﺒﻴﺎﻧﺎتﻳﺘﻄﻠﱠﺐ اﻟﺘﺤﺴنيﺑﻮاﺳﻄﺔ اﻵﻻت. وﻣﻦﻏري املُﺮﺟﱠﺢ أنﺗﻌﻴﺪﻣﺜﻞﻫﺬه
اﻟﺮؤىﺗﺸﻜﻴﻞﻋﻼﻗﺘﻨﺎﺑﺎﻟﺒﻴﺌﺔﺑﻄﺮﻳﻘﺔﺗُﺨﻔﱢﻒ اﻟﺘﺤﺪﻳﺎتﻣﺜﻞﺗﻐريﱡ املﻨﺎخ واملﺸﻜﻼت املﺸﺎر
إﻟﻴﻬﺎﺑﻤﺼﻄﻠﺢ اﻟﺘﺄﺛري اﻟﺒﴩي.
ﻧﻮاﺟﻪ أﻳﻀًﺎﺧﻄﺮ اﻟﻨﺰﻋﺔﻟﻠﺤﻠﻮل اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔﺑﻤﻌﻨﻰ أن اﻻﻗﱰاﺣﺎتﻻﺳﺘﺨﺪام
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ ملﻌﺎﻟﺠﺔ املﺸﻜﻼت اﻟﺒﻴﺌﻴﺔﻳُﻤﻜﻦ أنﺗﻔﱰض أنﻫﻨﺎكﺣﻼٍّﻧﻬﺎﺋﻴٍّﺎﻟﺠﻤﻴﻊ
املﺸﻜﻼت، وأن اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﺣﺪَﻫﺎﻳﻤﻜﻦ أنﺗُﺠﻴﺐﻋﻦ أﺻﻌﺐ أﺳﺌﻠﺘﻨﺎ، وأﻧﻨﺎﻳﻤﻜﻦ أن
ﻧﺤﻞ املﺸﻜﻼتﺑﺎﻟﻜﺎﻣﻞﻋﻦﻃﺮﻳﻖ اﺳﺘﺨﺪام اﻟﺬﻛﺎء اﻟﺒﴩي أو اﻻﺻﻄﻨﺎﻋﻲ. وﻟﻜﻦ املﺸﻜﻼت
اﻟﺒﻴﺌﻴﺔﻻﻳﻤﻜﻦﺣﻠﱡﻬﺎﻋﻦﻃﺮﻳﻖ اﻟﺬﻛﺎء اﻟﺘﻜﻨﻮﻟﻮﺟﻲ واﻟﻌﻠﻤﻲ؛ﻓﻬﻲﻣﺮﺗﺒﻄﺔ أﻳﻀًﺎﺑﺎملﺸﻜﻼت
اﻟﺴﻴﺎﺳﻴﺔ واﻻﺟﺘﻤﺎﻋﻴﺔ اﻟﺘﻲﻻﻳﻤﻜﻦ اﻟﺘﺼﺪيﻟﻬﺎﺑﺎﻟﻜﺎﻣﻞﻋﻦﻃﺮﻳﻖ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﺣﺪَﻫﺎ.
ﻛﻤﺎ أن املﺸﻜﻼت اﻟﺒﻴﺌﻴﺔ داﺋﻤًﺎﻣﺎﺗﻜﻮنﻣﺸﻜﻼتٍﺑﴩﻳﺔ. واﻟﺮﻳﺎﺿﻴﺎت وذُرﻳﺘﻬﺎ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ
ﻫﻲ أدواتﻣُﻔﻴﺪةﺟﺪٍّا، وﻟﻜﻨﻬﺎﻣﺤﺪودةﻓﻴﻤﺎﻳﺘﻌﻠﻖﺑﻔﻬﻢ املﺸﻜﻼت اﻟﺒﴩﻳﺔ واﻟﺘﻌﺎﻣُﻞ
ﻣﻌﻬﺎ.ﻋﲆﺳﺒﻴﻞ املﺜﺎل،ﻗﺪﺗﺘﻌﺎرَض اﻟﻘِﻴَﻢ. وﻟﻦﻳﺴﺘﻄﻴﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﺑﺎﻟﴬورة
أنﻳُﺴﺎﻋﺪﻧﺎﰲ اﻹﺟﺎﺑﺔﻋﻦ اﻟﺴﺆالﺣﻮل اﻷوﻟﻮﻳﺎت، وﻫﻮﺳﺆال أﺧﻼﻗﻲ وﺳﻴﺎﳼﻣُﻬﻢﻳﺠﺐ
أنﻧﱰكﻟﻠﺒﴩ اﻹﺟﺎﺑﺔﻋﻨﻪ. وﺗُﻌﻠﱢﻤﻨﺎ اﻟﻌﻠﻮم اﻹﻧﺴﺎﻧﻴﺔ واﻻﺟﺘﻤﺎﻋﻴﺔ أنﻧﻜﻮنﺣﺬِرﻳﻦﺟﺪٍّا
ﺑﺸﺄن اﻟﺤﻠﻮل »اﻟﻨﻬﺎﺋﻴﺔ«.
ﻋﻼوةًﻋﲆ ذﻟﻚ، اﻟﺒﴩﻟﻴﺴﻮا اﻟﻮﺣﻴﺪِﻳﻦ اﻟﺬﻳﻦﺗُﻮاﺟﻬﻬﻢﻣﺸﻜﻼت؛ﻓﺎﻟﻜﺎﺋﻨﺎتﻏري
اﻟﺒﴩﻳﺔ أﻳﻀًﺎﺗﻮاﺟﻬﻬﺎﺻﻌﻮﺑﺎت، واﻟﺘﻲﻏﺎﻟﺒًﺎﻣﺎﺗُﻬﻤَﻞﰲ املﻨﺎﻗﺸﺎت اﻟﺨﺎﺻﺔﺑﻤﺴﺘﻘﺒﻞ
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ. وأﺧريًا، اﻟﺮأي اﻟﻘﺎﺋﻞﺑﺄﻧﻨﺎﻳﺠِﺐ أنﻧﻬﺮبﻣﻦ اﻷرض، أو اﻟﺮؤﻳﺔ اﻟﻌﺎملﻴﺔ
اﻟﺘﻲﺗﻘﻮل إنﻛﻞﳾءٍﻋﺒﺎرةﻋﻦﺑﻴﺎﻧﺎتﻧﺴﺘﻄﻴﻊﻧﺤﻦ اﻟﺒﴩ اﻟﺘﻼﻋُﺐﺑﻬﺎﺑﻤﺴﺎﻋﺪة اﻵﻻت،
ﻳﻤﻜﻦ أنﻳﺆدﱢﻳﺎﰲ اﻟﻨﻬﺎﻳﺔ إﱃﺗﻮﺳﻴﻊ اﻟﻔﺠﻮةﺑني اﻷﻏﻨﻴﺎء واﻟﻔﻘﺮاء وإﱃ أﺷﻜﺎلٍ أوﺳﻊﻧﻄﺎﻗًﺎ
132</p>
<p>ﺗﺤﺪﱢيﺗﻐريﱡ املﻨﺎخ:ﺣﻮل اﻷوﻟﻮﻳﺎت وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي
ﻣﻦ اﻻﺳﺘﻐﻼل واﻻﻧﺘﻬﺎﻛﺎتﻟﻠﻜﺮاﻣﺔ اﻹﻧﺴﺎﻧﻴﺔ،ﺑﺎﻹﺿﺎﻓﺔ إﱃﺗﻬﺪﻳﺪﺣﻴﺎة اﻷﺟﻴﺎل اﻟﻘﺎدﻣﺔ
ﻋﻦﻃﺮﻳﻖ املﺨﺎﻃﺮةﺑﺘﺪﻣريﻇﺮوف اﻟﺤﻴﺎةﻋﲆﻛﻮﻛﺒﻨﺎ. إﻧﻨﺎﻧﺤﺘﺎج إﱃ اﻟﺘﻔﻜري اﻟﻌﻤﻴﻖﰲ
ﻛﻴﻔﻴﺔﺑﻨﺎءﻣﺠﺘﻤﻌﺎت وﺑﻴﺌﺎتﻣُﺴﺘﺪاﻣﺔ؛ إﻧﻨﺎﻧﺤﺘﺎج إﱃ اﻟﺘﻔﻜري اﻟﺒﴩي.
اﻟﺬﻛﺎء واﻟﺤﻜﻤﺔ
وﻣﻊ ذﻟﻚ،ﻓﻄﺮﻳﻘﺔﺗﻔﻜري اﻟﺒﴩﻟﻬﺎﺟﻮاﻧﺐﻣُﺘﻌﺪدة أﻳﻀًﺎ. واﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻣﺮﺗﺒﻂ
ﺑﻨﻮعٍ واﺣﺪﻣﻦ أﻧﻮاع اﻟﺘﻔﻜري اﻟﺒﴩي واﻟﺬﻛﺎء اﻟﺒﴩي: اﻟﻨﻮع املﻌﺮﰲ اﻷﻛﺜﺮﺗﺠﺮﻳﺪًا.ﻫﺬا
اﻟﻨﻮعﻣﻦ اﻟﺘﻔﻜريﻗﺪ أﺛﺒﺖﻧﺠﺎﺣًﺎﻛﺒريًا، وﻟﻜﻨﻪﻟﻪﻗﻴﻮده وﻫﻮﻟﻴﺲ اﻟﻨﻮع اﻟﻮﺣﻴﺪﻣﻦ
اﻟﺘﻔﻜري اﻟﺬيﻳُﻤﻜﻦ أوﻳﺠﺐﻋﻠﻴﻨﺎﻣُﻤﺎرﺳﺘﻪ. واﻹﺟﺎﺑﺔﻋﻦ اﻷﺳﺌﻠﺔ اﻷﺧﻼﻗﻴﺔ واﻟﺴﻴﺎﺳﻴﺔ
املُﺘﻌﻠﻘﺔﺑﻜﻴﻔﻴﺔ اﻟﻌﻴﺶ، وﻛﻴﻔﻴﺔ اﻟﺘﻌﺎﻣُﻞﻣﻊﺑﻴﺌﺘﻨﺎ، وﻛﻴﻔﻴﺔ اﻟﺘﻌﺎﻣُﻞﺑﺸﻜﻞٍ أﻓﻀﻞﻣﻊ
اﻟﻜﺎﺋﻨﺎت اﻟﺤﻴﺔﻏري اﻟﺒﴩﻳﺔﺗﺘﻄﻠﱠﺐﻣﺎﻫﻮ أﻛﺜﺮﻣﻦ اﻟﺬﻛﺎء اﻟﺒﴩي اﻟﺘﺠﺮﻳﺪي )ﻋﲆﺳﺒﻴﻞ
املﺜﺎل، اﻟﺤُﺠﺞ، واﻟﻨﻈﺮﻳﺎت، واﻟﻨﻤﺎذج( أو اﻟﺘﻌﺮﱡفﻋﲆ اﻷﻧﻤﺎطﺑﻮاﺳﻄﺔ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ.
أذﻛﻴﺎء وآﻻت ذﻛﻴﺔ، وﻟﻜﻨﻨﺎ أﻳﻀًﺎﺑﺤﺎﺟﺔٍ إﱃ اﻟﺤﺪس واﻟﺨﱪة اﻟﺘﻲﻻ
ﻧﺤﺘﺎج إﱃ أﺷﺨﺎصٍ
ﻳﻤﻜﻦ وﺻﻔُﻬﺎﺑﻮﺿﻮحﻛﺎﻣﻞ، وﻧﺤﺘﺎج إﱃ اﻟﺘﺤﲇﱢﺑﺎﻟﺤﻜﻤﺔ اﻟﻌﻤﻠﻴﺔ واﻟﻔﻀﻴﻠﺔ اﺳﺘﺠﺎﺑﺔً إﱃ
املﺸﻜﻼت واملﻮاﻗﻒ املﺎدﻳﺔ وﻣﻦ أﺟﻞﺗﺤﺪﻳﺪ أوﻟﻮﻳﺎﺗﻨﺎ.ﻗﺪﺗﺴﺘﻨريﻫﺬه اﻟﺤﻜﻤﺔﺑﺎﻟﻌﻤﻠﻴﺎت
املﻌﺮﻓﻴﺔ اﻟﺘﺠﺮﻳﺪﻳﺔ وﺑﺘﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎت، وﻟﻜﻨﻬﺎﺗﺴﺘﻨﺪ أﻳﻀًﺎ إﱃ اﻟﺘﺠﺎرب املُﺘﺠﺴﱢﺪة اﻟﺨﺎﺻﺔ
ﺑﺎﻟﻌﻼﻗﺎت واملﻮاﻗﻒ اﻟﺘﻲﻧﻤﺮﱡﺑﻬﺎﰲ اﻟﻌﺎﻟﻢ، وإﱃ اﻟﺘﻌﺎﻣُﻞﻣﻊ أﺷﺨﺎص آﺧﺮﻳﻦ، وﻣﻊ املﺎدﻳﺔ،
وﻣﻊﺑﻴﺌﺘﻨﺎ اﻟﻄﺒﻴﻌﻴﺔ. وﻣﻦ املُﺤﺘﻤﻞ أنﻳﻌﺘﻤﺪﻧﺠﺎﺣﻨﺎﰲ اﻟﺘﺼﺪيﻟﻠﻤﺸﻜﻼت اﻟﻜﺒرية اﻟﺘﻲ
ﺗُﻮاﺟﻬﻨﺎﰲﻋﴫﻧﺎﻋﲆﻣﺰﻳﺞﻣﻦ اﻟﺬﻛﺎء اﻟﺘﺠﺮﻳﺪي — اﻟﺒﴩي واﻻﺻﻄﻨﺎﻋﻲ — واﻟﺤﻜﻤﺔ
اﻟﻌﻤﻠﻴﺔ املﻠﻤﻮﺳﺔ اﻟﺘﻲﺗﻢﺗﻄﻮﻳﺮﻫﺎﻋﲆ أﺳﺎس اﻟﺘﺠﺎرب واملُﻤﺎرﺳﺎت اﻟﺒﴩﻳﺔ املﻠﻤﻮﺳﺔ
واﻟﺨﺎﺻﺔﺑﺎملﻮاﻗﻒ،ﺑﻤﺎﰲ ذﻟﻚﺗﺠﺎرﺑﻨﺎﻣﻊ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ. وأﻳٍّﺎﻛﺎن اﻻﺗﺠﺎه اﻟﺬيﺳﻴﺴري
ﻓﻴﻪﺗﻄﻮﻳﺮ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ،ﻓﺈن اﻟﺒﴩ وﺣﺪَﻫﻢﻫﻢﻣَﻦﻳُﻮاﺟِﻬﻮنﺗﺤﺪﱢيﺗﻄﻮﻳﺮﻫﺬا
اﻟﻨﻮع اﻷﺧريﻣﻦ املﻌﺮﻓﺔ واﻟﺘﻌﻠﻢ. وﻋﲆ اﻟﺒﴩ أنﻳﺘﺼﺪﱠواﻟﻪ.ﻓﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲﻗﺎدرﻋﲆ
اﻟﺘﻌﺮﱡفﻋﲆ اﻷﻧﻤﺎط، وﻟﻜﻦ اﻟﺤﻜﻤﺔﻻﻳﻤﻜﻦﺗﻔﻮﻳﻀﻬﺎ إﱃ اﻵﻻت.
133</p>
</section>
<section id="section-14">
    <h2>مسرد المصطلحات</h2>
    <div class="page-range">Pages 135-138</div>
    <p>ﻣﴪد اﳌﺼﻄﻠﺤﺎت
ﻧﻬﺞﻳﻤﻴﻞ إﱃﺟﻌﻞ اﻻﺑﺘﻜﺎر أﻛﺜﺮ أﺧﻼﻗﻴﺔ وﻣﺴﺌﻮﻟﻴﺔﻋﲆ اﻟﺼﻌﻴﺪ:اﻻﺑﺘﻜﺎر املﺴﺌﻮل
املﺠﺘﻤﻌﻲ، وﻳﻨﻄﻮيﻋﺎدةًﻋﲆﺗﻀﻤني اﻷﺧﻼقﰲ اﻟﺘﺼﻤﻴﻢ وﻣﺮاﻋﺎة آراء أﺻﺤﺎب اﻟﺸﺄن
وﻣﺼﺎﻟﺤﻬﻢ.
اﻷﺧﻼﻗﻴﺎت املﺮﺗﺒﻄﺔﺑﺎﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳﻨﺒﻐﻲ أنﻧﻌﻴﺶﺑﻬﺎ )ﻣﻌًﺎ(،:اﻷﺧﻼﻗﻴﺎت اﻹﻳﺠﺎﺑﻴﺔ
وﺗﺴﺘﻨﺪ إﱃ رؤﻳﺔﻟﻠﺤﻴﺎة اﻟﺠﻴﺪة واملﺠﺘﻤﻊ اﻟﺠﻴﺪ. وﺗﺘﻨﺎﻗﺾﻣﻊ اﻷﺧﻼﻗﻴﺎت اﻟﺴﻠﺒﻴﺔ، اﻟﺘﻲ
ﺗﻀﻊﻗﻴﻮدًا وﺗﺤﺪدﻣﺎﻳﻨﺒﻐﻲ أﻻﻧﻔﻌﻠﻪ.
ﻧﻬﺞﻷﺧﻼﻗﻴﺎت اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ وﻋﻨﴫ أﺳﺎﳼﰲ:اﻷﺧﻼﻗﻴﺎت املُﻀﻤﱠﻨﺔﰲ اﻟﺘﺼﻤﻴﻢ
»اﻻﺑﺘﻜﺎر املﺴﺌﻮل« اﻟﺬيﻳﻬﺪف إﱃ دﻣﺞ اﻷﺧﻼﻗﻴﺎتﰲﻣﺮﺣﻠﺔﺗﺼﻤﻴﻢ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
وﺗﻄﻮﻳﺮﻫﺎ. وﰲﺑﻌﺾ اﻷﺣﻴﺎن،ﻧُﺴﻤﻴﻬﺎ »ﺗﻀﻤني اﻟﻘﻴﻢﰲ اﻟﺘﺼﻤﻴﻢ«. وﻣﻦ املﺼﻄﻠﺤﺎت
املﺸﺎﺑﻬﺔﻟﻬﺬا املﺼﻄﻠﺢ »اﻟﺘﺼﻤﻴﻢ اﻟﺤﺴﱠﺎسﻟﻠﻘِﻴَﻢ« و»اﻟﺘﺼﻤﻴﻢ املُﺘﻤﺎﳾﻣﻊ اﻷﺧﻼق«.
اﻻﻋﺘﻘﺎدﺑﺄن اﻟﺒﴩﻳﺠِﺐ أنﻳُﻌﺰزوا أﻧﻔﺴﻬﻢﻣﻦﺧﻼل اﻟﺘﻘﻨﻴﺎت:ﺗﺠﺎوز اﻹﻧﺴﺎﻧﻴﺔ
املُﺘﻘﺪﻣﺔ، وﺑﻬﺬه اﻟﻄﺮﻳﻘﺔﻳﺘﺠﺎوزونﺣﺎﻟﺘﻬﻢ اﻹﻧﺴﺎﻧﻴﺔ؛ﺑﻤﻌﻨﻰ أن اﻹﻧﺴﺎﻧﻴﺔﻳﺠﺐ أن
ﺗﻨﺘﻘِﻞ إﱃﻣﺮﺣﻠﺔﺟﺪﻳﺪة. وﻫﺬه أﻳﻀًﺎﺣﺮﻛﺔ دوﻟﻴﺔ.
اﻟﺘﻤﻴﻴﺰﺿﺪ أوﻟﺼﺎﻟﺢ أﻓﺮادﺑﺄﻋﻴُﻨﻬﻢ أوﻣﺠﻤﻮﻋﺎتﺑﻌﻴﻨﻬﺎ.ﰲﺳﻴﺎق اﻷﺧﻼﻗﻴﺎت:اﻟﺘﺤﻴﺰ
.واﻟﺴﻴﺎﺳﺔ،ﻳُﺜﺎر اﻟﺴﺆالﺣﻮلﻣﺎ إذاﻛﺎنﺗَﺤﻴﱡﺰﻣﻌنيﻇﺎملًﺎ أوﻏريﻋﺎدل
آﻟﺔ أوﺑﺮﻧﺎﻣﺞﻳُﻤﻜﻨﻪ أنﻳﺘﻌﻠﻢﺗﻠﻘﺎﺋﻴٍّﺎ:ﻟﻴﺲﺑﺎﻟﻄﺮﻳﻘﺔ اﻟﺘﻲﻳﺘﻌﻠﱠﻢﺑﻬﺎ اﻟﺒﴩ،:ﺗﻌﻠﱡﻢ اﻵﻟﺔ
وﻟﻜﻦﺑﻨﺎءًﻋﲆﻋﻤﻠﻴﺔﺣﺴﺎﺑﻴﺔ وإﺣﺼﺎﺋﻴﺔ.ﻳﻤﻜﻦﻟﺨﻮارزﻣﻴﺎت اﻟﺘﻌﻠﱡﻢ،ﻣﻦﺧﻼلﺗﻐﺬﻳﺘﻬﺎ
ﺑﺎﻟﺒﻴﺎﻧﺎت،ﺗﺤﺪﻳﺪ اﻷﻧﻤﺎط أو اﻟﻘﻮاﻋﺪﰲ اﻟﺒﻴﺎﻧﺎت وإﺟﺮاءﺗﻮﻗﻌﺎتﻟﻠﺒﻴﺎﻧﺎت املﺴﺘﻘﺒﻠﻴﺔ.</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﺷﻜﻞﻣﻦ أﺷﻜﺎل »ﺗﻌﻠﻢ اﻵﻟﺔ«ﻳﺴﺘﺨﺪم اﻟﺸﺒﻜﺎت اﻟﻌﺼﺒﻴﺔ املﻜﻮﻧﺔﻣﻦﻋﺪة:اﻟﺘﻌﻠﱡﻢ اﻟﻌﻤﻴﻖ
.ﻃﺒﻘﺎتﻣﻦ »اﻟﺨﻼﻳﺎ اﻟﻌﺼﺒﻴﺔ«: وﺣﺪاتﻣُﻌﺎﻟﺠﺔﺑﺴﻴﻄﺔﻣﱰاﺑﻄﺔﻓﻴﻤﺎﺑﻴﻨﻬﺎ وﺗﺘﻔﺎﻋﻞ
اﻟﻔﻜﺮة اﻟﺘﻲﺗﻘﻮلﺑﺄﻧﻪﺳﺘﺤنيﻟﺤﻈﺔﰲﺗﺎرﻳﺦ اﻹﻧﺴﺎنﻋﻨﺪﻣﺎ:اﻟﺘﻔﺮﱡد اﻟﺘﻜﻨﻮﻟﻮﺟﻲ
.ﻳﺠﻠﺐ اﻧﻔﺠﺎرﰲ اﻟﺬﻛﺎء اﻵﱄﺗﻐﻴريًاﺟﺬرﻳٍّﺎﰲﺣﻀﺎرﺗﻨﺎﻳﺠﻌﻠﻨﺎﻻﻧﻔﻬﻢﺑﻌﺪﻫﺎﻣﺎﻳﺤﺪث
اﻟﺤﻘﺒﺔ اﻟﺠﻴﻮﻟﻮﺟﻴﺔ اﻟﺤﺎﻟﻴﺔ املﺰﻋﻮﻣﺔ اﻟﺘﻲ زادت:(ﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي )اﻷﻧﺜﺮوﺑﻮﺳني
.ﻓﻴﻬﺎﻗﻮة اﻟﺒﴩ وﺗﺄﺛريﻫﻢﻋﲆ اﻷرض وﻧﻈﻤﻬﺎ اﻟﺒﻴﺌﻴﺔ،ﻣﻤﺎﺟﻌﻞ اﻟﺒﴩﻗﻮةﺟﻴﻮﻟﻮﺟﻴﺔ
اﻟﺬﻛﺎء اﻟﺬيﺗُﻈﻬﺮه أوﺗُﺤﺎﻛﻴﻪ اﻟﻮﺳﺎﺋﻞ اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺔ.ﻏﺎﻟﺒًﺎﻣﺎ:اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
ﻳُﻔﱰض أنﻣﻌﻨﻰ »اﻟﺬﻛﺎء«ﰲﻫﺬا اﻟﺘﻌﺮﻳﻒﻳﺴﺘﻨﺪ إﱃﻣﻘﺎﻳﻴﺲ اﻟﺬﻛﺎء اﻟﺒﴩي، وﻳُﻘﺼَﺪ
ﺑﻪ اﻟﻘﺪرات واﻟﺴﻠﻮﻛﻴﺎت اﻟﺬﻛﻴﺔ اﻟﺘﻲﻳُﻈﻬﺮﻫﺎ اﻟﺒﴩ. وﻳﻤﻜﻦ أﻳﻀًﺎ أنﻳُﺸري املﺼﻄﻠﺢ
إﱃ اﻟﻌﻠﻢ أو إﱃ اﻟﺘﻘﻨﻴﺎت،ﻣﺜﻞﺧﻮارزﻣﻴﺎت اﻟﺘﻌﻠﻢ.
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳﻤﻜﻦﻟﻺﻧﺴﺎن اﻟﻮﺛﻮقﻓﻴﻪ.:اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺠﺪﻳﺮﺑﺎﻟﺜﻘﺔ
ﻳﻤﻜﻦ أنﺗُﺸريﴍوطﻫﺬه اﻟﺜﻘﺔ إﱃﻣﺒﺎدئ أﺧﻼﻗﻴﺔ )أﺧﺮى(ﻣﺜﻞ اﻟﻜﺮاﻣﺔ اﻹﻧﺴﺎﻧﻴﺔ
واﺣﱰامﺣﻘﻮق اﻹﻧﺴﺎن، وﻣﺎ إﱃ ذﻟﻚ، و/أو إﱃ اﻟﻌﻮاﻣﻞ اﻻﺟﺘﻤﺎﻋﻴﺔ واﻟﺘﻘﻨﻴﺔ اﻟﺘﻲﺗﺆﺛﺮ
ﻓﻴﻤﺎ إذاﻛﺎن اﻟﻨﺎسﻳﺮﻏﺒﻮنﰲ اﺳﺘﺨﺪام اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ. اﺳﺘﺨﺪامﻣﺼﻄﻠﺢ »اﻟﺜﻘﺔ«ﻓﻴﻤﺎ
ﻳﺘﻌﻠﻖﺑﺎﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎﻣُﺜريﻟﻠﺠﺪل.
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳﻌﺘﻤﺪﻋﲆ اﻟﺘﻤﺜﻴﻼت اﻟﺮﻣﺰﻳﺔ:اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺮﻣﺰي
ﻟﻠﻤﻬﺎم املﻌﺮﻓﻴﺔ اﻟﻌﻠﻴﺎ،ﻣﺜﻞ اﻟﺘﻔﻜري املﺠﺮد واﺗﺨﺎذ اﻟﻘﺮارات. وﻳﻤﻜﻦ أنﻳﺴﺘﺨﺪمﺷﺠﺮة
اﺗﺨﺎذ اﻟﻘﺮار وﻳﺄﺧﺬﺷﻜﻞﻧﻈﺎمﺧﺒريﻳﺘﻄﻠﺐﻣﺪﺧﻼتﻣﻦﺧﱪاء املﺠﺎل.
اﻟﺬﻛﺎء املُﺸﺎﺑﻪﻟﺬﻛﺎء اﻟﺒﴩ، وﻳﻤﻜﻦﺗﻄﺒﻴﻘﻪﻋﲆﻧﻄﺎقٍ واﺳﻊ:اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻌﺎم
ﺑﺎملﻘﺎرﻧﺔﻣﻊ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﺤﺪود، اﻟﺬيﻳﻤﻜﻦﺗﻄﺒﻴﻘﻪﻋﲆﻣﺸﻜﻠﺔٍ أوﻣُﻬﻤﺔ
ﻣُﻌﻴﻨﺔﻓﻘﻂ. وﻳُﻄﻠﻖﻋﻠﻴﻪ أﻳﻀًﺎ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ »اﻟﻘﻮي«ﰲﻣﻘﺎﺑﻞ اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
»اﻟﻀﻌﻴﻒ«.
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳﻤﻜﻦ أنﻳﴩحﻟﻠﺒﴩ:اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﻘﺎﺑﻞﻟﻠﺘﻔﺴري
ﺗﴫﻓﺎﺗﻪ أوﻗﺮاراﺗﻪ أوﺗﻮﺻﻴﺎﺗﻪ، أوﻳﻤﻜﻦ أنﻳﻮﻓﺮﻣﻌﻠﻮﻣﺎتﻛﺎﻓﻴﺔﺣﻮلﻛﻴﻔﻴﺔ
اﻟﻮﺻﻮل إﱃﻧﺘﻴﺠﺘﻪ.
136</p>
<p>ﻣﴪد املﺼﻄﻠﺤﺎت
اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ اﻟﺬيﻳُﻤَﻜﱢﻦ وﻳﺴﺎﻫﻢﰲﻃﺮﻳﻘﺔﻋﻴﺶ:اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ املﺴﺘﺪام
ﻣﺴﺘﺪاﻣﺔﻟﻠﺒﴩﻳﺔ وﻻﻳﺪﻣﺮ اﻟﻨﻈﻢ اﻟﺒﻴﺌﻴﺔﻋﲆ اﻷرض اﻟﺘﻲﻳﻌﺘﻤﺪﻋﻠﻴﻬﺎ اﻟﺒﴩ )وأﻳﻀًﺎ
اﻟﻌﺪﻳﺪﻣﻦﻏري اﻟﺒﴩ(.
اﻟﻔﻜﺮة اﻟﺘﻲﺗﻘﻮلﺑﺄن اﻵﻻتﺳﻮفﺗﺘﻔﻮﱠقﻋﲆ ذﻛﺎء اﻹﻧﺴﺎن. وﻳﺮﺗﺒﻂ:اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ
اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ أﺣﻴﺎﻧًﺎﺑﻔﻜﺮة »اﻧﻔﺠﺎر اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ« اﻟﺬيﻳُﺴﺒﱢﺒﻪﺗﺼﻤﻴﻢ اﻵﻻت
اﻟﺬﻛﻴﺔﻵﻻت أﻛﺜﺮ ذﻛﺎءً.
ﻋﻠﻢﻣﺘﻌﺪد اﻟﺘﺨﺼﺼﺎتﻳﺴﺘﺨﺪم اﻹﺣﺼﺎءات واﻟﺨﻮارزﻣﻴﺎت وﻏريﻫﺎﻣﻦ:ﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت
اﻷﺳﺎﻟﻴﺐﻻﺳﺘﺨﺮاج أﻧﻤﺎطٍﻣﻔﻴﺪة وذاتﻣﻌﻨًﻰﻣﻦﻣﺠﻤﻮﻋﺎت اﻟﺒﻴﺎﻧﺎت؛ املﻌﺮوﻓﺔ أﺣﻴﺎﻧًﺎ
ﺑﺎﺳﻢ »اﻟﺒﻴﺎﻧﺎت اﻟﻀﺨﻤﺔ«.ﰲ اﻟﻮﻗﺖ اﻟﺤﺎﱄ،ﻳُﺴﺘﺨﺪَمﺗﻌﻠﱡﻢ اﻵﻟﺔﰲﻫﺬا املﻀﻤﺎر. وﺑﺠﺎﻧﺐ
ﺗﺤﻠﻴﻞ اﻟﺒﻴﺎﻧﺎت،ﻳﻬﺘﻢﻋﻠﻢ اﻟﺒﻴﺎﻧﺎت أﻳﻀًﺎﺑﺎﺳﺘﺨﺮاج اﻟﺒﻴﺎﻧﺎت وإﻋﺪادﻫﺎ وﺗﻔﺴريﻫﺎ.
اﻟﻘﺪرةﻋﲆ اﻟﺘﻔﺴري أوﻗﺎﺑﻠﻴﺔ اﻟﺘﻔﺴري.ﰲﺳﻴﺎق اﻷﺧﻼﻗﻴﺎت،ﻓﺈﻧﻪ:اﻟﻘﺎﺑﻠﻴﺔﻟﻠﺘﻔﺴري
ﻳُﺸري إﱃ اﻟﻘﺪرةﻋﲆ اﻟﴩحﻟﻶﺧﺮﻳﻦ ملﺎذاﻗﻤﺖَﺑﴚءﻣُﻌني أو ملﺎذا اﺗﺨﺬتﻗﺮارًاﺑﻌﻴﻨِﻪ؛
وﻫﺬاﺟﺰءﻣﻤﺎﻳَﻌﻨﻴﻪ أنﺗﻜﻮنﻣﺴﺌﻮﻻً .
ﻣﺠﻤﻮﻋﺔﻣﻦ املُﻌﺘﻘﺪات اﻟﺘﻲﺗُﺸﻜﻚﰲ اﻹﻧﺴﺎﻧﻴﺔ، وﺧﺼﻮﺻًﺎ املﻜﺎﻧﺔ:ﻣﺎﺑﻌﺪ اﻹﻧﺴﺎﻧﻴﺔ
.املﺤﻮرﻳﺔﻟﻺﻧﺴﺎن، وﺗﻮﺳﻊ داﺋﺮة اﻻﻫﺘﻤﺎم اﻷﺧﻼﻗﻲﻟﺘﺸﻤﻞﻏري اﻟﺒﴩ
ﻳﻤﻜﻦ اﺳﺘﺨﺪاﻣﻬﺎﻛﻤﺮادفٍ ملﻌﻨﻰ أنﻳﺘﺤﲆ املﺮءﺑﺎﻷﺧﻼق، وﻣﻦ:املﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔ
ﺛَﻢﻓﺈﻧﻬﺎﺗﺸري إﱃﺗﺤﻘﻴﻖﻧﺘﺎﺋﺞﺟﻴﺪة أﺧﻼﻗﻴٍّﺎ، واﻻﻟﺘﺰامﺑﺎملﺒﺎدئ اﻷﺧﻼﻗﻴﺔ، واﻟﺘﻤﺘﻊ
ﺑﺎﻟﻔﻀﻴﻠﺔ، واﺳﺘﺤﻘﺎق اﻟﺜﻨﺎء، وﻣﺎ إﱃ ذﻟﻚ؛ﺣﺴﺐ اﻟﻨﻈﺮﻳﺔ املﻌﻴﺎرﻳﺔ املُﻔﱰﺿﺔ.ﻳﻤﻜﻦ
ﻟﻠﻤﺮء أﻳﻀًﺎ أنﻳﺘﺴﺎءلﻋﻦ اﻟﴩوط اﻟﺘﻲﺑﻤﻮﺟﺒﻬﺎﻳﻤﻜﻦ إﺳﻨﺎد املﺴﺌﻮﻟﻴﺔ إﻟﻴﻪ.ﺗُﻌﺪ
ﴍوط إﺳﻨﺎد املﺴﺌﻮﻟﻴﺔ اﻷﺧﻼﻗﻴﺔﻫﻲ اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ واملﻌﺮﻓﺔ. وﺗﺆﻛﺪﻧُﻬُﺞ اﻟﻌﻼﻗﺎت
أن املﺮءﻳﻜﻮن داﺋﻤًﺎﻣﺴﺌﻮﻻً أﻣﺎم اﻵﺧﺮﻳﻦ.
املﻨﺰﻟﺔ اﻷﺧﻼﻗﻴﺔ اﻟﺘﻲﻳﺘﻤﺘﱠﻊﺑﻬﺎﻛﻴﺎنﻣﺎ؛ أيﻛﻴﻒﻳﻨﺒﻐﻲ اﻟﺘﻌﺎﻣُﻞﻣﻊ:املﻜﺎﻧﺔ اﻷﺧﻼﻗﻴﺔ
.ﻫﺬا اﻟﻜﻴﺎن
اﻟﻘُﺪرةﻋﲆ اﻟﻔﻌﻞ واﻟﺘﻔﻜري واﻟﺤُﻜﻢ واﺗﺨﺎذ اﻟﻘﺮار اﻷﺧﻼﻗﻲ،ﺑﺪﻻًﻣﻦ:اﻟﻮﻛﺎﻟﺔ اﻷﺧﻼﻗﻴﺔ
.ﻣﺠﺮد وﺟﻮدﻋﻮاﻗﺐ أﺧﻼﻗﻴﺔ
137</p>
</section>
<section id="section-15">
    <h2>ملاحظات</h2>
    <div class="page-range">Pages 139-142</div>
    <p>ﻣﻼﺣﻈﺎت
اﻟﻔﺼﻞ اﻷول: أﻳﺘﻬﺎ املﺮآةﻋﲆ اﻟﺤﺎﺋﻂ
(1) See https://www.youtube.com/watch?v=D5VN56jQMWM.
(2) See the case of Paul Zilly as told by Fry (2018, 71-72). More de-
tails in Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, “Ma-
chine Bias,” ProPublica, May 23, 2016, https://www.propublica.org/article/
machine-bias-risk-assessments-in-criminal-sentencing.
(3) For example, in 2016 a local police zone in Belgium started using
predictive policing software to predict burglaries and vehicle theft (Algo-
rithm Watch 2019, 44).
(4)
BuzzFeedVideo, “You Won’t Believe What Obama Says in this
Video!”
https://www.youtube.com/watch?v=cQ54GDm1eL0&amp;fbclid=IwA
R1oD0AlopEZa00XHo3WNcey_qNnNqTsvHN_aZsNb0d2t9cmsDbm9oCf
X8A.
اﻟﻔﺼﻞ اﻟﺜﺎﻧﻲ: اﻟﺬﻛﺎء اﻟﻔﺎﺋﻖ واﻟﻮﺣﻮش وﻧﻬﺎﻳﺔ اﻟﻌﺎﻟﻢﺑﺎﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
(1) Some talk of taming or domesticating AI, although the analogy
with wild animals is problematic, if only because in contrast to the “wild”</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
AI some imagine, animals are limited by their natural faculties and can be
trained and developed only up to some point (Turner 2019).
(2) It is often suggested that Mary Shelley must have been influenced
by her parents, who discussed politics, philosophy, and literature, but also
science, and by her partner Percy Bysshe Shelley, who was an amateur sci-
entist especially interested in electricity.
اﻟﻔﺼﻞ اﻟﺜﺎﻟﺚ:ﻛﻞﻣﺎﻟﻪﻋﻼﻗﺔﺑﺎﻟﺒﴩ
(1) Dreyfus was influenced by Edmund Husserl, Martin Heidegger, and
Maurice Merleau-Ponty.
اﻟﻔﺼﻞ اﻟﺮاﺑﻊ: أﻫﻲﺣﻘٍّﺎﻣﺠﺮد آﻻت؟
(1) A real-world case of this was the robot dog Spot who was kicked by
its developers to test it, something that met with surprisingly empathetic
responses: https://www.youtube.com/watch?v=aR5Z6AoMh6U.
اﻟﻔﺼﻞ اﻟﺨﺎﻣﺲ: اﻟﺘﻜﻨﻮﻟﻮﺟﻴﺎ
(1) See https://www.humanbrainproject.eu/en/.
(2) See, for example, the European Commission’s AI High Level Expert
Group’s (2018) definition of AI.
اﻟﻔﺼﻞ اﻟﺴﺎدس:ﻻﺗﻨﺲَ )ﻋﻠﻢ( اﻟﺒﻴﺎﻧﺎت
(1) See http://tylervigen.com/spurious-correlations.
(2) Concrete examples such as Facebook, Walmart, American Express,
Hello Barbie, and BMW are drawn from Marr (2018).
140</p>
<p>ﻣﻼﺣﻈﺎت
اﻟﻔﺼﻞ اﻟﺜﺎﻣﻦ:ﻻﻣﺴﺌﻮﻟﻴﺔُ اﻵﻻت واﻟﻘﺮاراتﻏري املُﱪرة
(1) One could ask, however, if decisions made by AIs really count as
decisions, and if so, if there is a difference in the kind of decisions we dele-
gate or should delegate to AIs. In this sense, the problem regarding respon-
sibility of or for AI raises the very question of what a decision is. The prob-
lem also connects with issues about delegation: we delegate decisions to
machines. But what does this delegation entail in terms of responsibility?
(2) Indeed, this case is more complicated since one could argue that
the delegate is then still responsible for that particular task—at least to
some extent—and it may not be clear how the responsibility is distributed
in such cases.
(3) Note that this was and is not always the case; as Turner (2019)
reminds us, there are cases of animals being punished.
اﻟﻔﺼﻞ اﻟﺘﺎﺳﻊ: اﻟﺘﺤﻴﺰ وﻣﻌﻨﻰ اﻟﺤﻴﺎة
(1) Thanks to Bill Price for the thought experiment.
اﻟﻔﺼﻞ اﻟﻌﺎﴍ: اﻟﺴﻴﺎﺳﺎت املﻘﱰﺣﺔ
(1) See: https://www.acrai.at/en/.
(2) The resolution can be found here: http://www.europarl.europa.eu/
doceo/document/TA-8-2017-0051_EN.html?redirect#title1.
(3)
See:
https://www.scu.edu/ethics-in-technology-practice/
conceptual-frameworks/.
(4) See: https://www.partnershiponai.org/.
(5) See: https://www.blog.google/technology/ai/ai-principles/.
(6) See: https://www.microsoft.com/en-us/ai/our-approach-to-ai.
(7) See: https://www.accenture.com/t20160629T012639Z_w_/us-en/
_acnmedia/PDF-24/Accenture-Universal-Principles-Data-Ethics.pdf.
141</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
(8)
See:
https://www.businessinsider.de/apple-ceo-tim-cook-on
-privacy-the-free-market-is-not-working-regulations-2018-11?r=
US&amp;IR=T.
(9) See: https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?
bill_id=201720180SB1001.
(10) See: https://www.stopkillerrobots.org/.
(11) See: https://futureoflife.org/ai-principles/.
(12) Consider people such as Batya Friedman and Helen Nissenbaum
in the United States, and later Jeroen van den Hoven and others in the
Netherlands, who have been championing the ethical design of technology
for some time.
(13) See: https://www.tuev-sued.de/company/press/press-archive/
tuv-sud-and-dfki-to-develop-tuv-for-artificial-intelligence.
اﻟﻔﺼﻞ اﻟﺤﺎديﻋﴩ: اﻟﺘﺤﺪﻳﺎت اﻟﺘﻲﺗُﻮاﺟﻪﺻﺎﻧﻌﻲ اﻟﺴﻴﺎﺳﺎت
(1) See: https://ec.europa.eu/digital-single-market/en/european-ai-
alliance.
اﻟﻔﺼﻞ اﻟﺜﺎﻧﻲﻋﴩ:ﺗﺤﺪﱢيﺗﻐريﱡ املﻨﺎخ:ﺣﻮل اﻷوﻟﻮﻳﺎت وﺣﻘﺒﺔ اﻟﺘﺄﺛري اﻟﺒﴩي
(1) See: https://hai.stanford.edu/ and https://hcai.mit.edu.
(2) See: https://sustainabledevelopment.un.org/post2015/transform
ingourworld.
(3) See: https://www.theguardian.com/science/2018/feb/07/space-
oddity-elon-musk-spacex-car-mars-falcon-heavy.
(4) See: https://cosmosmagazine.com/space/why-we-need-to-send
-artists-into-space.
142</p>
</section>
<section id="section-16">
    <h2>قراءات إضافية</h2>
    <div class="page-range">Pages 143-146</div>
    <p>ﻗﺮاءات إﺿﺎﻓﻴﺔ
Alpaydin, Ethem, 2016, Machine Learning, Cambridge, MA: MIT Press.
Arendt, Hannah, 1958, The Human Condition, Chicago: Chicago University
Press.
Aristotle, 2002, Nichomachean Ethics, Translated by Christopher Rowe,
with commentary by Sarah Broadie, Oxford: Oxford University Press.
Boddington, Paula, 2017, Towards a Code of Ethics for Artificial Intelligence,
Cham: Springer.
Boden, Margaret A., 2016, AI: Its Nature and Future, Oxford: Oxford Uni-
versity Press.
Bostrom, Nick. 2014, Superintelligence, Oxford: Oxford University Press.
Brynjolfsson, Erik, and Andrew McAfee, 2014, The Second Machine Age,
New York: W. W. Norton.
Coeckelbergh, Mark, 2012, Growing Moral Relations: Critique of Moral
Status Ascription, New York: Palgrave Macmillan.
Crutzen, Paul J., 2006, “The ‘Anthropocene,’” In Earth System Science in
the Anthropocene, edited by Eckart Ehlers and Thomas Krafft, 13–18.
Cham: Springer.</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Dignum, Virginia, Matteo Baldoni, Cristina Baroglio, Maruiyio Caon, Raja
Chatila, Louise Dennis, Gonzalo Génova, et al. 2018, “Ethics by De-
sign: Necessity or Curse?” Association for the Advancement of Arti-
ficial Intelligence. http://www.aies-conference.com/2018/contents/
papers/main/AIES_2018_paper_68.pdf.
Dreyfus, Hubert L., 1972, What Computers Can’t Do, New York: Harper &amp;
Row.
Floridi, Luciano, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice
Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo
Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, and Effy
Vayena, 2018, “AI4People—An Ethical Framework for a Good AI So-
ciety: Opportunities, Risks, Principles, and Recommendations.” Minds
and Machines 28, no. 4: 689–707.
Frankish, Keith, and William M. Ramsey, eds. 2014. The Cambridge
Handbook of Artificial Intelligence. Cambridge: Cambridge University
Press.
European Commission AI HLEG (High-Level Expert Group on Artificial In-
telligence). 2019. “Ethics Guidelines for Trustworthy AI.” April 8, 2019.
Brussels: European Commission. https://ec.europa.eu/futurium/en/
ai-alliance-consultation/guidelines#Top.
Fry, Hannah. 2018. Hello World: Being Human in the Age of Algorithms.
New York and London: W. W. Norton.
Fuchs, Christian. 2014. Digital Labour and Karl Marx. New York: Routledge.
Gunkel, David. 2012. The Machine Question. Cambridge, MA: MIT Press.
Harari, Yuval Noah. 2015. Homo Deus: A Brief History of Tomorrow. Lon-
don: Hervill Secker.
Haraway, Donna. 1991. “A Cyborg Manifesto: Science, Technology, and
Socialist-Feminism in the Late Twentieth Century.” In Simians,
144</p>
<p>ﻗﺮاءات إﺿﺎﻓﻴﺔ
Cyborgs and Women: The Reinvention of Nature, 149–181. New
York: Routledge.
IEEE Global Initiative on Ethics of Autonomous and Intelligent Sys-
tems. 2017. “Ethically Aligned Design: A Vision for Prioritizing Hu-
man Well-being with Autonomous and Intelligent Systems,” Ver-
sion 2. IEEE, 2017. http://standards.Ieee.org/develop/indconn/ec/
autonomous_systems.html.
Kelleher, John D. and Brendan Tierney. 2018. Data Science. Cambridge, MA:
MIT Press.
Nemitz, Paul Friedrich, 2018. “Constitutional Democracy and Technol-
ogy in the Age of Artificial Intelligence.” Philosophical Transactions of
the Royal Society A 376, no. 2133. https://doi.org/10.1098/rsta.2018
.0089.
Noble, David F. 1997. The Religion of Technology. New York: Penguin Books.
Reijers, Wessel, David Wright, Philip Brey, Karsten Weber, Rowena Ro-
drigues, Declan O’Sullivan, and Bert Gordijn. 2018. “Methods for Prac-
tising Ethics in Research and Innovation: A Literature Review, Critical
Analysis and Recommendation.” Science and Engineering Ethics 24, no.
5: 1437–1481.
Shelley, Mary. 2017. Frankenstein. Annotated edition. Edited by David H.
Guston, Ed Finn, and Jason Scott Robert. Cambridge, MA: MIT Press.
Turkle, Sherry. 2011. Alone Together: Why We Expect More from Technology
and Less from Each Other. New York: Basic Books.
Wallach, Wendell, and Colin Allen. 2009. Moral Machines: Teaching Robots
Right from Wrong. Oxford: Oxford University Press.
145</p>
</section>
<section id="section-17">
    <h2>المراجع</h2>
    <div class="page-range">Pages 147-160</div>
    <p>اﳌﺮاﺟﻊ
Accessnow. 2018. “Mapping Regulatory Proposals for Artificial Intelli-
gence in Europe.” https://www.accessnow.org/cms/assets/uploads/
2018/11/mapping_regulatory_proposals_for_AI_in_EU.pdf.
ACRAI (Austria Council on Robotics and Artificial Intelligence). 2018. “Die
Zukunft Österreichs mit Robotik und Künstlicher Intelligenz posi-
tive gestalten: White paper des Österreichischen Rats für Robotik und
Künstliche Intelligenz.”
“Algorithm and Blues.” 2016. Nature 537:449.
AlgorithmWatch. 2019. “Automating Society: Taking Stock of Automated
Decision Making in the EU.” A report by AlgorithmWatch in co-
operation with Bertelsmann Stiftung. January 2019. Berlin: AW Al-
gorithmWatch GmbH. http://www.algorithmwatch.org/automating-
society.
Alpaydin, Ethem. 2016. Machine Learning. Cambridge, MA: MIT Press.
Anderson, Michael and Susan Anderson. 2011. “General Introduction.” In
Machine Ethics, edited by Michael Anderson and Susan Anderson, 1–4.
Cambridge: Cambridge University Press.
Arendt, Hannah. 1958. The Human Condition. Chicago: Chicago University
Press.</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Arkoudas, Konstantine, and Selmer Bringsjord. 2014. “Philosophical Foun-
dations.” In The Cambridge Handbook of Artificial Intelligence, edited
by Keith Frankish and William M. Ramsey. Cambridge: Cambridge Uni-
versity Press.
Armstrong, Stuart. 2014. Smarter Than Us: The Rise of Machine Intelligence.
Berkeley: Machine Intelligence Research Institute.
Awad, Edmond, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Hen-
rich, Azim Shariff, Jean-François Bonnefon, and Iyad Rahwan. 2018.
“The Moral Machine Experiment.” Nature 563:59–64.
Bacon, Francis. 1964. “The Refutation of Philosophies.” In The Philosophy
of Francis Bacon, edited by Benjamin Farrington, 103–132. Chicago:
University of Chicago Press.
Boddington, Paula. 2016. “The Distinctiveness of AI Ethics, and Im-
plications for Ethical Codes.” Paper presented at the workshop
Ethics for Artificial Intelligence, July 9, 2016, IJCAI-16, New York.
https://www.cs.ox.ac.uk/efai/2016/11/02/the-distinctiveness-of-
ai-ethics-and-implications-for-ethical-codes/.
Boddington, Paula. 2017. Towards a Code of Ethics for Artificial Intelligence.
Cham: Springer.
Boden, Margaret A. 2016. AI: Its Nature and Future. Oxford: Oxford Uni-
versity Press.
Borowiec, Steven. 2016. “AlphaGo Seals 4–1 Victory Over Go Grandmaster
Lee
Sedol.”
Guardian,
March
15.
https://www.theguardian.com/
technology/2016/mar/15/googles-alphago-seals-4-1-victory-
over-grandmaster-lee-sedol.
Bostrom, Nick. 2014. Superintelligence. Oxford: Oxford University Press.
Brynjolfsson, Erik, and Andrew McAfee. 2014. The Second Machine Age.
New York: W. W. Norton.
148</p>
<p>املﺮاﺟﻊ
Bryson, Joanna. 2010. “Robots Should Be Slaves.” In Close Engagements
with Artificial Companions: Key Social, Psychological, Ethical and
Design Issues, edited by Yorick Wilks, 63–74. Amsterdam: John
Benjamins.
Bryson, Joanna. 2018. “AI &amp; Global Governance: No One Should Trust AI.”
United Nations University Centre for Policy Research. AI &amp; Global
Governance,
November
13,
2018.
https://cpr.unu.edu/ai-global-
governance-no-one-should-trust-ai.html.
Bryson, Joanna, Mihailis E. Diamantis, and Thomas D. Grant. 2017. “Of, For,
and By the People: The Legal Lacuna of Synthetic Persons.” Artificial
Intelligence &amp; Law 25, no. 3: 273–291.
Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. 2017. “Semantics
Derived Automatically from Language Corpora Contain Human-like
Biases.” Science 356:183–186.
Castelvecchi, Davide. 2016. “Can We Open the Black Box of AI?” Nature
538, no. 7623: 21–23.
CDT (Centre for Democracy &amp; Technology) 2018. “Digital Decisions.”
https://cdt.org/issue/privacy-data/digital-decisions/.
Coeckelbergh, Mark. 2010. “Moral Appearances: Emotions, Robots, and
Human Morality.” Ethics and Information Technology 12, no. 3: 235–
241.
Coeckelbergh, Mark. 2011. “You, Robot: On the Linguistic Construction of
Artificial Others.” AI &amp; Society 26, no. 1: 61–69.
Coeckelbergh, Mark. 2012. Growing Moral Relations: Critique of Moral
Status Ascription. New York: Palgrave Macmillan.
Coeckelbergh, Mark. 2013. Human Being @ Risk: Enhancement, Technology,
and the Evaluation of Vulnerability Transformations. Cham: Springer.
Coeckelbergh, Mark. 2017. New Romantic Cyborgs. Cambridge, MA: MIT
Press.
149</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Crawford, Kate, and Ryan Calo. 2016. “There Is a Blind Spot in AI Research.”
Nature 538:311–313.
Crutzen, Paul J. 2006. “The ‘Anthropocene.’” In Earth System Science in
the Anthropocene edited by Eckart Ehlers and Thomas Krafft, 13–18.
Cham: Springer.
Darling, Kate, Palash Nandy, and Cynthia Breazeal. 2015. “Empathic Con-
cern and the Effect of Stories in Human-Robot Interaction.” In 2015
24th IEEE International Symposium on Robot and Human Interactive
Communication (RO-MAN), 770–775. New York: IEEE.
Dennett, Daniel C. 1997. “Consciousness in Human and Robot Minds. In
Cognition, Computation, and Consciousness, edited by Masao Ito, Ya-
sushi Miyashita, and Edmund T. Rolls, 17–29. New York: Oxford Uni-
versity Press.
Digital Europe. 2018. “Recommendations on AI Policy: Towards a Sustain-
able and Innovation-friendly Approach.” Digitaleurope.org, November
7, 2018.
Dignum, Virginia, Matteo Baldoni, Cristina Baroglio, Maruiyio Caon, Raja
Chatila, Louise Dennis, Gonzalo Génova, et al. 2018. “Ethics by De-
sign: Necessity or Curse?” Association for the Advancement of Arti-
ficial Intelligence. http://www.aies-conference.com/2018/contents/
papers/main/AIES_2018_paper_68.pdf.
Dowd, Maureen. 2017. “Elon Musk’s Billion-Dollar Crusade to Stop the
A.I. Apocalypse.” Vanity Fair, March 26, 2017. https://www.vanityfair
.com/news/2017/03/elon-musk-billion-dollar-crusade-to-stop-
ai-space-x.
Dreyfus,
Hubert
L.
1972.
What
Computers
Can’t
Do.
New
York:
HarperCollins.
150</p>
<p>املﺮاﺟﻊ
Druga, Stefania and Randi Williams. 2017. “Kids, AI Devices, and Intelli-
gent Toys.” MIT Media Lab, June 6, 2017. https://www.media.mit.edu/
posts/kids-ai-devices/f.
European
Commission.
2018.
“Ethics
and
Data
Protection.”
http://
ec.europa.eu/research/participants/data/ref/h2020/grants_manual/
hi/ethics/h2020_hi_ethics-data-protection_en.pdf.
European Commission Directorate-General of Employment, Social Affairs
and Inclusion. 2018. “Employment and Social Developments in Europe
2018.” Luxembourg: Publications Office of the European Union. http://
ec.europa.eu/social/main.jsp?catId=738&amp;langId=en&amp;pubId=8110.
European Commission AI HLEG (High-Level Expert Group on Artificial In-
telligence). 2018. “Draft Ethics Guidelines for Trustworthy AI: Working
Document for Stakeholders.” Working document, December 18, 2018.
Brussels: European Commission. https://ec.europa.eu/digital-single-
market/en/news/draft-ethics-guidelines-trustworthy-ai.
European Commission AI HLEG (High-Level Expert Group on Artificial In-
telligence). 2019. “Ethics Guidelines for Trustworthy AI.” April 8, 2019.
Brussels: European Commission. https://ec.europa.eu/futurium/en/
ai-alliance-consultation/guidelines#Top.
EGE (European Group on Ethics in Science and New Technologies). 2018.
“Statement on Artificial Intelligence, Robotics and ‘Autonomous’ Sys-
tems.” Brussels: European Commission.
European Parliament and the Council of the European Union. 2016. “Gen-
eral Data Protection Regulation (GDPR).” https://eur-lex.europa.eu/
legal-content/EN/TXT/?uri=celex%3A32016R0679.
Executive Office of the President, National Science and Technology Council
Committee on Technology. 2016. “Preparing for the Future of Artificial
Intelligence.” Washington, DC: Office of Science and Technology Policy
(OSTP).
151</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Floridi, Luciano, Josh Cowls, Monica Beltrametti, Raja Chatila, Patrice
Chazerand, Virginia Dignum, Christoph Luetge, Robert Madelin, Ugo
Pagallo, Francesca Rossi, Burkhard Schafer, Peggy Valcke, and Effy
Vayena. 2018. “AI4People—An Ethical Framework for a Good AI So-
ciety: Opportunities, Risks, Principles, and Recommendations.” Minds
and Machines 28, no. 4: 689–707.
Floridi, Luciano, and J. W. Sanders. 2004. “On the Morality of Artificial
Agents.” Minds and Machines 14, no. 3: 349–379.
Ford, Martin. 2015. Rise of the Robots: Technology and the Threat of a
Jobless Future. New York: Basic Books.
Frankish, Keith, and William M. Ramsey. 2014. “Introduction.” In The
Cambridge Handbook of Artificial Intelligence, edited by Keith Frank-
ish and William M. Ramsey, 1–14. Cambridge: Cambridge University
Press.
Frey, Carl Benedikt, and Michael A. Osborne. 2013. “The Future of Employ-
ment: How Susceptible Are Jobs to Computerisation?” Working paper,
Oxford Martin Programme on Technology and Employment, University
of Oxford.
Fry, Hannah. 2018. Hello World: Being Human in the Age of Algorithms.
New York: W. W. Norton.
Fuchs, Christian. 2014. Digital Labour and Karl Marx. New York: Routledge.
Goebel, Randy, Ajay Chander, Katharina Holzinger, Freddy Lecue, Zeynep
Akata, Simone Stumpf, Peter Kieseberg, and Andreas Holzinger. 2018.
“Explainable AI: The New 42?” Paper presented at the CD-MAKE 2018,
Hamburg, Germany, August 2018.
Gunkel, David. 2012. The Machine Question. Cambridge, MA: MIT Press.
Gunkel, David. 2018. “The Other Question: Can and Should Robots Have
Rights?” Ethics and Information Technology 20:87–99.
152</p>
<p>املﺮاﺟﻊ
Harari, Yuval Noah. 2015. Homo Deus: A Brief History of Tomorrow. Lon-
don: Hervill Secker.
Haraway, Donna. 1991. “A Cyborg Manifesto: Science, Technology, and
Socialist-Feminism in the Late Twentieth Century.” In Simians,
Cyborgs and Women: The Reinvention of Nature, 149–181. New
York: Routledge.
Haraway, Donna. 2015. “Anthropocene, Capitalocene, Plantationocene,
Chthulucene: Making Kin.” Environmental Humanities 6:159–165.
Herweijer, Celine. 2018. “8 Ways AI Can Help Save the Planet.” World
Economic
Forum,
January
24,
2018.
https://www.weforum.org/
agenda/2018/01/8-ways-ai-can-help-save-the-planet/.
House of Commons. 2018. “Algorithms in Decision-Making.” Fourth Re-
port of Session 2017-19, HC351. May 23, 2018.
ICDPPC (International Conference of Data Protection and Privacy Commis-
sioners). 2018. “Declaration on Ethics and Data Protection in Artifi-
cial Intelligence.” https://icdppc.org/wp-content/uploads/2018/10/
20180922_ICDPPC-40th_AI-Declaration_ADOPTED.pdf.
IEEE Global Initiative on Ethics of Autonomous and Intelligent Sys-
tems. 2017. “Ethically Aligned Design: A Vision for Prioritizing Hu-
man Well-Being with Autonomous and Intelligent Systems,” Version
2. IEEE. http://standards.Ieee.org/develop/indconn/ec/autonomous_
systems.html.
Ihde, Don. 1990. Technology and the Lifeworld: From Garden to Earth.
Bloomington: Indiana University Press.
Jansen, Philip, Stearns Broadhead, Rowena Rodrigues, David Wright, Philp
Brey, Alice Fox, and Ning Wang. 2018. “State-of-the-Art Review.”
Draft of the D4.1 deliverable submitted to the European Commission
on April 13, 2018. A report for The SIENNA Project, an EU H2020 re-
search and innovation program under grant agreement no. 741716.
153</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Johnson, Deborah G. 2006. “Computer Systems: Moral Entities but not
Moral Agents.” Ethics and Information Technology 8, no. 4: 195–204.
Kant, Immanuel. 1997. Lectures on Ethics. Edited by Peter Heath and J. B.
Schneewind. Translated by Peter Heath. Cambridge: Cambridge Uni-
versity Press.
Kelleher, John D., and Brendan Tierney. 2018. Data Science. Cambridge,
MA: MIT Press.
Kharpal, Arjun. 2017. “Stephen Hawking Says A.I. Could Be ‘Worst Event
in the History of Our Civilization.’” CNBC. November 6, 2017.
https://www.cnbc.com/2017/11/06/stephen-hawking-ai-could-
be-worst-event-in-civilization.html.
Kubrick, Stanley, dir. 1968. 2001: A Space Odyssey. Beverly Hills, CA:
Metro-Goldwyn-Mayer.
Kurzweil, Ray. 2005. The Singularity Is Near. New York: Viking.
Leta Jones, Meg. 2018. “Silencing Bad Bots: Global, Legal and Political Ques-
tions for Mean Machine Communication.” Communication Law and
Policy 23, no. 2: 159–195.
Lin, Patrick, Keith Abney, and George Bekey. 2011. “Robot Ethics: Mapping
the Issues for a Mechanized World.” Artificial Intelligence 175:942–
949.
MacIntyre, Lee C. 2018. Post-Truth. Cambridge, MA: MIT Press.
Marcuse, Herbert. 1991. One-Dimensional Man. Boston: Beacon Press.
Marr, Bernard. 2018. “27 Incredible Examples of AI and Machine Learn-
ing in Practice.” Forbes, April 30. https://www.forbes.com/sites/
bernardmarr/2018/04/30/27-incredible-examples-of-ai-and-ma
chine-learning-in-practice/#6b37edf27502.
McAfee, Andrew, and Erik Brynjolfsson. 2017. Machine, Platform, Crowd:
Harnessing Our Digital Future. New York: W. W. Norton.
154</p>
<p>املﺮاﺟﻊ
Miller, Tim. 2018. “Explanation in Artificial Intelligence: Insights from the
Social Sciences.” arXiv, August 15. https://arxiv.org/pdf/1706.07269
.pdf.
Mouffe, Chantal. 2013. Agonistics: Thinking the World Politically. London:
Verso.
Nemitz, Paul Friedrich, 2018. “Constitutional Democracy and Technol-
ogy in the Age of Artificial Intelligence.” Philosophical Transactions of
the Royal Society A 376, no. 2133. https://doi.org/10.1098/rsta.2018
.0089.
Noble, David F. 1997. The Religion of Technology. New York: Penguin Books.
Reijers, Wessel, David Wright, Philip Brey, Karsten Weber, Rowena Ro-
drigues, Declan O’ Sullivan, and Bert Gordijn. 2018. “Methods for Prac-
tising Ethics in Research and Innovation: A Literature Review, Critical
Analysis and Recommendation.” Science and Engineering Ethics 24, no.
5: 1437–1481.
Royal Society, the. 2018. “Portrayals and Perceptions of AI and Why They
Matter.” December 11, 2018. https://royalsociety.org/topics-policy/
projects/ai-narratives/.
Rushkoff, Douglas. 2018. “Survival of the Richest.” Medium, July 5.
https://medium.com/s/futurehuman/survival-of-the-richest-
9ef6cddd0cc1.
Samek, Wojciech, Thomas Wiegand, and Klaus-Robert Müller. 2017. “Ex-
plainable Artificial Intelligence: Understanding, Visualizing and In-
terpreting Deep Learning Models.” https://arxiv.org/pdf/1708.08296
.pdf.
Schwab,
Katharine.
2018.
“The
Exploitation,
Injustice,
and
Waste
Powering Our AI.” Fast Company. September 18, 2018. https://
www.fastcompany.com/90237802/the-exploitation-injustice-and-
waste-powering-our-ai.
155</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Seseri, Rudina. 2018. “The Problem with ‘Explainable AI.’” Tech Crunch.
June 14, 2018. https://techcrunch.com/2018/06/14/the-problem-
with-explainable-ai/?guccounter=1.
Searle, John. R. 1980. “Minds, Brains, and Programs.” Behavioral and Brain
Sciences 3, no. 3: 417–457.
Shanahan, Murray. 2015. The Technological Singularity. Cambridge, MA:
The MIT Press.
Siau, Keng, and Weiyu Wang. 2018. “Building Trust in Artificial Intelligence,
Machine Learning, and Robotics.” Cutter Business Technology Journal
32, no. 2: 46–53.
State Council of China. 2017. “New Generation Artificial Intelligence De-
velopment Plan.” Translated by Flora Sapio, Weiming Chen, and Adrian
Lo.
https://flia.org/notice-state-council-issuing-new-generation-
artificial-intelligence-development-plan/.
Stoica, Ion. 2017. “A Berkeley View of Systems Challenges for AI.” Techni-
cal Report No. UCB/EECS-2017-159. http://www2.eecs.berkeley.edu/
Pubs/TechRpts/2017/EECS-2017.
Sullins, John. 2006. “When Is a Robot a Moral Agent?” International Review
of Information Ethics 6: 23–30.
Surur. 2017. “Microsoft Aims to Lie to Their AI to Reduce Sexist Bias.”
August 25, 2017. https://mspoweruser.com/microsoft-aims-lie-ai-
reduce-sexist-bias/.
Suzuki, Yutaka, Lisa Galli, Ayaka Ikeda, Shoji Itakura, and Michiteru Ki-
tazaki. 2015. “Measuring Empathy for Human and Robot Hand Pain
Using Electroencephalography.” Scientific Reports 5, article number
15924. https://www.nature.com/articles/srep15924.
Tegmark, Max. 2017. Life 3.0: Being Human in the Age of Artificial
Intelligence. Allen Lane/Penguin Books.
156</p>
<p>املﺮاﺟﻊ
Turkle, Sherry. 2011. Alone Together: Why We Expect More from Technology
and Less from Each Other. New York: Basic Books.
Turner, Jacob. 2019. Robot Rules: Regulating Artificial Intelligence. Cham:
Palgrave Macmillan.
Université de Montréal. 2017. “Montréal Declaration Responsible AI.”
https://www.montrealdeclaration-responsibleai.com/the-declara
tion.
Vallor, Shannon. 2016. Technology and the Virtues. New York: Oxford Uni-
versity Press.
Vigen, Tyler. 2015. Spurious Correlations. New York: Hachette Books.
Villani, Cédric. 2018. For a Meaningful Artificial Intelligence: Towards a
French and European Strategy. Composition of a parliamentary mis-
sion from September 8, 2017, to March 8, 2018, and assigned by the
Prime Minister of France, Èdouard Philippe.
Von Schomberg, René, ed. 2011. “Towards Responsible Research and Inno-
vation in the Information and Communication Technologies and Se-
curity Technologies Fields.” A report from the European Commission
Services. Luxembourg: Publications Office of the European Union.
Vu, Mai-Anh T., Tülay Adalı, Demba Ba, György Buzsáki, David Carlson,
Katherine Heller, et al. 2018. “A Shared Vision for Machine Learning in
Neuroscience.” Journal of Neuroscience 38, no. 7: 1601–607.
Wachter, Sandra, Brent Mittelstadt, and Luciano Floridi. 2017. “Why a Right
to Explanation of Automated Decision-Making Does Not Exist in the
General Data Protection Regulation.” International Data Privacy Law,
2017. http://dx.doi.org/10.2139/ssrn.2903469.
Wallach, Wendell and Colin Allen. 2009. Moral Machines: Teaching Robots
Right from Wrong. Oxford: Oxford University Press.
Weld, Daniel S. and Gagan Bansal. 2018. “The Challenge of Crafting Intel-
ligible Intelligence.” https://arxiv.org/pdf/1803.04263.pdf.
157</p>
<p>أﺧﻼﻗﻴﺎت اﻟﺬﻛﺎء اﻻﺻﻄﻨﺎﻋﻲ
Winfield, Alan F.T. and Marina Jirotka. 2017. “The Case for an Ethical Black
Box.” In Towards Autonomous Robotic Systems, edited by Yang Gao,
Saber Fallah, Yaochu Jin, and Constantina Lekakou (proceedings of
TAROS 2017, Guildford, UK, July 2017), 262–273. Cham: Springer.
Winikoff,
Michael.
2018.
“Towards
Trusting
Autonomous
Systems.”
In
Engineering
Multi-Agent
Systems,
edited
by
Amal
El
Fallah
Seghrouchni, Alessandro Ricci, and Son Trao, 3–20. Cham: Springer.
Yampolskiy, Roman V. 2013. “Artificial Intelligence Safety Engineering:
Why Machine Ethics Is a Wrong Approach.” In Philosophy and Theory
of Artificial Intelligence edited by Vincent C. Müller, 289–296. Cham:
Springer.
Yeung, Karen. 2018. “A Study of the Implications of Advanced Digital
Technologies (Including AI Systems) for the Concept of Responsibil-
ity within a Human Rights Framework.” A study commissioned for the
Council of Europe Committee of experts on human rights dimensions
of automated data processing and different forms of artificial intelli-
gence. MSI-AUT (2018)05.
Zimmerman, Jess. 2015. “What If the Mega-Rich Just Want Rocket Ships
to Escape the Earth They Destroy?” Guardian, September 16, 2015.
https://www.theguardian.com/commentisfree/2015/sep/16/mega-
rich-rocket-ships-escape-earth.
Zou, James, and Londa Schiebinger. 2018. “Design AI So That It’s Fair.”
Nature 559:324–326.
158</p>
</section>
        </main>
    </div>
    <footer>
    <p>Generated by KitabiAI • 2025-10-23</p>
</footer>
</body>
</html>